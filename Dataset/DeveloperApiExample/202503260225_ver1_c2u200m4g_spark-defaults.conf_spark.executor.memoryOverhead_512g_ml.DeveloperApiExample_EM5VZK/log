2025-03-26 02:25:54,786 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NameNode STARTUP_MSG:   host = master/172.20.1.10 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:25:54,791 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:25:54,862 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2025-03-26 02:25:54,951 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:25:55,016 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2025-03-26 02:25:55,016 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:25:55,022 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://master:9000
2025-03-26 02:25:55,023 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use master:9000 to access this namenode/service.
2025-03-26 02:25:55,150 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:25:55,158 INFO org.apache.hadoop.hdfs.DFSUtil: Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-03-26 02:25:55,160 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2025-03-26 02:25:55,167 INFO org.eclipse.jetty.util.log: Logging initialized @668ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:25:55,221 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:25:55,226 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2025-03-26 02:25:55,231 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:25:55,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2025-03-26 02:25:55,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:25:55,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:25:55,234 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2025-03-26 02:25:55,234 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-03-26 02:25:55,234 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-03-26 02:25:55,253 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2025-03-26 02:25:55,257 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2025-03-26 02:25:55,258 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:25:55,271 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:25:55,271 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:25:55,272 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:25:55,284 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:25:55,286 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@79207381{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:25:55,286 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b4c50bc{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:25:55,324 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@c7045b9{hdfs,/,file:///hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/hdfs}
2025-03-26 02:25:55,329 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@17503f6b{HTTP/1.1, (http/1.1)}{0.0.0.0:9870}
2025-03-26 02:25:55,329 INFO org.eclipse.jetty.server.Server: Started @830ms
2025-03-26 02:25:55,496 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-03-26 02:25:55,496 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-03-26 02:25:55,527 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2025-03-26 02:25:55,550 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2025-03-26 02:25:55,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2025-03-26 02:25:55,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2025-03-26 02:25:55,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2025-03-26 02:25:55,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)
2025-03-26 02:25:55,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled    = true
2025-03-26 02:25:55,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isStoragePolicyEnabled = true
2025-03-26 02:25:55,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup             = supergroup
2025-03-26 02:25:55,570 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:25:55,574 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.11" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:25:55,574 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.12" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:25:55,574 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.13" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:25:55,575 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-26 02:25:55,575 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-26 02:25:55,577 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2025 Mar 26 02:25:55
2025-03-26 02:25:55,577 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-26 02:25:55,578 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2025-03-26 02:25:55,578 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:25:55,579 INFO org.apache.hadoop.util.GSet: 2.0% max memory 910.5 MB = 18.2 MB
2025-03-26 02:25:55,579 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2025-03-26 02:25:55,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Storage policy satisfier is disabled
2025-03-26 02:25:55,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2025-03-26 02:25:55,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2025-03-26 02:25:55,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2025-03-26 02:25:55,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2025-03-26 02:25:55,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2025-03-26 02:25:55,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2025-03-26 02:25:55,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2025-03-26 02:25:55,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2025-03-26 02:25:55,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2025-03-26 02:25:55,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2025-03-26 02:25:55,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
2025-03-26 02:25:55,608 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2025-03-26 02:25:55,608 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2025-03-26 02:25:55,608 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2025-03-26 02:25:55,609 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2025-03-26 02:25:55,618 INFO org.apache.hadoop.util.GSet: 1.0% max memory 910.5 MB = 9.1 MB
2025-03-26 02:25:55,618 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2025-03-26 02:25:55,618 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:25:55,618 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2025-03-26 02:25:55,620 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? true
2025-03-26 02:25:55,620 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2025-03-26 02:25:55,620 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2025-03-26 02:25:55,620 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2025-03-26 02:25:55,623 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-03-26 02:25:55,624 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2025-03-26 02:25:55,628 INFO org.apache.hadoop.util.GSet: 0.25% max memory 910.5 MB = 2.3 MB
2025-03-26 02:25:55,628 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2025-03-26 02:25:55,628 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:25:55,628 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2025-03-26 02:25:55,647 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2025-03-26 02:25:55,647 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-26 02:25:55,647 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-26 02:25:55,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2025-03-26 02:25:55,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2025-03-26 02:25:55,650 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 910.5 MB = 279.7 KB
2025-03-26 02:25:55,650 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2025-03-26 02:25:55,650 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:25:55,650 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2025-03-26 02:25:55,661 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/name/in_use.lock acquired by nodename 262@master
2025-03-26 02:25:55,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2025-03-26 02:25:55,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2025-03-26 02:25:55,680 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/tmp/dfs/name/current
2025-03-26 02:25:55,725 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2025-03-26 02:25:55,730 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
2025-03-26 02:25:55,734 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-26 02:25:55,738 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/tmp/dfs/name/current/fsimage_0000000000000000000
2025-03-26 02:25:55,738 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2025-03-26 02:25:55,741 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2025-03-26 02:25:55,742 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2025-03-26 02:25:55,806 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 155 msecs
2025-03-26 02:25:55,806 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2025-03-26 02:25:55,897 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Enable NameNode state context:false
2025-03-26 02:25:55,897 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master:9000
2025-03-26 02:25:55,903 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:25:55,911 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2025-03-26 02:25:56,018 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2025-03-26 02:25:56,027 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2025-03-26 02:25:56,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor: Initialized the Default Decommission and Maintenance monitor
2025-03-26 02:25:56,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Start MarkedDeleteBlockScrubber thread
2025-03-26 02:25:56,034 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2025-03-26 02:25:56,034 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2025-03-26 02:25:56,034 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2025-03-26 02:25:56,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2025-03-26 02:25:56,059 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2025-03-26 02:25:56,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2025-03-26 02:25:56,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2025-03-26 02:25:56,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2025-03-26 02:25:56,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2025-03-26 02:25:56,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2025-03-26 02:25:56,068 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:25:56,069 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2025-03-26 02:25:56,075 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master/172.20.1.10:9000
2025-03-26 02:25:56,077 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 12 thread(s)
2025-03-26 02:25:56,077 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2025-03-26 02:25:56,082 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds name space=1 storage space=0 storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2025-03-26 02:25:56,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2025-03-26 02:25:57,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave2/172.20.1.13 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:25:57,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:25:57,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave0/172.20.1.11 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:25:57,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:25:57,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave1/172.20.1.12 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:25:57,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:25:57,366 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:25:57,400 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:25:57,427 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:25:57,437 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:25:57,472 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:25:57,487 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:25:57,487 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:25:57,501 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:25:57,517 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:25:57,517 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:25:57,598 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:25:57,598 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:25:57,616 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:25:57,624 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:25:57,627 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:25:57,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2025-03-26 02:25:57,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:25:57,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:25:57,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:25:57,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:25:57,670 INFO org.eclipse.jetty.util.log: Logging initialized @875ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:25:57,676 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:25:57,684 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:25:57,687 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:25:57,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2025-03-26 02:25:57,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:25:57,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:25:57,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:25:57,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:25:57,723 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:25:57,727 INFO org.eclipse.jetty.util.log: Logging initialized @911ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:25:57,732 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:25:57,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave0
2025-03-26 02:25:57,736 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:25:57,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:25:57,741 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:25:57,745 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:25:57,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:25:57,750 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:25:57,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:25:57,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:25:57,751 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:25:57,751 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:25:57,751 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:25:57,779 INFO org.eclipse.jetty.util.log: Logging initialized @986ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:25:57,794 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:25:57,800 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:25:57,805 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:25:57,807 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:25:57,807 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:25:57,807 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:25:57,809 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40855
2025-03-26 02:25:57,810 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:25:57,825 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:25:57,825 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:25:57,826 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:25:57,834 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2a3888c1{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:25:57,834 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68f1b17f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:25:57,859 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:25:57,867 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:25:57,868 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35339
2025-03-26 02:25:57,869 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:25:57,872 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:25:57,874 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:25:57,874 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:25:57,874 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:25:57,878 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@49964d75{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:25:57,884 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:25:57,884 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:25:57,885 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@63eef88a{HTTP/1.1, (http/1.1)}{localhost:40855}
2025-03-26 02:25:57,885 INFO org.eclipse.jetty.server.Server: Started @1091ms
2025-03-26 02:25:57,885 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:25:57,895 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2a3888c1{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:25:57,896 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68f1b17f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:25:57,926 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:25:57,933 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 37473
2025-03-26 02:25:57,934 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:25:57,943 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@49964d75{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:25:57,949 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@63eef88a{HTTP/1.1, (http/1.1)}{localhost:35339}
2025-03-26 02:25:57,949 INFO org.eclipse.jetty.server.Server: Started @1134ms
2025-03-26 02:25:57,974 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:25:57,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:25:57,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:25:57,980 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:25:57,980 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:25:57,981 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:25:57,985 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:25:57,989 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@14fa86ae{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:25:57,989 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6c372fe6{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:25:57,994 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:25:58,012 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:25:58,026 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@42b02722{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:25:58,032 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:25:58,032 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@3370f42{HTTP/1.1, (http/1.1)}{localhost:37473}
2025-03-26 02:25:58,032 INFO org.eclipse.jetty.server.Server: Started @1239ms
2025-03-26 02:25:58,045 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:25:58,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:25:58,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:25:58,059 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:25:58,074 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:25:58,078 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:25:58,088 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:25:58,133 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:25:58,135 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:25:58,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:25:58,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:25:58,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:25:58,168 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:25:58,185 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:25:58,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:25:58,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:25:58,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:25:58,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000 starting to offer service
2025-03-26 02:25:58,222 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:25:58,227 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:25:58,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:25:58,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:25:58,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000 starting to offer service
2025-03-26 02:25:58,266 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:25:58,275 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:25:58,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:25:58,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:25:58,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:25:58,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000 starting to offer service
2025-03-26 02:25:58,363 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:25:58,363 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:25:58,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000
2025-03-26 02:25:58,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000
2025-03-26 02:25:58,404 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:25:58,404 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:25:58,408 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 95@slave1
2025-03-26 02:25:58,409 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 93@slave2
2025-03-26 02:25:58,409 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 1390501960. Formatting...
2025-03-26 02:25:58,410 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-62d616fc-2cc5-4efd-9061-3793feb2fa02 for directory /data/tmp/dfs/data
2025-03-26 02:25:58,410 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 1390501960. Formatting...
2025-03-26 02:25:58,411 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-fcac5ae1-53ce-466e-8c5b-23ad1ebb6b0d for directory /data/tmp/dfs/data
2025-03-26 02:25:58,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000
2025-03-26 02:25:58,438 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,438 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,439 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,439 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1623173709-172.20.1.10-1742955953500 is not formatted. Formatting ...
2025-03-26 02:25:58,439 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,440 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1623173709-172.20.1.10-1742955953500 is not formatted. Formatting ...
2025-03-26 02:25:58,440 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1623173709-172.20.1.10-1742955953500 directory /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500/current
2025-03-26 02:25:58,440 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:25:58,441 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1623173709-172.20.1.10-1742955953500 directory /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500/current
2025-03-26 02:25:58,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1390501960;bpid=BP-1623173709-172.20.1.10-1742955953500;lv=-57;nsInfo=lv=-66;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500;bpid=BP-1623173709-172.20.1.10-1742955953500;dnuuid=null
2025-03-26 02:25:58,444 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 97@slave0
2025-03-26 02:25:58,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 22bd61df-69f7-43b2-b990-c531a31b5f9e
2025-03-26 02:25:58,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1390501960;bpid=BP-1623173709-172.20.1.10-1742955953500;lv=-57;nsInfo=lv=-66;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500;bpid=BP-1623173709-172.20.1.10-1742955953500;dnuuid=null
2025-03-26 02:25:58,445 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 1390501960. Formatting...
2025-03-26 02:25:58,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID e739152d-7034-4d09-8901-eb5c4e443829
2025-03-26 02:25:58,446 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-4a17b5a3-52d0-44dc-b1d3-bf9bfe853de9 for directory /data/tmp/dfs/data
2025-03-26 02:25:58,454 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:25:58,458 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:25:58,470 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,470 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,471 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1623173709-172.20.1.10-1742955953500 is not formatted. Formatting ...
2025-03-26 02:25:58,471 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1623173709-172.20.1.10-1742955953500 directory /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500/current
2025-03-26 02:25:58,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1390501960;bpid=BP-1623173709-172.20.1.10-1742955953500;lv=-57;nsInfo=lv=-66;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500;bpid=BP-1623173709-172.20.1.10-1742955953500;dnuuid=null
2025-03-26 02:25:58,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 3bda9607-08c1-4368-b60c-1744aad33afb
2025-03-26 02:25:58,488 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:25:58,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-62d616fc-2cc5-4efd-9061-3793feb2fa02
2025-03-26 02:25:58,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:25:58,530 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:25:58,533 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-fcac5ae1-53ce-466e-8c5b-23ad1ebb6b0d
2025-03-26 02:25:58,534 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:25:58,534 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:25:58,537 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:25:58,539 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:25:58,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data...
2025-03-26 02:25:58,551 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500/current, will proceed with Du for space computation calculation,
2025-03-26 02:25:58,557 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-4a17b5a3-52d0-44dc-b1d3-bf9bfe853de9
2025-03-26 02:25:58,557 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:25:58,559 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data...
2025-03-26 02:25:58,562 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:25:58,567 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:25:58,567 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500/current, will proceed with Du for space computation calculation,
2025-03-26 02:25:58,576 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,576 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1623173709-172.20.1.10-1742955953500 on /data/tmp/dfs/data: 31ms
2025-03-26 02:25:58,577 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data...
2025-03-26 02:25:58,577 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1623173709-172.20.1.10-1742955953500: 32ms
2025-03-26 02:25:58,578 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500/current/replicas doesn't exist
2025-03-26 02:25:58,578 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data...
2025-03-26 02:25:58,583 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:25:58,583 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data: 4ms
2025-03-26 02:25:58,583 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1623173709-172.20.1.10-1742955953500: 5ms
2025-03-26 02:25:58,586 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500/current, will proceed with Du for space computation calculation,
2025-03-26 02:25:58,594 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1623173709-172.20.1.10-1742955953500 on /data/tmp/dfs/data: 35ms
2025-03-26 02:25:58,594 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1623173709-172.20.1.10-1742955953500: 52ms
2025-03-26 02:25:58,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data...
2025-03-26 02:25:58,596 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500/current/replicas doesn't exist
2025-03-26 02:25:58,598 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:25:58,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data: 2ms
2025-03-26 02:25:58,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1623173709-172.20.1.10-1742955953500: 3ms
2025-03-26 02:25:58,609 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:25:58,612 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data
2025-03-26 02:25:58,614 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-fcac5ae1-53ce-466e-8c5b-23ad1ebb6b0d): finished scanning block pool BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,615 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 20833811ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:25:58,615 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:25:58,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623173709-172.20.1.10-1742955953500 (Datanode Uuid e739152d-7034-4d09-8901-eb5c4e443829) service to master/172.20.1.10:9000 beginning handshake with NN
2025-03-26 02:25:58,621 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-fcac5ae1-53ce-466e-8c5b-23ad1ebb6b0d): no suitable block pools found to scan.  Waiting 1814399991 ms.
2025-03-26 02:25:58,622 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:25:58,625 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data
2025-03-26 02:25:58,627 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-62d616fc-2cc5-4efd-9061-3793feb2fa02): finished scanning block pool BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,630 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1623173709-172.20.1.10-1742955953500 on /data/tmp/dfs/data: 54ms
2025-03-26 02:25:58,631 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1623173709-172.20.1.10-1742955953500: 54ms
2025-03-26 02:25:58,632 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1623173709-172.20.1.10-1742955953500/current/replicas doesn't exist
2025-03-26 02:25:58,632 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data...
2025-03-26 02:25:58,633 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data: 2ms
2025-03-26 02:25:58,634 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:25:58,634 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1623173709-172.20.1.10-1742955953500: 2ms
2025-03-26 02:25:58,639 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:25:58,640 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 8442992ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:25:58,643 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-62d616fc-2cc5-4efd-9061-3793feb2fa02): no suitable block pools found to scan.  Waiting 1814399982 ms.
2025-03-26 02:25:58,648 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:25:58,651 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1623173709-172.20.1.10-1742955953500 on volume /data/tmp/dfs/data
2025-03-26 02:25:58,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623173709-172.20.1.10-1742955953500 (Datanode Uuid 22bd61df-69f7-43b2-b990-c531a31b5f9e) service to master/172.20.1.10:9000 beginning handshake with NN
2025-03-26 02:25:58,653 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-4a17b5a3-52d0-44dc-b1d3-bf9bfe853de9): finished scanning block pool BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,667 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:25:58,668 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 19116807ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:25:58,669 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-4a17b5a3-52d0-44dc-b1d3-bf9bfe853de9): no suitable block pools found to scan.  Waiting 1814399982 ms.
2025-03-26 02:25:58,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623173709-172.20.1.10-1742955953500 (Datanode Uuid 3bda9607-08c1-4368-b60c-1744aad33afb) service to master/172.20.1.10:9000 beginning handshake with NN
2025-03-26 02:25:58,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) storage e739152d-7034-4d09-8901-eb5c4e443829
2025-03-26 02:25:58,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e739152d-7034-4d09-8901-eb5c4e443829 (172.20.1.13:9866).
2025-03-26 02:25:58,756 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.13:9866
2025-03-26 02:25:58,758 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) storage 22bd61df-69f7-43b2-b990-c531a31b5f9e
2025-03-26 02:25:58,758 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 22bd61df-69f7-43b2-b990-c531a31b5f9e (172.20.1.12:9866).
2025-03-26 02:25:58,758 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.12:9866
2025-03-26 02:25:58,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623173709-172.20.1.10-1742955953500 (Datanode Uuid e739152d-7034-4d09-8901-eb5c4e443829) service to master/172.20.1.10:9000 successfully registered with NN
2025-03-26 02:25:58,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.10:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:25:58,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623173709-172.20.1.10-1742955953500 (Datanode Uuid 22bd61df-69f7-43b2-b990-c531a31b5f9e) service to master/172.20.1.10:9000 successfully registered with NN
2025-03-26 02:25:58,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.10:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:25:58,790 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.11:9866, datanodeUuid=3bda9607-08c1-4368-b60c-1744aad33afb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) storage 3bda9607-08c1-4368-b60c-1744aad33afb
2025-03-26 02:25:58,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 3bda9607-08c1-4368-b60c-1744aad33afb (172.20.1.11:9866).
2025-03-26 02:25:58,790 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.11:9866
2025-03-26 02:25:58,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623173709-172.20.1.10-1742955953500 (Datanode Uuid 3bda9607-08c1-4368-b60c-1744aad33afb) service to master/172.20.1.10:9000 successfully registered with NN
2025-03-26 02:25:58,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.10:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:25:58,797 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-62d616fc-2cc5-4efd-9061-3793feb2fa02 for DN 172.20.1.12:9866
2025-03-26 02:25:58,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fcac5ae1-53ce-466e-8c5b-23ad1ebb6b0d for DN 172.20.1.13:9866
2025-03-26 02:25:58,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-4a17b5a3-52d0-44dc-b1d3-bf9bfe853de9 for DN 172.20.1.11:9866
2025-03-26 02:25:58,821 INFO BlockStateChange: BLOCK* processReport 0x9073295dda2045ac with lease ID 0x3da651082c35c384: Processing first storage report for DS-62d616fc-2cc5-4efd-9061-3793feb2fa02 from datanode DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500)
2025-03-26 02:25:58,822 INFO BlockStateChange: BLOCK* processReport 0x9073295dda2045ac with lease ID 0x3da651082c35c384: from storage DS-62d616fc-2cc5-4efd-9061-3793feb2fa02 node DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-26 02:25:58,826 INFO BlockStateChange: BLOCK* processReport 0x624df1154cbacd3d with lease ID 0x3da651082c35c386: Processing first storage report for DS-4a17b5a3-52d0-44dc-b1d3-bf9bfe853de9 from datanode DatanodeRegistration(172.20.1.11:9866, datanodeUuid=3bda9607-08c1-4368-b60c-1744aad33afb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500)
2025-03-26 02:25:58,826 INFO BlockStateChange: BLOCK* processReport 0x624df1154cbacd3d with lease ID 0x3da651082c35c386: from storage DS-4a17b5a3-52d0-44dc-b1d3-bf9bfe853de9 node DatanodeRegistration(172.20.1.11:9866, datanodeUuid=3bda9607-08c1-4368-b60c-1744aad33afb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-26 02:25:58,832 INFO BlockStateChange: BLOCK* processReport 0x6fab2eb8802ed2e6 with lease ID 0x3da651082c35c385: Processing first storage report for DS-fcac5ae1-53ce-466e-8c5b-23ad1ebb6b0d from datanode DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500)
2025-03-26 02:25:58,832 INFO BlockStateChange: BLOCK* processReport 0x6fab2eb8802ed2e6 with lease ID 0x3da651082c35c385: from storage DS-fcac5ae1-53ce-466e-8c5b-23ad1ebb6b0d node DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-26 02:25:58,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x624df1154cbacd3d with lease ID 0x3da651082c35c386 to namenode: master/172.20.1.10:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msecs to generate and 20 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:25:58,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x9073295dda2045ac with lease ID 0x3da651082c35c384 to namenode: master/172.20.1.10:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msecs to generate and 26 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:25:58,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:58,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x6fab2eb8802ed2e6 with lease ID 0x3da651082c35c385 to namenode: master/172.20.1.10:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msecs to generate and 26 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:25:58,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1623173709-172.20.1.10-1742955953500
2025-03-26 02:25:59,909 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting SecondaryNameNode STARTUP_MSG:   host = master/172.20.1.10 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:25:59,913 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:00,186 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:00,234 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:00,234 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2025-03-26 02:26:00,500 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2025-03-26 02:26:00,510 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/namesecondary/in_use.lock acquired by nodename 469@master
2025-03-26 02:26:00,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2025-03-26 02:26:00,530 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2025-03-26 02:26:00,530 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2025-03-26 02:26:00,530 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2025-03-26 02:26:00,530 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)
2025-03-26 02:26:00,530 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled    = true
2025-03-26 02:26:00,530 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isStoragePolicyEnabled = true
2025-03-26 02:26:00,530 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup             = supergroup
2025-03-26 02:26:00,552 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:26:00,555 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.11" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:00,555 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.12" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:00,555 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.13" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:00,558 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-26 02:26:00,558 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-26 02:26:00,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2025 Mar 26 02:26:00
2025-03-26 02:26:00,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-26 02:26:00,561 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2025-03-26 02:26:00,561 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:26:00,562 INFO org.apache.hadoop.util.GSet: 2.0% max memory 910.5 MB = 18.2 MB
2025-03-26 02:26:00,562 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2025-03-26 02:26:00,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Storage policy satisfier is disabled
2025-03-26 02:26:00,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2025-03-26 02:26:00,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2025-03-26 02:26:00,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2025-03-26 02:26:00,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2025-03-26 02:26:00,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2025-03-26 02:26:00,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2025-03-26 02:26:00,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2025-03-26 02:26:00,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2025-03-26 02:26:00,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2025-03-26 02:26:00,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2025-03-26 02:26:00,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
2025-03-26 02:26:00,619 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2025-03-26 02:26:00,619 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2025-03-26 02:26:00,620 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2025-03-26 02:26:00,620 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2025-03-26 02:26:00,628 INFO org.apache.hadoop.util.GSet: 1.0% max memory 910.5 MB = 9.1 MB
2025-03-26 02:26:00,628 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2025-03-26 02:26:00,628 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:26:00,628 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2025-03-26 02:26:00,629 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? true
2025-03-26 02:26:00,629 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2025-03-26 02:26:00,629 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2025-03-26 02:26:00,629 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2025-03-26 02:26:00,632 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-03-26 02:26:00,633 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2025-03-26 02:26:00,636 INFO org.apache.hadoop.util.GSet: 0.25% max memory 910.5 MB = 2.3 MB
2025-03-26 02:26:00,636 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2025-03-26 02:26:00,636 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:26:00,636 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2025-03-26 02:26:00,641 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2025-03-26 02:26:00,641 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-26 02:26:00,641 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-26 02:26:00,651 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2025-03-26 02:26:00,651 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2025-03-26 02:26:00,652 INFO org.apache.hadoop.hdfs.DFSUtil: Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-03-26 02:26:00,658 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:9868
2025-03-26 02:26:00,673 INFO org.eclipse.jetty.util.log: Logging initialized @1080ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:00,730 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:00,732 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2025-03-26 02:26:00,737 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:00,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:00,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2025-03-26 02:26:00,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:00,739 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context secondary
2025-03-26 02:26:00,740 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-03-26 02:26:00,740 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-03-26 02:26:00,760 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9868
2025-03-26 02:26:00,760 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:00,777 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:00,777 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:00,778 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:26:00,789 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:00,790 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d9b7a8a{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:00,791 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b73be9f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:26:00,824 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@62e6b5c8{secondary,/,file:///hadoop/share/hadoop/hdfs/webapps/secondary/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/secondary}
2025-03-26 02:26:00,827 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2025-03-26 02:26:00,827 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6622fc65{HTTP/1.1, (http/1.1)}{0.0.0.0:9868}
2025-03-26 02:26:00,827 INFO org.eclipse.jetty.server.Server: Started @1235ms
2025-03-26 02:26:03,477 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting ResourceManager STARTUP_MSG:   host = master/172.20.1.10 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:03,482 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:03,726 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMInfo MBean
2025-03-26 02:26:03,730 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/hadoop/etc/hadoop/core-site.xml
2025-03-26 02:26:03,764 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:26:03,765 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:26:03,788 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/hadoop/etc/hadoop/yarn-site.xml
2025-03-26 02:26:03,792 INFO org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics: Registering GenericEventTypeMetrics
2025-03-26 02:26:03,794 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2025-03-26 02:26:03,821 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2025-03-26 02:26:03,826 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2025-03-26 02:26:03,838 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2025-03-26 02:26:03,862 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2025-03-26 02:26:03,864 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2025-03-26 02:26:03,864 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2025-03-26 02:26:03,884 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2025-03-26 02:26:03,884 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2025-03-26 02:26:03,884 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2025-03-26 02:26:03,885 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2025-03-26 02:26:03,916 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:03,923 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2025-03-26 02:26:03,923 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:03,943 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.
2025-03-26 02:26:03,945 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2025-03-26 02:26:03,949 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2025-03-26 02:26:04,193 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2025-03-26 02:26:04,193 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor: Application lifelime monitor interval set to 3000 ms.
2025-03-26 02:26:04,198 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: Initializing NodeSortingService=MultiNodeSortingManager
2025-03-26 02:26:04,200 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.11" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:04,200 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.12" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:04,200 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.13" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:26:04,200 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2025-03-26 02:26:04,204 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/hadoop/etc/hadoop/capacity-scheduler.xml
2025-03-26 02:26:04,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Minimum allocation = <memory:1024, vCores:1>
2025-03-26 02:26:04,209 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Maximum allocation = <memory:8192, vCores:4>
2025-03-26 02:26:04,241 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2025-03-26 02:26:04,241 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, absoluteCapacity=1.0, maxCapacity=1.0, absoluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*, , reservationsContinueLooking=true, orderingPolicy=utilization, priority=0
2025-03-26 02:26:04,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized queue: root
2025-03-26 02:26:04,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized queue: root.default
2025-03-26 02:26:04,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing root.default capacity = 1.0 [= (float) configuredCapacity / 100 ] absoluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ] maxCapacity = 1.0 [= configuredMaxCapacity ] absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ] effectiveMinResource=<memory:0, vCores:0> , effectiveMaxResource=<memory:0, vCores:0> userLimit = 100 [= configuredUserLimit ] userLimitFactor = 1.0 [= configuredUserLimitFactor ] maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)] maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ] maxParallelApps = 2147483647 usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)] absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory] maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ] minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ] maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ] numContainers = 0 [= currentNumContainers ] state = RUNNING [= configuredState ] acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ] nodeLocalityDelay = 40 rackLocalityAdditionalDelay = -1 labels=*, reservationsContinueLooking = true preemptionDisabled = true defaultAppPriorityPerQueue = 0 priority = 0 maxLifetime = -1 seconds defaultLifetime = -1 seconds
2025-03-26 02:26:04,254 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2025-03-26 02:26:04,255 INFO org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule: Initialized queue mappings, override: false
2025-03-26 02:26:04,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.WorkflowPriorityMappingsManager: Initialized workflow priority mappings, override: false
2025-03-26 02:26:04,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: MultiNode scheduling is 'false', and configured policies are
2025-03-26 02:26:04,256 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms,multiNodePlacementEnabled=false, assignMultipleEnabled=true, maxAssignPerHeartbeat=100, offswitchPerHeartbeatLimit=1
2025-03-26 02:26:04,264 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2025-03-26 02:26:04,265 INFO org.apache.hadoop.yarn.server.resourcemanager.AMSProcessingChain: Initializing AMS Processing chain. Root Processor=[org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor].
2025-03-26 02:26:04,265 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: disabled placement handler will be used, all scheduling requests will be rejected.
2025-03-26 02:26:04,266 INFO tp top of AMS Processing chain.
2025-03-26 02:26:04,270 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: TimelineServicePublisher is not configured
2025-03-26 02:26:04,297 INFO org.eclipse.jetty.util.log: Logging initialized @1101ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:04,383 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:04,387 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2025-03-26 02:26:04,391 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:04,394 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2025-03-26 02:26:04,394 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2025-03-26 02:26:04,394 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2025-03-26 02:26:04,394 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2025-03-26 02:26:04,394 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:04,395 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:04,654 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:26:04,658 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2025-03-26 02:26:04,659 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:04,681 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:04,681 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:04,682 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:26:04,691 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:04,695 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:26:04,696 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2025-03-26 02:26:04,696 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:26:04,707 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@232a7d73{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:26:04,707 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@305a0c5f{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:05,423 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@7add323c{cluster,/,file:///tmp/jetty-master-8088-hadoop-yarn-common-3_3_4_jar-_-any-6812377184565179077/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/cluster}
2025-03-26 02:26:05,430 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2025-03-26 02:26:05,430 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@5b068087{HTTP/1.1, (http/1.1)}{master:8088}
2025-03-26 02:26:05,430 INFO org.eclipse.jetty.server.Server: Started @2235ms
2025-03-26 02:26:05,632 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:05,669 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2025-03-26 02:26:05,804 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:05,804 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2025-03-26 02:26:05,805 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2025-03-26 02:26:05,805 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2025-03-26 02:26:05,818 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2025-03-26 02:26:05,819 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2025-03-26 02:26:05,819 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:26:05,819 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:26:05,819 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2025-03-26 02:26:05,819 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2025-03-26 02:26:05,819 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2025-03-26 02:26:05,819 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2025-03-26 02:26:05,819 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2025-03-26 02:26:05,820 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2025-03-26 02:26:05,822 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2025-03-26 02:26:05,952 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Created store directory :file:/tmp/hadoop-yarn-root/node-attribute
2025-03-26 02:26:05,981 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Finished create editlog file at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.editlog
2025-03-26 02:26:05,981 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Finished write mirror at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.mirror
2025-03-26 02:26:06,006 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$ForwardingEventHandler
2025-03-26 02:26:06,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: Starting NodeSortingService=MultiNodeSortingManager
2025-03-26 02:26:06,026 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:06,027 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2025-03-26 02:26:06,031 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2025-03-26 02:26:06,032 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:06,032 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2025-03-26 02:26:06,063 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:06,063 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:06,069 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2025-03-26 02:26:06,079 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:06,079 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2025-03-26 02:26:06,080 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2025-03-26 02:26:06,139 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave1/172.20.1.12 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:06,147 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:06,208 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:06,209 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2025-03-26 02:26:06,213 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2025-03-26 02:26:06,214 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:06,214 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2025-03-26 02:26:06,221 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave2/172.20.1.13 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:06,228 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:06,231 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave0/172.20.1.11 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:26:06,239 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:26:06,574 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:26:06,574 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:26:06,575 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:26:06,621 INFO org.apache.hadoop.yarn.server.webproxy.ProxyCA: Created Certificate for OU=YARN-d3d89e85-2efe-4b8b-b10b-4ce2c959fae8
2025-03-26 02:26:06,655 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:26:06,655 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:26:06,656 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:26:06,665 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:26:06,665 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:26:06,666 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:26:06,674 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2025-03-26 02:26:06,674 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing CA Certificate and Private Key
2025-03-26 02:26:06,749 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:26:06,750 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:26:06,750 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:26:06,751 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:26:06,751 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:26:06,751 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:26:06,751 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:26:06,752 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:26:06,761 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:26:06,761 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:26:06,792 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:06,815 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:26:06,815 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:26:06,816 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:26:06,816 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:26:06,816 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:26:06,816 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:26:06,816 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:26:06,817 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:26:06,826 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:26:06,826 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:26:06,826 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:26:06,826 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:26:06,827 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:26:06,827 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:26:06,827 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:26:06,827 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:26:06,827 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:26:06,828 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:26:06,837 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:26:06,837 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:06,837 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:26:06,838 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:26:06,842 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:26:06,853 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:06,857 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:06,862 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:06,866 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:26:06,892 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:26:06,893 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:26:06,894 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:26:06,894 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:26:06,894 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:26:06,897 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:26:06,897 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:06,903 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:26:06,908 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:26:06,910 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:26:06,910 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:26:06,915 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:06,916 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:26:06,917 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:26:06,919 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:26:06,919 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:26:06,923 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:06,926 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:06,932 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:26:06,932 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:26:06,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:26:06,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:26:06,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:26:06,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:26:06,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:26:06,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:26:06,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:26:06,934 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:26:06,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:26:06,937 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:26:06,937 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:26:06,939 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:26:06,952 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:26:06,953 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:26:06,953 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:26:06,953 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:26:06,953 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:26:06,960 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:26:06,962 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:26:06,963 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:26:06,964 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:26:06,964 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:26:06,964 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:26:06,966 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:26:06,976 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:26:06,978 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:26:06,978 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:26:06,980 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:26:06,989 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:26:06,991 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:26:06,991 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:26:06,992 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:06,996 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:26:06,997 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:26:06,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:26:06,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:26:06,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:26:06,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:26:06,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:26:06,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:26:06,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:26:06,999 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:26:07,000 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:26:07,000 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:26:07,001 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:26:07,006 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:26:07,006 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:26:07,007 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:26:07,007 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:26:07,007 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:26:07,007 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:26:07,007 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:26:07,007 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:26:07,007 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:26:07,008 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:26:07,009 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:26:07,009 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:26:07,010 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:26:07,014 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:26:07,020 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:26:07,033 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:26:07,045 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:07,050 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:07,069 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:26:07,070 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:07,070 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:26:07,073 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave1:46089
2025-03-26 02:26:07,078 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:07,078 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:26:07,080 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:26:07,081 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:07,081 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:26:07,082 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:26:07,083 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:26:07,083 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave1/172.20.1.12:46089
2025-03-26 02:26:07,083 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:26:07,087 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:26:07,092 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:26:07,096 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:26:07,107 INFO org.eclipse.jetty.util.log: Logging initialized @1362ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:07,128 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:07,128 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:26:07,128 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:26:07,131 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:07,131 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:26:07,131 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:26:07,131 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave0:45985
2025-03-26 02:26:07,136 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave2:35603
2025-03-26 02:26:07,137 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:07,137 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:26:07,142 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:26:07,144 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:26:07,146 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:07,146 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:26:07,147 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:26:07,149 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:26:07,152 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:26:07,152 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:26:07,153 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:26:07,154 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:26:07,158 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:26:07,158 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave2/172.20.1.13:35603
2025-03-26 02:26:07,158 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:26:07,159 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave0/172.20.1.11:45985
2025-03-26 02:26:07,160 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:26:07,160 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:26:07,162 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:26:07,166 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:26:07,181 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:07,184 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:26:07,188 INFO org.eclipse.jetty.util.log: Logging initialized @1376ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:07,190 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:07,192 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:26:07,192 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:26:07,192 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:26:07,192 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:07,192 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:26:07,192 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:07,192 INFO org.eclipse.jetty.util.log: Logging initialized @1371ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:26:07,253 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:07,255 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:26:07,258 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:07,260 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:26:07,260 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:07,261 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:07,261 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:26:07,261 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:07,262 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:26:07,262 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:26:07,262 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:26:07,265 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:26:07,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:26:07,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:26:07,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:26:07,267 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:26:07,267 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:26:07,267 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:26:07,456 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:26:07,457 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:26:07,458 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:07,471 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:07,472 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:07,473 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:26:07,483 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:07,484 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:07,485 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:26:07,508 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:26:07,509 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:26:07,510 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:07,517 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:26:07,517 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:26:07,518 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:26:07,528 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:07,528 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:07,529 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:26:07,535 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:26:07,535 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:26:07,536 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:26:07,539 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:07,540 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:07,541 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:26:07,545 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:26:07,546 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:26:07,547 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:26:08,059 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-2768104022400907755/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:26:08,068 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:26:08,069 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:26:08,069 INFO org.eclipse.jetty.server.Server: Started @2324ms
2025-03-26 02:26:08,074 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave1:46089
2025-03-26 02:26:08,084 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.10:8031
2025-03-26 02:26:08,094 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:08,200 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-2619635914883464381/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:26:08,202 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-9207557168303022914/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:26:08,206 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:26:08,206 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:26:08,206 INFO org.eclipse.jetty.server.Server: Started @2394ms
2025-03-26 02:26:08,207 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave2:35603
2025-03-26 02:26:08,208 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:26:08,208 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:26:08,208 INFO org.eclipse.jetty.server.Server: Started @2387ms
2025-03-26 02:26:08,209 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave0:45985
2025-03-26 02:26:08,214 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.10:8031
2025-03-26 02:26:08,215 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.10:8031
2025-03-26 02:26:08,222 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:08,231 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:26:08,542 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave2(cmPort: 35603 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave2:35603
2025-03-26 02:26:08,543 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave2:35603 Node Transitioned from NEW to RUNNING
2025-03-26 02:26:08,546 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave0(cmPort: 45985 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave0:45985
2025-03-26 02:26:08,550 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave0:45985 Node Transitioned from NEW to RUNNING
2025-03-26 02:26:08,552 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave2:35603 with total resource of <memory:8192, vCores:8>
2025-03-26 02:26:08,552 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1549878124
2025-03-26 02:26:08,552 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1263600202
2025-03-26 02:26:08,556 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave0:45985 with total resource of <memory:8192, vCores:8>
2025-03-26 02:26:08,556 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1549878124
2025-03-26 02:26:08,556 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1263600202
2025-03-26 02:26:08,567 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave1(cmPort: 46089 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave1:46089
2025-03-26 02:26:08,567 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave1:46089 Node Transitioned from NEW to RUNNING
2025-03-26 02:26:08,572 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1549878124
2025-03-26 02:26:08,573 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave1:46089 with total resource of <memory:8192, vCores:8>
2025-03-26 02:26:08,573 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1263600202
2025-03-26 02:26:08,593 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave2:35603 clusterResource: <memory:8192, vCores:8>
2025-03-26 02:26:08,598 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave0:45985 clusterResource: <memory:16384, vCores:16>
2025-03-26 02:26:08,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave1:46089 clusterResource: <memory:24576, vCores:24>
2025-03-26 02:26:09,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:09,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:09,673 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /file.txt._COPYING_
2025-03-26 02:26:09,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741825_1001 src: /172.20.1.10:48754 dest: /172.20.1.11:9866
2025-03-26 02:26:09,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741825_1001 src: /172.20.1.11:57762 dest: /172.20.1.13:9866
2025-03-26 02:26:09,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741825_1001 src: /172.20.1.13:58360 dest: /172.20.1.12:9866
2025-03-26 02:26:09,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:58360, dest: /172.20.1.12:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1681866584_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741825_1001, duration(ns): 22149903
2025-03-26 02:26:09,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:09,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:57762, dest: /172.20.1.13:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1681866584_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741825_1001, duration(ns): 22556100
2025-03-26 02:26:09,874 INFO terminating
2025-03-26 02:26:09,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48754, dest: /172.20.1.11:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1681866584_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741825_1001, duration(ns): 23766453
2025-03-26 02:26:09,877 INFO terminating
2025-03-26 02:26:09,883 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /file.txt._COPYING_
2025-03-26 02:26:10,289 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /file.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1681866584_1
2025-03-26 02:26:11,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:11,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:11,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /cluster.txt._COPYING_
2025-03-26 02:26:11,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741826_1002 src: /172.20.1.10:48758 dest: /172.20.1.11:9866
2025-03-26 02:26:11,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741826_1002 src: /172.20.1.11:57774 dest: /172.20.1.13:9866
2025-03-26 02:26:11,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741826_1002 src: /172.20.1.13:58374 dest: /172.20.1.12:9866
2025-03-26 02:26:11,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:58374, dest: /172.20.1.12:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_173667992_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741826_1002, duration(ns): 9073460
2025-03-26 02:26:11,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:11,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:57774, dest: /172.20.1.13:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_173667992_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741826_1002, duration(ns): 12504923
2025-03-26 02:26:11,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48758, dest: /172.20.1.11:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_173667992_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741826_1002, duration(ns): 15379475
2025-03-26 02:26:11,760 INFO terminating
2025-03-26 02:26:11,761 INFO terminating
2025-03-26 02:26:11,764 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /cluster.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_173667992_1
2025-03-26 02:26:13,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:13,138 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /page.txt._COPYING_
2025-03-26 02:26:13,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:13,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741827_1003 src: /172.20.1.10:52070 dest: /172.20.1.13:9866
2025-03-26 02:26:13,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741827_1003 src: /172.20.1.13:58388 dest: /172.20.1.12:9866
2025-03-26 02:26:13,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741827_1003 src: /172.20.1.12:45828 dest: /172.20.1.11:9866
2025-03-26 02:26:13,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45828, dest: /172.20.1.11:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1196908506_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741827_1003, duration(ns): 9178498
2025-03-26 02:26:13,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:13,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:58388, dest: /172.20.1.12:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1196908506_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741827_1003, duration(ns): 10049700
2025-03-26 02:26:13,221 INFO terminating
2025-03-26 02:26:13,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:52070, dest: /172.20.1.13:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1196908506_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741827_1003, duration(ns): 10759294
2025-03-26 02:26:13,223 INFO terminating
2025-03-26 02:26:13,226 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /page.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1196908506_1
2025-03-26 02:26:14,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:14,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /lr_test.txt._COPYING_
2025-03-26 02:26:14,686 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:14,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741828_1004 src: /172.20.1.10:48760 dest: /172.20.1.11:9866
2025-03-26 02:26:14,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741828_1004 src: /172.20.1.11:57776 dest: /172.20.1.13:9866
2025-03-26 02:26:14,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741828_1004 src: /172.20.1.13:58390 dest: /172.20.1.12:9866
2025-03-26 02:26:14,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:58390, dest: /172.20.1.12:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_277756546_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741828_1004, duration(ns): 8972075
2025-03-26 02:26:14,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:14,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:57776, dest: /172.20.1.13:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_277756546_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741828_1004, duration(ns): 9665237
2025-03-26 02:26:14,762 INFO terminating
2025-03-26 02:26:14,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48760, dest: /172.20.1.11:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_277756546_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741828_1004, duration(ns): 10778334
2025-03-26 02:26:14,764 INFO terminating
2025-03-26 02:26:14,767 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /lr_test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_277756546_1
2025-03-26 02:26:17,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,547 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/graphx/users.txt._COPYING_
2025-03-26 02:26:17,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741829_1005 src: /172.20.1.10:49870 dest: /172.20.1.12:9866
2025-03-26 02:26:17,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741829_1005 src: /172.20.1.12:53434 dest: /172.20.1.11:9866
2025-03-26 02:26:17,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741829_1005 src: /172.20.1.11:43680 dest: /172.20.1.13:9866
2025-03-26 02:26:17,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43680, dest: /172.20.1.13:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741829_1005, duration(ns): 8240571
2025-03-26 02:26:17,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53434, dest: /172.20.1.11:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741829_1005, duration(ns): 9067629
2025-03-26 02:26:17,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,616 INFO terminating
2025-03-26 02:26:17,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49870, dest: /172.20.1.12:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741829_1005, duration(ns): 9770870
2025-03-26 02:26:17,618 INFO terminating
2025-03-26 02:26:17,621 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/graphx/users.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,632 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/graphx/followers.txt._COPYING_
2025-03-26 02:26:17,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741830_1006 src: /172.20.1.10:49876 dest: /172.20.1.12:9866
2025-03-26 02:26:17,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741830_1006 src: /172.20.1.12:53444 dest: /172.20.1.11:9866
2025-03-26 02:26:17,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741830_1006 src: /172.20.1.11:43686 dest: /172.20.1.13:9866
2025-03-26 02:26:17,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43686, dest: /172.20.1.13:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741830_1006, duration(ns): 2064532
2025-03-26 02:26:17,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53444, dest: /172.20.1.11:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741830_1006, duration(ns): 3296072
2025-03-26 02:26:17,642 INFO terminating
2025-03-26 02:26:17,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49876, dest: /172.20.1.12:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741830_1006, duration(ns): 4103039
2025-03-26 02:26:17,643 INFO terminating
2025-03-26 02:26:17,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/graphx/followers.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,662 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,662 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,663 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/data/mllib/sample_fpgrowth.txt._COPYING_
2025-03-26 02:26:17,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741831_1007 src: /172.20.1.10:46798 dest: /172.20.1.13:9866
2025-03-26 02:26:17,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741831_1007 src: /172.20.1.13:60308 dest: /172.20.1.12:9866
2025-03-26 02:26:17,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741831_1007 src: /172.20.1.12:53456 dest: /172.20.1.11:9866
2025-03-26 02:26:17,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53456, dest: /172.20.1.11:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741831_1007, duration(ns): 2821244
2025-03-26 02:26:17,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60308, dest: /172.20.1.12:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741831_1007, duration(ns): 3730373
2025-03-26 02:26:17,673 INFO terminating
2025-03-26 02:26:17,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46798, dest: /172.20.1.13:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741831_1007, duration(ns): 4803952
2025-03-26 02:26:17,675 INFO terminating
2025-03-26 02:26:17,676 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_fpgrowth.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/pagerank_data.txt._COPYING_
2025-03-26 02:26:17,686 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,686 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741832_1008 src: /172.20.1.10:49892 dest: /172.20.1.11:9866
2025-03-26 02:26:17,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741832_1008 src: /172.20.1.11:43694 dest: /172.20.1.13:9866
2025-03-26 02:26:17,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741832_1008 src: /172.20.1.13:60310 dest: /172.20.1.12:9866
2025-03-26 02:26:17,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60310, dest: /172.20.1.12:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741832_1008, duration(ns): 2222626
2025-03-26 02:26:17,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43694, dest: /172.20.1.13:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741832_1008, duration(ns): 4046099
2025-03-26 02:26:17,696 INFO terminating
2025-03-26 02:26:17,697 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/pagerank_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49892, dest: /172.20.1.11:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741832_1008, duration(ns): 4944147
2025-03-26 02:26:17,697 INFO terminating
2025-03-26 02:26:17,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/streaming_kmeans_data_test.txt._COPYING_
2025-03-26 02:26:17,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741833_1009 src: /172.20.1.10:49886 dest: /172.20.1.12:9866
2025-03-26 02:26:17,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741833_1009 src: /172.20.1.12:35790 dest: /172.20.1.13:9866
2025-03-26 02:26:17,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741833_1009 src: /172.20.1.13:57156 dest: /172.20.1.11:9866
2025-03-26 02:26:17,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57156, dest: /172.20.1.11:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741833_1009, duration(ns): 2455538
2025-03-26 02:26:17,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35790, dest: /172.20.1.13:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741833_1009, duration(ns): 3610317
2025-03-26 02:26:17,717 INFO terminating
2025-03-26 02:26:17,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49886, dest: /172.20.1.12:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741833_1009, duration(ns): 5362338
2025-03-26 02:26:17,719 INFO terminating
2025-03-26 02:26:17,720 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/streaming_kmeans_data_test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,727 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_lda_data.txt._COPYING_
2025-03-26 02:26:17,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741834_1010 src: /172.20.1.10:46814 dest: /172.20.1.13:9866
2025-03-26 02:26:17,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741834_1010 src: /172.20.1.13:57158 dest: /172.20.1.11:9866
2025-03-26 02:26:17,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741834_1010 src: /172.20.1.11:36086 dest: /172.20.1.12:9866
2025-03-26 02:26:17,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36086, dest: /172.20.1.12:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741834_1010, duration(ns): 2410558
2025-03-26 02:26:17,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57158, dest: /172.20.1.11:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741834_1010, duration(ns): 3533065
2025-03-26 02:26:17,737 INFO terminating
2025-03-26 02:26:17,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46814, dest: /172.20.1.13:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741834_1010, duration(ns): 4165314
2025-03-26 02:26:17,738 INFO terminating
2025-03-26 02:26:17,739 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_lda_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,751 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/als/test.data._COPYING_
2025-03-26 02:26:17,751 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,751 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741835_1011 src: /172.20.1.10:49902 dest: /172.20.1.11:9866
2025-03-26 02:26:17,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741835_1011 src: /172.20.1.11:43710 dest: /172.20.1.13:9866
2025-03-26 02:26:17,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741835_1011 src: /172.20.1.13:60322 dest: /172.20.1.12:9866
2025-03-26 02:26:17,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43710, dest: /172.20.1.13:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741835_1011, duration(ns): 3364067
2025-03-26 02:26:17,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60322, dest: /172.20.1.12:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741835_1011, duration(ns): 1934844
2025-03-26 02:26:17,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,759 INFO terminating
2025-03-26 02:26:17,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49902, dest: /172.20.1.11:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741835_1011, duration(ns): 3836288
2025-03-26 02:26:17,760 INFO terminating
2025-03-26 02:26:17,761 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/als/test.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/data/mllib/als/sample_movielens_ratings.txt._COPYING_
2025-03-26 02:26:17,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741836_1012 src: /172.20.1.10:46818 dest: /172.20.1.13:9866
2025-03-26 02:26:17,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741836_1012 src: /172.20.1.13:60328 dest: /172.20.1.12:9866
2025-03-26 02:26:17,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741836_1012 src: /172.20.1.12:53460 dest: /172.20.1.11:9866
2025-03-26 02:26:17,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53460, dest: /172.20.1.11:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741836_1012, duration(ns): 2580407
2025-03-26 02:26:17,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60328, dest: /172.20.1.12:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741836_1012, duration(ns): 3408756
2025-03-26 02:26:17,782 INFO terminating
2025-03-26 02:26:17,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46818, dest: /172.20.1.13:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741836_1012, duration(ns): 3856805
2025-03-26 02:26:17,783 INFO terminating
2025-03-26 02:26:17,784 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/als/sample_movielens_ratings.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,792 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_kmeans_data.txt._COPYING_
2025-03-26 02:26:17,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741837_1013 src: /172.20.1.10:46830 dest: /172.20.1.13:9866
2025-03-26 02:26:17,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741837_1013 src: /172.20.1.11:36094 dest: /172.20.1.12:9866
2025-03-26 02:26:17,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741837_1013 src: /172.20.1.13:57160 dest: /172.20.1.11:9866
2025-03-26 02:26:17,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36094, dest: /172.20.1.12:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741837_1013, duration(ns): 2434748
2025-03-26 02:26:17,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57160, dest: /172.20.1.11:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741837_1013, duration(ns): 2850421
2025-03-26 02:26:17,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,799 INFO terminating
2025-03-26 02:26:17,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46830, dest: /172.20.1.13:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741837_1013, duration(ns): 3297101
2025-03-26 02:26:17,800 INFO terminating
2025-03-26 02:26:17,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_kmeans_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,815 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/mllib/ridge-data/lpsa.data._COPYING_
2025-03-26 02:26:17,815 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,815 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741838_1014 src: /172.20.1.10:49890 dest: /172.20.1.12:9866
2025-03-26 02:26:17,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741838_1014 src: /172.20.1.12:53466 dest: /172.20.1.11:9866
2025-03-26 02:26:17,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741838_1014 src: /172.20.1.11:43714 dest: /172.20.1.13:9866
2025-03-26 02:26:17,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43714, dest: /172.20.1.13:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741838_1014, duration(ns): 2258404
2025-03-26 02:26:17,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53466, dest: /172.20.1.11:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741838_1014, duration(ns): 2664042
2025-03-26 02:26:17,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,823 INFO terminating
2025-03-26 02:26:17,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49890, dest: /172.20.1.12:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741838_1014, duration(ns): 3149023
2025-03-26 02:26:17,824 INFO terminating
2025-03-26 02:26:17,825 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/ridge-data/lpsa.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/data/mllib/gmm_data.txt._COPYING_
2025-03-26 02:26:17,831 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,831 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741839_1015 src: /172.20.1.10:49910 dest: /172.20.1.11:9866
2025-03-26 02:26:17,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741839_1015 src: /172.20.1.11:36108 dest: /172.20.1.12:9866
2025-03-26 02:26:17,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741839_1015 src: /172.20.1.12:35798 dest: /172.20.1.13:9866
2025-03-26 02:26:17,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35798, dest: /172.20.1.13:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741839_1015, duration(ns): 2395699
2025-03-26 02:26:17,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36108, dest: /172.20.1.12:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741839_1015, duration(ns): 3309973
2025-03-26 02:26:17,841 INFO terminating
2025-03-26 02:26:17,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49910, dest: /172.20.1.11:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741839_1015, duration(ns): 4765400
2025-03-26 02:26:17,842 INFO terminating
2025-03-26 02:26:17,843 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/gmm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_lda_libsvm_data.txt._COPYING_
2025-03-26 02:26:17,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741840_1016 src: /172.20.1.10:46840 dest: /172.20.1.13:9866
2025-03-26 02:26:17,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741840_1016 src: /172.20.1.13:57168 dest: /172.20.1.11:9866
2025-03-26 02:26:17,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741840_1016 src: /172.20.1.11:36114 dest: /172.20.1.12:9866
2025-03-26 02:26:17,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36114, dest: /172.20.1.12:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741840_1016, duration(ns): 2944582
2025-03-26 02:26:17,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57168, dest: /172.20.1.11:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741840_1016, duration(ns): 4029140
2025-03-26 02:26:17,864 INFO terminating
2025-03-26 02:26:17,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46840, dest: /172.20.1.13:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741840_1016, duration(ns): 5939132
2025-03-26 02:26:17,866 INFO terminating
2025-03-26 02:26:17,867 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_lda_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/mllib/sample_libsvm_data.txt._COPYING_
2025-03-26 02:26:17,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741841_1017 src: /172.20.1.10:49904 dest: /172.20.1.12:9866
2025-03-26 02:26:17,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741841_1017 src: /172.20.1.12:53480 dest: /172.20.1.11:9866
2025-03-26 02:26:17,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741841_1017 src: /172.20.1.11:43718 dest: /172.20.1.13:9866
2025-03-26 02:26:17,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43718, dest: /172.20.1.13:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741841_1017, duration(ns): 2767168
2025-03-26 02:26:17,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53480, dest: /172.20.1.11:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741841_1017, duration(ns): 3442923
2025-03-26 02:26:17,889 INFO terminating
2025-03-26 02:26:17,890 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49904, dest: /172.20.1.12:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741841_1017, duration(ns): 5222456
2025-03-26 02:26:17,890 INFO terminating
2025-03-26 02:26:17,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_movielens_data.txt._COPYING_
2025-03-26 02:26:17,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741842_1018 src: /172.20.1.10:49918 dest: /172.20.1.11:9866
2025-03-26 02:26:17,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741842_1018 src: /172.20.1.11:43722 dest: /172.20.1.13:9866
2025-03-26 02:26:17,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741842_1018 src: /172.20.1.13:60330 dest: /172.20.1.12:9866
2025-03-26 02:26:17,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60330, dest: /172.20.1.12:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741842_1018, duration(ns): 2326890
2025-03-26 02:26:17,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43722, dest: /172.20.1.13:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741842_1018, duration(ns): 3126068
2025-03-26 02:26:17,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49918, dest: /172.20.1.11:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741842_1018, duration(ns): 4671941
2025-03-26 02:26:17,908 INFO terminating
2025-03-26 02:26:17,908 INFO terminating
2025-03-26 02:26:17,909 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_movielens_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_svm_data.txt._COPYING_
2025-03-26 02:26:17,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741843_1019 src: /172.20.1.10:49932 dest: /172.20.1.11:9866
2025-03-26 02:26:17,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741843_1019 src: /172.20.1.11:43736 dest: /172.20.1.13:9866
2025-03-26 02:26:17,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741843_1019 src: /172.20.1.13:60342 dest: /172.20.1.12:9866
2025-03-26 02:26:17,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60342, dest: /172.20.1.12:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741843_1019, duration(ns): 3905539
2025-03-26 02:26:17,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43736, dest: /172.20.1.13:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741843_1019, duration(ns): 4745745
2025-03-26 02:26:17,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:17,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49932, dest: /172.20.1.11:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741843_1019, duration(ns): 5324384
2025-03-26 02:26:17,931 INFO terminating
2025-03-26 02:26:17,931 INFO terminating
2025-03-26 02:26:17,932 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_svm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:17,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/data/mllib/images/license.txt._COPYING_
2025-03-26 02:26:17,949 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,949 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:17,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741844_1020 src: /172.20.1.10:49948 dest: /172.20.1.11:9866
2025-03-26 02:26:17,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741844_1020 src: /172.20.1.11:36122 dest: /172.20.1.12:9866
2025-03-26 02:26:17,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741844_1020 src: /172.20.1.12:35802 dest: /172.20.1.13:9866
2025-03-26 02:26:18,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35802, dest: /172.20.1.13:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741844_1020, duration(ns): 65286660
2025-03-26 02:26:18,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36122, dest: /172.20.1.12:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741844_1020, duration(ns): 69746662
2025-03-26 02:26:18,028 INFO terminating
2025-03-26 02:26:18,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49948, dest: /172.20.1.11:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741844_1020, duration(ns): 18168772
2025-03-26 02:26:18,030 INFO terminating
2025-03-26 02:26:18,032 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/license.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,048 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/images/origin/multi-channel/grayscale.jpg._COPYING_
2025-03-26 02:26:18,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741845_1021 src: /172.20.1.10:49914 dest: /172.20.1.12:9866
2025-03-26 02:26:18,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741845_1021 src: /172.20.1.12:35816 dest: /172.20.1.13:9866
2025-03-26 02:26:18,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741845_1021 src: /172.20.1.13:57172 dest: /172.20.1.11:9866
2025-03-26 02:26:18,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35816, dest: /172.20.1.13:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741845_1021, duration(ns): 3023210
2025-03-26 02:26:18,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57172, dest: /172.20.1.11:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741845_1021, duration(ns): 2556486
2025-03-26 02:26:18,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49914, dest: /172.20.1.12:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741845_1021, duration(ns): 3420768
2025-03-26 02:26:18,056 INFO terminating
2025-03-26 02:26:18,056 INFO terminating
2025-03-26 02:26:18,057 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/grayscale.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png._COPYING_
2025-03-26 02:26:18,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741846_1022 src: /172.20.1.10:46846 dest: /172.20.1.13:9866
2025-03-26 02:26:18,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741846_1022 src: /172.20.1.13:57186 dest: /172.20.1.11:9866
2025-03-26 02:26:18,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741846_1022 src: /172.20.1.11:36130 dest: /172.20.1.12:9866
2025-03-26 02:26:18,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36130, dest: /172.20.1.12:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741846_1022, duration(ns): 2373364
2025-03-26 02:26:18,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57186, dest: /172.20.1.11:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741846_1022, duration(ns): 2444962
2025-03-26 02:26:18,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,074 INFO terminating
2025-03-26 02:26:18,075 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46846, dest: /172.20.1.13:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741846_1022, duration(ns): 2826798
2025-03-26 02:26:18,075 INFO terminating
2025-03-26 02:26:18,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/data/mllib/images/origin/multi-channel/BGRA.png._COPYING_
2025-03-26 02:26:18,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741847_1023 src: /172.20.1.10:49956 dest: /172.20.1.11:9866
2025-03-26 02:26:18,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741847_1023 src: /172.20.1.11:36140 dest: /172.20.1.12:9866
2025-03-26 02:26:18,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741847_1023 src: /172.20.1.12:35830 dest: /172.20.1.13:9866
2025-03-26 02:26:18,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35830, dest: /172.20.1.13:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741847_1023, duration(ns): 2361233
2025-03-26 02:26:18,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36140, dest: /172.20.1.12:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741847_1023, duration(ns): 3058331
2025-03-26 02:26:18,092 INFO terminating
2025-03-26 02:26:18,093 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/BGRA.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49956, dest: /172.20.1.11:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741847_1023, duration(ns): 3600066
2025-03-26 02:26:18,093 INFO terminating
2025-03-26 02:26:18,101 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/data/mllib/images/origin/multi-channel/chr30.4.184.jpg._COPYING_
2025-03-26 02:26:18,101 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,101 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741848_1024 src: /172.20.1.10:46848 dest: /172.20.1.13:9866
2025-03-26 02:26:18,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741848_1024 src: /172.20.1.12:53492 dest: /172.20.1.11:9866
2025-03-26 02:26:18,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741848_1024 src: /172.20.1.13:60356 dest: /172.20.1.12:9866
2025-03-26 02:26:18,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53492, dest: /172.20.1.11:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741848_1024, duration(ns): 2335557
2025-03-26 02:26:18,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60356, dest: /172.20.1.12:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741848_1024, duration(ns): 3077759
2025-03-26 02:26:18,109 INFO terminating
2025-03-26 02:26:18,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46848, dest: /172.20.1.13:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741848_1024, duration(ns): 3519452
2025-03-26 02:26:18,110 INFO terminating
2025-03-26 02:26:18,111 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/chr30.4.184.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/images/origin/license.txt._COPYING_
2025-03-26 02:26:18,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741849_1025 src: /172.20.1.10:49964 dest: /172.20.1.11:9866
2025-03-26 02:26:18,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741849_1025 src: /172.20.1.11:43742 dest: /172.20.1.13:9866
2025-03-26 02:26:18,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741849_1025 src: /172.20.1.13:60358 dest: /172.20.1.12:9866
2025-03-26 02:26:18,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43742, dest: /172.20.1.13:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741849_1025, duration(ns): 3567523
2025-03-26 02:26:18,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60358, dest: /172.20.1.12:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741849_1025, duration(ns): 2460580
2025-03-26 02:26:18,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,130 INFO terminating
2025-03-26 02:26:18,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49964, dest: /172.20.1.11:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741849_1025, duration(ns): 4198017
2025-03-26 02:26:18,132 INFO terminating
2025-03-26 02:26:18,134 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/license.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,148 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,148 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,149 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg._COPYING_
2025-03-26 02:26:18,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741850_1026 src: /172.20.1.10:49924 dest: /172.20.1.12:9866
2025-03-26 02:26:18,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741850_1026 src: /172.20.1.12:35842 dest: /172.20.1.13:9866
2025-03-26 02:26:18,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741850_1026 src: /172.20.1.13:57192 dest: /172.20.1.11:9866
2025-03-26 02:26:18,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57192, dest: /172.20.1.11:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741850_1026, duration(ns): 1978768
2025-03-26 02:26:18,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35842, dest: /172.20.1.13:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741850_1026, duration(ns): 2753678
2025-03-26 02:26:18,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,156 INFO terminating
2025-03-26 02:26:18,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49924, dest: /172.20.1.12:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741850_1026, duration(ns): 3232670
2025-03-26 02:26:18,157 INFO terminating
2025-03-26 02:26:18,158 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/images/origin/kittens/DP802813.jpg._COPYING_
2025-03-26 02:26:18,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741851_1027 src: /172.20.1.10:49936 dest: /172.20.1.12:9866
2025-03-26 02:26:18,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741851_1027 src: /172.20.1.12:35856 dest: /172.20.1.13:9866
2025-03-26 02:26:18,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741851_1027 src: /172.20.1.13:57194 dest: /172.20.1.11:9866
2025-03-26 02:26:18,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35856, dest: /172.20.1.13:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741851_1027, duration(ns): 2950552
2025-03-26 02:26:18,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57194, dest: /172.20.1.11:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741851_1027, duration(ns): 2246150
2025-03-26 02:26:18,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,176 INFO terminating
2025-03-26 02:26:18,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49936, dest: /172.20.1.12:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741851_1027, duration(ns): 3246494
2025-03-26 02:26:18,177 INFO terminating
2025-03-26 02:26:18,179 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/DP802813.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,185 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/mllib/images/origin/kittens/DP153539.jpg._COPYING_
2025-03-26 02:26:18,185 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741852_1028 src: /172.20.1.10:49950 dest: /172.20.1.12:9866
2025-03-26 02:26:18,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741852_1028 src: /172.20.1.11:43752 dest: /172.20.1.13:9866
2025-03-26 02:26:18,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741852_1028 src: /172.20.1.12:53508 dest: /172.20.1.11:9866
2025-03-26 02:26:18,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43752, dest: /172.20.1.13:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741852_1028, duration(ns): 1899329
2025-03-26 02:26:18,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53508, dest: /172.20.1.11:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741852_1028, duration(ns): 2273731
2025-03-26 02:26:18,192 INFO terminating
2025-03-26 02:26:18,193 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/DP153539.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49950, dest: /172.20.1.12:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741852_1028, duration(ns): 3210392
2025-03-26 02:26:18,193 INFO terminating
2025-03-26 02:26:18,199 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/images/origin/kittens/not-image.txt._COPYING_
2025-03-26 02:26:18,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741853_1029 src: /172.20.1.10:49980 dest: /172.20.1.11:9866
2025-03-26 02:26:18,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741853_1029 src: /172.20.1.11:43758 dest: /172.20.1.13:9866
2025-03-26 02:26:18,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741853_1029 src: /172.20.1.13:60362 dest: /172.20.1.12:9866
2025-03-26 02:26:18,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60362, dest: /172.20.1.12:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741853_1029, duration(ns): 1980397
2025-03-26 02:26:18,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43758, dest: /172.20.1.13:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741853_1029, duration(ns): 2318469
2025-03-26 02:26:18,207 INFO terminating
2025-03-26 02:26:18,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49980, dest: /172.20.1.11:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741853_1029, duration(ns): 2838755
2025-03-26 02:26:18,208 INFO terminating
2025-03-26 02:26:18,209 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/not-image.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/images/origin/kittens/54893.jpg._COPYING_
2025-03-26 02:26:18,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741854_1030 src: /172.20.1.10:49966 dest: /172.20.1.12:9866
2025-03-26 02:26:18,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741854_1030 src: /172.20.1.12:35872 dest: /172.20.1.13:9866
2025-03-26 02:26:18,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741854_1030 src: /172.20.1.13:57206 dest: /172.20.1.11:9866
2025-03-26 02:26:18,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35872, dest: /172.20.1.13:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741854_1030, duration(ns): 3272628
2025-03-26 02:26:18,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57206, dest: /172.20.1.11:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741854_1030, duration(ns): 2018190
2025-03-26 02:26:18,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,227 INFO terminating
2025-03-26 02:26:18,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49966, dest: /172.20.1.12:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741854_1030, duration(ns): 3765168
2025-03-26 02:26:18,228 INFO terminating
2025-03-26 02:26:18,230 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/54893.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,240 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/sample_linear_regression_data.txt._COPYING_
2025-03-26 02:26:18,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741855_1031 src: /172.20.1.10:49968 dest: /172.20.1.12:9866
2025-03-26 02:26:18,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741855_1031 src: /172.20.1.12:35882 dest: /172.20.1.13:9866
2025-03-26 02:26:18,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741855_1031 src: /172.20.1.13:57214 dest: /172.20.1.11:9866
2025-03-26 02:26:18,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57214, dest: /172.20.1.11:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741855_1031, duration(ns): 2561924
2025-03-26 02:26:18,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35882, dest: /172.20.1.13:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741855_1031, duration(ns): 3029583
2025-03-26 02:26:18,248 INFO terminating
2025-03-26 02:26:18,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49968, dest: /172.20.1.12:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741855_1031, duration(ns): 3968114
2025-03-26 02:26:18,249 INFO terminating
2025-03-26 02:26:18,250 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_linear_regression_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_binary_classification_data.txt._COPYING_
2025-03-26 02:26:18,256 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,256 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741856_1032 src: /172.20.1.10:49982 dest: /172.20.1.11:9866
2025-03-26 02:26:18,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741856_1032 src: /172.20.1.11:43766 dest: /172.20.1.13:9866
2025-03-26 02:26:18,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741856_1032 src: /172.20.1.13:60378 dest: /172.20.1.12:9866
2025-03-26 02:26:18,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43766, dest: /172.20.1.13:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741856_1032, duration(ns): 2714845
2025-03-26 02:26:18,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60378, dest: /172.20.1.12:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741856_1032, duration(ns): 2283009
2025-03-26 02:26:18,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49982, dest: /172.20.1.11:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741856_1032, duration(ns): 3322773
2025-03-26 02:26:18,264 INFO terminating
2025-03-26 02:26:18,265 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_binary_classification_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,265 INFO terminating
2025-03-26 02:26:18,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_multiclass_classification_data.txt._COPYING_
2025-03-26 02:26:18,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741857_1033 src: /172.20.1.10:49998 dest: /172.20.1.11:9866
2025-03-26 02:26:18,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741857_1033 src: /172.20.1.11:43768 dest: /172.20.1.13:9866
2025-03-26 02:26:18,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741857_1033 src: /172.20.1.13:60384 dest: /172.20.1.12:9866
2025-03-26 02:26:18,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60384, dest: /172.20.1.12:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741857_1033, duration(ns): 2109192
2025-03-26 02:26:18,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43768, dest: /172.20.1.13:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741857_1033, duration(ns): 2538252
2025-03-26 02:26:18,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,279 INFO terminating
2025-03-26 02:26:18,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49998, dest: /172.20.1.11:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741857_1033, duration(ns): 3024013
2025-03-26 02:26:18,280 INFO terminating
2025-03-26 02:26:18,281 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_multiclass_classification_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_isotonic_regression_libsvm_data.txt._COPYING_
2025-03-26 02:26:18,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741858_1034 src: /172.20.1.10:46862 dest: /172.20.1.13:9866
2025-03-26 02:26:18,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741858_1034 src: /172.20.1.13:57218 dest: /172.20.1.11:9866
2025-03-26 02:26:18,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741858_1034 src: /172.20.1.11:36148 dest: /172.20.1.12:9866
2025-03-26 02:26:18,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36148, dest: /172.20.1.12:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741858_1034, duration(ns): 2129043
2025-03-26 02:26:18,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57218, dest: /172.20.1.11:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741858_1034, duration(ns): 3058478
2025-03-26 02:26:18,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,295 INFO terminating
2025-03-26 02:26:18,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46862, dest: /172.20.1.13:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741858_1034, duration(ns): 3497008
2025-03-26 02:26:18,296 INFO terminating
2025-03-26 02:26:18,297 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_isotonic_regression_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,304 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/pic_data.txt._COPYING_
2025-03-26 02:26:18,304 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,304 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741859_1035 src: /172.20.1.10:49984 dest: /172.20.1.12:9866
2025-03-26 02:26:18,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741859_1035 src: /172.20.1.12:35894 dest: /172.20.1.13:9866
2025-03-26 02:26:18,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741859_1035 src: /172.20.1.13:57224 dest: /172.20.1.11:9866
2025-03-26 02:26:18,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57224, dest: /172.20.1.11:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741859_1035, duration(ns): 1926312
2025-03-26 02:26:18,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49984, dest: /172.20.1.12:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741859_1035, duration(ns): 2785309
2025-03-26 02:26:18,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35894, dest: /172.20.1.13:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741859_1035, duration(ns): 2318756
2025-03-26 02:26:18,312 INFO terminating
2025-03-26 02:26:18,313 INFO terminating
2025-03-26 02:26:18,315 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/pic_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,324 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/kmeans_data.txt._COPYING_
2025-03-26 02:26:18,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741860_1036 src: /172.20.1.10:49986 dest: /172.20.1.12:9866
2025-03-26 02:26:18,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741860_1036 src: /172.20.1.12:35896 dest: /172.20.1.13:9866
2025-03-26 02:26:18,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741860_1036 src: /172.20.1.13:57238 dest: /172.20.1.11:9866
2025-03-26 02:26:18,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35896, dest: /172.20.1.13:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741860_1036, duration(ns): 2499587
2025-03-26 02:26:18,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57238, dest: /172.20.1.11:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741860_1036, duration(ns): 2226135
2025-03-26 02:26:18,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,331 INFO terminating
2025-03-26 02:26:18,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49986, dest: /172.20.1.12:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741860_1036, duration(ns): 2924496
2025-03-26 02:26:18,332 INFO terminating
2025-03-26 02:26:18,334 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/kmeans_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/streaming/AFINN-111.txt._COPYING_
2025-03-26 02:26:18,344 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,344 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:18,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741861_1037 src: /172.20.1.10:49996 dest: /172.20.1.12:9866
2025-03-26 02:26:18,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741861_1037 src: /172.20.1.12:35902 dest: /172.20.1.13:9866
2025-03-26 02:26:18,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741861_1037 src: /172.20.1.13:57240 dest: /172.20.1.11:9866
2025-03-26 02:26:18,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57240, dest: /172.20.1.11:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741861_1037, duration(ns): 2052976
2025-03-26 02:26:18,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:18,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35902, dest: /172.20.1.13:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741861_1037, duration(ns): 2476002
2025-03-26 02:26:18,352 INFO terminating
2025-03-26 02:26:18,353 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/streaming/AFINN-111.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-393431639_1
2025-03-26 02:26:18,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49996, dest: /172.20.1.12:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393431639_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741861_1037, duration(ns): 2935271
2025-03-26 02:26:18,353 INFO terminating
2025-03-26 02:26:19,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/jars/scopt_2.12-3.7.1.jar._COPYING_
2025-03-26 02:26:19,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741862_1038 src: /172.20.1.10:50010 dest: /172.20.1.11:9866
2025-03-26 02:26:19,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741862_1038 src: /172.20.1.11:43774 dest: /172.20.1.13:9866
2025-03-26 02:26:19,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741862_1038 src: /172.20.1.13:60398 dest: /172.20.1.12:9866
2025-03-26 02:26:19,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43774, dest: /172.20.1.13:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741862_1038, duration(ns): 7245879
2025-03-26 02:26:19,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60398, dest: /172.20.1.12:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741862_1038, duration(ns): 6842826
2025-03-26 02:26:19,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,804 INFO terminating
2025-03-26 02:26:19,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50010, dest: /172.20.1.11:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741862_1038, duration(ns): 7806477
2025-03-26 02:26:19,805 INFO terminating
2025-03-26 02:26:19,809 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/jars/scopt_2.12-3.7.1.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:19,822 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/jars/spark-examples_2.12-3.3.2.jar._COPYING_
2025-03-26 02:26:19,822 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,822 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,822 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,822 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:19,822 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:19,822 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:19,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741863_1039 src: /172.20.1.10:50000 dest: /172.20.1.12:9866
2025-03-26 02:26:19,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741863_1039 src: /172.20.1.12:35904 dest: /172.20.1.13:9866
2025-03-26 02:26:19,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35904, dest: /172.20.1.13:9866, bytes: 1567446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741863_1039, duration(ns): 4225850
2025-03-26 02:26:19,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50000, dest: /172.20.1.12:9866, bytes: 1567446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741863_1039, duration(ns): 4943653
2025-03-26 02:26:19,831 INFO terminating
2025-03-26 02:26:19,832 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/jars/spark-examples_2.12-3.3.2.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:19,856 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/wordcount.py._COPYING_
2025-03-26 02:26:19,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,856 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:19,856 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:19,856 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:19,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741864_1040 src: /172.20.1.10:46870 dest: /172.20.1.13:9866
2025-03-26 02:26:19,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741864_1040 src: /172.20.1.13:60406 dest: /172.20.1.12:9866
2025-03-26 02:26:19,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46870, dest: /172.20.1.13:9866, bytes: 1418, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741864_1040, duration(ns): 1605902
2025-03-26 02:26:19,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60406, dest: /172.20.1.12:9866, bytes: 1418, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741864_1040, duration(ns): 1310787
2025-03-26 02:26:19,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,861 INFO terminating
2025-03-26 02:26:19,866 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:19,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/transitive_closure.py._COPYING_
2025-03-26 02:26:19,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,881 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:19,881 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:19,881 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:19,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741865_1041 src: /172.20.1.10:50004 dest: /172.20.1.12:9866
2025-03-26 02:26:19,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741865_1041 src: /172.20.1.12:35920 dest: /172.20.1.13:9866
2025-03-26 02:26:19,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35920, dest: /172.20.1.13:9866, bytes: 2445, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741865_1041, duration(ns): 1196268
2025-03-26 02:26:19,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50004, dest: /172.20.1.12:9866, bytes: 2445, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741865_1041, duration(ns): 1899185
2025-03-26 02:26:19,887 INFO terminating
2025-03-26 02:26:19,889 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/transitive_closure.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:19,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_
2025-03-26 02:26:19,899 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,899 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,899 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,899 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:19,899 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:19,899 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:19,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741866_1042 src: /172.20.1.10:50020 dest: /172.20.1.12:9866
2025-03-26 02:26:19,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741866_1042 src: /172.20.1.12:35922 dest: /172.20.1.13:9866
2025-03-26 02:26:19,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35922, dest: /172.20.1.13:9866, bytes: 2432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741866_1042, duration(ns): 1073331
2025-03-26 02:26:19,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:19,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50020, dest: /172.20.1.12:9866, bytes: 2432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741866_1042, duration(ns): 1699016
2025-03-26 02:26:19,905 INFO terminating
2025-03-26 02:26:19,911 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/pi.py._COPYING_
2025-03-26 02:26:19,912 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,912 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,912 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:19,912 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:19,912 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:19,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741867_1043 src: /172.20.1.10:50024 dest: /172.20.1.12:9866
2025-03-26 02:26:19,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741867_1043 src: /172.20.1.12:35926 dest: /172.20.1.13:9866
2025-03-26 02:26:19,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35926, dest: /172.20.1.13:9866, bytes: 1444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741867_1043, duration(ns): 846223
2025-03-26 02:26:19,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,917 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/pi.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:19,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50024, dest: /172.20.1.12:9866, bytes: 1444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741867_1043, duration(ns): 1375957
2025-03-26 02:26:19,917 INFO terminating
2025-03-26 02:26:19,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,925 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/sort.py._COPYING_
2025-03-26 02:26:19,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:19,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,925 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:19,925 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:19,925 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:19,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741868_1044 src: /172.20.1.10:50030 dest: /172.20.1.12:9866
2025-03-26 02:26:19,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741868_1044 src: /172.20.1.12:35934 dest: /172.20.1.13:9866
2025-03-26 02:26:19,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50030, dest: /172.20.1.12:9866, bytes: 1594, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741868_1044, duration(ns): 2407989
2025-03-26 02:26:19,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35934, dest: /172.20.1.13:9866, bytes: 1594, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741868_1044, duration(ns): 2013214
2025-03-26 02:26:19,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741868_1044, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,932 INFO terminating
2025-03-26 02:26:19,933 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sort.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:19,945 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,946 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/status_api_demo.py._COPYING_
2025-03-26 02:26:19,946 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:19,946 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,946 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:19,946 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:19,946 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:19,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741869_1045 src: /172.20.1.10:46884 dest: /172.20.1.13:9866
2025-03-26 02:26:19,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741869_1045 src: /172.20.1.13:60412 dest: /172.20.1.12:9866
2025-03-26 02:26:19,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46884, dest: /172.20.1.13:9866, bytes: 2368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741869_1045, duration(ns): 1300712
2025-03-26 02:26:19,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60412, dest: /172.20.1.12:9866, bytes: 2368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741869_1045, duration(ns): 1073598
2025-03-26 02:26:19,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741869_1045, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,951 INFO terminating
2025-03-26 02:26:19,952 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/status_api_demo.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:19,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/avro_inputformat.py._COPYING_
2025-03-26 02:26:19,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,959 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:19,959 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:19,959 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:19,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741870_1046 src: /172.20.1.10:50034 dest: /172.20.1.12:9866
2025-03-26 02:26:19,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741870_1046 src: /172.20.1.12:35944 dest: /172.20.1.13:9866
2025-03-26 02:26:19,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50034, dest: /172.20.1.12:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741870_1046, duration(ns): 1268525
2025-03-26 02:26:19,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35944, dest: /172.20.1.13:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741870_1046, duration(ns): 1009663
2025-03-26 02:26:19,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741870_1046, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,964 INFO terminating
2025-03-26 02:26:19,965 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/avro_inputformat.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:19,976 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/logistic_regression.py._COPYING_
2025-03-26 02:26:19,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:19,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,976 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:19,976 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:19,976 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:19,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741871_1047 src: /172.20.1.10:46890 dest: /172.20.1.13:9866
2025-03-26 02:26:19,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741871_1047 src: /172.20.1.13:60414 dest: /172.20.1.12:9866
2025-03-26 02:26:19,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60414, dest: /172.20.1.12:9866, bytes: 3307, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741871_1047, duration(ns): 974820
2025-03-26 02:26:19,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46890, dest: /172.20.1.13:9866, bytes: 3307, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741871_1047, duration(ns): 1259668
2025-03-26 02:26:19,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741871_1047, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,982 INFO terminating
2025-03-26 02:26:19,983 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/logistic_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:19,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/kmeans.py._COPYING_
2025-03-26 02:26:19,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:19,991 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:19,991 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:19,991 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:19,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741872_1048 src: /172.20.1.10:50040 dest: /172.20.1.12:9866
2025-03-26 02:26:19,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741872_1048 src: /172.20.1.12:35958 dest: /172.20.1.13:9866
2025-03-26 02:26:19,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35958, dest: /172.20.1.13:9866, bytes: 2818, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741872_1048, duration(ns): 1066080
2025-03-26 02:26:19,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741872_1048, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:19,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50040, dest: /172.20.1.12:9866, bytes: 2818, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741872_1048, duration(ns): 1857912
2025-03-26 02:26:19,997 INFO terminating
2025-03-26 02:26:19,998 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/kmeans.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,018 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,018 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,018 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,019 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/svd_example.py._COPYING_
2025-03-26 02:26:20,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741873_1049 src: /172.20.1.10:50056 dest: /172.20.1.12:9866
2025-03-26 02:26:20,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741873_1049 src: /172.20.1.12:35960 dest: /172.20.1.13:9866
2025-03-26 02:26:20,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35960, dest: /172.20.1.13:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741873_1049, duration(ns): 1064291
2025-03-26 02:26:20,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741873_1049, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50056, dest: /172.20.1.12:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741873_1049, duration(ns): 1429961
2025-03-26 02:26:20,025 INFO terminating
2025-03-26 02:26:20,026 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/svd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,034 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,034 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,034 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,035 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/random_forest_regression_example.py._COPYING_
2025-03-26 02:26:20,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,035 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,036 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741874_1050 src: /172.20.1.10:46900 dest: /172.20.1.13:9866
2025-03-26 02:26:20,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741874_1050 src: /172.20.1.13:60424 dest: /172.20.1.12:9866
2025-03-26 02:26:20,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46900, dest: /172.20.1.13:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741874_1050, duration(ns): 2138953
2025-03-26 02:26:20,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60424, dest: /172.20.1.12:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741874_1050, duration(ns): 1712641
2025-03-26 02:26:20,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741874_1050, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,046 INFO terminating
2025-03-26 02:26:20,047 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_forest_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/streaming_linear_regression_example.py._COPYING_
2025-03-26 02:26:20,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,054 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,054 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,054 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741875_1051 src: /172.20.1.10:50070 dest: /172.20.1.12:9866
2025-03-26 02:26:20,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741875_1051 src: /172.20.1.12:35966 dest: /172.20.1.13:9866
2025-03-26 02:26:20,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35966, dest: /172.20.1.13:9866, bytes: 2082, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741875_1051, duration(ns): 1154152
2025-03-26 02:26:20,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741875_1051, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,060 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/streaming_linear_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50070, dest: /172.20.1.12:9866, bytes: 2082, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741875_1051, duration(ns): 1520553
2025-03-26 02:26:20,060 INFO terminating
2025-03-26 02:26:20,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/recommendation_example.py._COPYING_
2025-03-26 02:26:20,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,073 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,073 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,073 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741876_1052 src: /172.20.1.10:46916 dest: /172.20.1.13:9866
2025-03-26 02:26:20,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741876_1052 src: /172.20.1.13:60428 dest: /172.20.1.12:9866
2025-03-26 02:26:20,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60428, dest: /172.20.1.12:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741876_1052, duration(ns): 1376575
2025-03-26 02:26:20,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741876_1052, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46916, dest: /172.20.1.13:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741876_1052, duration(ns): 1760013
2025-03-26 02:26:20,079 INFO terminating
2025-03-26 02:26:20,080 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/recommendation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/random_forest_classification_example.py._COPYING_
2025-03-26 02:26:20,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,088 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,088 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,088 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741877_1053 src: /172.20.1.10:46928 dest: /172.20.1.13:9866
2025-03-26 02:26:20,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741877_1053 src: /172.20.1.13:60440 dest: /172.20.1.12:9866
2025-03-26 02:26:20,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60440, dest: /172.20.1.12:9866, bytes: 2533, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741877_1053, duration(ns): 1220803
2025-03-26 02:26:20,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741877_1053, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46928, dest: /172.20.1.13:9866, bytes: 2533, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741877_1053, duration(ns): 1559554
2025-03-26 02:26:20,094 INFO terminating
2025-03-26 02:26:20,095 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_forest_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/gaussian_mixture_model.py._COPYING_
2025-03-26 02:26:20,105 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,105 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,105 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,105 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,105 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,105 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741878_1054 src: /172.20.1.10:50086 dest: /172.20.1.12:9866
2025-03-26 02:26:20,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741878_1054 src: /172.20.1.12:35972 dest: /172.20.1.13:9866
2025-03-26 02:26:20,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50086, dest: /172.20.1.12:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741878_1054, duration(ns): 2796831
2025-03-26 02:26:20,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35972, dest: /172.20.1.13:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741878_1054, duration(ns): 2412105
2025-03-26 02:26:20,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741878_1054, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,112 INFO terminating
2025-03-26 02:26:20,113 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gaussian_mixture_model.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,119 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,119 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,119 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/stratified_sampling_example.py._COPYING_
2025-03-26 02:26:20,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741879_1055 src: /172.20.1.10:50100 dest: /172.20.1.12:9866
2025-03-26 02:26:20,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741879_1055 src: /172.20.1.12:35978 dest: /172.20.1.13:9866
2025-03-26 02:26:20,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50100, dest: /172.20.1.12:9866, bytes: 1329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741879_1055, duration(ns): 1598852
2025-03-26 02:26:20,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35978, dest: /172.20.1.13:9866, bytes: 1329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741879_1055, duration(ns): 1299562
2025-03-26 02:26:20,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741879_1055, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,128 INFO terminating
2025-03-26 02:26:20,131 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/stratified_sampling_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,137 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,137 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,138 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/tf_idf_example.py._COPYING_
2025-03-26 02:26:20,138 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741880_1056 src: /172.20.1.10:50110 dest: /172.20.1.12:9866
2025-03-26 02:26:20,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741880_1056 src: /172.20.1.12:35982 dest: /172.20.1.13:9866
2025-03-26 02:26:20,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35982, dest: /172.20.1.13:9866, bytes: 2027, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741880_1056, duration(ns): 2094183
2025-03-26 02:26:20,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741880_1056, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50110, dest: /172.20.1.12:9866, bytes: 2027, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741880_1056, duration(ns): 2497001
2025-03-26 02:26:20,144 INFO terminating
2025-03-26 02:26:20,147 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/tf_idf_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/bisecting_k_means_example.py._COPYING_
2025-03-26 02:26:20,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,153 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,153 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,153 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741881_1057 src: /172.20.1.10:50124 dest: /172.20.1.12:9866
2025-03-26 02:26:20,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741881_1057 src: /172.20.1.12:35986 dest: /172.20.1.13:9866
2025-03-26 02:26:20,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:35986, dest: /172.20.1.13:9866, bytes: 1512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741881_1057, duration(ns): 1003718
2025-03-26 02:26:20,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741881_1057, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50124, dest: /172.20.1.12:9866, bytes: 1512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741881_1057, duration(ns): 2359907
2025-03-26 02:26:20,160 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/bisecting_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,160 INFO terminating
2025-03-26 02:26:20,166 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/logistic_regression.py._COPYING_
2025-03-26 02:26:20,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,166 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,166 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,166 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741882_1058 src: /172.20.1.10:46944 dest: /172.20.1.13:9866
2025-03-26 02:26:20,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741882_1058 src: /172.20.1.13:60450 dest: /172.20.1.12:9866
2025-03-26 02:26:20,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60450, dest: /172.20.1.12:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741882_1058, duration(ns): 1040674
2025-03-26 02:26:20,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46944, dest: /172.20.1.13:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741882_1058, duration(ns): 4231438
2025-03-26 02:26:20,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741882_1058, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,174 INFO terminating
2025-03-26 02:26:20,175 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/logistic_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,185 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/naive_bayes_example.py._COPYING_
2025-03-26 02:26:20,185 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,185 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,185 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,185 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,185 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,185 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741883_1059 src: /172.20.1.10:50136 dest: /172.20.1.12:9866
2025-03-26 02:26:20,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741883_1059 src: /172.20.1.12:36002 dest: /172.20.1.13:9866
2025-03-26 02:26:20,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36002, dest: /172.20.1.13:9866, bytes: 2246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741883_1059, duration(ns): 936549
2025-03-26 02:26:20,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741883_1059, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50136, dest: /172.20.1.12:9866, bytes: 2246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741883_1059, duration(ns): 2045069
2025-03-26 02:26:20,191 INFO terminating
2025-03-26 02:26:20,192 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/naive_bayes_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,198 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/streaming_k_means_example.py._COPYING_
2025-03-26 02:26:20,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,198 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,198 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,198 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741884_1060 src: /172.20.1.10:46958 dest: /172.20.1.13:9866
2025-03-26 02:26:20,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741884_1060 src: /172.20.1.13:60458 dest: /172.20.1.12:9866
2025-03-26 02:26:20,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46958, dest: /172.20.1.13:9866, bytes: 2530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741884_1060, duration(ns): 1290829
2025-03-26 02:26:20,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60458, dest: /172.20.1.12:9866, bytes: 2530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741884_1060, duration(ns): 1026535
2025-03-26 02:26:20,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741884_1060, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,209 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/streaming_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,209 INFO terminating
2025-03-26 02:26:20,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,219 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,219 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,219 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py._COPYING_
2025-03-26 02:26:20,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741885_1061 src: /172.20.1.10:46966 dest: /172.20.1.13:9866
2025-03-26 02:26:20,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741885_1061 src: /172.20.1.13:60472 dest: /172.20.1.12:9866
2025-03-26 02:26:20,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60472, dest: /172.20.1.12:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741885_1061, duration(ns): 1874502
2025-03-26 02:26:20,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46966, dest: /172.20.1.13:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741885_1061, duration(ns): 2203717
2025-03-26 02:26:20,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741885_1061, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,226 INFO terminating
2025-03-26 02:26:20,227 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,235 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/decision_tree_classification_example.py._COPYING_
2025-03-26 02:26:20,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,235 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,235 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,235 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741886_1062 src: /172.20.1.10:46974 dest: /172.20.1.13:9866
2025-03-26 02:26:20,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741886_1062 src: /172.20.1.13:60474 dest: /172.20.1.12:9866
2025-03-26 02:26:20,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60474, dest: /172.20.1.12:9866, bytes: 2333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741886_1062, duration(ns): 989264
2025-03-26 02:26:20,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46974, dest: /172.20.1.13:9866, bytes: 2333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741886_1062, duration(ns): 1665353
2025-03-26 02:26:20,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741886_1062, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,240 INFO terminating
2025-03-26 02:26:20,241 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/decision_tree_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,248 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/word2vec.py._COPYING_
2025-03-26 02:26:20,248 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,248 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,248 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,248 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,248 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,248 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741887_1063 src: /172.20.1.10:46984 dest: /172.20.1.13:9866
2025-03-26 02:26:20,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741887_1063 src: /172.20.1.13:60476 dest: /172.20.1.12:9866
2025-03-26 02:26:20,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60476, dest: /172.20.1.12:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741887_1063, duration(ns): 1343760
2025-03-26 02:26:20,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741887_1063, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:46984, dest: /172.20.1.13:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741887_1063, duration(ns): 1640462
2025-03-26 02:26:20,254 INFO terminating
2025-03-26 02:26:20,255 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/word2vec.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/isotonic_regression_example.py._COPYING_
2025-03-26 02:26:20,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,260 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,260 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,260 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741888_1064 src: /172.20.1.10:47000 dest: /172.20.1.13:9866
2025-03-26 02:26:20,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741888_1064 src: /172.20.1.13:60486 dest: /172.20.1.12:9866
2025-03-26 02:26:20,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60486, dest: /172.20.1.12:9866, bytes: 2341, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741888_1064, duration(ns): 1513997
2025-03-26 02:26:20,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741888_1064, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,266 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/isotonic_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47000, dest: /172.20.1.13:9866, bytes: 2341, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741888_1064, duration(ns): 1904995
2025-03-26 02:26:20,266 INFO terminating
2025-03-26 02:26:20,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/pca_rowmatrix_example.py._COPYING_
2025-03-26 02:26:20,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,272 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,272 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,272 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741889_1065 src: /172.20.1.10:50146 dest: /172.20.1.12:9866
2025-03-26 02:26:20,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741889_1065 src: /172.20.1.12:36006 dest: /172.20.1.13:9866
2025-03-26 02:26:20,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36006, dest: /172.20.1.13:9866, bytes: 1712, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741889_1065, duration(ns): 1507074
2025-03-26 02:26:20,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741889_1065, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50146, dest: /172.20.1.12:9866, bytes: 1712, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741889_1065, duration(ns): 1810607
2025-03-26 02:26:20,279 INFO terminating
2025-03-26 02:26:20,280 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/pca_rowmatrix_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,285 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/kmeans.py._COPYING_
2025-03-26 02:26:20,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,285 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,285 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,285 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741890_1066 src: /172.20.1.10:47012 dest: /172.20.1.13:9866
2025-03-26 02:26:20,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741890_1066 src: /172.20.1.13:60502 dest: /172.20.1.12:9866
2025-03-26 02:26:20,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60502, dest: /172.20.1.12:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741890_1066, duration(ns): 825194
2025-03-26 02:26:20,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741890_1066, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47012, dest: /172.20.1.13:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741890_1066, duration(ns): 1297992
2025-03-26 02:26:20,290 INFO terminating
2025-03-26 02:26:20,291 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/kmeans.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,296 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/power_iteration_clustering_example.py._COPYING_
2025-03-26 02:26:20,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,296 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,296 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,296 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741891_1067 src: /172.20.1.10:47022 dest: /172.20.1.13:9866
2025-03-26 02:26:20,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741891_1067 src: /172.20.1.13:60512 dest: /172.20.1.12:9866
2025-03-26 02:26:20,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60512, dest: /172.20.1.12:9866, bytes: 1753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741891_1067, duration(ns): 977674
2025-03-26 02:26:20,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741891_1067, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,302 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/power_iteration_clustering_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47022, dest: /172.20.1.13:9866, bytes: 1753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741891_1067, duration(ns): 2015940
2025-03-26 02:26:20,302 INFO terminating
2025-03-26 02:26:20,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,308 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,308 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,308 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,309 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/gradient_boosting_regression_example.py._COPYING_
2025-03-26 02:26:20,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741892_1068 src: /172.20.1.10:50152 dest: /172.20.1.12:9866
2025-03-26 02:26:20,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741892_1068 src: /172.20.1.12:36008 dest: /172.20.1.13:9866
2025-03-26 02:26:20,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36008, dest: /172.20.1.13:9866, bytes: 2404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741892_1068, duration(ns): 1165339
2025-03-26 02:26:20,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741892_1068, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,314 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gradient_boosting_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50152, dest: /172.20.1.12:9866, bytes: 2404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741892_1068, duration(ns): 1639949
2025-03-26 02:26:20,314 INFO terminating
2025-03-26 02:26:20,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/hypothesis_testing_example.py._COPYING_
2025-03-26 02:26:20,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,320 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,320 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,320 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741893_1069 src: /172.20.1.10:47034 dest: /172.20.1.13:9866
2025-03-26 02:26:20,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741893_1069 src: /172.20.1.13:60516 dest: /172.20.1.12:9866
2025-03-26 02:26:20,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60516, dest: /172.20.1.12:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741893_1069, duration(ns): 1167324
2025-03-26 02:26:20,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741893_1069, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47034, dest: /172.20.1.13:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741893_1069, duration(ns): 1883627
2025-03-26 02:26:20,326 INFO terminating
2025-03-26 02:26:20,329 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/hypothesis_testing_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,334 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,334 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,334 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,335 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/__init__.py._COPYING_
2025-03-26 02:26:20,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741894_1070 src: /172.20.1.10:47038 dest: /172.20.1.13:9866
2025-03-26 02:26:20,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741894_1070 src: /172.20.1.13:60518 dest: /172.20.1.12:9866
2025-03-26 02:26:20,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60518, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741894_1070, duration(ns): 2184929
2025-03-26 02:26:20,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47038, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741894_1070, duration(ns): 3012662
2025-03-26 02:26:20,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741894_1070, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,341 INFO terminating
2025-03-26 02:26:20,342 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py._COPYING_
2025-03-26 02:26:20,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,349 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,349 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,349 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741895_1071 src: /172.20.1.10:50162 dest: /172.20.1.12:9866
2025-03-26 02:26:20,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741895_1071 src: /172.20.1.12:36016 dest: /172.20.1.13:9866
2025-03-26 02:26:20,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36016, dest: /172.20.1.13:9866, bytes: 2150, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741895_1071, duration(ns): 820945
2025-03-26 02:26:20,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741895_1071, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50162, dest: /172.20.1.12:9866, bytes: 2150, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741895_1071, duration(ns): 1135206
2025-03-26 02:26:20,354 INFO terminating
2025-03-26 02:26:20,355 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/summary_statistics_example.py._COPYING_
2025-03-26 02:26:20,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,360 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,360 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,360 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741896_1072 src: /172.20.1.10:47054 dest: /172.20.1.13:9866
2025-03-26 02:26:20,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741896_1072 src: /172.20.1.13:60524 dest: /172.20.1.12:9866
2025-03-26 02:26:20,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47054, dest: /172.20.1.13:9866, bytes: 1511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741896_1072, duration(ns): 2418507
2025-03-26 02:26:20,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60524, dest: /172.20.1.12:9866, bytes: 1511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741896_1072, duration(ns): 2093202
2025-03-26 02:26:20,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741896_1072, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,366 INFO terminating
2025-03-26 02:26:20,367 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/summary_statistics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,372 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/decision_tree_regression_example.py._COPYING_
2025-03-26 02:26:20,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,372 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,372 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,372 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741897_1073 src: /172.20.1.10:47060 dest: /172.20.1.13:9866
2025-03-26 02:26:20,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741897_1073 src: /172.20.1.13:60534 dest: /172.20.1.12:9866
2025-03-26 02:26:20,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60534, dest: /172.20.1.12:9866, bytes: 2328, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741897_1073, duration(ns): 1095469
2025-03-26 02:26:20,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741897_1073, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47060, dest: /172.20.1.13:9866, bytes: 2328, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741897_1073, duration(ns): 1485503
2025-03-26 02:26:20,377 INFO terminating
2025-03-26 02:26:20,378 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/decision_tree_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/word2vec_example.py._COPYING_
2025-03-26 02:26:20,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,384 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,384 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,384 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741898_1074 src: /172.20.1.10:47062 dest: /172.20.1.13:9866
2025-03-26 02:26:20,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741898_1074 src: /172.20.1.13:60546 dest: /172.20.1.12:9866
2025-03-26 02:26:20,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47062, dest: /172.20.1.13:9866, bytes: 1326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741898_1074, duration(ns): 1283063
2025-03-26 02:26:20,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60546, dest: /172.20.1.12:9866, bytes: 1326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741898_1074, duration(ns): 929297
2025-03-26 02:26:20,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741898_1074, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,389 INFO terminating
2025-03-26 02:26:20,391 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/word2vec_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/fpgrowth_example.py._COPYING_
2025-03-26 02:26:20,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,396 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,396 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,396 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741899_1075 src: /172.20.1.10:47066 dest: /172.20.1.13:9866
2025-03-26 02:26:20,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741899_1075 src: /172.20.1.13:60556 dest: /172.20.1.12:9866
2025-03-26 02:26:20,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47066, dest: /172.20.1.13:9866, bytes: 1280, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741899_1075, duration(ns): 1622307
2025-03-26 02:26:20,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60556, dest: /172.20.1.12:9866, bytes: 1280, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741899_1075, duration(ns): 1346174
2025-03-26 02:26:20,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741899_1075, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,401 INFO terminating
2025-03-26 02:26:20,402 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/fpgrowth_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,408 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/correlations_example.py._COPYING_
2025-03-26 02:26:20,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,408 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,408 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,408 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741900_1076 src: /172.20.1.10:50166 dest: /172.20.1.12:9866
2025-03-26 02:26:20,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741900_1076 src: /172.20.1.12:36032 dest: /172.20.1.13:9866
2025-03-26 02:26:20,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50166, dest: /172.20.1.12:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741900_1076, duration(ns): 1848041
2025-03-26 02:26:20,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36032, dest: /172.20.1.13:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741900_1076, duration(ns): 1439329
2025-03-26 02:26:20,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741900_1076, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,414 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/correlations_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,414 INFO terminating
2025-03-26 02:26:20,423 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/binary_classification_metrics_example.py._COPYING_
2025-03-26 02:26:20,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,423 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,423 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,423 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741901_1077 src: /172.20.1.10:47072 dest: /172.20.1.13:9866
2025-03-26 02:26:20,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741901_1077 src: /172.20.1.13:60558 dest: /172.20.1.12:9866
2025-03-26 02:26:20,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60558, dest: /172.20.1.12:9866, bytes: 2083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741901_1077, duration(ns): 1320809
2025-03-26 02:26:20,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47072, dest: /172.20.1.13:9866, bytes: 2083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741901_1077, duration(ns): 1947428
2025-03-26 02:26:20,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741901_1077, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,429 INFO terminating
2025-03-26 02:26:20,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/binary_classification_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,440 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/multi_label_metrics_example.py._COPYING_
2025-03-26 02:26:20,440 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,440 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,440 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741902_1078 src: /172.20.1.10:47076 dest: /172.20.1.13:9866
2025-03-26 02:26:20,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741902_1078 src: /172.20.1.13:60562 dest: /172.20.1.12:9866
2025-03-26 02:26:20,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60562, dest: /172.20.1.12:9866, bytes: 2277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741902_1078, duration(ns): 1530221
2025-03-26 02:26:20,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741902_1078, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47076, dest: /172.20.1.13:9866, bytes: 2277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741902_1078, duration(ns): 1803605
2025-03-26 02:26:20,445 INFO terminating
2025-03-26 02:26:20,450 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/multi_label_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,455 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py._COPYING_
2025-03-26 02:26:20,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,455 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,455 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,455 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741903_1079 src: /172.20.1.10:50180 dest: /172.20.1.12:9866
2025-03-26 02:26:20,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741903_1079 src: /172.20.1.12:36044 dest: /172.20.1.13:9866
2025-03-26 02:26:20,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50180, dest: /172.20.1.12:9866, bytes: 1619, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741903_1079, duration(ns): 5034487
2025-03-26 02:26:20,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36044, dest: /172.20.1.13:9866, bytes: 1619, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741903_1079, duration(ns): 998637
2025-03-26 02:26:20,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741903_1079, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,463 INFO terminating
2025-03-26 02:26:20,464 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/gradient_boosting_classification_example.py._COPYING_
2025-03-26 02:26:20,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,469 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741904_1080 src: /172.20.1.10:47078 dest: /172.20.1.13:9866
2025-03-26 02:26:20,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741904_1080 src: /172.20.1.13:60572 dest: /172.20.1.12:9866
2025-03-26 02:26:20,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60572, dest: /172.20.1.12:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741904_1080, duration(ns): 1011312
2025-03-26 02:26:20,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741904_1080, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47078, dest: /172.20.1.13:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741904_1080, duration(ns): 1272712
2025-03-26 02:26:20,474 INFO terminating
2025-03-26 02:26:20,475 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gradient_boosting_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,487 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/correlations.py._COPYING_
2025-03-26 02:26:20,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,487 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,487 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,487 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741905_1081 src: /172.20.1.10:50184 dest: /172.20.1.12:9866
2025-03-26 02:26:20,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741905_1081 src: /172.20.1.12:36060 dest: /172.20.1.13:9866
2025-03-26 02:26:20,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50184, dest: /172.20.1.12:9866, bytes: 2049, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741905_1081, duration(ns): 1325198
2025-03-26 02:26:20,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36060, dest: /172.20.1.13:9866, bytes: 2049, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741905_1081, duration(ns): 1062891
2025-03-26 02:26:20,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741905_1081, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,492 INFO terminating
2025-03-26 02:26:20,493 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/correlations.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,503 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/gaussian_mixture_example.py._COPYING_
2025-03-26 02:26:20,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,503 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,503 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,503 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741906_1082 src: /172.20.1.10:47092 dest: /172.20.1.13:9866
2025-03-26 02:26:20,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741906_1082 src: /172.20.1.13:60576 dest: /172.20.1.12:9866
2025-03-26 02:26:20,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60576, dest: /172.20.1.12:9866, bytes: 1839, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741906_1082, duration(ns): 1337577
2025-03-26 02:26:20,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741906_1082, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47092, dest: /172.20.1.13:9866, bytes: 1839, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741906_1082, duration(ns): 1900039
2025-03-26 02:26:20,510 INFO terminating
2025-03-26 02:26:20,511 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gaussian_mixture_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,517 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/k_means_example.py._COPYING_
2025-03-26 02:26:20,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,517 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,517 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,517 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741907_1083 src: /172.20.1.10:50186 dest: /172.20.1.12:9866
2025-03-26 02:26:20,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741907_1083 src: /172.20.1.12:36062 dest: /172.20.1.13:9866
2025-03-26 02:26:20,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36062, dest: /172.20.1.13:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741907_1083, duration(ns): 808816
2025-03-26 02:26:20,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50186, dest: /172.20.1.12:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741907_1083, duration(ns): 1038447
2025-03-26 02:26:20,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741907_1083, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,522 INFO terminating
2025-03-26 02:26:20,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/ranking_metrics_example.py._COPYING_
2025-03-26 02:26:20,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,529 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,529 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,529 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741908_1084 src: /172.20.1.10:47098 dest: /172.20.1.13:9866
2025-03-26 02:26:20,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741908_1084 src: /172.20.1.13:60582 dest: /172.20.1.12:9866
2025-03-26 02:26:20,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47098, dest: /172.20.1.13:9866, bytes: 2181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741908_1084, duration(ns): 5141439
2025-03-26 02:26:20,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60582, dest: /172.20.1.12:9866, bytes: 2181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741908_1084, duration(ns): 4891290
2025-03-26 02:26:20,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741908_1084, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,537 INFO terminating
2025-03-26 02:26:20,539 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/ranking_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,544 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/multi_class_metrics_example.py._COPYING_
2025-03-26 02:26:20,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,544 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,544 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,544 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741909_1085 src: /172.20.1.10:47106 dest: /172.20.1.13:9866
2025-03-26 02:26:20,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741909_1085 src: /172.20.1.13:60588 dest: /172.20.1.12:9866
2025-03-26 02:26:20,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60588, dest: /172.20.1.12:9866, bytes: 2836, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741909_1085, duration(ns): 991966
2025-03-26 02:26:20,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741909_1085, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47106, dest: /172.20.1.13:9866, bytes: 2836, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741909_1085, duration(ns): 1525202
2025-03-26 02:26:20,549 INFO terminating
2025-03-26 02:26:20,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/multi_class_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,555 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/linear_regression_with_sgd_example.py._COPYING_
2025-03-26 02:26:20,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,555 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,555 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,555 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741910_1086 src: /172.20.1.10:50190 dest: /172.20.1.12:9866
2025-03-26 02:26:20,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741910_1086 src: /172.20.1.12:36068 dest: /172.20.1.13:9866
2025-03-26 02:26:20,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36068, dest: /172.20.1.13:9866, bytes: 2013, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741910_1086, duration(ns): 847204
2025-03-26 02:26:20,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741910_1086, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,562 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/linear_regression_with_sgd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50190, dest: /172.20.1.12:9866, bytes: 2013, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741910_1086, duration(ns): 1206468
2025-03-26 02:26:20,562 INFO terminating
2025-03-26 02:26:20,569 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/standard_scaler_example.py._COPYING_
2025-03-26 02:26:20,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,569 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,569 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,569 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741911_1087 src: /172.20.1.10:50200 dest: /172.20.1.12:9866
2025-03-26 02:26:20,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741911_1087 src: /172.20.1.12:36082 dest: /172.20.1.13:9866
2025-03-26 02:26:20,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50200, dest: /172.20.1.12:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741911_1087, duration(ns): 1182780
2025-03-26 02:26:20,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36082, dest: /172.20.1.13:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741911_1087, duration(ns): 919067
2025-03-26 02:26:20,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741911_1087, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,573 INFO terminating
2025-03-26 02:26:20,574 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/standard_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/kernel_density_estimation_example.py._COPYING_
2025-03-26 02:26:20,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,579 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,579 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,579 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741912_1088 src: /172.20.1.10:50210 dest: /172.20.1.12:9866
2025-03-26 02:26:20,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741912_1088 src: /172.20.1.12:36090 dest: /172.20.1.13:9866
2025-03-26 02:26:20,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50210, dest: /172.20.1.12:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741912_1088, duration(ns): 2081990
2025-03-26 02:26:20,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36090, dest: /172.20.1.13:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741912_1088, duration(ns): 913522
2025-03-26 02:26:20,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741912_1088, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,584 INFO terminating
2025-03-26 02:26:20,585 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/kernel_density_estimation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,596 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/regression_metrics_example.py._COPYING_
2025-03-26 02:26:20,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,596 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,596 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,596 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741913_1089 src: /172.20.1.10:50212 dest: /172.20.1.12:9866
2025-03-26 02:26:20,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741913_1089 src: /172.20.1.12:36100 dest: /172.20.1.13:9866
2025-03-26 02:26:20,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36100, dest: /172.20.1.13:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741913_1089, duration(ns): 1393034
2025-03-26 02:26:20,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741913_1089, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/regression_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50212, dest: /172.20.1.12:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741913_1089, duration(ns): 1692228
2025-03-26 02:26:20,602 INFO terminating
2025-03-26 02:26:20,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/svm_with_sgd_example.py._COPYING_
2025-03-26 02:26:20,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,607 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,607 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,607 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741914_1090 src: /172.20.1.10:47116 dest: /172.20.1.13:9866
2025-03-26 02:26:20,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741914_1090 src: /172.20.1.13:60594 dest: /172.20.1.12:9866
2025-03-26 02:26:20,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47116, dest: /172.20.1.13:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741914_1090, duration(ns): 1258249
2025-03-26 02:26:20,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60594, dest: /172.20.1.12:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741914_1090, duration(ns): 937235
2025-03-26 02:26:20,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741914_1090, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,612 INFO terminating
2025-03-26 02:26:20,614 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/svm_with_sgd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/normalizer_example.py._COPYING_
2025-03-26 02:26:20,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,622 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,622 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,622 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741915_1091 src: /172.20.1.10:47124 dest: /172.20.1.13:9866
2025-03-26 02:26:20,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741915_1091 src: /172.20.1.13:60602 dest: /172.20.1.12:9866
2025-03-26 02:26:20,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60602, dest: /172.20.1.12:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741915_1091, duration(ns): 715836
2025-03-26 02:26:20,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741915_1091, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,627 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/normalizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47124, dest: /172.20.1.13:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741915_1091, duration(ns): 1212939
2025-03-26 02:26:20,627 INFO terminating
2025-03-26 02:26:20,632 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/random_rdd_generation.py._COPYING_
2025-03-26 02:26:20,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:20,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,632 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,632 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,632 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741916_1092 src: /172.20.1.10:50220 dest: /172.20.1.12:9866
2025-03-26 02:26:20,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741916_1092 src: /172.20.1.12:36104 dest: /172.20.1.13:9866
2025-03-26 02:26:20,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36104, dest: /172.20.1.13:9866, bytes: 1905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741916_1092, duration(ns): 824904
2025-03-26 02:26:20,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50220, dest: /172.20.1.12:9866, bytes: 1905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741916_1092, duration(ns): 1189473
2025-03-26 02:26:20,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741916_1092, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,637 INFO terminating
2025-03-26 02:26:20,638 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_rdd_generation.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,642 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/sampled_rdds.py._COPYING_
2025-03-26 02:26:20,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,642 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,642 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,642 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741917_1093 src: /172.20.1.10:47130 dest: /172.20.1.13:9866
2025-03-26 02:26:20,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741917_1093 src: /172.20.1.13:60612 dest: /172.20.1.12:9866
2025-03-26 02:26:20,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47130, dest: /172.20.1.13:9866, bytes: 3185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741917_1093, duration(ns): 3875309
2025-03-26 02:26:20,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60612, dest: /172.20.1.12:9866, bytes: 3185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741917_1093, duration(ns): 706629
2025-03-26 02:26:20,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741917_1093, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,649 INFO terminating
2025-03-26 02:26:20,650 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/sampled_rdds.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,655 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/elementwise_product_example.py._COPYING_
2025-03-26 02:26:20,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,655 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,655 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,655 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741918_1094 src: /172.20.1.10:50222 dest: /172.20.1.12:9866
2025-03-26 02:26:20,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741918_1094 src: /172.20.1.12:36110 dest: /172.20.1.13:9866
2025-03-26 02:26:20,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50222, dest: /172.20.1.12:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741918_1094, duration(ns): 1351764
2025-03-26 02:26:20,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36110, dest: /172.20.1.13:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741918_1094, duration(ns): 834626
2025-03-26 02:26:20,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741918_1094, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,661 INFO terminating
2025-03-26 02:26:20,663 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/elementwise_product_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,667 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,667 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/__init__.py._COPYING_
2025-03-26 02:26:20,668 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741919_1095 src: /172.20.1.10:50230 dest: /172.20.1.12:9866
2025-03-26 02:26:20,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741919_1095 src: /172.20.1.12:36116 dest: /172.20.1.13:9866
2025-03-26 02:26:20,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36116, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741919_1095, duration(ns): 928056
2025-03-26 02:26:20,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741919_1095, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50230, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741919_1095, duration(ns): 1208153
2025-03-26 02:26:20,672 INFO terminating
2025-03-26 02:26:20,673 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,677 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/pagerank.py._COPYING_
2025-03-26 02:26:20,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,677 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,677 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,677 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741920_1096 src: /172.20.1.10:47132 dest: /172.20.1.13:9866
2025-03-26 02:26:20,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741920_1096 src: /172.20.1.13:60618 dest: /172.20.1.12:9866
2025-03-26 02:26:20,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47132, dest: /172.20.1.13:9866, bytes: 3339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741920_1096, duration(ns): 1252067
2025-03-26 02:26:20,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60618, dest: /172.20.1.12:9866, bytes: 3339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741920_1096, duration(ns): 652423
2025-03-26 02:26:20,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741920_1096, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,682 INFO terminating
2025-03-26 02:26:20,683 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/pagerank.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,699 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/fm_regressor_example.py._COPYING_
2025-03-26 02:26:20,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,699 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,699 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,699 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741921_1097 src: /172.20.1.10:47134 dest: /172.20.1.13:9866
2025-03-26 02:26:20,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741921_1097 src: /172.20.1.13:60628 dest: /172.20.1.12:9866
2025-03-26 02:26:20,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47134, dest: /172.20.1.13:9866, bytes: 2559, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741921_1097, duration(ns): 1127261
2025-03-26 02:26:20,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60628, dest: /172.20.1.12:9866, bytes: 2559, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741921_1097, duration(ns): 905943
2025-03-26 02:26:20,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741921_1097, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,703 INFO terminating
2025-03-26 02:26:20,704 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fm_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,710 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/string_indexer_example.py._COPYING_
2025-03-26 02:26:20,710 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,710 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,710 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,710 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,710 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,710 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741922_1098 src: /172.20.1.10:50234 dest: /172.20.1.12:9866
2025-03-26 02:26:20,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741922_1098 src: /172.20.1.12:36120 dest: /172.20.1.13:9866
2025-03-26 02:26:20,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50234, dest: /172.20.1.12:9866, bytes: 1363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741922_1098, duration(ns): 1179040
2025-03-26 02:26:20,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36120, dest: /172.20.1.13:9866, bytes: 1363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741922_1098, duration(ns): 854255
2025-03-26 02:26:20,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741922_1098, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,714 INFO terminating
2025-03-26 02:26:20,715 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/string_indexer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/vector_assembler_example.py._COPYING_
2025-03-26 02:26:20,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,722 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,722 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,722 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741923_1099 src: /172.20.1.10:47150 dest: /172.20.1.13:9866
2025-03-26 02:26:20,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741923_1099 src: /172.20.1.13:60636 dest: /172.20.1.12:9866
2025-03-26 02:26:20,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60636, dest: /172.20.1.12:9866, bytes: 1610, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741923_1099, duration(ns): 703375
2025-03-26 02:26:20,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741923_1099, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,727 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_assembler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47150, dest: /172.20.1.13:9866, bytes: 1610, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741923_1099, duration(ns): 1286075
2025-03-26 02:26:20,727 INFO terminating
2025-03-26 02:26:20,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/robust_scaler_example.py._COPYING_
2025-03-26 02:26:20,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,731 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,731 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,731 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741924_1100 src: /172.20.1.10:47154 dest: /172.20.1.13:9866
2025-03-26 02:26:20,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741924_1100 src: /172.20.1.13:60642 dest: /172.20.1.12:9866
2025-03-26 02:26:20,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60642, dest: /172.20.1.12:9866, bytes: 1600, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741924_1100, duration(ns): 842448
2025-03-26 02:26:20,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741924_1100, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,736 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/robust_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47154, dest: /172.20.1.13:9866, bytes: 1600, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741924_1100, duration(ns): 1362040
2025-03-26 02:26:20,736 INFO terminating
2025-03-26 02:26:20,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_
2025-03-26 02:26:20,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,740 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,740 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,740 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741925_1101 src: /172.20.1.10:50246 dest: /172.20.1.12:9866
2025-03-26 02:26:20,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741925_1101 src: /172.20.1.12:36136 dest: /172.20.1.13:9866
2025-03-26 02:26:20,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36136, dest: /172.20.1.13:9866, bytes: 2653, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741925_1101, duration(ns): 707271
2025-03-26 02:26:20,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741925_1101, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,745 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50246, dest: /172.20.1.12:9866, bytes: 2653, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741925_1101, duration(ns): 1076441
2025-03-26 02:26:20,745 INFO terminating
2025-03-26 02:26:20,750 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/vector_indexer_example.py._COPYING_
2025-03-26 02:26:20,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,750 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,750 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,750 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741926_1102 src: /172.20.1.10:47158 dest: /172.20.1.13:9866
2025-03-26 02:26:20,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741926_1102 src: /172.20.1.13:60646 dest: /172.20.1.12:9866
2025-03-26 02:26:20,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47158, dest: /172.20.1.13:9866, bytes: 1646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741926_1102, duration(ns): 1386962
2025-03-26 02:26:20,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60646, dest: /172.20.1.12:9866, bytes: 1646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741926_1102, duration(ns): 1119724
2025-03-26 02:26:20,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741926_1102, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,754 INFO terminating
2025-03-26 02:26:20,755 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_indexer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/variance_threshold_selector_example.py._COPYING_
2025-03-26 02:26:20,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,759 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,759 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,759 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741927_1103 src: /172.20.1.10:47172 dest: /172.20.1.13:9866
2025-03-26 02:26:20,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741927_1103 src: /172.20.1.13:60658 dest: /172.20.1.12:9866
2025-03-26 02:26:20,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47172, dest: /172.20.1.13:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741927_1103, duration(ns): 1013039
2025-03-26 02:26:20,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60658, dest: /172.20.1.12:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741927_1103, duration(ns): 564101
2025-03-26 02:26:20,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741927_1103, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,763 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/variance_threshold_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,763 INFO terminating
2025-03-26 02:26:20,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,766 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/feature_hasher_example.py._COPYING_
2025-03-26 02:26:20,767 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,767 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741928_1104 src: /172.20.1.10:47180 dest: /172.20.1.13:9866
2025-03-26 02:26:20,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741928_1104 src: /172.20.1.13:60662 dest: /172.20.1.12:9866
2025-03-26 02:26:20,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60662, dest: /172.20.1.12:9866, bytes: 1521, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741928_1104, duration(ns): 726251
2025-03-26 02:26:20,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741928_1104, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47180, dest: /172.20.1.13:9866, bytes: 1521, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741928_1104, duration(ns): 1035234
2025-03-26 02:26:20,772 INFO terminating
2025-03-26 02:26:20,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/feature_hasher_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:20,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_
2025-03-26 02:26:20,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:20,777 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:20,777 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:20,777 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:20,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741929_1105 src: /172.20.1.10:50256 dest: /172.20.1.12:9866
2025-03-26 02:26:20,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741929_1105 src: /172.20.1.12:36140 dest: /172.20.1.13:9866
2025-03-26 02:26:20,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50256, dest: /172.20.1.12:9866, bytes: 1934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741929_1105, duration(ns): 1267104
2025-03-26 02:26:20,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36140, dest: /172.20.1.13:9866, bytes: 1934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741929_1105, duration(ns): 778437
2025-03-26 02:26:20,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741929_1105, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:20,781 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741929_1105 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_
2025-03-26 02:26:20,781 INFO terminating
2025-03-26 02:26:21,182 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,188 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/tf_idf_example.py._COPYING_
2025-03-26 02:26:21,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,188 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,188 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,188 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741930_1106 src: /172.20.1.10:47182 dest: /172.20.1.13:9866
2025-03-26 02:26:21,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741930_1106 src: /172.20.1.13:60668 dest: /172.20.1.12:9866
2025-03-26 02:26:21,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60668, dest: /172.20.1.12:9866, bytes: 1863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741930_1106, duration(ns): 695188
2025-03-26 02:26:21,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47182, dest: /172.20.1.13:9866, bytes: 1863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741930_1106, duration(ns): 1409546
2025-03-26 02:26:21,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741930_1106, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,193 INFO terminating
2025-03-26 02:26:21,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/tf_idf_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,201 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/stopwords_remover_example.py._COPYING_
2025-03-26 02:26:21,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,201 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,201 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,201 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741931_1107 src: /172.20.1.10:50266 dest: /172.20.1.12:9866
2025-03-26 02:26:21,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741931_1107 src: /172.20.1.12:36152 dest: /172.20.1.13:9866
2025-03-26 02:26:21,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36152, dest: /172.20.1.13:9866, bytes: 1395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741931_1107, duration(ns): 846793
2025-03-26 02:26:21,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741931_1107, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,206 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/stopwords_remover_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50266, dest: /172.20.1.12:9866, bytes: 1395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741931_1107, duration(ns): 1108740
2025-03-26 02:26:21,206 INFO terminating
2025-03-26 02:26:21,210 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/cross_validator.py._COPYING_
2025-03-26 02:26:21,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,210 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,210 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,210 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741932_1108 src: /172.20.1.10:50280 dest: /172.20.1.12:9866
2025-03-26 02:26:21,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741932_1108 src: /172.20.1.12:36158 dest: /172.20.1.13:9866
2025-03-26 02:26:21,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36158, dest: /172.20.1.13:9866, bytes: 3904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741932_1108, duration(ns): 890241
2025-03-26 02:26:21,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50280, dest: /172.20.1.12:9866, bytes: 3904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741932_1108, duration(ns): 1500275
2025-03-26 02:26:21,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741932_1108, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,216 INFO terminating
2025-03-26 02:26:21,217 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/cross_validator.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,223 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py._COPYING_
2025-03-26 02:26:21,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,223 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,223 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,223 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741933_1109 src: /172.20.1.10:47184 dest: /172.20.1.13:9866
2025-03-26 02:26:21,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741933_1109 src: /172.20.1.13:60680 dest: /172.20.1.12:9866
2025-03-26 02:26:21,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47184, dest: /172.20.1.13:9866, bytes: 2950, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741933_1109, duration(ns): 1322788
2025-03-26 02:26:21,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60680, dest: /172.20.1.12:9866, bytes: 2950, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741933_1109, duration(ns): 1057071
2025-03-26 02:26:21,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741933_1109, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,228 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,228 INFO terminating
2025-03-26 02:26:21,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/bisecting_k_means_example.py._COPYING_
2025-03-26 02:26:21,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,233 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,233 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,233 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741934_1110 src: /172.20.1.10:50290 dest: /172.20.1.12:9866
2025-03-26 02:26:21,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741934_1110 src: /172.20.1.12:36168 dest: /172.20.1.13:9866
2025-03-26 02:26:21,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50290, dest: /172.20.1.12:9866, bytes: 1953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741934_1110, duration(ns): 975549
2025-03-26 02:26:21,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36168, dest: /172.20.1.13:9866, bytes: 1953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741934_1110, duration(ns): 742984
2025-03-26 02:26:21,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741934_1110, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,237 INFO terminating
2025-03-26 02:26:21,239 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bisecting_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,249 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/correlation_example.py._COPYING_
2025-03-26 02:26:21,249 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,249 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,249 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,249 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,249 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,249 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741935_1111 src: /172.20.1.10:47190 dest: /172.20.1.13:9866
2025-03-26 02:26:21,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741935_1111 src: /172.20.1.13:60686 dest: /172.20.1.12:9866
2025-03-26 02:26:21,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47190, dest: /172.20.1.13:9866, bytes: 1885, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741935_1111, duration(ns): 1069957
2025-03-26 02:26:21,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60686, dest: /172.20.1.12:9866, bytes: 1885, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741935_1111, duration(ns): 789007
2025-03-26 02:26:21,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741935_1111, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,253 INFO terminating
2025-03-26 02:26:21,254 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/correlation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,257 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,257 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,257 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,258 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/kmeans_example.py._COPYING_
2025-03-26 02:26:21,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741936_1112 src: /172.20.1.10:47202 dest: /172.20.1.13:9866
2025-03-26 02:26:21,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741936_1112 src: /172.20.1.13:60702 dest: /172.20.1.12:9866
2025-03-26 02:26:21,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60702, dest: /172.20.1.12:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741936_1112, duration(ns): 754492
2025-03-26 02:26:21,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741936_1112, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,263 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/kmeans_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47202, dest: /172.20.1.13:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741936_1112, duration(ns): 1449695
2025-03-26 02:26:21,263 INFO terminating
2025-03-26 02:26:21,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py._COPYING_
2025-03-26 02:26:21,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,268 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,268 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,268 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741937_1113 src: /172.20.1.10:50294 dest: /172.20.1.12:9866
2025-03-26 02:26:21,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741937_1113 src: /172.20.1.12:36184 dest: /172.20.1.13:9866
2025-03-26 02:26:21,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50294, dest: /172.20.1.12:9866, bytes: 2654, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741937_1113, duration(ns): 1128468
2025-03-26 02:26:21,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36184, dest: /172.20.1.13:9866, bytes: 2654, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741937_1113, duration(ns): 807634
2025-03-26 02:26:21,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741937_1113, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,272 INFO terminating
2025-03-26 02:26:21,273 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,277 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,277 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,277 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/naive_bayes_example.py._COPYING_
2025-03-26 02:26:21,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741938_1114 src: /172.20.1.10:47206 dest: /172.20.1.13:9866
2025-03-26 02:26:21,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741938_1114 src: /172.20.1.13:60712 dest: /172.20.1.12:9866
2025-03-26 02:26:21,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60712, dest: /172.20.1.12:9866, bytes: 1978, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741938_1114, duration(ns): 830260
2025-03-26 02:26:21,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741938_1114, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47206, dest: /172.20.1.13:9866, bytes: 1978, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741938_1114, duration(ns): 1194252
2025-03-26 02:26:21,282 INFO terminating
2025-03-26 02:26:21,284 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/naive_bayes_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,289 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/count_vectorizer_example.py._COPYING_
2025-03-26 02:26:21,290 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,290 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741939_1115 src: /172.20.1.10:47218 dest: /172.20.1.13:9866
2025-03-26 02:26:21,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741939_1115 src: /172.20.1.13:60720 dest: /172.20.1.12:9866
2025-03-26 02:26:21,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47218, dest: /172.20.1.13:9866, bytes: 1509, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741939_1115, duration(ns): 1114304
2025-03-26 02:26:21,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60720, dest: /172.20.1.12:9866, bytes: 1509, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741939_1115, duration(ns): 783670
2025-03-26 02:26:21,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741939_1115, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,294 INFO terminating
2025-03-26 02:26:21,295 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/count_vectorizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/decision_tree_classification_example.py._COPYING_
2025-03-26 02:26:21,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,300 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,300 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,300 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741940_1116 src: /172.20.1.10:50298 dest: /172.20.1.12:9866
2025-03-26 02:26:21,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741940_1116 src: /172.20.1.12:36192 dest: /172.20.1.13:9866
2025-03-26 02:26:21,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36192, dest: /172.20.1.13:9866, bytes: 2964, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741940_1116, duration(ns): 924625
2025-03-26 02:26:21,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50298, dest: /172.20.1.12:9866, bytes: 2964, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741940_1116, duration(ns): 1224528
2025-03-26 02:26:21,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741940_1116, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,304 INFO terminating
2025-03-26 02:26:21,305 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/decision_tree_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,312 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/isotonic_regression_example.py._COPYING_
2025-03-26 02:26:21,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,312 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,312 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,312 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741941_1117 src: /172.20.1.10:50310 dest: /172.20.1.12:9866
2025-03-26 02:26:21,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741941_1117 src: /172.20.1.12:36200 dest: /172.20.1.13:9866
2025-03-26 02:26:21,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36200, dest: /172.20.1.13:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741941_1117, duration(ns): 888173
2025-03-26 02:26:21,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741941_1117, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50310, dest: /172.20.1.12:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741941_1117, duration(ns): 1217879
2025-03-26 02:26:21,317 INFO terminating
2025-03-26 02:26:21,318 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/isotonic_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,324 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/sql_transformer.py._COPYING_
2025-03-26 02:26:21,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,324 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,324 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,324 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741942_1118 src: /172.20.1.10:47224 dest: /172.20.1.13:9866
2025-03-26 02:26:21,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741942_1118 src: /172.20.1.13:60724 dest: /172.20.1.12:9866
2025-03-26 02:26:21,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60724, dest: /172.20.1.12:9866, bytes: 1343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741942_1118, duration(ns): 715023
2025-03-26 02:26:21,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47224, dest: /172.20.1.13:9866, bytes: 1343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741942_1118, duration(ns): 996801
2025-03-26 02:26:21,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741942_1118, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,328 INFO terminating
2025-03-26 02:26:21,329 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/sql_transformer.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,333 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,333 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,333 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,333 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,334 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/polynomial_expansion_example.py._COPYING_
2025-03-26 02:26:21,334 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,334 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741943_1119 src: /172.20.1.10:47236 dest: /172.20.1.13:9866
2025-03-26 02:26:21,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741943_1119 src: /172.20.1.13:60734 dest: /172.20.1.12:9866
2025-03-26 02:26:21,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60734, dest: /172.20.1.12:9866, bytes: 1483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741943_1119, duration(ns): 4313659
2025-03-26 02:26:21,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741943_1119, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47236, dest: /172.20.1.13:9866, bytes: 1483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741943_1119, duration(ns): 5237966
2025-03-26 02:26:21,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/polynomial_expansion_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,345 INFO terminating
2025-03-26 02:26:21,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,351 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,351 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/bucketizer_example.py._COPYING_
2025-03-26 02:26:21,352 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741944_1120 src: /172.20.1.10:50316 dest: /172.20.1.12:9866
2025-03-26 02:26:21,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741944_1120 src: /172.20.1.12:36214 dest: /172.20.1.13:9866
2025-03-26 02:26:21,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36214, dest: /172.20.1.13:9866, bytes: 1580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741944_1120, duration(ns): 907676
2025-03-26 02:26:21,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741944_1120, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50316, dest: /172.20.1.12:9866, bytes: 1580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741944_1120, duration(ns): 1169684
2025-03-26 02:26:21,356 INFO terminating
2025-03-26 02:26:21,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bucketizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/univariate_feature_selector_example.py._COPYING_
2025-03-26 02:26:21,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,361 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,361 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,361 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741945_1121 src: /172.20.1.10:47252 dest: /172.20.1.13:9866
2025-03-26 02:26:21,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741945_1121 src: /172.20.1.13:60748 dest: /172.20.1.12:9866
2025-03-26 02:26:21,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60748, dest: /172.20.1.12:9866, bytes: 2243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741945_1121, duration(ns): 1813023
2025-03-26 02:26:21,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741945_1121, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47252, dest: /172.20.1.13:9866, bytes: 2243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741945_1121, duration(ns): 2998460
2025-03-26 02:26:21,370 INFO terminating
2025-03-26 02:26:21,371 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/univariate_feature_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,380 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/power_iteration_clustering_example.py._COPYING_
2025-03-26 02:26:21,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,380 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,380 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,380 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741946_1122 src: /172.20.1.10:47264 dest: /172.20.1.13:9866
2025-03-26 02:26:21,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741946_1122 src: /172.20.1.13:60750 dest: /172.20.1.12:9866
2025-03-26 02:26:21,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60750, dest: /172.20.1.12:9866, bytes: 1604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741946_1122, duration(ns): 939831
2025-03-26 02:26:21,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741946_1122, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,385 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/power_iteration_clustering_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47264, dest: /172.20.1.13:9866, bytes: 1604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741946_1122, duration(ns): 1182247
2025-03-26 02:26:21,385 INFO terminating
2025-03-26 02:26:21,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,389 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,389 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,389 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/als_example.py._COPYING_
2025-03-26 02:26:21,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741947_1123 src: /172.20.1.10:47270 dest: /172.20.1.13:9866
2025-03-26 02:26:21,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741947_1123 src: /172.20.1.13:60764 dest: /172.20.1.12:9866
2025-03-26 02:26:21,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47270, dest: /172.20.1.13:9866, bytes: 2936, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741947_1123, duration(ns): 948489
2025-03-26 02:26:21,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60764, dest: /172.20.1.12:9866, bytes: 2936, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741947_1123, duration(ns): 748618
2025-03-26 02:26:21,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741947_1123, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,393 INFO terminating
2025-03-26 02:26:21,394 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/als_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,398 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/logistic_regression_summary_example.py._COPYING_
2025-03-26 02:26:21,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,398 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,398 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,398 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741948_1124 src: /172.20.1.10:50332 dest: /172.20.1.12:9866
2025-03-26 02:26:21,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741948_1124 src: /172.20.1.12:36230 dest: /172.20.1.13:9866
2025-03-26 02:26:21,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50332, dest: /172.20.1.12:9866, bytes: 2402, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741948_1124, duration(ns): 1019981
2025-03-26 02:26:21,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36230, dest: /172.20.1.13:9866, bytes: 2402, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741948_1124, duration(ns): 656886
2025-03-26 02:26:21,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741948_1124, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,403 INFO terminating
2025-03-26 02:26:21,405 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/logistic_regression_summary_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,413 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/summarizer_example.py._COPYING_
2025-03-26 02:26:21,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,413 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,413 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,413 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741949_1125 src: /172.20.1.10:47276 dest: /172.20.1.13:9866
2025-03-26 02:26:21,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741949_1125 src: /172.20.1.13:60774 dest: /172.20.1.12:9866
2025-03-26 02:26:21,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47276, dest: /172.20.1.13:9866, bytes: 2121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741949_1125, duration(ns): 1417561
2025-03-26 02:26:21,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60774, dest: /172.20.1.12:9866, bytes: 2121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741949_1125, duration(ns): 795465
2025-03-26 02:26:21,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741949_1125, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/summarizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,418 INFO terminating
2025-03-26 02:26:21,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/vector_slicer_example.py._COPYING_
2025-03-26 02:26:21,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,422 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,422 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,422 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741950_1126 src: /172.20.1.10:47290 dest: /172.20.1.13:9866
2025-03-26 02:26:21,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741950_1126 src: /172.20.1.13:60788 dest: /172.20.1.12:9866
2025-03-26 02:26:21,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47290, dest: /172.20.1.13:9866, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741950_1126, duration(ns): 963690
2025-03-26 02:26:21,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60788, dest: /172.20.1.12:9866, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741950_1126, duration(ns): 694406
2025-03-26 02:26:21,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741950_1126, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,426 INFO terminating
2025-03-26 02:26:21,427 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_slicer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/imputer_example.py._COPYING_
2025-03-26 02:26:21,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,432 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,432 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,432 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741951_1127 src: /172.20.1.10:50348 dest: /172.20.1.12:9866
2025-03-26 02:26:21,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741951_1127 src: /172.20.1.12:36234 dest: /172.20.1.13:9866
2025-03-26 02:26:21,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36234, dest: /172.20.1.13:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741951_1127, duration(ns): 834299
2025-03-26 02:26:21,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741951_1127, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/imputer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50348, dest: /172.20.1.12:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741951_1127, duration(ns): 1254374
2025-03-26 02:26:21,437 INFO terminating
2025-03-26 02:26:21,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/onehot_encoder_example.py._COPYING_
2025-03-26 02:26:21,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,442 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,442 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,442 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741952_1128 src: /172.20.1.10:47306 dest: /172.20.1.13:9866
2025-03-26 02:26:21,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741952_1128 src: /172.20.1.13:60794 dest: /172.20.1.12:9866
2025-03-26 02:26:21,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60794, dest: /172.20.1.12:9866, bytes: 1599, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741952_1128, duration(ns): 592361
2025-03-26 02:26:21,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741952_1128, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47306, dest: /172.20.1.13:9866, bytes: 1599, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741952_1128, duration(ns): 1367223
2025-03-26 02:26:21,447 INFO terminating
2025-03-26 02:26:21,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/onehot_encoder_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,453 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,453 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,453 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,454 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/linearsvc.py._COPYING_
2025-03-26 02:26:21,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741953_1129 src: /172.20.1.10:47318 dest: /172.20.1.13:9866
2025-03-26 02:26:21,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741953_1129 src: /172.20.1.13:60800 dest: /172.20.1.12:9866
2025-03-26 02:26:21,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60800, dest: /172.20.1.12:9866, bytes: 1477, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741953_1129, duration(ns): 744111
2025-03-26 02:26:21,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741953_1129, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,458 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/linearsvc.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47318, dest: /172.20.1.13:9866, bytes: 1477, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741953_1129, duration(ns): 1171905
2025-03-26 02:26:21,458 INFO terminating
2025-03-26 02:26:21,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_
2025-03-26 02:26:21,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,466 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,466 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,466 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741954_1130 src: /172.20.1.10:50358 dest: /172.20.1.12:9866
2025-03-26 02:26:21,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741954_1130 src: /172.20.1.12:36242 dest: /172.20.1.13:9866
2025-03-26 02:26:21,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50358, dest: /172.20.1.12:9866, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741954_1130, duration(ns): 1008527
2025-03-26 02:26:21,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36242, dest: /172.20.1.13:9866, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741954_1130, duration(ns): 766425
2025-03-26 02:26:21,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741954_1130, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,470 INFO terminating
2025-03-26 02:26:21,472 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/fm_classifier_example.py._COPYING_
2025-03-26 02:26:21,476 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,476 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,476 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741955_1131 src: /172.20.1.10:47320 dest: /172.20.1.13:9866
2025-03-26 02:26:21,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741955_1131 src: /172.20.1.13:60814 dest: /172.20.1.12:9866
2025-03-26 02:26:21,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47320, dest: /172.20.1.13:9866, bytes: 2855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741955_1131, duration(ns): 820538
2025-03-26 02:26:21,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60814, dest: /172.20.1.12:9866, bytes: 2855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741955_1131, duration(ns): 609360
2025-03-26 02:26:21,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741955_1131, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,482 INFO terminating
2025-03-26 02:26:21,483 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fm_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,487 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,487 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,487 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,488 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/decision_tree_regression_example.py._COPYING_
2025-03-26 02:26:21,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741956_1132 src: /172.20.1.10:50368 dest: /172.20.1.12:9866
2025-03-26 02:26:21,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741956_1132 src: /172.20.1.12:36258 dest: /172.20.1.13:9866
2025-03-26 02:26:21,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36258, dest: /172.20.1.13:9866, bytes: 2661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741956_1132, duration(ns): 746859
2025-03-26 02:26:21,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741956_1132, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,492 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/decision_tree_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50368, dest: /172.20.1.12:9866, bytes: 2661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741956_1132, duration(ns): 1287705
2025-03-26 02:26:21,492 INFO terminating
2025-03-26 02:26:21,500 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/word2vec_example.py._COPYING_
2025-03-26 02:26:21,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,500 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,500 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,500 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741957_1133 src: /172.20.1.10:50384 dest: /172.20.1.12:9866
2025-03-26 02:26:21,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741957_1133 src: /172.20.1.12:36272 dest: /172.20.1.13:9866
2025-03-26 02:26:21,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50384, dest: /172.20.1.12:9866, bytes: 1737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741957_1133, duration(ns): 1148796
2025-03-26 02:26:21,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36272, dest: /172.20.1.13:9866, bytes: 1737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741957_1133, duration(ns): 866929
2025-03-26 02:26:21,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741957_1133, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/word2vec_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,505 INFO terminating
2025-03-26 02:26:21,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/fpgrowth_example.py._COPYING_
2025-03-26 02:26:21,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,509 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,509 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,509 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741958_1134 src: /172.20.1.10:50400 dest: /172.20.1.12:9866
2025-03-26 02:26:21,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741958_1134 src: /172.20.1.12:36276 dest: /172.20.1.13:9866
2025-03-26 02:26:21,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36276, dest: /172.20.1.13:9866, bytes: 1733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741958_1134, duration(ns): 628222
2025-03-26 02:26:21,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741958_1134, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,513 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fpgrowth_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50400, dest: /172.20.1.12:9866, bytes: 1733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741958_1134, duration(ns): 909073
2025-03-26 02:26:21,513 INFO terminating
2025-03-26 02:26:21,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,517 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,517 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,517 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,518 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/pipeline_example.py._COPYING_
2025-03-26 02:26:21,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741959_1135 src: /172.20.1.10:50402 dest: /172.20.1.12:9866
2025-03-26 02:26:21,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741959_1135 src: /172.20.1.12:36290 dest: /172.20.1.13:9866
2025-03-26 02:26:21,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50402, dest: /172.20.1.12:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741959_1135, duration(ns): 895454
2025-03-26 02:26:21,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36290, dest: /172.20.1.13:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741959_1135, duration(ns): 657871
2025-03-26 02:26:21,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741959_1135, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,521 INFO terminating
2025-03-26 02:26:21,522 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/pipeline_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/logistic_regression_with_elastic_net.py._COPYING_
2025-03-26 02:26:21,526 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,526 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,526 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,526 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,526 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,526 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741960_1136 src: /172.20.1.10:50414 dest: /172.20.1.12:9866
2025-03-26 02:26:21,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741960_1136 src: /172.20.1.12:36294 dest: /172.20.1.13:9866
2025-03-26 02:26:21,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50414, dest: /172.20.1.12:9866, bytes: 1990, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741960_1136, duration(ns): 744134
2025-03-26 02:26:21,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36294, dest: /172.20.1.13:9866, bytes: 1990, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741960_1136, duration(ns): 561491
2025-03-26 02:26:21,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741960_1136, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,529 INFO terminating
2025-03-26 02:26:21,530 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/logistic_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,536 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/train_validation_split.py._COPYING_
2025-03-26 02:26:21,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,536 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,536 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,536 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741961_1137 src: /172.20.1.10:50430 dest: /172.20.1.12:9866
2025-03-26 02:26:21,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741961_1137 src: /172.20.1.12:36306 dest: /172.20.1.13:9866
2025-03-26 02:26:21,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50430, dest: /172.20.1.12:9866, bytes: 2841, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741961_1137, duration(ns): 864941
2025-03-26 02:26:21,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36306, dest: /172.20.1.13:9866, bytes: 2841, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741961_1137, duration(ns): 608560
2025-03-26 02:26:21,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741961_1137, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,540 INFO terminating
2025-03-26 02:26:21,541 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/train_validation_split.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,545 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/interaction_example.py._COPYING_
2025-03-26 02:26:21,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,545 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,545 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,545 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741962_1138 src: /172.20.1.10:50434 dest: /172.20.1.12:9866
2025-03-26 02:26:21,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741962_1138 src: /172.20.1.12:36316 dest: /172.20.1.13:9866
2025-03-26 02:26:21,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36316, dest: /172.20.1.13:9866, bytes: 1868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741962_1138, duration(ns): 649821
2025-03-26 02:26:21,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741962_1138, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50434, dest: /172.20.1.12:9866, bytes: 1868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741962_1138, duration(ns): 842131
2025-03-26 02:26:21,549 INFO terminating
2025-03-26 02:26:21,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/interaction_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/random_forest_classifier_example.py._COPYING_
2025-03-26 02:26:21,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,554 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,554 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,554 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741963_1139 src: /172.20.1.10:50446 dest: /172.20.1.12:9866
2025-03-26 02:26:21,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741963_1139 src: /172.20.1.12:36318 dest: /172.20.1.13:9866
2025-03-26 02:26:21,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50446, dest: /172.20.1.12:9866, bytes: 3195, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741963_1139, duration(ns): 777328
2025-03-26 02:26:21,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36318, dest: /172.20.1.13:9866, bytes: 3195, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741963_1139, duration(ns): 519539
2025-03-26 02:26:21,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741963_1139, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,557 INFO terminating
2025-03-26 02:26:21,558 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/random_forest_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/quantile_discretizer_example.py._COPYING_
2025-03-26 02:26:21,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,562 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,562 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,562 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741964_1140 src: /172.20.1.10:47334 dest: /172.20.1.13:9866
2025-03-26 02:26:21,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741964_1140 src: /172.20.1.13:60830 dest: /172.20.1.12:9866
2025-03-26 02:26:21,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47334, dest: /172.20.1.13:9866, bytes: 1668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741964_1140, duration(ns): 906269
2025-03-26 02:26:21,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60830, dest: /172.20.1.12:9866, bytes: 1668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741964_1140, duration(ns): 652772
2025-03-26 02:26:21,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741964_1140, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,566 INFO terminating
2025-03-26 02:26:21,567 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/quantile_discretizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,570 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,570 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,570 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/aft_survival_regression.py._COPYING_
2025-03-26 02:26:21,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741965_1141 src: /172.20.1.10:50462 dest: /172.20.1.12:9866
2025-03-26 02:26:21,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741965_1141 src: /172.20.1.12:36330 dest: /172.20.1.13:9866
2025-03-26 02:26:21,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36330, dest: /172.20.1.13:9866, bytes: 2112, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741965_1141, duration(ns): 653977
2025-03-26 02:26:21,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741965_1141, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,578 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/aft_survival_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50462, dest: /172.20.1.12:9866, bytes: 2112, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741965_1141, duration(ns): 1005207
2025-03-26 02:26:21,578 INFO terminating
2025-03-26 02:26:21,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/estimator_transformer_param_example.py._COPYING_
2025-03-26 02:26:21,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,582 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,582 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,582 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741966_1142 src: /172.20.1.10:47336 dest: /172.20.1.13:9866
2025-03-26 02:26:21,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741966_1142 src: /172.20.1.13:60832 dest: /172.20.1.12:9866
2025-03-26 02:26:21,586 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/estimator_transformer_param_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47336, dest: /172.20.1.13:9866, bytes: 3951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741966_1142, duration(ns): 752424
2025-03-26 02:26:21,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60832, dest: /172.20.1.12:9866, bytes: 3951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741966_1142, duration(ns): 559856
2025-03-26 02:26:21,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741966_1142, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,586 INFO terminating
2025-03-26 02:26:21,592 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,592 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,592 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/__init__,py._COPYING_
2025-03-26 02:26:21,593 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,593 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,593 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741967_1143 src: /172.20.1.10:50474 dest: /172.20.1.12:9866
2025-03-26 02:26:21,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741967_1143 src: /172.20.1.12:36340 dest: /172.20.1.13:9866
2025-03-26 02:26:21,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36340, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741967_1143, duration(ns): 777789
2025-03-26 02:26:21,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50474, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741967_1143, duration(ns): 1035111
2025-03-26 02:26:21,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741967_1143, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,597 INFO terminating
2025-03-26 02:26:21,598 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/__init__,py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,602 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/chi_square_test_example.py._COPYING_
2025-03-26 02:26:21,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,602 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,602 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,602 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741968_1144 src: /172.20.1.10:47338 dest: /172.20.1.13:9866
2025-03-26 02:26:21,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741968_1144 src: /172.20.1.13:60834 dest: /172.20.1.12:9866
2025-03-26 02:26:21,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60834, dest: /172.20.1.12:9866, bytes: 1869, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741968_1144, duration(ns): 584339
2025-03-26 02:26:21,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47338, dest: /172.20.1.13:9866, bytes: 1869, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741968_1144, duration(ns): 1600979
2025-03-26 02:26:21,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741968_1144, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,607 INFO terminating
2025-03-26 02:26:21,609 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/chi_square_test_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/multilayer_perceptron_classification.py._COPYING_
2025-03-26 02:26:21,612 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,612 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,612 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,612 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,612 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,612 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741969_1145 src: /172.20.1.10:47342 dest: /172.20.1.13:9866
2025-03-26 02:26:21,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741969_1145 src: /172.20.1.13:60840 dest: /172.20.1.12:9866
2025-03-26 02:26:21,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47342, dest: /172.20.1.13:9866, bytes: 2133, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741969_1145, duration(ns): 3102953
2025-03-26 02:26:21,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60840, dest: /172.20.1.12:9866, bytes: 2133, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741969_1145, duration(ns): 749344
2025-03-26 02:26:21,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741969_1145, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,619 INFO terminating
2025-03-26 02:26:21,622 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/multilayer_perceptron_classification.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,627 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,627 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,627 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,628 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/dataframe_example.py._COPYING_
2025-03-26 02:26:21,628 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,628 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,628 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741970_1146 src: /172.20.1.10:47358 dest: /172.20.1.13:9866
2025-03-26 02:26:21,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741970_1146 src: /172.20.1.13:60856 dest: /172.20.1.12:9866
2025-03-26 02:26:21,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47358, dest: /172.20.1.13:9866, bytes: 2663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741970_1146, duration(ns): 1192036
2025-03-26 02:26:21,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60856, dest: /172.20.1.12:9866, bytes: 2663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741970_1146, duration(ns): 929441
2025-03-26 02:26:21,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741970_1146, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,632 INFO terminating
2025-03-26 02:26:21,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/dataframe_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/prefixspan_example.py._COPYING_
2025-03-26 02:26:21,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,640 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,640 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,640 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741971_1147 src: /172.20.1.10:47360 dest: /172.20.1.13:9866
2025-03-26 02:26:21,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741971_1147 src: /172.20.1.13:60860 dest: /172.20.1.12:9866
2025-03-26 02:26:21,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60860, dest: /172.20.1.12:9866, bytes: 1685, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741971_1147, duration(ns): 893916
2025-03-26 02:26:21,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741971_1147, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/prefixspan_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47360, dest: /172.20.1.13:9866, bytes: 1685, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741971_1147, duration(ns): 1119718
2025-03-26 02:26:21,644 INFO terminating
2025-03-26 02:26:21,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/index_to_string_example.py._COPYING_
2025-03-26 02:26:21,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,648 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,648 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,648 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741972_1148 src: /172.20.1.10:47368 dest: /172.20.1.13:9866
2025-03-26 02:26:21,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741972_1148 src: /172.20.1.13:60874 dest: /172.20.1.12:9866
2025-03-26 02:26:21,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47368, dest: /172.20.1.13:9866, bytes: 1975, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741972_1148, duration(ns): 1129390
2025-03-26 02:26:21,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60874, dest: /172.20.1.12:9866, bytes: 1975, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741972_1148, duration(ns): 896159
2025-03-26 02:26:21,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741972_1148, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,652 INFO terminating
2025-03-26 02:26:21,653 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/index_to_string_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/one_vs_rest_example.py._COPYING_
2025-03-26 02:26:21,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,657 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,657 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,657 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741973_1149 src: /172.20.1.10:50476 dest: /172.20.1.12:9866
2025-03-26 02:26:21,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741973_1149 src: /172.20.1.12:36356 dest: /172.20.1.13:9866
2025-03-26 02:26:21,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50476, dest: /172.20.1.12:9866, bytes: 2197, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741973_1149, duration(ns): 1384636
2025-03-26 02:26:21,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36356, dest: /172.20.1.13:9866, bytes: 2197, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741973_1149, duration(ns): 1180880
2025-03-26 02:26:21,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741973_1149, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,661 INFO terminating
2025-03-26 02:26:21,662 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/one_vs_rest_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/chisq_selector_example.py._COPYING_
2025-03-26 02:26:21,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,667 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,667 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,667 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741974_1150 src: /172.20.1.10:50488 dest: /172.20.1.12:9866
2025-03-26 02:26:21,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741974_1150 src: /172.20.1.12:36372 dest: /172.20.1.13:9866
2025-03-26 02:26:21,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50488, dest: /172.20.1.12:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741974_1150, duration(ns): 973092
2025-03-26 02:26:21,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36372, dest: /172.20.1.13:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741974_1150, duration(ns): 752940
2025-03-26 02:26:21,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741974_1150, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/chisq_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,672 INFO terminating
2025-03-26 02:26:21,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/gaussian_mixture_example.py._COPYING_
2025-03-26 02:26:21,676 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,676 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,676 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,676 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,676 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,676 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741975_1151 src: /172.20.1.10:50502 dest: /172.20.1.12:9866
2025-03-26 02:26:21,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741975_1151 src: /172.20.1.12:36380 dest: /172.20.1.13:9866
2025-03-26 02:26:21,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36380, dest: /172.20.1.13:9866, bytes: 1530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741975_1151, duration(ns): 869970
2025-03-26 02:26:21,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741975_1151, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,680 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gaussian_mixture_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50502, dest: /172.20.1.12:9866, bytes: 1530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741975_1151, duration(ns): 1091292
2025-03-26 02:26:21,680 INFO terminating
2025-03-26 02:26:21,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/pca_example.py._COPYING_
2025-03-26 02:26:21,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,685 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,685 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,685 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741976_1152 src: /172.20.1.10:47380 dest: /172.20.1.13:9866
2025-03-26 02:26:21,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741976_1152 src: /172.20.1.13:60886 dest: /172.20.1.12:9866
2025-03-26 02:26:21,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47380, dest: /172.20.1.13:9866, bytes: 1510, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741976_1152, duration(ns): 975629
2025-03-26 02:26:21,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60886, dest: /172.20.1.12:9866, bytes: 1510, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741976_1152, duration(ns): 775366
2025-03-26 02:26:21,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741976_1152, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,688 INFO terminating
2025-03-26 02:26:21,689 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/pca_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,693 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1153, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/generalized_linear_regression_example.py._COPYING_
2025-03-26 02:26:21,693 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,693 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,693 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,693 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,693 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,693 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741977_1153 src: /172.20.1.10:50514 dest: /172.20.1.12:9866
2025-03-26 02:26:21,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741977_1153 src: /172.20.1.12:36396 dest: /172.20.1.13:9866
2025-03-26 02:26:21,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36396, dest: /172.20.1.13:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741977_1153, duration(ns): 758649
2025-03-26 02:26:21,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741977_1153, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,698 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/generalized_linear_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50514, dest: /172.20.1.12:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741977_1153, duration(ns): 1039025
2025-03-26 02:26:21,698 INFO terminating
2025-03-26 02:26:21,705 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,705 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,705 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,705 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,705 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,705 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,706 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1154, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/lda_example.py._COPYING_
2025-03-26 02:26:21,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741978_1154 src: /172.20.1.10:47382 dest: /172.20.1.13:9866
2025-03-26 02:26:21,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741978_1154 src: /172.20.1.13:60898 dest: /172.20.1.12:9866
2025-03-26 02:26:21,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60898, dest: /172.20.1.12:9866, bytes: 1859, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741978_1154, duration(ns): 690247
2025-03-26 02:26:21,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741978_1154, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,710 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/lda_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47382, dest: /172.20.1.13:9866, bytes: 1859, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741978_1154, duration(ns): 1306082
2025-03-26 02:26:21,710 INFO terminating
2025-03-26 02:26:21,717 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1155, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/min_max_scaler_example.py._COPYING_
2025-03-26 02:26:21,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,717 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,717 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,717 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741979_1155 src: /172.20.1.10:47384 dest: /172.20.1.13:9866
2025-03-26 02:26:21,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741979_1155 src: /172.20.1.13:60910 dest: /172.20.1.12:9866
2025-03-26 02:26:21,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60910, dest: /172.20.1.12:9866, bytes: 1759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741979_1155, duration(ns): 2526772
2025-03-26 02:26:21,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741979_1155, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47384, dest: /172.20.1.13:9866, bytes: 1759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741979_1155, duration(ns): 3114699
2025-03-26 02:26:21,724 INFO terminating
2025-03-26 02:26:21,725 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/min_max_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1156, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_
2025-03-26 02:26:21,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,729 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,729 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,729 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741980_1156 src: /172.20.1.10:50526 dest: /172.20.1.12:9866
2025-03-26 02:26:21,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741980_1156 src: /172.20.1.12:36408 dest: /172.20.1.13:9866
2025-03-26 02:26:21,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50526, dest: /172.20.1.12:9866, bytes: 3199, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741980_1156, duration(ns): 1550726
2025-03-26 02:26:21,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36408, dest: /172.20.1.13:9866, bytes: 3199, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741980_1156, duration(ns): 1267915
2025-03-26 02:26:21,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741980_1156, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,734 INFO terminating
2025-03-26 02:26:21,736 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,743 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1157, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/standard_scaler_example.py._COPYING_
2025-03-26 02:26:21,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,743 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,743 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,743 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741981_1157 src: /172.20.1.10:50534 dest: /172.20.1.12:9866
2025-03-26 02:26:21,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741981_1157 src: /172.20.1.12:36424 dest: /172.20.1.13:9866
2025-03-26 02:26:21,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50534, dest: /172.20.1.12:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741981_1157, duration(ns): 1247979
2025-03-26 02:26:21,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36424, dest: /172.20.1.13:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741981_1157, duration(ns): 940546
2025-03-26 02:26:21,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741981_1157, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,747 INFO terminating
2025-03-26 02:26:21,748 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/standard_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1158, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/tokenizer_example.py._COPYING_
2025-03-26 02:26:21,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,753 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,753 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,753 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741982_1158 src: /172.20.1.10:50540 dest: /172.20.1.12:9866
2025-03-26 02:26:21,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741982_1158 src: /172.20.1.12:36432 dest: /172.20.1.13:9866
2025-03-26 02:26:21,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50540, dest: /172.20.1.12:9866, bytes: 2044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741982_1158, duration(ns): 1064107
2025-03-26 02:26:21,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36432, dest: /172.20.1.13:9866, bytes: 2044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741982_1158, duration(ns): 871234
2025-03-26 02:26:21,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741982_1158, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,757 INFO terminating
2025-03-26 02:26:21,758 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/tokenizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,762 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1159, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/rformula_example.py._COPYING_
2025-03-26 02:26:21,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,762 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,762 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,762 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741983_1159 src: /172.20.1.10:47388 dest: /172.20.1.13:9866
2025-03-26 02:26:21,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741983_1159 src: /172.20.1.13:60914 dest: /172.20.1.12:9866
2025-03-26 02:26:21,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47388, dest: /172.20.1.13:9866, bytes: 1481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741983_1159, duration(ns): 841120
2025-03-26 02:26:21,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60914, dest: /172.20.1.12:9866, bytes: 1481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741983_1159, duration(ns): 624141
2025-03-26 02:26:21,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741983_1159, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,766 INFO terminating
2025-03-26 02:26:21,768 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/rformula_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,778 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1160, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/normalizer_example.py._COPYING_
2025-03-26 02:26:21,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,778 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,778 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,778 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741984_1160 src: /172.20.1.10:50542 dest: /172.20.1.12:9866
2025-03-26 02:26:21,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741984_1160 src: /172.20.1.12:36448 dest: /172.20.1.13:9866
2025-03-26 02:26:21,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50542, dest: /172.20.1.12:9866, bytes: 1768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741984_1160, duration(ns): 1937672
2025-03-26 02:26:21,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36448, dest: /172.20.1.13:9866, bytes: 1768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741984_1160, duration(ns): 1701437
2025-03-26 02:26:21,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741984_1160, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,783 INFO terminating
2025-03-26 02:26:21,787 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/normalizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1161, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/n_gram_example.py._COPYING_
2025-03-26 02:26:21,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,791 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,791 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,791 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741985_1161 src: /172.20.1.10:47402 dest: /172.20.1.13:9866
2025-03-26 02:26:21,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741985_1161 src: /172.20.1.13:60926 dest: /172.20.1.12:9866
2025-03-26 02:26:21,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60926, dest: /172.20.1.12:9866, bytes: 1506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741985_1161, duration(ns): 807388
2025-03-26 02:26:21,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741985_1161, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47402, dest: /172.20.1.13:9866, bytes: 1506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741985_1161, duration(ns): 1061872
2025-03-26 02:26:21,796 INFO terminating
2025-03-26 02:26:21,797 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/n_gram_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,801 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,801 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,801 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1162, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/dct_example.py._COPYING_
2025-03-26 02:26:21,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741986_1162 src: /172.20.1.10:47404 dest: /172.20.1.13:9866
2025-03-26 02:26:21,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741986_1162 src: /172.20.1.13:60934 dest: /172.20.1.12:9866
2025-03-26 02:26:21,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47404, dest: /172.20.1.13:9866, bytes: 1470, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741986_1162, duration(ns): 1051496
2025-03-26 02:26:21,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60934, dest: /172.20.1.12:9866, bytes: 1470, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741986_1162, duration(ns): 828204
2025-03-26 02:26:21,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741986_1162, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,806 INFO terminating
2025-03-26 02:26:21,807 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/dct_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,811 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1163, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/min_hash_lsh_example.py._COPYING_
2025-03-26 02:26:21,811 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,811 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,811 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,811 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,811 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,811 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741987_1163 src: /172.20.1.10:50552 dest: /172.20.1.12:9866
2025-03-26 02:26:21,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741987_1163 src: /172.20.1.12:36454 dest: /172.20.1.13:9866
2025-03-26 02:26:21,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50552, dest: /172.20.1.12:9866, bytes: 3183, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741987_1163, duration(ns): 1154035
2025-03-26 02:26:21,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36454, dest: /172.20.1.13:9866, bytes: 3183, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741987_1163, duration(ns): 858618
2025-03-26 02:26:21,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741987_1163, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,815 INFO terminating
2025-03-26 02:26:21,823 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/min_hash_lsh_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,828 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1164, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py._COPYING_
2025-03-26 02:26:21,828 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,828 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,828 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,828 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,828 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741988_1164 src: /172.20.1.10:47418 dest: /172.20.1.13:9866
2025-03-26 02:26:21,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741988_1164 src: /172.20.1.13:60944 dest: /172.20.1.12:9866
2025-03-26 02:26:21,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47418, dest: /172.20.1.13:9866, bytes: 3128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741988_1164, duration(ns): 1219793
2025-03-26 02:26:21,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60944, dest: /172.20.1.12:9866, bytes: 3128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741988_1164, duration(ns): 1003605
2025-03-26 02:26:21,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741988_1164, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,832 INFO terminating
2025-03-26 02:26:21,833 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,837 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1165, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/binarizer_example.py._COPYING_
2025-03-26 02:26:21,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,837 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,837 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,837 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741989_1165 src: /172.20.1.10:47422 dest: /172.20.1.13:9866
2025-03-26 02:26:21,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741989_1165 src: /172.20.1.13:60950 dest: /172.20.1.12:9866
2025-03-26 02:26:21,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47422, dest: /172.20.1.13:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741989_1165, duration(ns): 1116157
2025-03-26 02:26:21,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60950, dest: /172.20.1.12:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741989_1165, duration(ns): 959411
2025-03-26 02:26:21,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741989_1165, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,842 INFO terminating
2025-03-26 02:26:21,843 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/binarizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1166, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/elementwise_product_example.py._COPYING_
2025-03-26 02:26:21,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,847 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,847 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,847 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741990_1166 src: /172.20.1.10:47426 dest: /172.20.1.13:9866
2025-03-26 02:26:21,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741990_1166 src: /172.20.1.13:60960 dest: /172.20.1.12:9866
2025-03-26 02:26:21,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60960, dest: /172.20.1.12:9866, bytes: 1593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741990_1166, duration(ns): 642491
2025-03-26 02:26:21,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741990_1166, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,851 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/elementwise_product_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47426, dest: /172.20.1.13:9866, bytes: 1593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741990_1166, duration(ns): 914940
2025-03-26 02:26:21,851 INFO terminating
2025-03-26 02:26:21,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1167, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/max_abs_scaler_example.py._COPYING_
2025-03-26 02:26:21,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,857 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,857 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,857 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741991_1167 src: /172.20.1.10:47432 dest: /172.20.1.13:9866
2025-03-26 02:26:21,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741991_1167 src: /172.20.1.13:60976 dest: /172.20.1.12:9866
2025-03-26 02:26:21,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47432, dest: /172.20.1.13:9866, bytes: 1673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741991_1167, duration(ns): 1311617
2025-03-26 02:26:21,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60976, dest: /172.20.1.12:9866, bytes: 1673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741991_1167, duration(ns): 679802
2025-03-26 02:26:21,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741991_1167, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,861 INFO terminating
2025-03-26 02:26:21,862 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/max_abs_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1168, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/als.py._COPYING_
2025-03-26 02:26:21,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:21,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,865 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,865 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,865 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741992_1168 src: /172.20.1.10:47434 dest: /172.20.1.13:9866
2025-03-26 02:26:21,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741992_1168 src: /172.20.1.13:60984 dest: /172.20.1.12:9866
2025-03-26 02:26:21,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60984, dest: /172.20.1.12:9866, bytes: 3329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741992_1168, duration(ns): 483878
2025-03-26 02:26:21,869 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/als.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47434, dest: /172.20.1.13:9866, bytes: 3329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741992_1168, duration(ns): 757839
2025-03-26 02:26:21,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741992_1168, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,869 INFO terminating
2025-03-26 02:26:21,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1169, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/sql/hive.py._COPYING_
2025-03-26 02:26:21,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,874 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,874 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,874 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741993_1169 src: /172.20.1.10:50554 dest: /172.20.1.12:9866
2025-03-26 02:26:21,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741993_1169 src: /172.20.1.12:36466 dest: /172.20.1.13:9866
2025-03-26 02:26:21,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50554, dest: /172.20.1.12:9866, bytes: 3260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741993_1169, duration(ns): 745757
2025-03-26 02:26:21,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36466, dest: /172.20.1.13:9866, bytes: 3260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741993_1169, duration(ns): 539956
2025-03-26 02:26:21,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741993_1169, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,878 INFO terminating
2025-03-26 02:26:21,879 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/hive.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:21,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1170, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/sql/__init__.py._COPYING_
2025-03-26 02:26:21,882 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,882 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,882 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:21,882 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:21,882 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:21,882 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:21,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741994_1170 src: /172.20.1.10:47438 dest: /172.20.1.13:9866
2025-03-26 02:26:21,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741994_1170 src: /172.20.1.13:60994 dest: /172.20.1.12:9866
2025-03-26 02:26:21,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47438, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741994_1170, duration(ns): 808736
2025-03-26 02:26:21,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:60994, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741994_1170, duration(ns): 484453
2025-03-26 02:26:21,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741994_1170, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:21,885 INFO terminating
2025-03-26 02:26:21,886 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741994_1170 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/python/sql/__init__.py._COPYING_
2025-03-26 02:26:22,288 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,299 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,299 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,299 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1171, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/sql/datasource.py._COPYING_
2025-03-26 02:26:22,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741995_1171 src: /172.20.1.10:50570 dest: /172.20.1.12:9866
2025-03-26 02:26:22,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741995_1171 src: /172.20.1.12:36478 dest: /172.20.1.13:9866
2025-03-26 02:26:22,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36478, dest: /172.20.1.13:9866, bytes: 15038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741995_1171, duration(ns): 2232529
2025-03-26 02:26:22,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741995_1171, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50570, dest: /172.20.1.12:9866, bytes: 15038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741995_1171, duration(ns): 3280106
2025-03-26 02:26:22,313 INFO terminating
2025-03-26 02:26:22,314 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/datasource.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,322 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1172, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/sql/basic.py._COPYING_
2025-03-26 02:26:22,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,322 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,322 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,322 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741996_1172 src: /172.20.1.10:50576 dest: /172.20.1.12:9866
2025-03-26 02:26:22,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741996_1172 src: /172.20.1.12:36488 dest: /172.20.1.13:9866
2025-03-26 02:26:22,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36488, dest: /172.20.1.13:9866, bytes: 6331, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741996_1172, duration(ns): 3142513
2025-03-26 02:26:22,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741996_1172, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50576, dest: /172.20.1.12:9866, bytes: 6331, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741996_1172, duration(ns): 3353150
2025-03-26 02:26:22,331 INFO terminating
2025-03-26 02:26:22,332 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/basic.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,339 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1173, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/sql/arrow.py._COPYING_
2025-03-26 02:26:22,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,339 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,339 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,339 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741997_1173 src: /172.20.1.10:47440 dest: /172.20.1.13:9866
2025-03-26 02:26:22,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741997_1173 src: /172.20.1.13:32770 dest: /172.20.1.12:9866
2025-03-26 02:26:22,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47440, dest: /172.20.1.13:9866, bytes: 9733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741997_1173, duration(ns): 1010482
2025-03-26 02:26:22,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32770, dest: /172.20.1.12:9866, bytes: 9733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741997_1173, duration(ns): 802259
2025-03-26 02:26:22,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741997_1173, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/arrow.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,344 INFO terminating
2025-03-26 02:26:22,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1174, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/sql/streaming/structured_sessionization.py._COPYING_
2025-03-26 02:26:22,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:22,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,352 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,352 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,352 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741998_1174 src: /172.20.1.10:47454 dest: /172.20.1.13:9866
2025-03-26 02:26:22,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741998_1174 src: /172.20.1.13:32776 dest: /172.20.1.12:9866
2025-03-26 02:26:22,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47454, dest: /172.20.1.13:9866, bytes: 3213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741998_1174, duration(ns): 2629546
2025-03-26 02:26:22,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32776, dest: /172.20.1.12:9866, bytes: 3213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741998_1174, duration(ns): 757046
2025-03-26 02:26:22,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741998_1174, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,357 INFO terminating
2025-03-26 02:26:22,358 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_sessionization.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1175, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py._COPYING_
2025-03-26 02:26:22,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,362 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,362 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,362 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741999_1175 src: /172.20.1.10:47470 dest: /172.20.1.13:9866
2025-03-26 02:26:22,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741999_1175 src: /172.20.1.13:32784 dest: /172.20.1.12:9866
2025-03-26 02:26:22,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32784, dest: /172.20.1.12:9866, bytes: 3172, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741999_1175, duration(ns): 475654
2025-03-26 02:26:22,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073741999_1175, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,366 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47470, dest: /172.20.1.13:9866, bytes: 3172, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073741999_1175, duration(ns): 742236
2025-03-26 02:26:22,366 INFO terminating
2025-03-26 02:26:22,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1176, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/sql/streaming/__init__,py._COPYING_
2025-03-26 02:26:22,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:22,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,370 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,370 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,370 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742000_1176 src: /172.20.1.10:47476 dest: /172.20.1.13:9866
2025-03-26 02:26:22,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742000_1176 src: /172.20.1.13:32792 dest: /172.20.1.12:9866
2025-03-26 02:26:22,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47476, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742000_1176, duration(ns): 871930
2025-03-26 02:26:22,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32792, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742000_1176, duration(ns): 613487
2025-03-26 02:26:22,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742000_1176, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,374 INFO terminating
2025-03-26 02:26:22,378 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/__init__,py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,383 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1177, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount.py._COPYING_
2025-03-26 02:26:22,383 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,383 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,383 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742001_1177 src: /172.20.1.10:50584 dest: /172.20.1.12:9866
2025-03-26 02:26:22,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742001_1177 src: /172.20.1.12:36498 dest: /172.20.1.13:9866
2025-03-26 02:26:22,386 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50584, dest: /172.20.1.12:9866, bytes: 2500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742001_1177, duration(ns): 749947
2025-03-26 02:26:22,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36498, dest: /172.20.1.13:9866, bytes: 2500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742001_1177, duration(ns): 630004
2025-03-26 02:26:22,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742001_1177, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,386 INFO terminating
2025-03-26 02:26:22,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1178, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py._COPYING_
2025-03-26 02:26:22,394 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,394 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,394 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,394 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,394 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,394 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742002_1178 src: /172.20.1.10:47490 dest: /172.20.1.13:9866
2025-03-26 02:26:22,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742002_1178 src: /172.20.1.13:32808 dest: /172.20.1.12:9866
2025-03-26 02:26:22,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32808, dest: /172.20.1.12:9866, bytes: 4047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742002_1178, duration(ns): 1773630
2025-03-26 02:26:22,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742002_1178, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,400 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47490, dest: /172.20.1.13:9866, bytes: 4047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742002_1178, duration(ns): 2286556
2025-03-26 02:26:22,400 INFO terminating
2025-03-26 02:26:22,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:22,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,408 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,408 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,408 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1179, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/streaming/queue_stream.py._COPYING_
2025-03-26 02:26:22,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742003_1179 src: /172.20.1.10:50588 dest: /172.20.1.12:9866
2025-03-26 02:26:22,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742003_1179 src: /172.20.1.12:36514 dest: /172.20.1.13:9866
2025-03-26 02:26:22,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50588, dest: /172.20.1.12:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742003_1179, duration(ns): 987145
2025-03-26 02:26:22,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36514, dest: /172.20.1.13:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742003_1179, duration(ns): 820555
2025-03-26 02:26:22,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742003_1179, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,412 INFO terminating
2025-03-26 02:26:22,413 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/queue_stream.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,417 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1180, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/streaming/network_wordcount.py._COPYING_
2025-03-26 02:26:22,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,417 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,417 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,417 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742004_1180 src: /172.20.1.10:50590 dest: /172.20.1.12:9866
2025-03-26 02:26:22,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742004_1180 src: /172.20.1.12:36528 dest: /172.20.1.13:9866
2025-03-26 02:26:22,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50590, dest: /172.20.1.12:9866, bytes: 1883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742004_1180, duration(ns): 668010
2025-03-26 02:26:22,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36528, dest: /172.20.1.13:9866, bytes: 1883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742004_1180, duration(ns): 520452
2025-03-26 02:26:22,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742004_1180, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,420 INFO terminating
2025-03-26 02:26:22,425 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1181, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/streaming/__init__.py._COPYING_
2025-03-26 02:26:22,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,425 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,425 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,425 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742005_1181 src: /172.20.1.10:50598 dest: /172.20.1.12:9866
2025-03-26 02:26:22,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742005_1181 src: /172.20.1.12:36532 dest: /172.20.1.13:9866
2025-03-26 02:26:22,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36532, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742005_1181, duration(ns): 583241
2025-03-26 02:26:22,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742005_1181, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50598, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742005_1181, duration(ns): 1295339
2025-03-26 02:26:22,430 INFO terminating
2025-03-26 02:26:22,434 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1182, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/streaming/sql_network_wordcount.py._COPYING_
2025-03-26 02:26:22,434 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,434 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,434 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,434 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,434 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,434 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742006_1182 src: /172.20.1.10:47504 dest: /172.20.1.13:9866
2025-03-26 02:26:22,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742006_1182 src: /172.20.1.13:32810 dest: /172.20.1.12:9866
2025-03-26 02:26:22,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47504, dest: /172.20.1.13:9866, bytes: 3297, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742006_1182, duration(ns): 716905
2025-03-26 02:26:22,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32810, dest: /172.20.1.12:9866, bytes: 3297, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742006_1182, duration(ns): 528791
2025-03-26 02:26:22,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742006_1182, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,437 INFO terminating
2025-03-26 02:26:22,438 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/sql_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,442 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1183, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/streaming/hdfs_wordcount.py._COPYING_
2025-03-26 02:26:22,443 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742007_1183 src: /172.20.1.10:47512 dest: /172.20.1.13:9866
2025-03-26 02:26:22,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742007_1183 src: /172.20.1.13:32812 dest: /172.20.1.12:9866
2025-03-26 02:26:22,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47512, dest: /172.20.1.13:9866, bytes: 1832, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742007_1183, duration(ns): 2071839
2025-03-26 02:26:22,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32812, dest: /172.20.1.12:9866, bytes: 1832, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742007_1183, duration(ns): 1791825
2025-03-26 02:26:22,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742007_1183, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,447 INFO terminating
2025-03-26 02:26:22,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/hdfs_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1184, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/streaming/network_wordjoinsentiments.py._COPYING_
2025-03-26 02:26:22,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:22,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,451 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,451 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,451 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742008_1184 src: /172.20.1.10:47522 dest: /172.20.1.13:9866
2025-03-26 02:26:22,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742008_1184 src: /172.20.1.13:32820 dest: /172.20.1.12:9866
2025-03-26 02:26:22,454 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/network_wordjoinsentiments.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47522, dest: /172.20.1.13:9866, bytes: 3393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742008_1184, duration(ns): 599488
2025-03-26 02:26:22,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32820, dest: /172.20.1.12:9866, bytes: 3393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742008_1184, duration(ns): 389197
2025-03-26 02:26:22,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742008_1184, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,454 INFO terminating
2025-03-26 02:26:22,458 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1185, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_
2025-03-26 02:26:22,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,458 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:22,458 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:22,458 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:22,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742009_1185 src: /172.20.1.10:50602 dest: /172.20.1.12:9866
2025-03-26 02:26:22,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742009_1185 src: /172.20.1.12:36546 dest: /172.20.1.13:9866
2025-03-26 02:26:22,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50602, dest: /172.20.1.12:9866, bytes: 2310, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742009_1185, duration(ns): 774138
2025-03-26 02:26:22,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36546, dest: /172.20.1.13:9866, bytes: 2310, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742009_1185, duration(ns): 464543
2025-03-26 02:26:22,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742009_1185, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,462 INFO terminating
2025-03-26 02:26:22,463 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742009_1185 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_
2025-03-26 02:26:22,864 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,868 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1186, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/streaming/recoverable_network_wordcount.py._COPYING_
2025-03-26 02:26:22,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742010_1186 src: /172.20.1.10:50616 dest: /172.20.1.12:9866
2025-03-26 02:26:22,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742010_1186 src: /172.20.1.12:36556 dest: /172.20.1.13:9866
2025-03-26 02:26:22,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742010_1186 src: /172.20.1.13:57254 dest: /172.20.1.11:9866
2025-03-26 02:26:22,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36556, dest: /172.20.1.13:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742010_1186, duration(ns): 3869197
2025-03-26 02:26:22,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57254, dest: /172.20.1.11:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742010_1186, duration(ns): 3311929
2025-03-26 02:26:22,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742010_1186, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,876 INFO terminating
2025-03-26 02:26:22,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50616, dest: /172.20.1.12:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742010_1186, duration(ns): 4157253
2025-03-26 02:26:22,877 INFO terminating
2025-03-26 02:26:22,878 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/recoverable_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1187, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/data-manipulation.R._COPYING_
2025-03-26 02:26:22,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742011_1187 src: /172.20.1.10:50628 dest: /172.20.1.12:9866
2025-03-26 02:26:22,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742011_1187 src: /172.20.1.12:36558 dest: /172.20.1.13:9866
2025-03-26 02:26:22,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742011_1187 src: /172.20.1.13:57264 dest: /172.20.1.11:9866
2025-03-26 02:26:22,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57264, dest: /172.20.1.11:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742011_1187, duration(ns): 1759126
2025-03-26 02:26:22,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742011_1187, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50628, dest: /172.20.1.12:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742011_1187, duration(ns): 2463621
2025-03-26 02:26:22,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36558, dest: /172.20.1.13:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742011_1187, duration(ns): 2113474
2025-03-26 02:26:22,897 INFO terminating
2025-03-26 02:26:22,898 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/data-manipulation.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,898 INFO terminating
2025-03-26 02:26:22,903 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1188, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/RSparkSQLExample.R._COPYING_
2025-03-26 02:26:22,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742012_1188 src: /172.20.1.10:50644 dest: /172.20.1.12:9866
2025-03-26 02:26:22,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742012_1188 src: /172.20.1.12:53518 dest: /172.20.1.11:9866
2025-03-26 02:26:22,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742012_1188 src: /172.20.1.11:43790 dest: /172.20.1.13:9866
2025-03-26 02:26:22,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43790, dest: /172.20.1.13:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742012_1188, duration(ns): 4049845
2025-03-26 02:26:22,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53518, dest: /172.20.1.11:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742012_1188, duration(ns): 4275198
2025-03-26 02:26:22,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742012_1188, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50644, dest: /172.20.1.12:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742012_1188, duration(ns): 5008542
2025-03-26 02:26:22,913 INFO terminating
2025-03-26 02:26:22,913 INFO terminating
2025-03-26 02:26:22,914 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/RSparkSQLExample.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1189, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/als.R._COPYING_
2025-03-26 02:26:22,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742013_1189 src: /172.20.1.10:47524 dest: /172.20.1.13:9866
2025-03-26 02:26:22,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742013_1189 src: /172.20.1.13:57276 dest: /172.20.1.11:9866
2025-03-26 02:26:22,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742013_1189 src: /172.20.1.11:36150 dest: /172.20.1.12:9866
2025-03-26 02:26:22,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36150, dest: /172.20.1.12:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742013_1189, duration(ns): 1533819
2025-03-26 02:26:22,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57276, dest: /172.20.1.11:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742013_1189, duration(ns): 2189425
2025-03-26 02:26:22,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742013_1189, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,928 INFO terminating
2025-03-26 02:26:22,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47524, dest: /172.20.1.13:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742013_1189, duration(ns): 2637577
2025-03-26 02:26:22,929 INFO terminating
2025-03-26 02:26:22,930 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/als.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1190, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/ml.R._COPYING_
2025-03-26 02:26:22,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742014_1190 src: /172.20.1.10:50022 dest: /172.20.1.11:9866
2025-03-26 02:26:22,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742014_1190 src: /172.20.1.11:36160 dest: /172.20.1.12:9866
2025-03-26 02:26:22,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742014_1190 src: /172.20.1.12:36570 dest: /172.20.1.13:9866
2025-03-26 02:26:22,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36160, dest: /172.20.1.12:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742014_1190, duration(ns): 5037067
2025-03-26 02:26:22,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36570, dest: /172.20.1.13:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742014_1190, duration(ns): 4706720
2025-03-26 02:26:22,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742014_1190, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,944 INFO terminating
2025-03-26 02:26:22,945 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/ml.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50022, dest: /172.20.1.11:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742014_1190, duration(ns): 5326030
2025-03-26 02:26:22,945 INFO terminating
2025-03-26 02:26:22,950 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1191, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/prefixSpan.R._COPYING_
2025-03-26 02:26:22,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742015_1191 src: /172.20.1.10:50032 dest: /172.20.1.11:9866
2025-03-26 02:26:22,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742015_1191 src: /172.20.1.11:36168 dest: /172.20.1.12:9866
2025-03-26 02:26:22,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742015_1191 src: /172.20.1.12:36572 dest: /172.20.1.13:9866
2025-03-26 02:26:22,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36168, dest: /172.20.1.12:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742015_1191, duration(ns): 2040345
2025-03-26 02:26:22,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36572, dest: /172.20.1.13:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742015_1191, duration(ns): 1711734
2025-03-26 02:26:22,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742015_1191, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,957 INFO terminating
2025-03-26 02:26:22,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50032, dest: /172.20.1.11:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742015_1191, duration(ns): 2258099
2025-03-26 02:26:22,958 INFO terminating
2025-03-26 02:26:22,959 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/prefixSpan.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1192, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_
2025-03-26 02:26:22,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742016_1192 src: /172.20.1.10:47538 dest: /172.20.1.13:9866
2025-03-26 02:26:22,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742016_1192 src: /172.20.1.13:32830 dest: /172.20.1.12:9866
2025-03-26 02:26:22,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742016_1192 src: /172.20.1.12:53526 dest: /172.20.1.11:9866
2025-03-26 02:26:22,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53526, dest: /172.20.1.11:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742016_1192, duration(ns): 1736225
2025-03-26 02:26:22,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742016_1192, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47538, dest: /172.20.1.13:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742016_1192, duration(ns): 3490852
2025-03-26 02:26:22,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32830, dest: /172.20.1.12:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742016_1192, duration(ns): 2676756
2025-03-26 02:26:22,973 INFO terminating
2025-03-26 02:26:22,973 INFO terminating
2025-03-26 02:26:22,976 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1193, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/lm_with_elastic_net.R._COPYING_
2025-03-26 02:26:22,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742017_1193 src: /172.20.1.10:50044 dest: /172.20.1.11:9866
2025-03-26 02:26:22,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742017_1193 src: /172.20.1.11:36178 dest: /172.20.1.12:9866
2025-03-26 02:26:22,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742017_1193 src: /172.20.1.12:36582 dest: /172.20.1.13:9866
2025-03-26 02:26:22,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36582, dest: /172.20.1.13:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742017_1193, duration(ns): 1212732
2025-03-26 02:26:22,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742017_1193, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50044, dest: /172.20.1.11:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742017_1193, duration(ns): 2267391
2025-03-26 02:26:22,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36178, dest: /172.20.1.12:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742017_1193, duration(ns): 1944251
2025-03-26 02:26:22,987 INFO terminating
2025-03-26 02:26:22,987 INFO terminating
2025-03-26 02:26:22,988 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/lm_with_elastic_net.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:22,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1194, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/naiveBayes.R._COPYING_
2025-03-26 02:26:22,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:22,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742018_1194 src: /172.20.1.10:50046 dest: /172.20.1.11:9866
2025-03-26 02:26:22,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742018_1194 src: /172.20.1.11:36194 dest: /172.20.1.12:9866
2025-03-26 02:26:22,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742018_1194 src: /172.20.1.12:36598 dest: /172.20.1.13:9866
2025-03-26 02:26:22,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36194, dest: /172.20.1.12:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742018_1194, duration(ns): 1323885
2025-03-26 02:26:22,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36598, dest: /172.20.1.13:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742018_1194, duration(ns): 1063378
2025-03-26 02:26:22,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742018_1194, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:22,998 INFO terminating
2025-03-26 02:26:22,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50046, dest: /172.20.1.11:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742018_1194, duration(ns): 1984916
2025-03-26 02:26:22,999 INFO terminating
2025-03-26 02:26:23,000 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/naiveBayes.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,006 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1195, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/decisionTree.R._COPYING_
2025-03-26 02:26:23,006 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,006 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742019_1195 src: /172.20.1.10:50660 dest: /172.20.1.12:9866
2025-03-26 02:26:23,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742019_1195 src: /172.20.1.12:36604 dest: /172.20.1.13:9866
2025-03-26 02:26:23,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742019_1195 src: /172.20.1.13:57290 dest: /172.20.1.11:9866
2025-03-26 02:26:23,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57290, dest: /172.20.1.11:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742019_1195, duration(ns): 1869075
2025-03-26 02:26:23,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50660, dest: /172.20.1.12:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742019_1195, duration(ns): 2627310
2025-03-26 02:26:23,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36604, dest: /172.20.1.13:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742019_1195, duration(ns): 2265006
2025-03-26 02:26:23,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742019_1195, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,013 INFO terminating
2025-03-26 02:26:23,013 INFO terminating
2025-03-26 02:26:23,014 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/decisionTree.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,018 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1196, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/lda.R._COPYING_
2025-03-26 02:26:23,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742020_1196 src: /172.20.1.10:47546 dest: /172.20.1.13:9866
2025-03-26 02:26:23,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742020_1196 src: /172.20.1.13:57296 dest: /172.20.1.11:9866
2025-03-26 02:26:23,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742020_1196 src: /172.20.1.11:36202 dest: /172.20.1.12:9866
2025-03-26 02:26:23,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36202, dest: /172.20.1.12:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742020_1196, duration(ns): 1644889
2025-03-26 02:26:23,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742020_1196, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47546, dest: /172.20.1.13:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742020_1196, duration(ns): 2327730
2025-03-26 02:26:23,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57296, dest: /172.20.1.11:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742020_1196, duration(ns): 1873570
2025-03-26 02:26:23,024 INFO terminating
2025-03-26 02:26:23,025 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/lda.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,025 INFO terminating
2025-03-26 02:26:23,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1197, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/survreg.R._COPYING_
2025-03-26 02:26:23,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742021_1197 src: /172.20.1.10:50662 dest: /172.20.1.12:9866
2025-03-26 02:26:23,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742021_1197 src: /172.20.1.12:36612 dest: /172.20.1.13:9866
2025-03-26 02:26:23,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742021_1197 src: /172.20.1.13:57304 dest: /172.20.1.11:9866
2025-03-26 02:26:23,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36612, dest: /172.20.1.13:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742021_1197, duration(ns): 1479636
2025-03-26 02:26:23,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57304, dest: /172.20.1.11:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742021_1197, duration(ns): 1120141
2025-03-26 02:26:23,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742021_1197, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,034 INFO terminating
2025-03-26 02:26:23,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50662, dest: /172.20.1.12:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742021_1197, duration(ns): 1784691
2025-03-26 02:26:23,035 INFO terminating
2025-03-26 02:26:23,036 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/survreg.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,037 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,037 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,037 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,037 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,040 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1198, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/svmLinear.R._COPYING_
2025-03-26 02:26:23,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742022_1198 src: /172.20.1.10:47548 dest: /172.20.1.13:9866
2025-03-26 02:26:23,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742022_1198 src: /172.20.1.13:32840 dest: /172.20.1.12:9866
2025-03-26 02:26:23,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742022_1198 src: /172.20.1.12:53530 dest: /172.20.1.11:9866
2025-03-26 02:26:23,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53530, dest: /172.20.1.11:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742022_1198, duration(ns): 2581229
2025-03-26 02:26:23,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742022_1198, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47548, dest: /172.20.1.13:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742022_1198, duration(ns): 3796484
2025-03-26 02:26:23,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32840, dest: /172.20.1.12:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742022_1198, duration(ns): 3484247
2025-03-26 02:26:23,048 INFO terminating
2025-03-26 02:26:23,048 INFO terminating
2025-03-26 02:26:23,049 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/svmLinear.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1199, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/isoreg.R._COPYING_
2025-03-26 02:26:23,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742023_1199 src: /172.20.1.10:50058 dest: /172.20.1.11:9866
2025-03-26 02:26:23,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742023_1199 src: /172.20.1.11:43804 dest: /172.20.1.13:9866
2025-03-26 02:26:23,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742023_1199 src: /172.20.1.13:32852 dest: /172.20.1.12:9866
2025-03-26 02:26:23,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43804, dest: /172.20.1.13:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742023_1199, duration(ns): 1497079
2025-03-26 02:26:23,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32852, dest: /172.20.1.12:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742023_1199, duration(ns): 1338077
2025-03-26 02:26:23,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742023_1199, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,057 INFO terminating
2025-03-26 02:26:23,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/isoreg.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50058, dest: /172.20.1.11:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742023_1199, duration(ns): 1780456
2025-03-26 02:26:23,058 INFO terminating
2025-03-26 02:26:23,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742024_1200, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/bisectingKmeans.R._COPYING_
2025-03-26 02:26:23,062 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,062 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742024_1200 src: /172.20.1.10:47560 dest: /172.20.1.13:9866
2025-03-26 02:26:23,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742024_1200 src: /172.20.1.13:32860 dest: /172.20.1.12:9866
2025-03-26 02:26:23,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742024_1200 src: /172.20.1.12:53544 dest: /172.20.1.11:9866
2025-03-26 02:26:23,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53544, dest: /172.20.1.11:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742024_1200, duration(ns): 1356617
2025-03-26 02:26:23,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32860, dest: /172.20.1.12:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742024_1200, duration(ns): 2707374
2025-03-26 02:26:23,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742024_1200, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,068 INFO terminating
2025-03-26 02:26:23,069 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/bisectingKmeans.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47560, dest: /172.20.1.13:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742024_1200, duration(ns): 2998873
2025-03-26 02:26:23,069 INFO terminating
2025-03-26 02:26:23,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742025_1201, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/mlp.R._COPYING_
2025-03-26 02:26:23,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742025_1201 src: /172.20.1.10:50674 dest: /172.20.1.12:9866
2025-03-26 02:26:23,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742025_1201 src: /172.20.1.11:43818 dest: /172.20.1.13:9866
2025-03-26 02:26:23,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742025_1201 src: /172.20.1.12:53552 dest: /172.20.1.11:9866
2025-03-26 02:26:23,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43818, dest: /172.20.1.13:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742025_1201, duration(ns): 1290798
2025-03-26 02:26:23,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742025_1201, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50674, dest: /172.20.1.12:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742025_1201, duration(ns): 1708043
2025-03-26 02:26:23,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53552, dest: /172.20.1.11:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742025_1201, duration(ns): 1418159
2025-03-26 02:26:23,078 INFO terminating
2025-03-26 02:26:23,078 INFO terminating
2025-03-26 02:26:23,079 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/mlp.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,082 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742026_1202, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/fpm.R._COPYING_
2025-03-26 02:26:23,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742026_1202 src: /172.20.1.10:50680 dest: /172.20.1.12:9866
2025-03-26 02:26:23,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742026_1202 src: /172.20.1.12:53566 dest: /172.20.1.11:9866
2025-03-26 02:26:23,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742026_1202 src: /172.20.1.11:43820 dest: /172.20.1.13:9866
2025-03-26 02:26:23,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43820, dest: /172.20.1.13:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742026_1202, duration(ns): 8915810
2025-03-26 02:26:23,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742026_1202, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50680, dest: /172.20.1.12:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742026_1202, duration(ns): 9617233
2025-03-26 02:26:23,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53566, dest: /172.20.1.11:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742026_1202, duration(ns): 9057280
2025-03-26 02:26:23,096 INFO terminating
2025-03-26 02:26:23,096 INFO terminating
2025-03-26 02:26:23,097 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fpm.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,100 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742027_1203, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/glm.R._COPYING_
2025-03-26 02:26:23,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742027_1203 src: /172.20.1.10:50686 dest: /172.20.1.12:9866
2025-03-26 02:26:23,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742027_1203 src: /172.20.1.12:53576 dest: /172.20.1.11:9866
2025-03-26 02:26:23,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742027_1203 src: /172.20.1.11:43826 dest: /172.20.1.13:9866
2025-03-26 02:26:23,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43826, dest: /172.20.1.13:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742027_1203, duration(ns): 3222013
2025-03-26 02:26:23,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742027_1203, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50686, dest: /172.20.1.12:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742027_1203, duration(ns): 3958950
2025-03-26 02:26:23,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53576, dest: /172.20.1.11:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742027_1203, duration(ns): 3469074
2025-03-26 02:26:23,108 INFO terminating
2025-03-26 02:26:23,108 INFO terminating
2025-03-26 02:26:23,109 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/glm.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742028_1204, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/randomForest.R._COPYING_
2025-03-26 02:26:23,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742028_1204 src: /172.20.1.10:50690 dest: /172.20.1.12:9866
2025-03-26 02:26:23,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742028_1204 src: /172.20.1.12:53580 dest: /172.20.1.11:9866
2025-03-26 02:26:23,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742028_1204 src: /172.20.1.11:43832 dest: /172.20.1.13:9866
2025-03-26 02:26:23,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50690, dest: /172.20.1.12:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742028_1204, duration(ns): 1790946
2025-03-26 02:26:23,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43832, dest: /172.20.1.13:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742028_1204, duration(ns): 1188134
2025-03-26 02:26:23,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53580, dest: /172.20.1.11:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742028_1204, duration(ns): 1389796
2025-03-26 02:26:23,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742028_1204, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,118 INFO terminating
2025-03-26 02:26:23,118 INFO terminating
2025-03-26 02:26:23,119 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/randomForest.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742029_1205, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/gaussianMixture.R._COPYING_
2025-03-26 02:26:23,126 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,126 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742029_1205 src: /172.20.1.10:50068 dest: /172.20.1.11:9866
2025-03-26 02:26:23,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742029_1205 src: /172.20.1.11:36216 dest: /172.20.1.12:9866
2025-03-26 02:26:23,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742029_1205 src: /172.20.1.12:36614 dest: /172.20.1.13:9866
2025-03-26 02:26:23,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36614, dest: /172.20.1.13:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742029_1205, duration(ns): 5197867
2025-03-26 02:26:23,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50068, dest: /172.20.1.11:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742029_1205, duration(ns): 5966212
2025-03-26 02:26:23,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36216, dest: /172.20.1.12:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742029_1205, duration(ns): 5573301
2025-03-26 02:26:23,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742029_1205, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,136 INFO terminating
2025-03-26 02:26:23,137 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/gaussianMixture.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,137 INFO terminating
2025-03-26 02:26:23,141 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742030_1206, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/fmClassifier.R._COPYING_
2025-03-26 02:26:23,141 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,141 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742030_1206 src: /172.20.1.10:47572 dest: /172.20.1.13:9866
2025-03-26 02:26:23,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742030_1206 src: /172.20.1.13:32870 dest: /172.20.1.12:9866
2025-03-26 02:26:23,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742030_1206 src: /172.20.1.12:53582 dest: /172.20.1.11:9866
2025-03-26 02:26:23,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53582, dest: /172.20.1.11:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742030_1206, duration(ns): 1158891
2025-03-26 02:26:23,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32870, dest: /172.20.1.12:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742030_1206, duration(ns): 1612638
2025-03-26 02:26:23,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742030_1206, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,146 INFO terminating
2025-03-26 02:26:23,147 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fmClassifier.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47572, dest: /172.20.1.13:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742030_1206, duration(ns): 1913973
2025-03-26 02:26:23,147 INFO terminating
2025-03-26 02:26:23,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742031_1207, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/gbt.R._COPYING_
2025-03-26 02:26:23,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742031_1207 src: /172.20.1.10:50072 dest: /172.20.1.11:9866
2025-03-26 02:26:23,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742031_1207 src: /172.20.1.11:43846 dest: /172.20.1.13:9866
2025-03-26 02:26:23,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742031_1207 src: /172.20.1.13:32882 dest: /172.20.1.12:9866
2025-03-26 02:26:23,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32882, dest: /172.20.1.12:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742031_1207, duration(ns): 3367300
2025-03-26 02:26:23,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742031_1207, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50072, dest: /172.20.1.11:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742031_1207, duration(ns): 3977419
2025-03-26 02:26:23,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43846, dest: /172.20.1.13:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742031_1207, duration(ns): 3635511
2025-03-26 02:26:23,160 INFO terminating
2025-03-26 02:26:23,160 INFO terminating
2025-03-26 02:26:23,161 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/gbt.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,165 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742032_1208, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/fmRegressor.R._COPYING_
2025-03-26 02:26:23,165 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,165 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742032_1208 src: /172.20.1.10:47588 dest: /172.20.1.13:9866
2025-03-26 02:26:23,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742032_1208 src: /172.20.1.13:57314 dest: /172.20.1.11:9866
2025-03-26 02:26:23,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742032_1208 src: /172.20.1.11:36222 dest: /172.20.1.12:9866
2025-03-26 02:26:23,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36222, dest: /172.20.1.12:9866, bytes: 1458, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742032_1208, duration(ns): 1227727
2025-03-26 02:26:23,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57314, dest: /172.20.1.11:9866, bytes: 1458, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742032_1208, duration(ns): 1569529
2025-03-26 02:26:23,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742032_1208, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47588, dest: /172.20.1.13:9866, bytes: 1458, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742032_1208, duration(ns): 1871989
2025-03-26 02:26:23,171 INFO terminating
2025-03-26 02:26:23,171 INFO terminating
2025-03-26 02:26:23,172 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fmRegressor.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,175 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742033_1209, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/kmeans.R._COPYING_
2025-03-26 02:26:23,175 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,175 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742033_1209 src: /172.20.1.10:47602 dest: /172.20.1.13:9866
2025-03-26 02:26:23,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742033_1209 src: /172.20.1.13:57326 dest: /172.20.1.11:9866
2025-03-26 02:26:23,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742033_1209 src: /172.20.1.11:36234 dest: /172.20.1.12:9866
2025-03-26 02:26:23,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36234, dest: /172.20.1.12:9866, bytes: 1558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742033_1209, duration(ns): 3130932
2025-03-26 02:26:23,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742033_1209, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47602, dest: /172.20.1.13:9866, bytes: 1558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742033_1209, duration(ns): 2202822
2025-03-26 02:26:23,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57326, dest: /172.20.1.11:9866, bytes: 1558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742033_1209, duration(ns): 1439006
2025-03-26 02:26:23,183 INFO terminating
2025-03-26 02:26:23,184 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/kmeans.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,184 INFO terminating
2025-03-26 02:26:23,189 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742034_1210, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/kstest.R._COPYING_
2025-03-26 02:26:23,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742034_1210 src: /172.20.1.10:50088 dest: /172.20.1.11:9866
2025-03-26 02:26:23,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742034_1210 src: /172.20.1.11:36238 dest: /172.20.1.12:9866
2025-03-26 02:26:23,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742034_1210 src: /172.20.1.12:36626 dest: /172.20.1.13:9866
2025-03-26 02:26:23,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36626, dest: /172.20.1.13:9866, bytes: 1345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742034_1210, duration(ns): 1467507
2025-03-26 02:26:23,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742034_1210, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50088, dest: /172.20.1.11:9866, bytes: 1345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742034_1210, duration(ns): 1935657
2025-03-26 02:26:23,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36238, dest: /172.20.1.12:9866, bytes: 1345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742034_1210, duration(ns): 1707146
2025-03-26 02:26:23,200 INFO terminating
2025-03-26 02:26:23,200 INFO terminating
2025-03-26 02:26:23,201 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/kstest.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742035_1211, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/logit.R._COPYING_
2025-03-26 02:26:23,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742035_1211 src: /172.20.1.10:47606 dest: /172.20.1.13:9866
2025-03-26 02:26:23,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742035_1211 src: /172.20.1.13:57330 dest: /172.20.1.11:9866
2025-03-26 02:26:23,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742035_1211 src: /172.20.1.11:36250 dest: /172.20.1.12:9866
2025-03-26 02:26:23,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36250, dest: /172.20.1.12:9866, bytes: 1980, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742035_1211, duration(ns): 1975106
2025-03-26 02:26:23,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57330, dest: /172.20.1.11:9866, bytes: 1980, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742035_1211, duration(ns): 2323074
2025-03-26 02:26:23,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742035_1211, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,211 INFO terminating
2025-03-26 02:26:23,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47606, dest: /172.20.1.13:9866, bytes: 1980, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742035_1211, duration(ns): 2813823
2025-03-26 02:26:23,212 INFO terminating
2025-03-26 02:26:23,213 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/logit.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,218 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742036_1212, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/dataframe.R._COPYING_
2025-03-26 02:26:23,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742036_1212 src: /172.20.1.10:47610 dest: /172.20.1.13:9866
2025-03-26 02:26:23,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742036_1212 src: /172.20.1.13:57346 dest: /172.20.1.11:9866
2025-03-26 02:26:23,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742036_1212 src: /172.20.1.11:36264 dest: /172.20.1.12:9866
2025-03-26 02:26:23,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36264, dest: /172.20.1.12:9866, bytes: 1930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742036_1212, duration(ns): 1269666
2025-03-26 02:26:23,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57346, dest: /172.20.1.11:9866, bytes: 1930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742036_1212, duration(ns): 1926118
2025-03-26 02:26:23,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742036_1212, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,223 INFO terminating
2025-03-26 02:26:23,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47610, dest: /172.20.1.13:9866, bytes: 1930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742036_1212, duration(ns): 2288387
2025-03-26 02:26:23,224 INFO terminating
2025-03-26 02:26:23,225 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/dataframe.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,230 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742037_1213, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/streaming/structured_network_wordcount.R._COPYING_
2025-03-26 02:26:23,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742037_1213 src: /172.20.1.10:50102 dest: /172.20.1.11:9866
2025-03-26 02:26:23,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742037_1213 src: /172.20.1.11:43856 dest: /172.20.1.13:9866
2025-03-26 02:26:23,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742037_1213 src: /172.20.1.13:32894 dest: /172.20.1.12:9866
2025-03-26 02:26:23,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32894, dest: /172.20.1.12:9866, bytes: 2084, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742037_1213, duration(ns): 1144985
2025-03-26 02:26:23,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742037_1213, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50102, dest: /172.20.1.11:9866, bytes: 2084, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742037_1213, duration(ns): 2058241
2025-03-26 02:26:23,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43856, dest: /172.20.1.13:9866, bytes: 2084, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742037_1213, duration(ns): 1428078
2025-03-26 02:26:23,236 INFO terminating
2025-03-26 02:26:23,236 INFO terminating
2025-03-26 02:26:23,237 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/streaming/structured_network_wordcount.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,242 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742038_1214, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/resources/kv1.txt._COPYING_
2025-03-26 02:26:23,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742038_1214 src: /172.20.1.10:50116 dest: /172.20.1.11:9866
2025-03-26 02:26:23,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742038_1214 src: /172.20.1.11:43860 dest: /172.20.1.13:9866
2025-03-26 02:26:23,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742038_1214 src: /172.20.1.13:32904 dest: /172.20.1.12:9866
2025-03-26 02:26:23,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43860, dest: /172.20.1.13:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742038_1214, duration(ns): 2158254
2025-03-26 02:26:23,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32904, dest: /172.20.1.12:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742038_1214, duration(ns): 1523418
2025-03-26 02:26:23,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742038_1214, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,248 INFO terminating
2025-03-26 02:26:23,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50116, dest: /172.20.1.11:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742038_1214, duration(ns): 2491372
2025-03-26 02:26:23,249 INFO terminating
2025-03-26 02:26:23,250 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/kv1.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,255 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,255 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742039_1215, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/resources/dir1/file1.parquet._COPYING_
2025-03-26 02:26:23,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742039_1215 src: /172.20.1.10:50132 dest: /172.20.1.11:9866
2025-03-26 02:26:23,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742039_1215 src: /172.20.1.11:43876 dest: /172.20.1.13:9866
2025-03-26 02:26:23,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742039_1215 src: /172.20.1.13:32920 dest: /172.20.1.12:9866
2025-03-26 02:26:23,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32920, dest: /172.20.1.12:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742039_1215, duration(ns): 1256012
2025-03-26 02:26:23,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742039_1215, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50132, dest: /172.20.1.11:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742039_1215, duration(ns): 2086350
2025-03-26 02:26:23,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43876, dest: /172.20.1.13:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742039_1215, duration(ns): 1519891
2025-03-26 02:26:23,262 INFO terminating
2025-03-26 02:26:23,262 INFO terminating
2025-03-26 02:26:23,263 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/file1.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742040_1216, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/resources/dir1/file3.json._COPYING_
2025-03-26 02:26:23,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742040_1216 src: /172.20.1.10:50136 dest: /172.20.1.11:9866
2025-03-26 02:26:23,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742040_1216 src: /172.20.1.11:36278 dest: /172.20.1.12:9866
2025-03-26 02:26:23,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742040_1216 src: /172.20.1.12:36638 dest: /172.20.1.13:9866
2025-03-26 02:26:23,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36638, dest: /172.20.1.13:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742040_1216, duration(ns): 1854477
2025-03-26 02:26:23,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50136, dest: /172.20.1.11:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742040_1216, duration(ns): 2422055
2025-03-26 02:26:23,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36278, dest: /172.20.1.12:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742040_1216, duration(ns): 2105931
2025-03-26 02:26:23,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742040_1216, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,273 INFO terminating
2025-03-26 02:26:23,274 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/file3.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,274 INFO terminating
2025-03-26 02:26:23,281 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742041_1217, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/resources/dir1/dir2/file2.parquet._COPYING_
2025-03-26 02:26:23,281 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,281 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742041_1217 src: /172.20.1.10:50144 dest: /172.20.1.11:9866
2025-03-26 02:26:23,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742041_1217 src: /172.20.1.11:36292 dest: /172.20.1.12:9866
2025-03-26 02:26:23,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742041_1217 src: /172.20.1.12:36644 dest: /172.20.1.13:9866
2025-03-26 02:26:23,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36292, dest: /172.20.1.12:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742041_1217, duration(ns): 2288364
2025-03-26 02:26:23,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36644, dest: /172.20.1.13:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742041_1217, duration(ns): 2000374
2025-03-26 02:26:23,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742041_1217, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,287 INFO terminating
2025-03-26 02:26:23,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50144, dest: /172.20.1.11:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742041_1217, duration(ns): 2627200
2025-03-26 02:26:23,288 INFO terminating
2025-03-26 02:26:23,289 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/dir2/file2.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742042_1218, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/resources/user.avsc._COPYING_
2025-03-26 02:26:23,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742042_1218 src: /172.20.1.10:47620 dest: /172.20.1.13:9866
2025-03-26 02:26:23,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742042_1218 src: /172.20.1.13:57358 dest: /172.20.1.11:9866
2025-03-26 02:26:23,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742042_1218 src: /172.20.1.11:36300 dest: /172.20.1.12:9866
2025-03-26 02:26:23,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36300, dest: /172.20.1.12:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742042_1218, duration(ns): 1128561
2025-03-26 02:26:23,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47620, dest: /172.20.1.13:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742042_1218, duration(ns): 1799505
2025-03-26 02:26:23,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57358, dest: /172.20.1.11:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742042_1218, duration(ns): 1338716
2025-03-26 02:26:23,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742042_1218, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,298 INFO terminating
2025-03-26 02:26:23,298 INFO terminating
2025-03-26 02:26:23,299 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/user.avsc._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,302 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,302 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742043_1219, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/resources/people.csv._COPYING_
2025-03-26 02:26:23,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742043_1219 src: /172.20.1.10:50152 dest: /172.20.1.11:9866
2025-03-26 02:26:23,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742043_1219 src: /172.20.1.11:43886 dest: /172.20.1.13:9866
2025-03-26 02:26:23,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742043_1219 src: /172.20.1.13:32924 dest: /172.20.1.12:9866
2025-03-26 02:26:23,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32924, dest: /172.20.1.12:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742043_1219, duration(ns): 4057803
2025-03-26 02:26:23,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742043_1219, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43886, dest: /172.20.1.13:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742043_1219, duration(ns): 4353819
2025-03-26 02:26:23,312 INFO terminating
2025-03-26 02:26:23,313 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50152, dest: /172.20.1.11:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742043_1219, duration(ns): 4825049
2025-03-26 02:26:23,313 INFO terminating
2025-03-26 02:26:23,317 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742044_1220, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/resources/full_user.avsc._COPYING_
2025-03-26 02:26:23,317 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,317 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742044_1220 src: /172.20.1.10:50702 dest: /172.20.1.12:9866
2025-03-26 02:26:23,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742044_1220 src: /172.20.1.12:36654 dest: /172.20.1.13:9866
2025-03-26 02:26:23,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742044_1220 src: /172.20.1.13:57366 dest: /172.20.1.11:9866
2025-03-26 02:26:23,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57366, dest: /172.20.1.11:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742044_1220, duration(ns): 1229831
2025-03-26 02:26:23,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50702, dest: /172.20.1.12:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742044_1220, duration(ns): 1970566
2025-03-26 02:26:23,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36654, dest: /172.20.1.13:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742044_1220, duration(ns): 1692024
2025-03-26 02:26:23,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742044_1220, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,324 INFO terminating
2025-03-26 02:26:23,324 INFO terminating
2025-03-26 02:26:23,327 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/full_user.avsc._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,332 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742045_1221, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/resources/users.avro._COPYING_
2025-03-26 02:26:23,332 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,332 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742045_1221 src: /172.20.1.10:50714 dest: /172.20.1.12:9866
2025-03-26 02:26:23,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742045_1221 src: /172.20.1.12:36666 dest: /172.20.1.13:9866
2025-03-26 02:26:23,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742045_1221 src: /172.20.1.13:57376 dest: /172.20.1.11:9866
2025-03-26 02:26:23,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57376, dest: /172.20.1.11:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742045_1221, duration(ns): 1207336
2025-03-26 02:26:23,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742045_1221, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50714, dest: /172.20.1.12:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742045_1221, duration(ns): 1864133
2025-03-26 02:26:23,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36666, dest: /172.20.1.13:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742045_1221, duration(ns): 1526061
2025-03-26 02:26:23,338 INFO terminating
2025-03-26 02:26:23,338 INFO terminating
2025-03-26 02:26:23,339 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.avro._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,345 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,345 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742046_1222, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider._COPYING_
2025-03-26 02:26:23,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742046_1222 src: /172.20.1.10:47624 dest: /172.20.1.13:9866
2025-03-26 02:26:23,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742046_1222 src: /172.20.1.13:32926 dest: /172.20.1.12:9866
2025-03-26 02:26:23,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742046_1222 src: /172.20.1.12:53588 dest: /172.20.1.11:9866
2025-03-26 02:26:23,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53588, dest: /172.20.1.11:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742046_1222, duration(ns): 1370569
2025-03-26 02:26:23,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32926, dest: /172.20.1.12:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742046_1222, duration(ns): 1806153
2025-03-26 02:26:23,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742046_1222, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,351 INFO terminating
2025-03-26 02:26:23,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47624, dest: /172.20.1.13:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742046_1222, duration(ns): 2123225
2025-03-26 02:26:23,352 INFO terminating
2025-03-26 02:26:23,353 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,357 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,358 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742047_1223, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider._COPYING_
2025-03-26 02:26:23,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742047_1223 src: /172.20.1.10:47634 dest: /172.20.1.13:9866
2025-03-26 02:26:23,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742047_1223 src: /172.20.1.13:57392 dest: /172.20.1.11:9866
2025-03-26 02:26:23,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742047_1223 src: /172.20.1.11:36302 dest: /172.20.1.12:9866
2025-03-26 02:26:23,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47634, dest: /172.20.1.13:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742047_1223, duration(ns): 1739735
2025-03-26 02:26:23,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36302, dest: /172.20.1.12:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742047_1223, duration(ns): 1083403
2025-03-26 02:26:23,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57392, dest: /172.20.1.11:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742047_1223, duration(ns): 1368650
2025-03-26 02:26:23,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742047_1223, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,363 INFO terminating
2025-03-26 02:26:23,364 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,364 INFO terminating
2025-03-26 02:26:23,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742048_1224, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/resources/users.parquet._COPYING_
2025-03-26 02:26:23,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742048_1224 src: /172.20.1.10:50718 dest: /172.20.1.12:9866
2025-03-26 02:26:23,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742048_1224 src: /172.20.1.12:36676 dest: /172.20.1.13:9866
2025-03-26 02:26:23,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742048_1224 src: /172.20.1.13:57394 dest: /172.20.1.11:9866
2025-03-26 02:26:23,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36676, dest: /172.20.1.13:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742048_1224, duration(ns): 1883411
2025-03-26 02:26:23,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57394, dest: /172.20.1.11:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742048_1224, duration(ns): 1199835
2025-03-26 02:26:23,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742048_1224, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,374 INFO terminating
2025-03-26 02:26:23,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50718, dest: /172.20.1.12:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742048_1224, duration(ns): 2164170
2025-03-26 02:26:23,375 INFO terminating
2025-03-26 02:26:23,376 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742049_1225, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/resources/users.orc._COPYING_
2025-03-26 02:26:23,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742049_1225 src: /172.20.1.10:50734 dest: /172.20.1.12:9866
2025-03-26 02:26:23,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742049_1225 src: /172.20.1.12:36684 dest: /172.20.1.13:9866
2025-03-26 02:26:23,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742049_1225 src: /172.20.1.13:57398 dest: /172.20.1.11:9866
2025-03-26 02:26:23,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57398, dest: /172.20.1.11:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742049_1225, duration(ns): 1117051
2025-03-26 02:26:23,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742049_1225, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36684, dest: /172.20.1.13:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742049_1225, duration(ns): 1368770
2025-03-26 02:26:23,386 INFO terminating
2025-03-26 02:26:23,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50734, dest: /172.20.1.12:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742049_1225, duration(ns): 2129851
2025-03-26 02:26:23,387 INFO terminating
2025-03-26 02:26:23,388 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.orc._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742050_1226, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/resources/people.txt._COPYING_
2025-03-26 02:26:23,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742050_1226 src: /172.20.1.10:50166 dest: /172.20.1.11:9866
2025-03-26 02:26:23,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742050_1226 src: /172.20.1.11:43896 dest: /172.20.1.13:9866
2025-03-26 02:26:23,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742050_1226 src: /172.20.1.13:32928 dest: /172.20.1.12:9866
2025-03-26 02:26:23,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43896, dest: /172.20.1.13:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742050_1226, duration(ns): 1344760
2025-03-26 02:26:23,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32928, dest: /172.20.1.12:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742050_1226, duration(ns): 1112713
2025-03-26 02:26:23,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742050_1226, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,396 INFO terminating
2025-03-26 02:26:23,397 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50166, dest: /172.20.1.11:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742050_1226, duration(ns): 1649494
2025-03-26 02:26:23,397 INFO terminating
2025-03-26 02:26:23,401 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742051_1227, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/resources/people.json._COPYING_
2025-03-26 02:26:23,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742051_1227 src: /172.20.1.10:50174 dest: /172.20.1.11:9866
2025-03-26 02:26:23,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742051_1227 src: /172.20.1.11:43902 dest: /172.20.1.13:9866
2025-03-26 02:26:23,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742051_1227 src: /172.20.1.13:32944 dest: /172.20.1.12:9866
2025-03-26 02:26:23,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32944, dest: /172.20.1.12:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742051_1227, duration(ns): 953157
2025-03-26 02:26:23,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742051_1227, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43902, dest: /172.20.1.13:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742051_1227, duration(ns): 1160654
2025-03-26 02:26:23,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50174, dest: /172.20.1.11:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742051_1227, duration(ns): 2325203
2025-03-26 02:26:23,407 INFO terminating
2025-03-26 02:26:23,407 INFO terminating
2025-03-26 02:26:23,408 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,411 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742052_1228, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/resources/employees.json._COPYING_
2025-03-26 02:26:23,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742052_1228 src: /172.20.1.10:47636 dest: /172.20.1.13:9866
2025-03-26 02:26:23,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742052_1228 src: /172.20.1.12:53596 dest: /172.20.1.11:9866
2025-03-26 02:26:23,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742052_1228 src: /172.20.1.13:32954 dest: /172.20.1.12:9866
2025-03-26 02:26:23,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53596, dest: /172.20.1.11:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742052_1228, duration(ns): 1301439
2025-03-26 02:26:23,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47636, dest: /172.20.1.13:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742052_1228, duration(ns): 2001609
2025-03-26 02:26:23,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32954, dest: /172.20.1.12:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742052_1228, duration(ns): 1578527
2025-03-26 02:26:23,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742052_1228, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,417 INFO terminating
2025-03-26 02:26:23,417 INFO terminating
2025-03-26 02:26:23,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/employees.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,430 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742053_1229, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala._COPYING_
2025-03-26 02:26:23,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742053_1229 src: /172.20.1.10:50746 dest: /172.20.1.12:9866
2025-03-26 02:26:23,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742053_1229 src: /172.20.1.12:53598 dest: /172.20.1.11:9866
2025-03-26 02:26:23,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742053_1229 src: /172.20.1.11:43906 dest: /172.20.1.13:9866
2025-03-26 02:26:23,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43906, dest: /172.20.1.13:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742053_1229, duration(ns): 1106685
2025-03-26 02:26:23,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53598, dest: /172.20.1.11:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742053_1229, duration(ns): 1437650
2025-03-26 02:26:23,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742053_1229, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,435 INFO terminating
2025-03-26 02:26:23,436 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50746, dest: /172.20.1.12:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742053_1229, duration(ns): 1876395
2025-03-26 02:26:23,436 INFO terminating
2025-03-26 02:26:23,444 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742054_1230, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala._COPYING_
2025-03-26 02:26:23,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742054_1230 src: /172.20.1.10:50750 dest: /172.20.1.12:9866
2025-03-26 02:26:23,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742054_1230 src: /172.20.1.12:53612 dest: /172.20.1.11:9866
2025-03-26 02:26:23,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742054_1230 src: /172.20.1.11:43916 dest: /172.20.1.13:9866
2025-03-26 02:26:23,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43916, dest: /172.20.1.13:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742054_1230, duration(ns): 1386736
2025-03-26 02:26:23,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53612, dest: /172.20.1.11:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742054_1230, duration(ns): 1584521
2025-03-26 02:26:23,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742054_1230, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,449 INFO terminating
2025-03-26 02:26:23,450 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50750, dest: /172.20.1.12:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742054_1230, duration(ns): 1933892
2025-03-26 02:26:23,450 INFO terminating
2025-03-26 02:26:23,454 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742055_1231, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_
2025-03-26 02:26:23,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742055_1231 src: /172.20.1.10:50762 dest: /172.20.1.12:9866
2025-03-26 02:26:23,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742055_1231 src: /172.20.1.12:36696 dest: /172.20.1.13:9866
2025-03-26 02:26:23,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742055_1231 src: /172.20.1.13:57414 dest: /172.20.1.11:9866
2025-03-26 02:26:23,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36696, dest: /172.20.1.13:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742055_1231, duration(ns): 1976358
2025-03-26 02:26:23,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57414, dest: /172.20.1.11:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742055_1231, duration(ns): 1483522
2025-03-26 02:26:23,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742055_1231, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,460 INFO terminating
2025-03-26 02:26:23,461 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50762, dest: /172.20.1.12:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742055_1231, duration(ns): 2404953
2025-03-26 02:26:23,461 INFO terminating
2025-03-26 02:26:23,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742056_1232, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala._COPYING_
2025-03-26 02:26:23,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742056_1232 src: /172.20.1.10:47652 dest: /172.20.1.13:9866
2025-03-26 02:26:23,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742056_1232 src: /172.20.1.13:57422 dest: /172.20.1.11:9866
2025-03-26 02:26:23,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742056_1232 src: /172.20.1.11:36304 dest: /172.20.1.12:9866
2025-03-26 02:26:23,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36304, dest: /172.20.1.12:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742056_1232, duration(ns): 1562963
2025-03-26 02:26:23,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742056_1232, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57422, dest: /172.20.1.11:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742056_1232, duration(ns): 2147689
2025-03-26 02:26:23,472 INFO terminating
2025-03-26 02:26:23,473 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47652, dest: /172.20.1.13:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742056_1232, duration(ns): 2891449
2025-03-26 02:26:23,473 INFO terminating
2025-03-26 02:26:23,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742057_1233, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala._COPYING_
2025-03-26 02:26:23,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742057_1233 src: /172.20.1.10:47658 dest: /172.20.1.13:9866
2025-03-26 02:26:23,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742057_1233 src: /172.20.1.13:57430 dest: /172.20.1.11:9866
2025-03-26 02:26:23,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742057_1233 src: /172.20.1.11:36310 dest: /172.20.1.12:9866
2025-03-26 02:26:23,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36310, dest: /172.20.1.12:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742057_1233, duration(ns): 1180641
2025-03-26 02:26:23,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57430, dest: /172.20.1.11:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742057_1233, duration(ns): 1478913
2025-03-26 02:26:23,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742057_1233, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,483 INFO terminating
2025-03-26 02:26:23,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47658, dest: /172.20.1.13:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742057_1233, duration(ns): 1904122
2025-03-26 02:26:23,484 INFO terminating
2025-03-26 02:26:23,485 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,488 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742058_1234, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala._COPYING_
2025-03-26 02:26:23,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742058_1234 src: /172.20.1.10:47670 dest: /172.20.1.13:9866
2025-03-26 02:26:23,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742058_1234 src: /172.20.1.13:57434 dest: /172.20.1.11:9866
2025-03-26 02:26:23,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742058_1234 src: /172.20.1.11:36314 dest: /172.20.1.12:9866
2025-03-26 02:26:23,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36314, dest: /172.20.1.12:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742058_1234, duration(ns): 1081515
2025-03-26 02:26:23,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57434, dest: /172.20.1.11:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742058_1234, duration(ns): 1249935
2025-03-26 02:26:23,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742058_1234, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,493 INFO terminating
2025-03-26 02:26:23,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47670, dest: /172.20.1.13:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742058_1234, duration(ns): 1571791
2025-03-26 02:26:23,494 INFO terminating
2025-03-26 02:26:23,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742059_1235, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala._COPYING_
2025-03-26 02:26:23,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742059_1235 src: /172.20.1.10:50774 dest: /172.20.1.12:9866
2025-03-26 02:26:23,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742059_1235 src: /172.20.1.11:43920 dest: /172.20.1.13:9866
2025-03-26 02:26:23,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742059_1235 src: /172.20.1.12:53616 dest: /172.20.1.11:9866
2025-03-26 02:26:23,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43920, dest: /172.20.1.13:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742059_1235, duration(ns): 904166
2025-03-26 02:26:23,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742059_1235, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53616, dest: /172.20.1.11:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742059_1235, duration(ns): 1136358
2025-03-26 02:26:23,504 INFO terminating
2025-03-26 02:26:23,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50774, dest: /172.20.1.12:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742059_1235, duration(ns): 3094980
2025-03-26 02:26:23,505 INFO terminating
2025-03-26 02:26:23,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742060_1236, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala._COPYING_
2025-03-26 02:26:23,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742060_1236 src: /172.20.1.10:50186 dest: /172.20.1.11:9866
2025-03-26 02:26:23,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742060_1236 src: /172.20.1.11:36316 dest: /172.20.1.12:9866
2025-03-26 02:26:23,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742060_1236 src: /172.20.1.12:36704 dest: /172.20.1.13:9866
2025-03-26 02:26:23,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36704, dest: /172.20.1.13:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742060_1236, duration(ns): 904608
2025-03-26 02:26:23,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742060_1236, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50186, dest: /172.20.1.11:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742060_1236, duration(ns): 1410347
2025-03-26 02:26:23,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36316, dest: /172.20.1.12:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742060_1236, duration(ns): 1151916
2025-03-26 02:26:23,514 INFO terminating
2025-03-26 02:26:23,514 INFO terminating
2025-03-26 02:26:23,515 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,518 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742061_1237, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala._COPYING_
2025-03-26 02:26:23,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742061_1237 src: /172.20.1.10:50784 dest: /172.20.1.12:9866
2025-03-26 02:26:23,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742061_1237 src: /172.20.1.12:53624 dest: /172.20.1.11:9866
2025-03-26 02:26:23,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742061_1237 src: /172.20.1.11:43926 dest: /172.20.1.13:9866
2025-03-26 02:26:23,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43926, dest: /172.20.1.13:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742061_1237, duration(ns): 1241606
2025-03-26 02:26:23,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742061_1237, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50784, dest: /172.20.1.12:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742061_1237, duration(ns): 1946261
2025-03-26 02:26:23,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53624, dest: /172.20.1.11:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742061_1237, duration(ns): 1444627
2025-03-26 02:26:23,524 INFO terminating
2025-03-26 02:26:23,524 INFO terminating
2025-03-26 02:26:23,525 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,531 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742062_1238, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala._COPYING_
2025-03-26 02:26:23,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742062_1238 src: /172.20.1.10:47672 dest: /172.20.1.13:9866
2025-03-26 02:26:23,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742062_1238 src: /172.20.1.13:57440 dest: /172.20.1.11:9866
2025-03-26 02:26:23,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742062_1238 src: /172.20.1.11:36320 dest: /172.20.1.12:9866
2025-03-26 02:26:23,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36320, dest: /172.20.1.12:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742062_1238, duration(ns): 1891939
2025-03-26 02:26:23,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47672, dest: /172.20.1.13:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742062_1238, duration(ns): 2532975
2025-03-26 02:26:23,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57440, dest: /172.20.1.11:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742062_1238, duration(ns): 2149014
2025-03-26 02:26:23,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742062_1238, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,537 INFO terminating
2025-03-26 02:26:23,538 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,538 INFO terminating
2025-03-26 02:26:23,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742063_1239, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala._COPYING_
2025-03-26 02:26:23,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742063_1239 src: /172.20.1.10:50792 dest: /172.20.1.12:9866
2025-03-26 02:26:23,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742063_1239 src: /172.20.1.12:36706 dest: /172.20.1.13:9866
2025-03-26 02:26:23,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742063_1239 src: /172.20.1.13:57452 dest: /172.20.1.11:9866
2025-03-26 02:26:23,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57452, dest: /172.20.1.11:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742063_1239, duration(ns): 1250418
2025-03-26 02:26:23,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742063_1239, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50792, dest: /172.20.1.12:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742063_1239, duration(ns): 1986688
2025-03-26 02:26:23,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36706, dest: /172.20.1.13:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742063_1239, duration(ns): 1683966
2025-03-26 02:26:23,549 INFO terminating
2025-03-26 02:26:23,549 INFO terminating
2025-03-26 02:26:23,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,553 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742064_1240, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala._COPYING_
2025-03-26 02:26:23,553 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,553 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742064_1240 src: /172.20.1.10:50802 dest: /172.20.1.12:9866
2025-03-26 02:26:23,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742064_1240 src: /172.20.1.12:36716 dest: /172.20.1.13:9866
2025-03-26 02:26:23,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742064_1240 src: /172.20.1.13:57454 dest: /172.20.1.11:9866
2025-03-26 02:26:23,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50802, dest: /172.20.1.12:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742064_1240, duration(ns): 1608196
2025-03-26 02:26:23,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36716, dest: /172.20.1.13:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742064_1240, duration(ns): 1289000
2025-03-26 02:26:23,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57454, dest: /172.20.1.11:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742064_1240, duration(ns): 943328
2025-03-26 02:26:23,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742064_1240, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,558 INFO terminating
2025-03-26 02:26:23,559 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,559 INFO terminating
2025-03-26 02:26:23,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742065_1241, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala._COPYING_
2025-03-26 02:26:23,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742065_1241 src: /172.20.1.10:47676 dest: /172.20.1.13:9866
2025-03-26 02:26:23,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742065_1241 src: /172.20.1.13:32968 dest: /172.20.1.12:9866
2025-03-26 02:26:23,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742065_1241 src: /172.20.1.12:53638 dest: /172.20.1.11:9866
2025-03-26 02:26:23,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53638, dest: /172.20.1.11:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742065_1241, duration(ns): 1065169
2025-03-26 02:26:23,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32968, dest: /172.20.1.12:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742065_1241, duration(ns): 4263351
2025-03-26 02:26:23,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742065_1241, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,570 INFO terminating
2025-03-26 02:26:23,571 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47676, dest: /172.20.1.13:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742065_1241, duration(ns): 4658004
2025-03-26 02:26:23,571 INFO terminating
2025-03-26 02:26:23,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742066_1242, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala._COPYING_
2025-03-26 02:26:23,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742066_1242 src: /172.20.1.10:50812 dest: /172.20.1.12:9866
2025-03-26 02:26:23,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742066_1242 src: /172.20.1.12:53644 dest: /172.20.1.11:9866
2025-03-26 02:26:23,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742066_1242 src: /172.20.1.11:43932 dest: /172.20.1.13:9866
2025-03-26 02:26:23,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43932, dest: /172.20.1.13:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742066_1242, duration(ns): 1401053
2025-03-26 02:26:23,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53644, dest: /172.20.1.11:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742066_1242, duration(ns): 2166016
2025-03-26 02:26:23,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742066_1242, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,582 INFO terminating
2025-03-26 02:26:23,583 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50812, dest: /172.20.1.12:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742066_1242, duration(ns): 2553752
2025-03-26 02:26:23,583 INFO terminating
2025-03-26 02:26:23,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742067_1243, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala._COPYING_
2025-03-26 02:26:23,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742067_1243 src: /172.20.1.10:50822 dest: /172.20.1.12:9866
2025-03-26 02:26:23,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742067_1243 src: /172.20.1.11:43944 dest: /172.20.1.13:9866
2025-03-26 02:26:23,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742067_1243 src: /172.20.1.12:53654 dest: /172.20.1.11:9866
2025-03-26 02:26:23,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43944, dest: /172.20.1.13:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742067_1243, duration(ns): 1335161
2025-03-26 02:26:23,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742067_1243, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50822, dest: /172.20.1.12:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742067_1243, duration(ns): 1938585
2025-03-26 02:26:23,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53654, dest: /172.20.1.11:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742067_1243, duration(ns): 1549330
2025-03-26 02:26:23,601 INFO terminating
2025-03-26 02:26:23,601 INFO terminating
2025-03-26 02:26:23,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742068_1244, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala._COPYING_
2025-03-26 02:26:23,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742068_1244 src: /172.20.1.10:47682 dest: /172.20.1.13:9866
2025-03-26 02:26:23,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742068_1244 src: /172.20.1.13:32972 dest: /172.20.1.12:9866
2025-03-26 02:26:23,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742068_1244 src: /172.20.1.12:53668 dest: /172.20.1.11:9866
2025-03-26 02:26:23,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47682, dest: /172.20.1.13:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742068_1244, duration(ns): 2004151
2025-03-26 02:26:23,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53668, dest: /172.20.1.11:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742068_1244, duration(ns): 1165281
2025-03-26 02:26:23,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32972, dest: /172.20.1.12:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742068_1244, duration(ns): 1735525
2025-03-26 02:26:23,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742068_1244, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,613 INFO terminating
2025-03-26 02:26:23,613 INFO terminating
2025-03-26 02:26:23,614 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,618 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742069_1245, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala._COPYING_
2025-03-26 02:26:23,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742069_1245 src: /172.20.1.10:50196 dest: /172.20.1.11:9866
2025-03-26 02:26:23,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742069_1245 src: /172.20.1.11:36334 dest: /172.20.1.12:9866
2025-03-26 02:26:23,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742069_1245 src: /172.20.1.12:36732 dest: /172.20.1.13:9866
2025-03-26 02:26:23,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50196, dest: /172.20.1.11:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742069_1245, duration(ns): 1635691
2025-03-26 02:26:23,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36334, dest: /172.20.1.12:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742069_1245, duration(ns): 1330935
2025-03-26 02:26:23,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36732, dest: /172.20.1.13:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742069_1245, duration(ns): 1114705
2025-03-26 02:26:23,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742069_1245, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,624 INFO terminating
2025-03-26 02:26:23,625 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,625 INFO terminating
2025-03-26 02:26:23,630 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742070_1246, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala._COPYING_
2025-03-26 02:26:23,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742070_1246 src: /172.20.1.10:47696 dest: /172.20.1.13:9866
2025-03-26 02:26:23,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742070_1246 src: /172.20.1.13:32984 dest: /172.20.1.12:9866
2025-03-26 02:26:23,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742070_1246 src: /172.20.1.12:53680 dest: /172.20.1.11:9866
2025-03-26 02:26:23,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53680, dest: /172.20.1.11:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742070_1246, duration(ns): 1186320
2025-03-26 02:26:23,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32984, dest: /172.20.1.12:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742070_1246, duration(ns): 1407729
2025-03-26 02:26:23,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742070_1246, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,636 INFO terminating
2025-03-26 02:26:23,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47696, dest: /172.20.1.13:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742070_1246, duration(ns): 1794065
2025-03-26 02:26:23,637 INFO terminating
2025-03-26 02:26:23,638 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742071_1247, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala._COPYING_
2025-03-26 02:26:23,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742071_1247 src: /172.20.1.10:50202 dest: /172.20.1.11:9866
2025-03-26 02:26:23,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742071_1247 src: /172.20.1.11:36348 dest: /172.20.1.12:9866
2025-03-26 02:26:23,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742071_1247 src: /172.20.1.12:36738 dest: /172.20.1.13:9866
2025-03-26 02:26:23,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36348, dest: /172.20.1.12:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742071_1247, duration(ns): 1249662
2025-03-26 02:26:23,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36738, dest: /172.20.1.13:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742071_1247, duration(ns): 958617
2025-03-26 02:26:23,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742071_1247, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,650 INFO terminating
2025-03-26 02:26:23,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50202, dest: /172.20.1.11:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742071_1247, duration(ns): 1830191
2025-03-26 02:26:23,651 INFO terminating
2025-03-26 02:26:23,654 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,658 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742072_1248, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala._COPYING_
2025-03-26 02:26:23,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742072_1248 src: /172.20.1.10:50828 dest: /172.20.1.12:9866
2025-03-26 02:26:23,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742072_1248 src: /172.20.1.12:36754 dest: /172.20.1.13:9866
2025-03-26 02:26:23,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742072_1248 src: /172.20.1.13:57470 dest: /172.20.1.11:9866
2025-03-26 02:26:23,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57470, dest: /172.20.1.11:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742072_1248, duration(ns): 1389226
2025-03-26 02:26:23,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742072_1248, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36754, dest: /172.20.1.13:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742072_1248, duration(ns): 2812946
2025-03-26 02:26:23,667 INFO terminating
2025-03-26 02:26:23,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50828, dest: /172.20.1.12:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742072_1248, duration(ns): 3992825
2025-03-26 02:26:23,668 INFO terminating
2025-03-26 02:26:23,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,673 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742073_1249, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala._COPYING_
2025-03-26 02:26:23,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742073_1249 src: /172.20.1.10:50210 dest: /172.20.1.11:9866
2025-03-26 02:26:23,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742073_1249 src: /172.20.1.11:36358 dest: /172.20.1.12:9866
2025-03-26 02:26:23,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742073_1249 src: /172.20.1.12:36758 dest: /172.20.1.13:9866
2025-03-26 02:26:23,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50210, dest: /172.20.1.11:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742073_1249, duration(ns): 1618572
2025-03-26 02:26:23,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36358, dest: /172.20.1.12:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742073_1249, duration(ns): 1300110
2025-03-26 02:26:23,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36758, dest: /172.20.1.13:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742073_1249, duration(ns): 1027117
2025-03-26 02:26:23,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742073_1249, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,679 INFO terminating
2025-03-26 02:26:23,680 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,680 INFO terminating
2025-03-26 02:26:23,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742074_1250, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala._COPYING_
2025-03-26 02:26:23,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742074_1250 src: /172.20.1.10:50840 dest: /172.20.1.12:9866
2025-03-26 02:26:23,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742074_1250 src: /172.20.1.12:36774 dest: /172.20.1.13:9866
2025-03-26 02:26:23,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742074_1250 src: /172.20.1.13:57480 dest: /172.20.1.11:9866
2025-03-26 02:26:23,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57480, dest: /172.20.1.11:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742074_1250, duration(ns): 975172
2025-03-26 02:26:23,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742074_1250, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50840, dest: /172.20.1.12:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742074_1250, duration(ns): 1759546
2025-03-26 02:26:23,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36774, dest: /172.20.1.13:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742074_1250, duration(ns): 1546732
2025-03-26 02:26:23,691 INFO terminating
2025-03-26 02:26:23,691 INFO terminating
2025-03-26 02:26:23,692 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,695 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,695 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,696 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742075_1251, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala._COPYING_
2025-03-26 02:26:23,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742075_1251 src: /172.20.1.10:50842 dest: /172.20.1.12:9866
2025-03-26 02:26:23,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742075_1251 src: /172.20.1.11:43960 dest: /172.20.1.13:9866
2025-03-26 02:26:23,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742075_1251 src: /172.20.1.12:53688 dest: /172.20.1.11:9866
2025-03-26 02:26:23,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43960, dest: /172.20.1.13:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742075_1251, duration(ns): 954087
2025-03-26 02:26:23,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53688, dest: /172.20.1.11:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742075_1251, duration(ns): 1233222
2025-03-26 02:26:23,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742075_1251, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,701 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50842, dest: /172.20.1.12:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742075_1251, duration(ns): 1540123
2025-03-26 02:26:23,701 INFO terminating
2025-03-26 02:26:23,701 INFO terminating
2025-03-26 02:26:23,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742076_1252, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala._COPYING_
2025-03-26 02:26:23,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742076_1252 src: /172.20.1.10:50852 dest: /172.20.1.12:9866
2025-03-26 02:26:23,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742076_1252 src: /172.20.1.12:36790 dest: /172.20.1.13:9866
2025-03-26 02:26:23,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742076_1252 src: /172.20.1.13:57492 dest: /172.20.1.11:9866
2025-03-26 02:26:23,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36790, dest: /172.20.1.13:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742076_1252, duration(ns): 1291956
2025-03-26 02:26:23,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57492, dest: /172.20.1.11:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742076_1252, duration(ns): 995772
2025-03-26 02:26:23,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742076_1252, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,715 INFO terminating
2025-03-26 02:26:23,716 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50852, dest: /172.20.1.12:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742076_1252, duration(ns): 1614995
2025-03-26 02:26:23,716 INFO terminating
2025-03-26 02:26:23,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742077_1253, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala._COPYING_
2025-03-26 02:26:23,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742077_1253 src: /172.20.1.10:47710 dest: /172.20.1.13:9866
2025-03-26 02:26:23,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742077_1253 src: /172.20.1.13:57494 dest: /172.20.1.11:9866
2025-03-26 02:26:23,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742077_1253 src: /172.20.1.11:36362 dest: /172.20.1.12:9866
2025-03-26 02:26:23,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36362, dest: /172.20.1.12:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742077_1253, duration(ns): 1110997
2025-03-26 02:26:23,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57494, dest: /172.20.1.11:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742077_1253, duration(ns): 1276101
2025-03-26 02:26:23,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742077_1253, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,725 INFO terminating
2025-03-26 02:26:23,726 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47710, dest: /172.20.1.13:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742077_1253, duration(ns): 1612011
2025-03-26 02:26:23,726 INFO terminating
2025-03-26 02:26:23,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742078_1254, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala._COPYING_
2025-03-26 02:26:23,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742078_1254 src: /172.20.1.10:47724 dest: /172.20.1.13:9866
2025-03-26 02:26:23,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742078_1254 src: /172.20.1.13:57506 dest: /172.20.1.11:9866
2025-03-26 02:26:23,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742078_1254 src: /172.20.1.11:36374 dest: /172.20.1.12:9866
2025-03-26 02:26:23,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36374, dest: /172.20.1.12:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742078_1254, duration(ns): 1011163
2025-03-26 02:26:23,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57506, dest: /172.20.1.11:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742078_1254, duration(ns): 1369702
2025-03-26 02:26:23,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742078_1254, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47724, dest: /172.20.1.13:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742078_1254, duration(ns): 2047902
2025-03-26 02:26:23,736 INFO terminating
2025-03-26 02:26:23,736 INFO terminating
2025-03-26 02:26:23,750 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,754 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742079_1255, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala._COPYING_
2025-03-26 02:26:23,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742079_1255 src: /172.20.1.10:50860 dest: /172.20.1.12:9866
2025-03-26 02:26:23,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742079_1255 src: /172.20.1.12:36798 dest: /172.20.1.13:9866
2025-03-26 02:26:23,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742079_1255 src: /172.20.1.13:57508 dest: /172.20.1.11:9866
2025-03-26 02:26:23,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36798, dest: /172.20.1.13:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742079_1255, duration(ns): 1466776
2025-03-26 02:26:23,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57508, dest: /172.20.1.11:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742079_1255, duration(ns): 1147548
2025-03-26 02:26:23,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742079_1255, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50860, dest: /172.20.1.12:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742079_1255, duration(ns): 1742707
2025-03-26 02:26:23,761 INFO terminating
2025-03-26 02:26:23,761 INFO terminating
2025-03-26 02:26:23,762 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742080_1256, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala._COPYING_
2025-03-26 02:26:23,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742080_1256 src: /172.20.1.10:47726 dest: /172.20.1.13:9866
2025-03-26 02:26:23,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742080_1256 src: /172.20.1.13:32992 dest: /172.20.1.12:9866
2025-03-26 02:26:23,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742080_1256 src: /172.20.1.12:53694 dest: /172.20.1.11:9866
2025-03-26 02:26:23,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53694, dest: /172.20.1.11:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742080_1256, duration(ns): 1999182
2025-03-26 02:26:23,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742080_1256, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47726, dest: /172.20.1.13:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742080_1256, duration(ns): 3612993
2025-03-26 02:26:23,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32992, dest: /172.20.1.12:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742080_1256, duration(ns): 2357277
2025-03-26 02:26:23,777 INFO terminating
2025-03-26 02:26:23,777 INFO terminating
2025-03-26 02:26:23,778 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,794 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,794 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,795 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742081_1257, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala._COPYING_
2025-03-26 02:26:23,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742081_1257 src: /172.20.1.10:50220 dest: /172.20.1.11:9866
2025-03-26 02:26:23,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742081_1257 src: /172.20.1.11:43962 dest: /172.20.1.13:9866
2025-03-26 02:26:23,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742081_1257 src: /172.20.1.13:32998 dest: /172.20.1.12:9866
2025-03-26 02:26:23,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:32998, dest: /172.20.1.12:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742081_1257, duration(ns): 939112
2025-03-26 02:26:23,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742081_1257, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50220, dest: /172.20.1.11:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742081_1257, duration(ns): 1564092
2025-03-26 02:26:23,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43962, dest: /172.20.1.13:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742081_1257, duration(ns): 1221814
2025-03-26 02:26:23,805 INFO terminating
2025-03-26 02:26:23,805 INFO terminating
2025-03-26 02:26:23,806 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,810 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742082_1258, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 02:26:23,810 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,810 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742082_1258 src: /172.20.1.10:50870 dest: /172.20.1.12:9866
2025-03-26 02:26:23,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742082_1258 src: /172.20.1.12:53708 dest: /172.20.1.11:9866
2025-03-26 02:26:23,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742082_1258 src: /172.20.1.11:43974 dest: /172.20.1.13:9866
2025-03-26 02:26:23,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43974, dest: /172.20.1.13:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742082_1258, duration(ns): 780221
2025-03-26 02:26:23,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53708, dest: /172.20.1.11:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742082_1258, duration(ns): 982140
2025-03-26 02:26:23,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742082_1258, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,814 INFO terminating
2025-03-26 02:26:23,816 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50870, dest: /172.20.1.12:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742082_1258, duration(ns): 1237651
2025-03-26 02:26:23,816 INFO terminating
2025-03-26 02:26:23,821 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742083_1259, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala._COPYING_
2025-03-26 02:26:23,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742083_1259 src: /172.20.1.10:50878 dest: /172.20.1.12:9866
2025-03-26 02:26:23,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742083_1259 src: /172.20.1.12:53714 dest: /172.20.1.11:9866
2025-03-26 02:26:23,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742083_1259 src: /172.20.1.11:43980 dest: /172.20.1.13:9866
2025-03-26 02:26:23,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43980, dest: /172.20.1.13:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742083_1259, duration(ns): 2605505
2025-03-26 02:26:23,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53714, dest: /172.20.1.11:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742083_1259, duration(ns): 2817976
2025-03-26 02:26:23,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742083_1259, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,827 INFO terminating
2025-03-26 02:26:23,828 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50878, dest: /172.20.1.12:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742083_1259, duration(ns): 3110217
2025-03-26 02:26:23,828 INFO terminating
2025-03-26 02:26:23,832 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742084_1260, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala._COPYING_
2025-03-26 02:26:23,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742084_1260 src: /172.20.1.10:50892 dest: /172.20.1.12:9866
2025-03-26 02:26:23,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742084_1260 src: /172.20.1.12:53724 dest: /172.20.1.11:9866
2025-03-26 02:26:23,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742084_1260 src: /172.20.1.11:43990 dest: /172.20.1.13:9866
2025-03-26 02:26:23,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43990, dest: /172.20.1.13:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742084_1260, duration(ns): 3879123
2025-03-26 02:26:23,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53724, dest: /172.20.1.11:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742084_1260, duration(ns): 4051082
2025-03-26 02:26:23,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742084_1260, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,839 INFO terminating
2025-03-26 02:26:23,840 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50892, dest: /172.20.1.12:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742084_1260, duration(ns): 4345906
2025-03-26 02:26:23,840 INFO terminating
2025-03-26 02:26:23,859 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742085_1261, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala._COPYING_
2025-03-26 02:26:23,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742085_1261 src: /172.20.1.10:50902 dest: /172.20.1.12:9866
2025-03-26 02:26:23,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742085_1261 src: /172.20.1.12:36808 dest: /172.20.1.13:9866
2025-03-26 02:26:23,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742085_1261 src: /172.20.1.13:57524 dest: /172.20.1.11:9866
2025-03-26 02:26:23,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36808, dest: /172.20.1.13:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742085_1261, duration(ns): 1682390
2025-03-26 02:26:23,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57524, dest: /172.20.1.11:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742085_1261, duration(ns): 1421149
2025-03-26 02:26:23,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742085_1261, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,865 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50902, dest: /172.20.1.12:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742085_1261, duration(ns): 1956426
2025-03-26 02:26:23,865 INFO terminating
2025-03-26 02:26:23,865 INFO terminating
2025-03-26 02:26:23,870 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742086_1262, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala._COPYING_
2025-03-26 02:26:23,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742086_1262 src: /172.20.1.10:50916 dest: /172.20.1.12:9866
2025-03-26 02:26:23,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742086_1262 src: /172.20.1.12:36822 dest: /172.20.1.13:9866
2025-03-26 02:26:23,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742086_1262 src: /172.20.1.13:57536 dest: /172.20.1.11:9866
2025-03-26 02:26:23,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36822, dest: /172.20.1.13:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742086_1262, duration(ns): 1701576
2025-03-26 02:26:23,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57536, dest: /172.20.1.11:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742086_1262, duration(ns): 1414129
2025-03-26 02:26:23,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742086_1262, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,875 INFO terminating
2025-03-26 02:26:23,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50916, dest: /172.20.1.12:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742086_1262, duration(ns): 2092857
2025-03-26 02:26:23,876 INFO terminating
2025-03-26 02:26:23,879 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,883 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742087_1263, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala._COPYING_
2025-03-26 02:26:23,883 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,883 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742087_1263 src: /172.20.1.10:50926 dest: /172.20.1.12:9866
2025-03-26 02:26:23,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742087_1263 src: /172.20.1.12:53738 dest: /172.20.1.11:9866
2025-03-26 02:26:23,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742087_1263 src: /172.20.1.11:43996 dest: /172.20.1.13:9866
2025-03-26 02:26:23,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:43996, dest: /172.20.1.13:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742087_1263, duration(ns): 4715996
2025-03-26 02:26:23,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742087_1263, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53738, dest: /172.20.1.11:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742087_1263, duration(ns): 5046982
2025-03-26 02:26:23,895 INFO terminating
2025-03-26 02:26:23,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50926, dest: /172.20.1.12:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742087_1263, duration(ns): 6072096
2025-03-26 02:26:23,896 INFO terminating
2025-03-26 02:26:23,904 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742088_1264, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala._COPYING_
2025-03-26 02:26:23,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742088_1264 src: /172.20.1.10:47730 dest: /172.20.1.13:9866
2025-03-26 02:26:23,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742088_1264 src: /172.20.1.12:53740 dest: /172.20.1.11:9866
2025-03-26 02:26:23,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742088_1264 src: /172.20.1.13:33004 dest: /172.20.1.12:9866
2025-03-26 02:26:23,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53740, dest: /172.20.1.11:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742088_1264, duration(ns): 1092823
2025-03-26 02:26:23,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47730, dest: /172.20.1.13:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742088_1264, duration(ns): 1645876
2025-03-26 02:26:23,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33004, dest: /172.20.1.12:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742088_1264, duration(ns): 1461439
2025-03-26 02:26:23,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742088_1264, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,949 INFO terminating
2025-03-26 02:26:23,949 INFO terminating
2025-03-26 02:26:23,951 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742089_1265, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala._COPYING_
2025-03-26 02:26:23,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742089_1265 src: /172.20.1.10:50228 dest: /172.20.1.11:9866
2025-03-26 02:26:23,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742089_1265 src: /172.20.1.11:44010 dest: /172.20.1.13:9866
2025-03-26 02:26:23,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742089_1265 src: /172.20.1.13:33008 dest: /172.20.1.12:9866
2025-03-26 02:26:23,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33008, dest: /172.20.1.12:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742089_1265, duration(ns): 1196833
2025-03-26 02:26:23,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44010, dest: /172.20.1.13:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742089_1265, duration(ns): 1927459
2025-03-26 02:26:23,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742089_1265, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,965 INFO terminating
2025-03-26 02:26:23,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50228, dest: /172.20.1.11:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742089_1265, duration(ns): 1966650
2025-03-26 02:26:23,966 INFO terminating
2025-03-26 02:26:23,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742090_1266, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala._COPYING_
2025-03-26 02:26:23,971 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742090_1266 src: /172.20.1.10:47732 dest: /172.20.1.13:9866
2025-03-26 02:26:23,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742090_1266 src: /172.20.1.12:53742 dest: /172.20.1.11:9866
2025-03-26 02:26:23,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742090_1266 src: /172.20.1.13:33010 dest: /172.20.1.12:9866
2025-03-26 02:26:23,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53742, dest: /172.20.1.11:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742090_1266, duration(ns): 1131555
2025-03-26 02:26:23,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742090_1266, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47732, dest: /172.20.1.13:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742090_1266, duration(ns): 1631451
2025-03-26 02:26:23,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33010, dest: /172.20.1.12:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742090_1266, duration(ns): 1408143
2025-03-26 02:26:23,976 INFO terminating
2025-03-26 02:26:23,976 INFO terminating
2025-03-26 02:26:23,977 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:23,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742091_1267, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala._COPYING_
2025-03-26 02:26:23,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742091_1267 src: /172.20.1.10:50936 dest: /172.20.1.12:9866
2025-03-26 02:26:23,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742091_1267 src: /172.20.1.12:36838 dest: /172.20.1.13:9866
2025-03-26 02:26:23,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742091_1267 src: /172.20.1.13:57546 dest: /172.20.1.11:9866
2025-03-26 02:26:23,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36838, dest: /172.20.1.13:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742091_1267, duration(ns): 1371893
2025-03-26 02:26:23,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57546, dest: /172.20.1.11:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742091_1267, duration(ns): 967964
2025-03-26 02:26:23,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742091_1267, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:23,991 INFO terminating
2025-03-26 02:26:23,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:23,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50936, dest: /172.20.1.12:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742091_1267, duration(ns): 1753400
2025-03-26 02:26:23,992 INFO terminating
2025-03-26 02:26:24,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,003 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742092_1268, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala._COPYING_
2025-03-26 02:26:24,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742092_1268 src: /172.20.1.10:50948 dest: /172.20.1.12:9866
2025-03-26 02:26:24,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742092_1268 src: /172.20.1.12:36840 dest: /172.20.1.13:9866
2025-03-26 02:26:24,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742092_1268 src: /172.20.1.13:57552 dest: /172.20.1.11:9866
2025-03-26 02:26:24,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57552, dest: /172.20.1.11:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742092_1268, duration(ns): 1003338
2025-03-26 02:26:24,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742092_1268, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50948, dest: /172.20.1.12:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742092_1268, duration(ns): 1618293
2025-03-26 02:26:24,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36840, dest: /172.20.1.13:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742092_1268, duration(ns): 1387092
2025-03-26 02:26:24,008 INFO terminating
2025-03-26 02:26:24,008 INFO terminating
2025-03-26 02:26:24,009 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,035 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742093_1269, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala._COPYING_
2025-03-26 02:26:24,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742093_1269 src: /172.20.1.10:50238 dest: /172.20.1.11:9866
2025-03-26 02:26:24,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742093_1269 src: /172.20.1.11:44022 dest: /172.20.1.13:9866
2025-03-26 02:26:24,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742093_1269 src: /172.20.1.13:33014 dest: /172.20.1.12:9866
2025-03-26 02:26:24,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50238, dest: /172.20.1.11:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742093_1269, duration(ns): 8569040
2025-03-26 02:26:24,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44022, dest: /172.20.1.13:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742093_1269, duration(ns): 8307826
2025-03-26 02:26:24,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33014, dest: /172.20.1.12:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742093_1269, duration(ns): 8074051
2025-03-26 02:26:24,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742093_1269, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,047 INFO terminating
2025-03-26 02:26:24,048 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,048 INFO terminating
2025-03-26 02:26:24,053 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742094_1270, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala._COPYING_
2025-03-26 02:26:24,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742094_1270 src: /172.20.1.10:50252 dest: /172.20.1.11:9866
2025-03-26 02:26:24,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742094_1270 src: /172.20.1.11:36380 dest: /172.20.1.12:9866
2025-03-26 02:26:24,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742094_1270 src: /172.20.1.12:36856 dest: /172.20.1.13:9866
2025-03-26 02:26:24,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36856, dest: /172.20.1.13:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742094_1270, duration(ns): 1211886
2025-03-26 02:26:24,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742094_1270, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50252, dest: /172.20.1.11:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742094_1270, duration(ns): 1774591
2025-03-26 02:26:24,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36380, dest: /172.20.1.12:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742094_1270, duration(ns): 1405474
2025-03-26 02:26:24,058 INFO terminating
2025-03-26 02:26:24,058 INFO terminating
2025-03-26 02:26:24,059 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742095_1271, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala._COPYING_
2025-03-26 02:26:24,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742095_1271 src: /172.20.1.10:47738 dest: /172.20.1.13:9866
2025-03-26 02:26:24,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742095_1271 src: /172.20.1.13:33020 dest: /172.20.1.12:9866
2025-03-26 02:26:24,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742095_1271 src: /172.20.1.12:53756 dest: /172.20.1.11:9866
2025-03-26 02:26:24,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53756, dest: /172.20.1.11:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742095_1271, duration(ns): 1554941
2025-03-26 02:26:24,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33020, dest: /172.20.1.12:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742095_1271, duration(ns): 2057933
2025-03-26 02:26:24,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742095_1271, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,076 INFO terminating
2025-03-26 02:26:24,077 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47738, dest: /172.20.1.13:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742095_1271, duration(ns): 2541494
2025-03-26 02:26:24,077 INFO terminating
2025-03-26 02:26:24,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742096_1272, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala._COPYING_
2025-03-26 02:26:24,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742096_1272 src: /172.20.1.10:50954 dest: /172.20.1.12:9866
2025-03-26 02:26:24,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742096_1272 src: /172.20.1.12:36872 dest: /172.20.1.13:9866
2025-03-26 02:26:24,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742096_1272 src: /172.20.1.13:57554 dest: /172.20.1.11:9866
2025-03-26 02:26:24,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36872, dest: /172.20.1.13:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742096_1272, duration(ns): 18218049
2025-03-26 02:26:24,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57554, dest: /172.20.1.11:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742096_1272, duration(ns): 17525575
2025-03-26 02:26:24,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742096_1272, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,112 INFO terminating
2025-03-26 02:26:24,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50954, dest: /172.20.1.12:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742096_1272, duration(ns): 18566137
2025-03-26 02:26:24,113 INFO terminating
2025-03-26 02:26:24,114 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742097_1273, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala._COPYING_
2025-03-26 02:26:24,123 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742097_1273 src: /172.20.1.10:50260 dest: /172.20.1.11:9866
2025-03-26 02:26:24,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742097_1273 src: /172.20.1.11:44038 dest: /172.20.1.13:9866
2025-03-26 02:26:24,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742097_1273 src: /172.20.1.13:33036 dest: /172.20.1.12:9866
2025-03-26 02:26:24,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50260, dest: /172.20.1.11:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742097_1273, duration(ns): 1789825
2025-03-26 02:26:24,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44038, dest: /172.20.1.13:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742097_1273, duration(ns): 1510203
2025-03-26 02:26:24,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33036, dest: /172.20.1.12:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742097_1273, duration(ns): 1323523
2025-03-26 02:26:24,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742097_1273, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,128 INFO terminating
2025-03-26 02:26:24,129 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,129 INFO terminating
2025-03-26 02:26:24,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742098_1274, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala._COPYING_
2025-03-26 02:26:24,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742098_1274 src: /172.20.1.10:47740 dest: /172.20.1.13:9866
2025-03-26 02:26:24,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742098_1274 src: /172.20.1.11:36394 dest: /172.20.1.12:9866
2025-03-26 02:26:24,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742098_1274 src: /172.20.1.13:57562 dest: /172.20.1.11:9866
2025-03-26 02:26:24,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36394, dest: /172.20.1.12:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742098_1274, duration(ns): 1050038
2025-03-26 02:26:24,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742098_1274, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47740, dest: /172.20.1.13:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742098_1274, duration(ns): 1837249
2025-03-26 02:26:24,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57562, dest: /172.20.1.11:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742098_1274, duration(ns): 1342305
2025-03-26 02:26:24,140 INFO terminating
2025-03-26 02:26:24,140 INFO terminating
2025-03-26 02:26:24,141 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742099_1275, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala._COPYING_
2025-03-26 02:26:24,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742099_1275 src: /172.20.1.10:47752 dest: /172.20.1.13:9866
2025-03-26 02:26:24,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742099_1275 src: /172.20.1.13:57566 dest: /172.20.1.11:9866
2025-03-26 02:26:24,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742099_1275 src: /172.20.1.11:36402 dest: /172.20.1.12:9866
2025-03-26 02:26:24,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36402, dest: /172.20.1.12:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742099_1275, duration(ns): 1157779
2025-03-26 02:26:24,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742099_1275, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,153 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47752, dest: /172.20.1.13:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742099_1275, duration(ns): 2192292
2025-03-26 02:26:24,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57566, dest: /172.20.1.11:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742099_1275, duration(ns): 1298917
2025-03-26 02:26:24,153 INFO terminating
2025-03-26 02:26:24,153 INFO terminating
2025-03-26 02:26:24,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742100_1276, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala._COPYING_
2025-03-26 02:26:24,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742100_1276 src: /172.20.1.10:50270 dest: /172.20.1.11:9866
2025-03-26 02:26:24,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742100_1276 src: /172.20.1.11:36416 dest: /172.20.1.12:9866
2025-03-26 02:26:24,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742100_1276 src: /172.20.1.12:36880 dest: /172.20.1.13:9866
2025-03-26 02:26:24,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50270, dest: /172.20.1.11:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742100_1276, duration(ns): 3097082
2025-03-26 02:26:24,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36416, dest: /172.20.1.12:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742100_1276, duration(ns): 2829636
2025-03-26 02:26:24,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36880, dest: /172.20.1.13:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742100_1276, duration(ns): 2604696
2025-03-26 02:26:24,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742100_1276, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,171 INFO terminating
2025-03-26 02:26:24,172 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,172 INFO terminating
2025-03-26 02:26:24,178 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,178 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,179 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742101_1277, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala._COPYING_
2025-03-26 02:26:24,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742101_1277 src: /172.20.1.10:50272 dest: /172.20.1.11:9866
2025-03-26 02:26:24,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742101_1277 src: /172.20.1.11:36418 dest: /172.20.1.12:9866
2025-03-26 02:26:24,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742101_1277 src: /172.20.1.12:36890 dest: /172.20.1.13:9866
2025-03-26 02:26:24,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36418, dest: /172.20.1.12:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742101_1277, duration(ns): 1573457
2025-03-26 02:26:24,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36890, dest: /172.20.1.13:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742101_1277, duration(ns): 1408619
2025-03-26 02:26:24,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742101_1277, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,184 INFO terminating
2025-03-26 02:26:24,185 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50272, dest: /172.20.1.11:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742101_1277, duration(ns): 1915685
2025-03-26 02:26:24,185 INFO terminating
2025-03-26 02:26:24,189 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742102_1278, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala._COPYING_
2025-03-26 02:26:24,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742102_1278 src: /172.20.1.10:47756 dest: /172.20.1.13:9866
2025-03-26 02:26:24,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742102_1278 src: /172.20.1.13:57572 dest: /172.20.1.11:9866
2025-03-26 02:26:24,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742102_1278 src: /172.20.1.11:36430 dest: /172.20.1.12:9866
2025-03-26 02:26:24,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36430, dest: /172.20.1.12:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742102_1278, duration(ns): 932022
2025-03-26 02:26:24,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57572, dest: /172.20.1.11:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742102_1278, duration(ns): 1127644
2025-03-26 02:26:24,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742102_1278, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,194 INFO terminating
2025-03-26 02:26:24,195 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47756, dest: /172.20.1.13:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742102_1278, duration(ns): 1515297
2025-03-26 02:26:24,195 INFO terminating
2025-03-26 02:26:24,200 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742103_1279, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala._COPYING_
2025-03-26 02:26:24,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742103_1279 src: /172.20.1.10:47766 dest: /172.20.1.13:9866
2025-03-26 02:26:24,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742103_1279 src: /172.20.1.13:33050 dest: /172.20.1.12:9866
2025-03-26 02:26:24,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742103_1279 src: /172.20.1.12:53772 dest: /172.20.1.11:9866
2025-03-26 02:26:24,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53772, dest: /172.20.1.11:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742103_1279, duration(ns): 1239335
2025-03-26 02:26:24,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47766, dest: /172.20.1.13:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742103_1279, duration(ns): 2003125
2025-03-26 02:26:24,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33050, dest: /172.20.1.12:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742103_1279, duration(ns): 1734504
2025-03-26 02:26:24,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742103_1279, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,206 INFO terminating
2025-03-26 02:26:24,206 INFO terminating
2025-03-26 02:26:24,207 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742104_1280, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala._COPYING_
2025-03-26 02:26:24,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742104_1280 src: /172.20.1.10:50278 dest: /172.20.1.11:9866
2025-03-26 02:26:24,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742104_1280 src: /172.20.1.11:44054 dest: /172.20.1.13:9866
2025-03-26 02:26:24,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742104_1280 src: /172.20.1.13:33054 dest: /172.20.1.12:9866
2025-03-26 02:26:24,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44054, dest: /172.20.1.13:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742104_1280, duration(ns): 1919308
2025-03-26 02:26:24,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33054, dest: /172.20.1.12:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742104_1280, duration(ns): 1469936
2025-03-26 02:26:24,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742104_1280, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,224 INFO terminating
2025-03-26 02:26:24,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50278, dest: /172.20.1.11:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742104_1280, duration(ns): 2477521
2025-03-26 02:26:24,225 INFO terminating
2025-03-26 02:26:24,226 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,231 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742105_1281, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala._COPYING_
2025-03-26 02:26:24,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742105_1281 src: /172.20.1.10:50290 dest: /172.20.1.11:9866
2025-03-26 02:26:24,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742105_1281 src: /172.20.1.11:44056 dest: /172.20.1.13:9866
2025-03-26 02:26:24,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742105_1281 src: /172.20.1.13:33056 dest: /172.20.1.12:9866
2025-03-26 02:26:24,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44056, dest: /172.20.1.13:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742105_1281, duration(ns): 11160985
2025-03-26 02:26:24,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33056, dest: /172.20.1.12:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742105_1281, duration(ns): 10799360
2025-03-26 02:26:24,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742105_1281, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50290, dest: /172.20.1.11:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742105_1281, duration(ns): 11570334
2025-03-26 02:26:24,246 INFO terminating
2025-03-26 02:26:24,246 INFO terminating
2025-03-26 02:26:24,247 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,251 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742106_1282, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala._COPYING_
2025-03-26 02:26:24,251 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,251 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742106_1282 src: /172.20.1.10:50304 dest: /172.20.1.11:9866
2025-03-26 02:26:24,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742106_1282 src: /172.20.1.11:36442 dest: /172.20.1.12:9866
2025-03-26 02:26:24,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742106_1282 src: /172.20.1.12:36902 dest: /172.20.1.13:9866
2025-03-26 02:26:24,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36902, dest: /172.20.1.13:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742106_1282, duration(ns): 1450809
2025-03-26 02:26:24,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742106_1282, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36442, dest: /172.20.1.12:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742106_1282, duration(ns): 1722841
2025-03-26 02:26:24,257 INFO terminating
2025-03-26 02:26:24,258 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50304, dest: /172.20.1.11:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742106_1282, duration(ns): 2382484
2025-03-26 02:26:24,258 INFO terminating
2025-03-26 02:26:24,263 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742107_1283, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala._COPYING_
2025-03-26 02:26:24,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742107_1283 src: /172.20.1.10:50966 dest: /172.20.1.12:9866
2025-03-26 02:26:24,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742107_1283 src: /172.20.1.12:53782 dest: /172.20.1.11:9866
2025-03-26 02:26:24,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742107_1283 src: /172.20.1.11:44062 dest: /172.20.1.13:9866
2025-03-26 02:26:24,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44062, dest: /172.20.1.13:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742107_1283, duration(ns): 1167792
2025-03-26 02:26:24,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50966, dest: /172.20.1.12:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742107_1283, duration(ns): 1711101
2025-03-26 02:26:24,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53782, dest: /172.20.1.11:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742107_1283, duration(ns): 1478772
2025-03-26 02:26:24,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742107_1283, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,269 INFO terminating
2025-03-26 02:26:24,269 INFO terminating
2025-03-26 02:26:24,270 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742108_1284, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala._COPYING_
2025-03-26 02:26:24,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742108_1284 src: /172.20.1.10:47770 dest: /172.20.1.13:9866
2025-03-26 02:26:24,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742108_1284 src: /172.20.1.13:57582 dest: /172.20.1.11:9866
2025-03-26 02:26:24,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742108_1284 src: /172.20.1.11:36446 dest: /172.20.1.12:9866
2025-03-26 02:26:24,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36446, dest: /172.20.1.12:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742108_1284, duration(ns): 1313354
2025-03-26 02:26:24,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742108_1284, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57582, dest: /172.20.1.11:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742108_1284, duration(ns): 1699011
2025-03-26 02:26:24,281 INFO terminating
2025-03-26 02:26:24,282 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47770, dest: /172.20.1.13:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742108_1284, duration(ns): 2037461
2025-03-26 02:26:24,282 INFO terminating
2025-03-26 02:26:24,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742109_1285, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala._COPYING_
2025-03-26 02:26:24,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742109_1285 src: /172.20.1.10:50978 dest: /172.20.1.12:9866
2025-03-26 02:26:24,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742109_1285 src: /172.20.1.12:36908 dest: /172.20.1.13:9866
2025-03-26 02:26:24,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742109_1285 src: /172.20.1.13:57590 dest: /172.20.1.11:9866
2025-03-26 02:26:24,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57590, dest: /172.20.1.11:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742109_1285, duration(ns): 1268017
2025-03-26 02:26:24,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50978, dest: /172.20.1.12:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742109_1285, duration(ns): 2030986
2025-03-26 02:26:24,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36908, dest: /172.20.1.13:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742109_1285, duration(ns): 1615620
2025-03-26 02:26:24,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742109_1285, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,292 INFO terminating
2025-03-26 02:26:24,293 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,293 INFO terminating
2025-03-26 02:26:24,298 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742110_1286, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala._COPYING_
2025-03-26 02:26:24,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742110_1286 src: /172.20.1.10:47782 dest: /172.20.1.13:9866
2025-03-26 02:26:24,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742110_1286 src: /172.20.1.13:33062 dest: /172.20.1.12:9866
2025-03-26 02:26:24,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742110_1286 src: /172.20.1.12:53788 dest: /172.20.1.11:9866
2025-03-26 02:26:24,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53788, dest: /172.20.1.11:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742110_1286, duration(ns): 1252141
2025-03-26 02:26:24,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742110_1286, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33062, dest: /172.20.1.12:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742110_1286, duration(ns): 1543589
2025-03-26 02:26:24,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47782, dest: /172.20.1.13:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742110_1286, duration(ns): 2671445
2025-03-26 02:26:24,305 INFO terminating
2025-03-26 02:26:24,305 INFO terminating
2025-03-26 02:26:24,306 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,310 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742111_1287, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala._COPYING_
2025-03-26 02:26:24,310 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,310 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742111_1287 src: /172.20.1.10:50318 dest: /172.20.1.11:9866
2025-03-26 02:26:24,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742111_1287 src: /172.20.1.11:36458 dest: /172.20.1.12:9866
2025-03-26 02:26:24,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742111_1287 src: /172.20.1.12:36920 dest: /172.20.1.13:9866
2025-03-26 02:26:24,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36920, dest: /172.20.1.13:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742111_1287, duration(ns): 1436426
2025-03-26 02:26:24,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742111_1287, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50318, dest: /172.20.1.11:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742111_1287, duration(ns): 2070076
2025-03-26 02:26:24,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36458, dest: /172.20.1.12:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742111_1287, duration(ns): 1782856
2025-03-26 02:26:24,316 INFO terminating
2025-03-26 02:26:24,317 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,317 INFO terminating
2025-03-26 02:26:24,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742112_1288, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala._COPYING_
2025-03-26 02:26:24,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742112_1288 src: /172.20.1.10:47796 dest: /172.20.1.13:9866
2025-03-26 02:26:24,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742112_1288 src: /172.20.1.12:53800 dest: /172.20.1.11:9866
2025-03-26 02:26:24,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742112_1288 src: /172.20.1.13:33076 dest: /172.20.1.12:9866
2025-03-26 02:26:24,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53800, dest: /172.20.1.11:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742112_1288, duration(ns): 812580
2025-03-26 02:26:24,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33076, dest: /172.20.1.12:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742112_1288, duration(ns): 3145897
2025-03-26 02:26:24,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742112_1288, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,328 INFO terminating
2025-03-26 02:26:24,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47796, dest: /172.20.1.13:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742112_1288, duration(ns): 3670290
2025-03-26 02:26:24,329 INFO terminating
2025-03-26 02:26:24,330 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,334 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742113_1289, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala._COPYING_
2025-03-26 02:26:24,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742113_1289 src: /172.20.1.10:50988 dest: /172.20.1.12:9866
2025-03-26 02:26:24,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742113_1289 src: /172.20.1.11:44074 dest: /172.20.1.13:9866
2025-03-26 02:26:24,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742113_1289 src: /172.20.1.12:53806 dest: /172.20.1.11:9866
2025-03-26 02:26:24,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44074, dest: /172.20.1.13:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742113_1289, duration(ns): 938042
2025-03-26 02:26:24,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53806, dest: /172.20.1.11:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742113_1289, duration(ns): 1251666
2025-03-26 02:26:24,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742113_1289, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50988, dest: /172.20.1.12:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742113_1289, duration(ns): 1565233
2025-03-26 02:26:24,339 INFO terminating
2025-03-26 02:26:24,339 INFO terminating
2025-03-26 02:26:24,340 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742114_1290, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala._COPYING_
2025-03-26 02:26:24,344 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,344 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742114_1290 src: /172.20.1.10:47810 dest: /172.20.1.13:9866
2025-03-26 02:26:24,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742114_1290 src: /172.20.1.13:57598 dest: /172.20.1.11:9866
2025-03-26 02:26:24,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742114_1290 src: /172.20.1.11:36470 dest: /172.20.1.12:9866
2025-03-26 02:26:24,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36470, dest: /172.20.1.12:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742114_1290, duration(ns): 1143487
2025-03-26 02:26:24,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742114_1290, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47810, dest: /172.20.1.13:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742114_1290, duration(ns): 1775953
2025-03-26 02:26:24,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57598, dest: /172.20.1.11:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742114_1290, duration(ns): 1451501
2025-03-26 02:26:24,352 INFO terminating
2025-03-26 02:26:24,352 INFO terminating
2025-03-26 02:26:24,353 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,357 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742115_1291, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala._COPYING_
2025-03-26 02:26:24,357 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,357 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742115_1291 src: /172.20.1.10:50332 dest: /172.20.1.11:9866
2025-03-26 02:26:24,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742115_1291 src: /172.20.1.11:44088 dest: /172.20.1.13:9866
2025-03-26 02:26:24,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742115_1291 src: /172.20.1.13:33086 dest: /172.20.1.12:9866
2025-03-26 02:26:24,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33086, dest: /172.20.1.12:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742115_1291, duration(ns): 711387
2025-03-26 02:26:24,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742115_1291, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50332, dest: /172.20.1.11:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742115_1291, duration(ns): 1228610
2025-03-26 02:26:24,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44088, dest: /172.20.1.13:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742115_1291, duration(ns): 1028648
2025-03-26 02:26:24,362 INFO terminating
2025-03-26 02:26:24,362 INFO terminating
2025-03-26 02:26:24,363 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742116_1292, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala._COPYING_
2025-03-26 02:26:24,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742116_1292 src: /172.20.1.10:50348 dest: /172.20.1.11:9866
2025-03-26 02:26:24,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742116_1292 src: /172.20.1.11:36486 dest: /172.20.1.12:9866
2025-03-26 02:26:24,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742116_1292 src: /172.20.1.12:36934 dest: /172.20.1.13:9866
2025-03-26 02:26:24,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36486, dest: /172.20.1.12:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742116_1292, duration(ns): 1138861
2025-03-26 02:26:24,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36934, dest: /172.20.1.13:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742116_1292, duration(ns): 908143
2025-03-26 02:26:24,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742116_1292, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,373 INFO terminating
2025-03-26 02:26:24,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50348, dest: /172.20.1.11:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742116_1292, duration(ns): 1372822
2025-03-26 02:26:24,374 INFO terminating
2025-03-26 02:26:24,375 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742117_1293, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala._COPYING_
2025-03-26 02:26:24,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742117_1293 src: /172.20.1.10:47826 dest: /172.20.1.13:9866
2025-03-26 02:26:24,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742117_1293 src: /172.20.1.11:36502 dest: /172.20.1.12:9866
2025-03-26 02:26:24,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742117_1293 src: /172.20.1.13:57600 dest: /172.20.1.11:9866
2025-03-26 02:26:24,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36502, dest: /172.20.1.12:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742117_1293, duration(ns): 5162808
2025-03-26 02:26:24,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47826, dest: /172.20.1.13:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742117_1293, duration(ns): 6086352
2025-03-26 02:26:24,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57600, dest: /172.20.1.11:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742117_1293, duration(ns): 5701095
2025-03-26 02:26:24,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742117_1293, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,390 INFO terminating
2025-03-26 02:26:24,391 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,391 INFO terminating
2025-03-26 02:26:24,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,398 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742118_1294, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala._COPYING_
2025-03-26 02:26:24,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742118_1294 src: /172.20.1.10:50990 dest: /172.20.1.12:9866
2025-03-26 02:26:24,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742118_1294 src: /172.20.1.12:36938 dest: /172.20.1.13:9866
2025-03-26 02:26:24,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742118_1294 src: /172.20.1.13:57608 dest: /172.20.1.11:9866
2025-03-26 02:26:24,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36938, dest: /172.20.1.13:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742118_1294, duration(ns): 1121484
2025-03-26 02:26:24,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57608, dest: /172.20.1.11:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742118_1294, duration(ns): 911641
2025-03-26 02:26:24,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742118_1294, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,402 INFO terminating
2025-03-26 02:26:24,403 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50990, dest: /172.20.1.12:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742118_1294, duration(ns): 1658862
2025-03-26 02:26:24,403 INFO terminating
2025-03-26 02:26:24,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742119_1295, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala._COPYING_
2025-03-26 02:26:24,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742119_1295 src: /172.20.1.10:47842 dest: /172.20.1.13:9866
2025-03-26 02:26:24,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742119_1295 src: /172.20.1.13:57610 dest: /172.20.1.11:9866
2025-03-26 02:26:24,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742119_1295 src: /172.20.1.11:36504 dest: /172.20.1.12:9866
2025-03-26 02:26:24,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36504, dest: /172.20.1.12:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742119_1295, duration(ns): 842450
2025-03-26 02:26:24,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57610, dest: /172.20.1.11:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742119_1295, duration(ns): 1413502
2025-03-26 02:26:24,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742119_1295, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,414 INFO terminating
2025-03-26 02:26:24,415 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47842, dest: /172.20.1.13:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742119_1295, duration(ns): 1747163
2025-03-26 02:26:24,415 INFO terminating
2025-03-26 02:26:24,423 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742120_1296, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala._COPYING_
2025-03-26 02:26:24,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742120_1296 src: /172.20.1.10:50994 dest: /172.20.1.12:9866
2025-03-26 02:26:24,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742120_1296 src: /172.20.1.12:53820 dest: /172.20.1.11:9866
2025-03-26 02:26:24,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742120_1296 src: /172.20.1.11:44096 dest: /172.20.1.13:9866
2025-03-26 02:26:24,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50994, dest: /172.20.1.12:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742120_1296, duration(ns): 1469313
2025-03-26 02:26:24,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44096, dest: /172.20.1.13:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742120_1296, duration(ns): 968604
2025-03-26 02:26:24,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53820, dest: /172.20.1.11:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742120_1296, duration(ns): 1183474
2025-03-26 02:26:24,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742120_1296, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,428 INFO terminating
2025-03-26 02:26:24,429 INFO terminating
2025-03-26 02:26:24,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,433 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742121_1297, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala._COPYING_
2025-03-26 02:26:24,433 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,433 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742121_1297 src: /172.20.1.10:47848 dest: /172.20.1.13:9866
2025-03-26 02:26:24,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742121_1297 src: /172.20.1.11:36510 dest: /172.20.1.12:9866
2025-03-26 02:26:24,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742121_1297 src: /172.20.1.13:57618 dest: /172.20.1.11:9866
2025-03-26 02:26:24,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36510, dest: /172.20.1.12:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742121_1297, duration(ns): 735139
2025-03-26 02:26:24,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57618, dest: /172.20.1.11:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742121_1297, duration(ns): 985027
2025-03-26 02:26:24,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742121_1297, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,438 INFO terminating
2025-03-26 02:26:24,439 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47848, dest: /172.20.1.13:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742121_1297, duration(ns): 1220542
2025-03-26 02:26:24,439 INFO terminating
2025-03-26 02:26:24,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742122_1298, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala._COPYING_
2025-03-26 02:26:24,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742122_1298 src: /172.20.1.10:50998 dest: /172.20.1.12:9866
2025-03-26 02:26:24,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742122_1298 src: /172.20.1.12:53836 dest: /172.20.1.11:9866
2025-03-26 02:26:24,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742122_1298 src: /172.20.1.11:44108 dest: /172.20.1.13:9866
2025-03-26 02:26:24,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44108, dest: /172.20.1.13:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742122_1298, duration(ns): 697996
2025-03-26 02:26:24,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742122_1298, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50998, dest: /172.20.1.12:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742122_1298, duration(ns): 1147840
2025-03-26 02:26:24,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53836, dest: /172.20.1.11:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742122_1298, duration(ns): 942186
2025-03-26 02:26:24,450 INFO terminating
2025-03-26 02:26:24,450 INFO terminating
2025-03-26 02:26:24,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,456 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742123_1299, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala._COPYING_
2025-03-26 02:26:24,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742123_1299 src: /172.20.1.10:50354 dest: /172.20.1.11:9866
2025-03-26 02:26:24,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742123_1299 src: /172.20.1.11:36520 dest: /172.20.1.12:9866
2025-03-26 02:26:24,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742123_1299 src: /172.20.1.12:36950 dest: /172.20.1.13:9866
2025-03-26 02:26:24,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50354, dest: /172.20.1.11:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742123_1299, duration(ns): 1340711
2025-03-26 02:26:24,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36520, dest: /172.20.1.12:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742123_1299, duration(ns): 1107254
2025-03-26 02:26:24,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36950, dest: /172.20.1.13:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742123_1299, duration(ns): 922343
2025-03-26 02:26:24,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742123_1299, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,461 INFO terminating
2025-03-26 02:26:24,462 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,462 INFO terminating
2025-03-26 02:26:24,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742124_1300, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala._COPYING_
2025-03-26 02:26:24,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742124_1300 src: /172.20.1.10:50362 dest: /172.20.1.11:9866
2025-03-26 02:26:24,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742124_1300 src: /172.20.1.11:44124 dest: /172.20.1.13:9866
2025-03-26 02:26:24,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742124_1300 src: /172.20.1.13:33102 dest: /172.20.1.12:9866
2025-03-26 02:26:24,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50362, dest: /172.20.1.11:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742124_1300, duration(ns): 1173118
2025-03-26 02:26:24,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44124, dest: /172.20.1.13:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742124_1300, duration(ns): 898398
2025-03-26 02:26:24,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33102, dest: /172.20.1.12:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742124_1300, duration(ns): 745012
2025-03-26 02:26:24,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742124_1300, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,470 INFO terminating
2025-03-26 02:26:24,470 INFO terminating
2025-03-26 02:26:24,471 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,474 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742125_1301, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala._COPYING_
2025-03-26 02:26:24,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742125_1301 src: /172.20.1.10:47850 dest: /172.20.1.13:9866
2025-03-26 02:26:24,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742125_1301 src: /172.20.1.13:33106 dest: /172.20.1.12:9866
2025-03-26 02:26:24,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742125_1301 src: /172.20.1.12:53844 dest: /172.20.1.11:9866
2025-03-26 02:26:24,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47850, dest: /172.20.1.13:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742125_1301, duration(ns): 1596540
2025-03-26 02:26:24,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53844, dest: /172.20.1.11:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742125_1301, duration(ns): 726567
2025-03-26 02:26:24,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33106, dest: /172.20.1.12:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742125_1301, duration(ns): 1349446
2025-03-26 02:26:24,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742125_1301, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,479 INFO terminating
2025-03-26 02:26:24,479 INFO terminating
2025-03-26 02:26:24,480 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,483 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742126_1302, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala._COPYING_
2025-03-26 02:26:24,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742126_1302 src: /172.20.1.10:50366 dest: /172.20.1.11:9866
2025-03-26 02:26:24,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742126_1302 src: /172.20.1.11:44126 dest: /172.20.1.13:9866
2025-03-26 02:26:24,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742126_1302 src: /172.20.1.13:33118 dest: /172.20.1.12:9866
2025-03-26 02:26:24,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33118, dest: /172.20.1.12:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742126_1302, duration(ns): 1110862
2025-03-26 02:26:24,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742126_1302, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50366, dest: /172.20.1.11:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742126_1302, duration(ns): 3614759
2025-03-26 02:26:24,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44126, dest: /172.20.1.13:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742126_1302, duration(ns): 1264703
2025-03-26 02:26:24,490 INFO terminating
2025-03-26 02:26:24,490 INFO terminating
2025-03-26 02:26:24,491 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,494 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742127_1303, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala._COPYING_
2025-03-26 02:26:24,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742127_1303 src: /172.20.1.10:47854 dest: /172.20.1.13:9866
2025-03-26 02:26:24,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742127_1303 src: /172.20.1.12:53854 dest: /172.20.1.11:9866
2025-03-26 02:26:24,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742127_1303 src: /172.20.1.13:33124 dest: /172.20.1.12:9866
2025-03-26 02:26:24,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53854, dest: /172.20.1.11:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742127_1303, duration(ns): 1259880
2025-03-26 02:26:24,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742127_1303, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47854, dest: /172.20.1.13:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742127_1303, duration(ns): 1728057
2025-03-26 02:26:24,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33124, dest: /172.20.1.12:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742127_1303, duration(ns): 1552184
2025-03-26 02:26:24,500 INFO terminating
2025-03-26 02:26:24,500 INFO terminating
2025-03-26 02:26:24,502 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742128_1304, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_
2025-03-26 02:26:24,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742128_1304 src: /172.20.1.10:51006 dest: /172.20.1.12:9866
2025-03-26 02:26:24,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742128_1304 src: /172.20.1.12:36966 dest: /172.20.1.13:9866
2025-03-26 02:26:24,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742128_1304 src: /172.20.1.13:57634 dest: /172.20.1.11:9866
2025-03-26 02:26:24,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57634, dest: /172.20.1.11:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742128_1304, duration(ns): 1024779
2025-03-26 02:26:24,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742128_1304, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51006, dest: /172.20.1.12:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742128_1304, duration(ns): 1383825
2025-03-26 02:26:24,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36966, dest: /172.20.1.13:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742128_1304, duration(ns): 1223127
2025-03-26 02:26:24,510 INFO terminating
2025-03-26 02:26:24,510 INFO terminating
2025-03-26 02:26:24,511 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742128_1304 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_
2025-03-26 02:26:24,911 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742129_1305, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala._COPYING_
2025-03-26 02:26:24,915 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,915 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742129_1305 src: /172.20.1.10:50382 dest: /172.20.1.11:9866
2025-03-26 02:26:24,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742129_1305 src: /172.20.1.11:44140 dest: /172.20.1.13:9866
2025-03-26 02:26:24,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742129_1305 src: /172.20.1.13:33136 dest: /172.20.1.12:9866
2025-03-26 02:26:24,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33136, dest: /172.20.1.12:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742129_1305, duration(ns): 1241557
2025-03-26 02:26:24,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742129_1305, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50382, dest: /172.20.1.11:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742129_1305, duration(ns): 1752976
2025-03-26 02:26:24,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44140, dest: /172.20.1.13:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742129_1305, duration(ns): 1463115
2025-03-26 02:26:24,921 INFO terminating
2025-03-26 02:26:24,921 INFO terminating
2025-03-26 02:26:24,922 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,925 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742130_1306, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala._COPYING_
2025-03-26 02:26:24,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742130_1306 src: /172.20.1.10:50396 dest: /172.20.1.11:9866
2025-03-26 02:26:24,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742130_1306 src: /172.20.1.11:44146 dest: /172.20.1.13:9866
2025-03-26 02:26:24,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742130_1306 src: /172.20.1.13:33148 dest: /172.20.1.12:9866
2025-03-26 02:26:24,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33148, dest: /172.20.1.12:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742130_1306, duration(ns): 1620422
2025-03-26 02:26:24,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742130_1306, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44146, dest: /172.20.1.13:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742130_1306, duration(ns): 1863865
2025-03-26 02:26:24,934 INFO terminating
2025-03-26 02:26:24,935 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50396, dest: /172.20.1.11:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742130_1306, duration(ns): 5781692
2025-03-26 02:26:24,935 INFO terminating
2025-03-26 02:26:24,938 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742131_1307, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala._COPYING_
2025-03-26 02:26:24,939 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742131_1307 src: /172.20.1.10:51012 dest: /172.20.1.12:9866
2025-03-26 02:26:24,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742131_1307 src: /172.20.1.12:36968 dest: /172.20.1.13:9866
2025-03-26 02:26:24,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742131_1307 src: /172.20.1.13:57642 dest: /172.20.1.11:9866
2025-03-26 02:26:24,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57642, dest: /172.20.1.11:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742131_1307, duration(ns): 1223957
2025-03-26 02:26:24,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742131_1307, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51012, dest: /172.20.1.12:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742131_1307, duration(ns): 1792251
2025-03-26 02:26:24,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36968, dest: /172.20.1.13:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742131_1307, duration(ns): 1486865
2025-03-26 02:26:24,944 INFO terminating
2025-03-26 02:26:24,944 INFO terminating
2025-03-26 02:26:24,945 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,948 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742132_1308, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala._COPYING_
2025-03-26 02:26:24,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742132_1308 src: /172.20.1.10:50404 dest: /172.20.1.11:9866
2025-03-26 02:26:24,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742132_1308 src: /172.20.1.11:44158 dest: /172.20.1.13:9866
2025-03-26 02:26:24,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742132_1308 src: /172.20.1.13:33156 dest: /172.20.1.12:9866
2025-03-26 02:26:24,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33156, dest: /172.20.1.12:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742132_1308, duration(ns): 3338506
2025-03-26 02:26:24,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50404, dest: /172.20.1.11:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742132_1308, duration(ns): 3871986
2025-03-26 02:26:24,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44158, dest: /172.20.1.13:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742132_1308, duration(ns): 3575177
2025-03-26 02:26:24,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742132_1308, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,955 INFO terminating
2025-03-26 02:26:24,955 INFO terminating
2025-03-26 02:26:24,956 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742133_1309, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala._COPYING_
2025-03-26 02:26:24,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742133_1309 src: /172.20.1.10:50406 dest: /172.20.1.11:9866
2025-03-26 02:26:24,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742133_1309 src: /172.20.1.11:36528 dest: /172.20.1.12:9866
2025-03-26 02:26:24,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742133_1309 src: /172.20.1.12:36976 dest: /172.20.1.13:9866
2025-03-26 02:26:24,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50406, dest: /172.20.1.11:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742133_1309, duration(ns): 1622517
2025-03-26 02:26:24,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36528, dest: /172.20.1.12:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742133_1309, duration(ns): 1399434
2025-03-26 02:26:24,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36976, dest: /172.20.1.13:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742133_1309, duration(ns): 1217126
2025-03-26 02:26:24,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742133_1309, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,965 INFO terminating
2025-03-26 02:26:24,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,966 INFO terminating
2025-03-26 02:26:24,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742134_1310, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala._COPYING_
2025-03-26 02:26:24,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742134_1310 src: /172.20.1.10:51028 dest: /172.20.1.12:9866
2025-03-26 02:26:24,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742134_1310 src: /172.20.1.11:44170 dest: /172.20.1.13:9866
2025-03-26 02:26:24,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742134_1310 src: /172.20.1.12:53862 dest: /172.20.1.11:9866
2025-03-26 02:26:24,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44170, dest: /172.20.1.13:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742134_1310, duration(ns): 3055919
2025-03-26 02:26:24,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742134_1310, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51028, dest: /172.20.1.12:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742134_1310, duration(ns): 3904937
2025-03-26 02:26:24,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53862, dest: /172.20.1.11:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742134_1310, duration(ns): 3636435
2025-03-26 02:26:24,977 INFO terminating
2025-03-26 02:26:24,977 INFO terminating
2025-03-26 02:26:24,983 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742135_1311, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala._COPYING_
2025-03-26 02:26:24,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742135_1311 src: /172.20.1.10:50422 dest: /172.20.1.11:9866
2025-03-26 02:26:24,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742135_1311 src: /172.20.1.11:44184 dest: /172.20.1.13:9866
2025-03-26 02:26:24,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742135_1311 src: /172.20.1.13:33166 dest: /172.20.1.12:9866
2025-03-26 02:26:24,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44184, dest: /172.20.1.13:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742135_1311, duration(ns): 1424351
2025-03-26 02:26:24,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33166, dest: /172.20.1.12:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742135_1311, duration(ns): 1244848
2025-03-26 02:26:24,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742135_1311, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:24,992 INFO terminating
2025-03-26 02:26:24,993 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:24,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50422, dest: /172.20.1.11:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742135_1311, duration(ns): 1721532
2025-03-26 02:26:24,993 INFO terminating
2025-03-26 02:26:24,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742136_1312, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala._COPYING_
2025-03-26 02:26:24,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:24,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742136_1312 src: /172.20.1.10:47866 dest: /172.20.1.13:9866
2025-03-26 02:26:24,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742136_1312 src: /172.20.1.13:33180 dest: /172.20.1.12:9866
2025-03-26 02:26:25,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742136_1312 src: /172.20.1.12:53864 dest: /172.20.1.11:9866
2025-03-26 02:26:25,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53864, dest: /172.20.1.11:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742136_1312, duration(ns): 764429
2025-03-26 02:26:25,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33180, dest: /172.20.1.12:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742136_1312, duration(ns): 973440
2025-03-26 02:26:25,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742136_1312, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,001 INFO terminating
2025-03-26 02:26:25,002 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47866, dest: /172.20.1.13:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742136_1312, duration(ns): 1217925
2025-03-26 02:26:25,002 INFO terminating
2025-03-26 02:26:25,005 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742137_1313, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala._COPYING_
2025-03-26 02:26:25,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742137_1313 src: /172.20.1.10:47882 dest: /172.20.1.13:9866
2025-03-26 02:26:25,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742137_1313 src: /172.20.1.13:57658 dest: /172.20.1.11:9866
2025-03-26 02:26:25,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742137_1313 src: /172.20.1.11:36536 dest: /172.20.1.12:9866
2025-03-26 02:26:25,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36536, dest: /172.20.1.12:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742137_1313, duration(ns): 5566700
2025-03-26 02:26:25,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742137_1313, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47882, dest: /172.20.1.13:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742137_1313, duration(ns): 6207356
2025-03-26 02:26:25,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57658, dest: /172.20.1.11:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742137_1313, duration(ns): 5919523
2025-03-26 02:26:25,015 INFO terminating
2025-03-26 02:26:25,015 INFO terminating
2025-03-26 02:26:25,016 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742138_1314, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_
2025-03-26 02:26:25,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742138_1314 src: /172.20.1.10:47890 dest: /172.20.1.13:9866
2025-03-26 02:26:25,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742138_1314 src: /172.20.1.13:57660 dest: /172.20.1.11:9866
2025-03-26 02:26:25,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742138_1314 src: /172.20.1.11:36538 dest: /172.20.1.12:9866
2025-03-26 02:26:25,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36538, dest: /172.20.1.12:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742138_1314, duration(ns): 870014
2025-03-26 02:26:25,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57660, dest: /172.20.1.11:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742138_1314, duration(ns): 1049933
2025-03-26 02:26:25,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742138_1314, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47890, dest: /172.20.1.13:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742138_1314, duration(ns): 1171649
2025-03-26 02:26:25,026 INFO terminating
2025-03-26 02:26:25,026 INFO terminating
2025-03-26 02:26:25,027 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742139_1315, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala._COPYING_
2025-03-26 02:26:25,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742139_1315 src: /172.20.1.10:47902 dest: /172.20.1.13:9866
2025-03-26 02:26:25,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742139_1315 src: /172.20.1.13:57672 dest: /172.20.1.11:9866
2025-03-26 02:26:25,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742139_1315 src: /172.20.1.11:36550 dest: /172.20.1.12:9866
2025-03-26 02:26:25,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36550, dest: /172.20.1.12:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742139_1315, duration(ns): 1155116
2025-03-26 02:26:25,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57672, dest: /172.20.1.11:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742139_1315, duration(ns): 1303387
2025-03-26 02:26:25,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742139_1315, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,039 INFO terminating
2025-03-26 02:26:25,041 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47902, dest: /172.20.1.13:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742139_1315, duration(ns): 2585090
2025-03-26 02:26:25,041 INFO terminating
2025-03-26 02:26:25,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742140_1316, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala._COPYING_
2025-03-26 02:26:25,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742140_1316 src: /172.20.1.10:47908 dest: /172.20.1.13:9866
2025-03-26 02:26:25,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742140_1316 src: /172.20.1.13:33182 dest: /172.20.1.12:9866
2025-03-26 02:26:25,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742140_1316 src: /172.20.1.12:53876 dest: /172.20.1.11:9866
2025-03-26 02:26:25,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47908, dest: /172.20.1.13:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742140_1316, duration(ns): 1657022
2025-03-26 02:26:25,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53876, dest: /172.20.1.11:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742140_1316, duration(ns): 1179914
2025-03-26 02:26:25,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33182, dest: /172.20.1.12:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742140_1316, duration(ns): 1405924
2025-03-26 02:26:25,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742140_1316, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,057 INFO terminating
2025-03-26 02:26:25,057 INFO terminating
2025-03-26 02:26:25,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742141_1317, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala._COPYING_
2025-03-26 02:26:25,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742141_1317 src: /172.20.1.10:47916 dest: /172.20.1.13:9866
2025-03-26 02:26:25,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742141_1317 src: /172.20.1.13:57676 dest: /172.20.1.11:9866
2025-03-26 02:26:25,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742141_1317 src: /172.20.1.11:36552 dest: /172.20.1.12:9866
2025-03-26 02:26:25,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36552, dest: /172.20.1.12:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742141_1317, duration(ns): 952802
2025-03-26 02:26:25,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57676, dest: /172.20.1.11:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742141_1317, duration(ns): 1341621
2025-03-26 02:26:25,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742141_1317, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,067 INFO terminating
2025-03-26 02:26:25,068 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47916, dest: /172.20.1.13:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742141_1317, duration(ns): 2053122
2025-03-26 02:26:25,068 INFO terminating
2025-03-26 02:26:25,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742142_1318, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala._COPYING_
2025-03-26 02:26:25,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742142_1318 src: /172.20.1.10:50434 dest: /172.20.1.11:9866
2025-03-26 02:26:25,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742142_1318 src: /172.20.1.11:44196 dest: /172.20.1.13:9866
2025-03-26 02:26:25,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742142_1318 src: /172.20.1.13:33198 dest: /172.20.1.12:9866
2025-03-26 02:26:25,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44196, dest: /172.20.1.13:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742142_1318, duration(ns): 1125148
2025-03-26 02:26:25,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33198, dest: /172.20.1.12:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742142_1318, duration(ns): 824377
2025-03-26 02:26:25,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742142_1318, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50434, dest: /172.20.1.11:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742142_1318, duration(ns): 1595312
2025-03-26 02:26:25,079 INFO terminating
2025-03-26 02:26:25,079 INFO terminating
2025-03-26 02:26:25,080 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742143_1319, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala._COPYING_
2025-03-26 02:26:25,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742143_1319 src: /172.20.1.10:50450 dest: /172.20.1.11:9866
2025-03-26 02:26:25,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742143_1319 src: /172.20.1.11:44200 dest: /172.20.1.13:9866
2025-03-26 02:26:25,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742143_1319 src: /172.20.1.13:33202 dest: /172.20.1.12:9866
2025-03-26 02:26:25,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33202, dest: /172.20.1.12:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742143_1319, duration(ns): 1087706
2025-03-26 02:26:25,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742143_1319, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50450, dest: /172.20.1.11:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742143_1319, duration(ns): 1572638
2025-03-26 02:26:25,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44200, dest: /172.20.1.13:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742143_1319, duration(ns): 1320931
2025-03-26 02:26:25,091 INFO terminating
2025-03-26 02:26:25,091 INFO terminating
2025-03-26 02:26:25,092 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,095 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742144_1320, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_
2025-03-26 02:26:25,095 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,095 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742144_1320 src: /172.20.1.10:50466 dest: /172.20.1.11:9866
2025-03-26 02:26:25,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742144_1320 src: /172.20.1.11:36560 dest: /172.20.1.12:9866
2025-03-26 02:26:25,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742144_1320 src: /172.20.1.12:36988 dest: /172.20.1.13:9866
2025-03-26 02:26:25,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36988, dest: /172.20.1.13:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742144_1320, duration(ns): 1124871
2025-03-26 02:26:25,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742144_1320, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36560, dest: /172.20.1.12:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742144_1320, duration(ns): 1616482
2025-03-26 02:26:25,102 INFO terminating
2025-03-26 02:26:25,103 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50466, dest: /172.20.1.11:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742144_1320, duration(ns): 2741963
2025-03-26 02:26:25,103 INFO terminating
2025-03-26 02:26:25,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1321, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala._COPYING_
2025-03-26 02:26:25,109 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,109 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742145_1321 src: /172.20.1.10:51030 dest: /172.20.1.12:9866
2025-03-26 02:26:25,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742145_1321 src: /172.20.1.12:53884 dest: /172.20.1.11:9866
2025-03-26 02:26:25,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742145_1321 src: /172.20.1.11:44206 dest: /172.20.1.13:9866
2025-03-26 02:26:25,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51030, dest: /172.20.1.12:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742145_1321, duration(ns): 1317969
2025-03-26 02:26:25,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44206, dest: /172.20.1.13:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742145_1321, duration(ns): 708144
2025-03-26 02:26:25,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53884, dest: /172.20.1.11:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742145_1321, duration(ns): 915716
2025-03-26 02:26:25,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742145_1321, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,114 INFO terminating
2025-03-26 02:26:25,115 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,115 INFO terminating
2025-03-26 02:26:25,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1322, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala._COPYING_
2025-03-26 02:26:25,121 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,121 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742146_1322 src: /172.20.1.10:50478 dest: /172.20.1.11:9866
2025-03-26 02:26:25,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742146_1322 src: /172.20.1.11:36564 dest: /172.20.1.12:9866
2025-03-26 02:26:25,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742146_1322 src: /172.20.1.12:36990 dest: /172.20.1.13:9866
2025-03-26 02:26:25,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36564, dest: /172.20.1.12:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742146_1322, duration(ns): 886450
2025-03-26 02:26:25,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36990, dest: /172.20.1.13:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742146_1322, duration(ns): 748031
2025-03-26 02:26:25,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742146_1322, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,126 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50478, dest: /172.20.1.11:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742146_1322, duration(ns): 1047105
2025-03-26 02:26:25,126 INFO terminating
2025-03-26 02:26:25,126 INFO terminating
2025-03-26 02:26:25,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,130 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1323, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 02:26:25,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742147_1323 src: /172.20.1.10:50482 dest: /172.20.1.11:9866
2025-03-26 02:26:25,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742147_1323 src: /172.20.1.11:44210 dest: /172.20.1.13:9866
2025-03-26 02:26:25,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742147_1323 src: /172.20.1.13:33208 dest: /172.20.1.12:9866
2025-03-26 02:26:25,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44210, dest: /172.20.1.13:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742147_1323, duration(ns): 748322
2025-03-26 02:26:25,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33208, dest: /172.20.1.12:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742147_1323, duration(ns): 637217
2025-03-26 02:26:25,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742147_1323, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,134 INFO terminating
2025-03-26 02:26:25,135 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50482, dest: /172.20.1.11:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742147_1323, duration(ns): 1155656
2025-03-26 02:26:25,135 INFO terminating
2025-03-26 02:26:25,144 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1324, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala._COPYING_
2025-03-26 02:26:25,144 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,144 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742148_1324 src: /172.20.1.10:51042 dest: /172.20.1.12:9866
2025-03-26 02:26:25,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742148_1324 src: /172.20.1.12:53898 dest: /172.20.1.11:9866
2025-03-26 02:26:25,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742148_1324 src: /172.20.1.11:44216 dest: /172.20.1.13:9866
2025-03-26 02:26:25,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44216, dest: /172.20.1.13:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742148_1324, duration(ns): 942759
2025-03-26 02:26:25,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742148_1324, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51042, dest: /172.20.1.12:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742148_1324, duration(ns): 1507632
2025-03-26 02:26:25,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53898, dest: /172.20.1.11:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742148_1324, duration(ns): 1208270
2025-03-26 02:26:25,149 INFO terminating
2025-03-26 02:26:25,149 INFO terminating
2025-03-26 02:26:25,150 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1325, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala._COPYING_
2025-03-26 02:26:25,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742149_1325 src: /172.20.1.10:51052 dest: /172.20.1.12:9866
2025-03-26 02:26:25,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742149_1325 src: /172.20.1.12:36994 dest: /172.20.1.13:9866
2025-03-26 02:26:25,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742149_1325 src: /172.20.1.13:57690 dest: /172.20.1.11:9866
2025-03-26 02:26:25,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:36994, dest: /172.20.1.13:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742149_1325, duration(ns): 1733844
2025-03-26 02:26:25,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57690, dest: /172.20.1.11:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742149_1325, duration(ns): 1489698
2025-03-26 02:26:25,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742149_1325, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,161 INFO terminating
2025-03-26 02:26:25,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51052, dest: /172.20.1.12:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742149_1325, duration(ns): 2368930
2025-03-26 02:26:25,162 INFO terminating
2025-03-26 02:26:25,163 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,169 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1326, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala._COPYING_
2025-03-26 02:26:25,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742150_1326 src: /172.20.1.10:51058 dest: /172.20.1.12:9866
2025-03-26 02:26:25,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742150_1326 src: /172.20.1.11:44230 dest: /172.20.1.13:9866
2025-03-26 02:26:25,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742150_1326 src: /172.20.1.12:53914 dest: /172.20.1.11:9866
2025-03-26 02:26:25,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44230, dest: /172.20.1.13:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742150_1326, duration(ns): 984274
2025-03-26 02:26:25,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53914, dest: /172.20.1.11:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742150_1326, duration(ns): 1750332
2025-03-26 02:26:25,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742150_1326, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,175 INFO terminating
2025-03-26 02:26:25,176 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51058, dest: /172.20.1.12:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742150_1326, duration(ns): 2183752
2025-03-26 02:26:25,176 INFO terminating
2025-03-26 02:26:25,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1327, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala._COPYING_
2025-03-26 02:26:25,180 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,180 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742151_1327 src: /172.20.1.10:51064 dest: /172.20.1.12:9866
2025-03-26 02:26:25,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742151_1327 src: /172.20.1.12:53918 dest: /172.20.1.11:9866
2025-03-26 02:26:25,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742151_1327 src: /172.20.1.11:44236 dest: /172.20.1.13:9866
2025-03-26 02:26:25,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44236, dest: /172.20.1.13:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742151_1327, duration(ns): 880960
2025-03-26 02:26:25,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53918, dest: /172.20.1.11:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742151_1327, duration(ns): 1574283
2025-03-26 02:26:25,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742151_1327, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,186 INFO terminating
2025-03-26 02:26:25,187 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51064, dest: /172.20.1.12:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742151_1327, duration(ns): 1874958
2025-03-26 02:26:25,187 INFO terminating
2025-03-26 02:26:25,199 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1328, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala._COPYING_
2025-03-26 02:26:25,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742152_1328 src: /172.20.1.10:50486 dest: /172.20.1.11:9866
2025-03-26 02:26:25,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742152_1328 src: /172.20.1.11:36570 dest: /172.20.1.12:9866
2025-03-26 02:26:25,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742152_1328 src: /172.20.1.12:37004 dest: /172.20.1.13:9866
2025-03-26 02:26:25,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36570, dest: /172.20.1.12:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742152_1328, duration(ns): 1726216
2025-03-26 02:26:25,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37004, dest: /172.20.1.13:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742152_1328, duration(ns): 1129760
2025-03-26 02:26:25,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742152_1328, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,205 INFO terminating
2025-03-26 02:26:25,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50486, dest: /172.20.1.11:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742152_1328, duration(ns): 2028235
2025-03-26 02:26:25,206 INFO terminating
2025-03-26 02:26:25,207 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,211 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1329, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala._COPYING_
2025-03-26 02:26:25,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742153_1329 src: /172.20.1.10:51072 dest: /172.20.1.12:9866
2025-03-26 02:26:25,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742153_1329 src: /172.20.1.12:53930 dest: /172.20.1.11:9866
2025-03-26 02:26:25,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742153_1329 src: /172.20.1.11:44238 dest: /172.20.1.13:9866
2025-03-26 02:26:25,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44238, dest: /172.20.1.13:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742153_1329, duration(ns): 755461
2025-03-26 02:26:25,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742153_1329, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51072, dest: /172.20.1.12:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742153_1329, duration(ns): 1942804
2025-03-26 02:26:25,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53930, dest: /172.20.1.11:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742153_1329, duration(ns): 1261529
2025-03-26 02:26:25,217 INFO terminating
2025-03-26 02:26:25,217 INFO terminating
2025-03-26 02:26:25,218 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,226 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1330, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala._COPYING_
2025-03-26 02:26:25,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742154_1330 src: /172.20.1.10:50498 dest: /172.20.1.11:9866
2025-03-26 02:26:25,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742154_1330 src: /172.20.1.11:44242 dest: /172.20.1.13:9866
2025-03-26 02:26:25,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742154_1330 src: /172.20.1.13:33218 dest: /172.20.1.12:9866
2025-03-26 02:26:25,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33218, dest: /172.20.1.12:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742154_1330, duration(ns): 1025523
2025-03-26 02:26:25,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742154_1330, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50498, dest: /172.20.1.11:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742154_1330, duration(ns): 2387162
2025-03-26 02:26:25,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44242, dest: /172.20.1.13:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742154_1330, duration(ns): 1244916
2025-03-26 02:26:25,232 INFO terminating
2025-03-26 02:26:25,232 INFO terminating
2025-03-26 02:26:25,233 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,244 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1331, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:26:25,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742155_1331 src: /172.20.1.10:50502 dest: /172.20.1.11:9866
2025-03-26 02:26:25,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742155_1331 src: /172.20.1.11:44258 dest: /172.20.1.13:9866
2025-03-26 02:26:25,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742155_1331 src: /172.20.1.13:33226 dest: /172.20.1.12:9866
2025-03-26 02:26:25,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44258, dest: /172.20.1.13:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742155_1331, duration(ns): 1762360
2025-03-26 02:26:25,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33226, dest: /172.20.1.12:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742155_1331, duration(ns): 1664070
2025-03-26 02:26:25,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742155_1331, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,251 INFO terminating
2025-03-26 02:26:25,252 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50502, dest: /172.20.1.11:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742155_1331, duration(ns): 2102251
2025-03-26 02:26:25,252 INFO terminating
2025-03-26 02:26:25,258 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,258 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,259 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1332, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala._COPYING_
2025-03-26 02:26:25,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742156_1332 src: /172.20.1.10:47918 dest: /172.20.1.13:9866
2025-03-26 02:26:25,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742156_1332 src: /172.20.1.13:57698 dest: /172.20.1.11:9866
2025-03-26 02:26:25,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742156_1332 src: /172.20.1.11:36580 dest: /172.20.1.12:9866
2025-03-26 02:26:25,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36580, dest: /172.20.1.12:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742156_1332, duration(ns): 1246186
2025-03-26 02:26:25,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742156_1332, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57698, dest: /172.20.1.11:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742156_1332, duration(ns): 1596017
2025-03-26 02:26:25,267 INFO terminating
2025-03-26 02:26:25,268 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47918, dest: /172.20.1.13:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742156_1332, duration(ns): 1958404
2025-03-26 02:26:25,268 INFO terminating
2025-03-26 02:26:25,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1333, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala._COPYING_
2025-03-26 02:26:25,274 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,274 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742157_1333 src: /172.20.1.10:51078 dest: /172.20.1.12:9866
2025-03-26 02:26:25,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742157_1333 src: /172.20.1.12:37016 dest: /172.20.1.13:9866
2025-03-26 02:26:25,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742157_1333 src: /172.20.1.13:57704 dest: /172.20.1.11:9866
2025-03-26 02:26:25,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51078, dest: /172.20.1.12:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742157_1333, duration(ns): 1550841
2025-03-26 02:26:25,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37016, dest: /172.20.1.13:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742157_1333, duration(ns): 1273442
2025-03-26 02:26:25,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57704, dest: /172.20.1.11:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742157_1333, duration(ns): 1067847
2025-03-26 02:26:25,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742157_1333, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,281 INFO terminating
2025-03-26 02:26:25,281 INFO terminating
2025-03-26 02:26:25,282 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1334, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala._COPYING_
2025-03-26 02:26:25,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742158_1334 src: /172.20.1.10:51082 dest: /172.20.1.12:9866
2025-03-26 02:26:25,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742158_1334 src: /172.20.1.12:37022 dest: /172.20.1.13:9866
2025-03-26 02:26:25,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742158_1334 src: /172.20.1.13:57712 dest: /172.20.1.11:9866
2025-03-26 02:26:25,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57712, dest: /172.20.1.11:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742158_1334, duration(ns): 1217898
2025-03-26 02:26:25,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742158_1334, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51082, dest: /172.20.1.12:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742158_1334, duration(ns): 1810153
2025-03-26 02:26:25,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37022, dest: /172.20.1.13:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742158_1334, duration(ns): 1520974
2025-03-26 02:26:25,295 INFO terminating
2025-03-26 02:26:25,295 INFO terminating
2025-03-26 02:26:25,296 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1335, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala._COPYING_
2025-03-26 02:26:25,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742159_1335 src: /172.20.1.10:50504 dest: /172.20.1.11:9866
2025-03-26 02:26:25,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742159_1335 src: /172.20.1.11:44262 dest: /172.20.1.13:9866
2025-03-26 02:26:25,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742159_1335 src: /172.20.1.13:33228 dest: /172.20.1.12:9866
2025-03-26 02:26:25,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44262, dest: /172.20.1.13:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742159_1335, duration(ns): 1707678
2025-03-26 02:26:25,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33228, dest: /172.20.1.12:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742159_1335, duration(ns): 1454133
2025-03-26 02:26:25,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742159_1335, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,315 INFO terminating
2025-03-26 02:26:25,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50504, dest: /172.20.1.11:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742159_1335, duration(ns): 1953887
2025-03-26 02:26:25,316 INFO terminating
2025-03-26 02:26:25,317 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,323 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1336, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala._COPYING_
2025-03-26 02:26:25,323 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,323 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742160_1336 src: /172.20.1.10:47924 dest: /172.20.1.13:9866
2025-03-26 02:26:25,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742160_1336 src: /172.20.1.13:57714 dest: /172.20.1.11:9866
2025-03-26 02:26:25,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742160_1336 src: /172.20.1.11:36582 dest: /172.20.1.12:9866
2025-03-26 02:26:25,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36582, dest: /172.20.1.12:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742160_1336, duration(ns): 1346429
2025-03-26 02:26:25,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742160_1336, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57714, dest: /172.20.1.11:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742160_1336, duration(ns): 2175379
2025-03-26 02:26:25,331 INFO terminating
2025-03-26 02:26:25,332 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47924, dest: /172.20.1.13:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742160_1336, duration(ns): 2974912
2025-03-26 02:26:25,332 INFO terminating
2025-03-26 02:26:25,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1337, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala._COPYING_
2025-03-26 02:26:25,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742161_1337 src: /172.20.1.10:50514 dest: /172.20.1.11:9866
2025-03-26 02:26:25,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742161_1337 src: /172.20.1.11:36584 dest: /172.20.1.12:9866
2025-03-26 02:26:25,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742161_1337 src: /172.20.1.12:37028 dest: /172.20.1.13:9866
2025-03-26 02:26:25,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36584, dest: /172.20.1.12:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742161_1337, duration(ns): 1581747
2025-03-26 02:26:25,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37028, dest: /172.20.1.13:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742161_1337, duration(ns): 1272428
2025-03-26 02:26:25,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742161_1337, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,343 INFO terminating
2025-03-26 02:26:25,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50514, dest: /172.20.1.11:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742161_1337, duration(ns): 1910824
2025-03-26 02:26:25,344 INFO terminating
2025-03-26 02:26:25,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1338, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala._COPYING_
2025-03-26 02:26:25,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742162_1338 src: /172.20.1.10:47934 dest: /172.20.1.13:9866
2025-03-26 02:26:25,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742162_1338 src: /172.20.1.13:33244 dest: /172.20.1.12:9866
2025-03-26 02:26:25,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742162_1338 src: /172.20.1.12:53934 dest: /172.20.1.11:9866
2025-03-26 02:26:25,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53934, dest: /172.20.1.11:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742162_1338, duration(ns): 1323297
2025-03-26 02:26:25,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742162_1338, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33244, dest: /172.20.1.12:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742162_1338, duration(ns): 1640451
2025-03-26 02:26:25,356 INFO terminating
2025-03-26 02:26:25,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47934, dest: /172.20.1.13:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742162_1338, duration(ns): 2653893
2025-03-26 02:26:25,357 INFO terminating
2025-03-26 02:26:25,358 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1339, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala._COPYING_
2025-03-26 02:26:25,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742163_1339 src: /172.20.1.10:47940 dest: /172.20.1.13:9866
2025-03-26 02:26:25,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742163_1339 src: /172.20.1.13:33260 dest: /172.20.1.12:9866
2025-03-26 02:26:25,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742163_1339 src: /172.20.1.12:53948 dest: /172.20.1.11:9866
2025-03-26 02:26:25,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53948, dest: /172.20.1.11:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742163_1339, duration(ns): 829046
2025-03-26 02:26:25,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742163_1339, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33260, dest: /172.20.1.12:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742163_1339, duration(ns): 1604542
2025-03-26 02:26:25,369 INFO terminating
2025-03-26 02:26:25,370 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47940, dest: /172.20.1.13:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742163_1339, duration(ns): 2712805
2025-03-26 02:26:25,370 INFO terminating
2025-03-26 02:26:25,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1340, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala._COPYING_
2025-03-26 02:26:25,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742164_1340 src: /172.20.1.10:50520 dest: /172.20.1.11:9866
2025-03-26 02:26:25,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742164_1340 src: /172.20.1.11:36600 dest: /172.20.1.12:9866
2025-03-26 02:26:25,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742164_1340 src: /172.20.1.12:37030 dest: /172.20.1.13:9866
2025-03-26 02:26:25,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37030, dest: /172.20.1.13:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742164_1340, duration(ns): 1364263
2025-03-26 02:26:25,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742164_1340, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36600, dest: /172.20.1.12:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742164_1340, duration(ns): 1904954
2025-03-26 02:26:25,390 INFO terminating
2025-03-26 02:26:25,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50520, dest: /172.20.1.11:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742164_1340, duration(ns): 3174969
2025-03-26 02:26:25,391 INFO terminating
2025-03-26 02:26:25,392 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1341, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala._COPYING_
2025-03-26 02:26:25,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742165_1341 src: /172.20.1.10:47944 dest: /172.20.1.13:9866
2025-03-26 02:26:25,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742165_1341 src: /172.20.1.13:33266 dest: /172.20.1.12:9866
2025-03-26 02:26:25,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742165_1341 src: /172.20.1.12:53958 dest: /172.20.1.11:9866
2025-03-26 02:26:25,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53958, dest: /172.20.1.11:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742165_1341, duration(ns): 1010620
2025-03-26 02:26:25,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742165_1341, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33266, dest: /172.20.1.12:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742165_1341, duration(ns): 1617288
2025-03-26 02:26:25,403 INFO terminating
2025-03-26 02:26:25,404 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47944, dest: /172.20.1.13:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742165_1341, duration(ns): 2329069
2025-03-26 02:26:25,404 INFO terminating
2025-03-26 02:26:25,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1342, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala._COPYING_
2025-03-26 02:26:25,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742166_1342 src: /172.20.1.10:50522 dest: /172.20.1.11:9866
2025-03-26 02:26:25,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742166_1342 src: /172.20.1.11:36604 dest: /172.20.1.12:9866
2025-03-26 02:26:25,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742166_1342 src: /172.20.1.12:37038 dest: /172.20.1.13:9866
2025-03-26 02:26:25,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37038, dest: /172.20.1.13:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742166_1342, duration(ns): 1150341
2025-03-26 02:26:25,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742166_1342, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50522, dest: /172.20.1.11:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742166_1342, duration(ns): 2491474
2025-03-26 02:26:25,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36604, dest: /172.20.1.12:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742166_1342, duration(ns): 1763405
2025-03-26 02:26:25,423 INFO terminating
2025-03-26 02:26:25,423 INFO terminating
2025-03-26 02:26:25,424 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1343, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala._COPYING_
2025-03-26 02:26:25,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742167_1343 src: /172.20.1.10:50524 dest: /172.20.1.11:9866
2025-03-26 02:26:25,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742167_1343 src: /172.20.1.11:44274 dest: /172.20.1.13:9866
2025-03-26 02:26:25,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742167_1343 src: /172.20.1.13:33274 dest: /172.20.1.12:9866
2025-03-26 02:26:25,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33274, dest: /172.20.1.12:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742167_1343, duration(ns): 1016595
2025-03-26 02:26:25,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742167_1343, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50524, dest: /172.20.1.11:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742167_1343, duration(ns): 1856992
2025-03-26 02:26:25,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44274, dest: /172.20.1.13:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742167_1343, duration(ns): 1640585
2025-03-26 02:26:25,434 INFO terminating
2025-03-26 02:26:25,434 INFO terminating
2025-03-26 02:26:25,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,440 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1344, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala._COPYING_
2025-03-26 02:26:25,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742168_1344 src: /172.20.1.10:51086 dest: /172.20.1.12:9866
2025-03-26 02:26:25,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742168_1344 src: /172.20.1.12:37042 dest: /172.20.1.13:9866
2025-03-26 02:26:25,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742168_1344 src: /172.20.1.13:57718 dest: /172.20.1.11:9866
2025-03-26 02:26:25,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37042, dest: /172.20.1.13:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742168_1344, duration(ns): 938113
2025-03-26 02:26:25,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57718, dest: /172.20.1.11:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742168_1344, duration(ns): 775181
2025-03-26 02:26:25,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742168_1344, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,449 INFO terminating
2025-03-26 02:26:25,450 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51086, dest: /172.20.1.12:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742168_1344, duration(ns): 1127440
2025-03-26 02:26:25,450 INFO terminating
2025-03-26 02:26:25,454 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1345, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala._COPYING_
2025-03-26 02:26:25,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742169_1345 src: /172.20.1.10:51096 dest: /172.20.1.12:9866
2025-03-26 02:26:25,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742169_1345 src: /172.20.1.12:53972 dest: /172.20.1.11:9866
2025-03-26 02:26:25,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742169_1345 src: /172.20.1.11:44290 dest: /172.20.1.13:9866
2025-03-26 02:26:25,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44290, dest: /172.20.1.13:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742169_1345, duration(ns): 2584749
2025-03-26 02:26:25,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742169_1345, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53972, dest: /172.20.1.11:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742169_1345, duration(ns): 2813860
2025-03-26 02:26:25,462 INFO terminating
2025-03-26 02:26:25,463 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51096, dest: /172.20.1.12:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742169_1345, duration(ns): 3264073
2025-03-26 02:26:25,463 INFO terminating
2025-03-26 02:26:25,468 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1346, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala._COPYING_
2025-03-26 02:26:25,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742170_1346 src: /172.20.1.10:47956 dest: /172.20.1.13:9866
2025-03-26 02:26:25,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742170_1346 src: /172.20.1.13:57728 dest: /172.20.1.11:9866
2025-03-26 02:26:25,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742170_1346 src: /172.20.1.11:36620 dest: /172.20.1.12:9866
2025-03-26 02:26:25,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36620, dest: /172.20.1.12:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742170_1346, duration(ns): 1022896
2025-03-26 02:26:25,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57728, dest: /172.20.1.11:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742170_1346, duration(ns): 1556034
2025-03-26 02:26:25,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742170_1346, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,474 INFO terminating
2025-03-26 02:26:25,475 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47956, dest: /172.20.1.13:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742170_1346, duration(ns): 1794112
2025-03-26 02:26:25,475 INFO terminating
2025-03-26 02:26:25,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1347, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala._COPYING_
2025-03-26 02:26:25,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742171_1347 src: /172.20.1.10:50530 dest: /172.20.1.11:9866
2025-03-26 02:26:25,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742171_1347 src: /172.20.1.11:36634 dest: /172.20.1.12:9866
2025-03-26 02:26:25,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742171_1347 src: /172.20.1.12:37046 dest: /172.20.1.13:9866
2025-03-26 02:26:25,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37046, dest: /172.20.1.13:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742171_1347, duration(ns): 1125069
2025-03-26 02:26:25,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742171_1347, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36634, dest: /172.20.1.12:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742171_1347, duration(ns): 1378805
2025-03-26 02:26:25,486 INFO terminating
2025-03-26 02:26:25,487 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50530, dest: /172.20.1.11:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742171_1347, duration(ns): 2252511
2025-03-26 02:26:25,487 INFO terminating
2025-03-26 02:26:25,492 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1348, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala._COPYING_
2025-03-26 02:26:25,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742172_1348 src: /172.20.1.10:51104 dest: /172.20.1.12:9866
2025-03-26 02:26:25,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742172_1348 src: /172.20.1.12:37058 dest: /172.20.1.13:9866
2025-03-26 02:26:25,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742172_1348 src: /172.20.1.13:57730 dest: /172.20.1.11:9866
2025-03-26 02:26:25,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57730, dest: /172.20.1.11:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742172_1348, duration(ns): 1500624
2025-03-26 02:26:25,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742172_1348, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37058, dest: /172.20.1.13:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742172_1348, duration(ns): 2146722
2025-03-26 02:26:25,500 INFO terminating
2025-03-26 02:26:25,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51104, dest: /172.20.1.12:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742172_1348, duration(ns): 2217033
2025-03-26 02:26:25,501 INFO terminating
2025-03-26 02:26:25,502 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742173_1349, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala._COPYING_
2025-03-26 02:26:25,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742173_1349 src: /172.20.1.10:51108 dest: /172.20.1.12:9866
2025-03-26 02:26:25,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742173_1349 src: /172.20.1.12:37062 dest: /172.20.1.13:9866
2025-03-26 02:26:25,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742173_1349 src: /172.20.1.13:57738 dest: /172.20.1.11:9866
2025-03-26 02:26:25,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37062, dest: /172.20.1.13:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742173_1349, duration(ns): 1189288
2025-03-26 02:26:25,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57738, dest: /172.20.1.11:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742173_1349, duration(ns): 952760
2025-03-26 02:26:25,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742173_1349, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,511 INFO terminating
2025-03-26 02:26:25,512 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51108, dest: /172.20.1.12:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742173_1349, duration(ns): 1463303
2025-03-26 02:26:25,512 INFO terminating
2025-03-26 02:26:25,520 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742174_1350, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala._COPYING_
2025-03-26 02:26:25,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742174_1350 src: /172.20.1.10:47966 dest: /172.20.1.13:9866
2025-03-26 02:26:25,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742174_1350 src: /172.20.1.13:57748 dest: /172.20.1.11:9866
2025-03-26 02:26:25,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742174_1350 src: /172.20.1.11:36640 dest: /172.20.1.12:9866
2025-03-26 02:26:25,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36640, dest: /172.20.1.12:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742174_1350, duration(ns): 1171027
2025-03-26 02:26:25,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57748, dest: /172.20.1.11:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742174_1350, duration(ns): 1977619
2025-03-26 02:26:25,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742174_1350, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,528 INFO terminating
2025-03-26 02:26:25,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47966, dest: /172.20.1.13:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742174_1350, duration(ns): 2313311
2025-03-26 02:26:25,529 INFO terminating
2025-03-26 02:26:25,530 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742175_1351, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala._COPYING_
2025-03-26 02:26:25,533 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,533 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742175_1351 src: /172.20.1.10:50544 dest: /172.20.1.11:9866
2025-03-26 02:26:25,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742175_1351 src: /172.20.1.11:44294 dest: /172.20.1.13:9866
2025-03-26 02:26:25,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742175_1351 src: /172.20.1.13:33276 dest: /172.20.1.12:9866
2025-03-26 02:26:25,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33276, dest: /172.20.1.12:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742175_1351, duration(ns): 887252
2025-03-26 02:26:25,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742175_1351, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50544, dest: /172.20.1.11:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742175_1351, duration(ns): 1794649
2025-03-26 02:26:25,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44294, dest: /172.20.1.13:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742175_1351, duration(ns): 1561214
2025-03-26 02:26:25,539 INFO terminating
2025-03-26 02:26:25,539 INFO terminating
2025-03-26 02:26:25,540 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742176_1352, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala._COPYING_
2025-03-26 02:26:25,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742176_1352 src: /172.20.1.10:47980 dest: /172.20.1.13:9866
2025-03-26 02:26:25,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742176_1352 src: /172.20.1.13:57754 dest: /172.20.1.11:9866
2025-03-26 02:26:25,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742176_1352 src: /172.20.1.11:36650 dest: /172.20.1.12:9866
2025-03-26 02:26:25,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36650, dest: /172.20.1.12:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742176_1352, duration(ns): 1208473
2025-03-26 02:26:25,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742176_1352, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47980, dest: /172.20.1.13:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742176_1352, duration(ns): 2154313
2025-03-26 02:26:25,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57754, dest: /172.20.1.11:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742176_1352, duration(ns): 1939741
2025-03-26 02:26:25,550 INFO terminating
2025-03-26 02:26:25,550 INFO terminating
2025-03-26 02:26:25,551 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,561 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742177_1353, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala._COPYING_
2025-03-26 02:26:25,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742177_1353 src: /172.20.1.10:51112 dest: /172.20.1.12:9866
2025-03-26 02:26:25,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742177_1353 src: /172.20.1.12:37066 dest: /172.20.1.13:9866
2025-03-26 02:26:25,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742177_1353 src: /172.20.1.13:57770 dest: /172.20.1.11:9866
2025-03-26 02:26:25,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37066, dest: /172.20.1.13:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742177_1353, duration(ns): 1399659
2025-03-26 02:26:25,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57770, dest: /172.20.1.11:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742177_1353, duration(ns): 1144015
2025-03-26 02:26:25,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742177_1353, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,567 INFO terminating
2025-03-26 02:26:25,568 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51112, dest: /172.20.1.12:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742177_1353, duration(ns): 1664817
2025-03-26 02:26:25,568 INFO terminating
2025-03-26 02:26:25,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742178_1354, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala._COPYING_
2025-03-26 02:26:25,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742178_1354 src: /172.20.1.10:50550 dest: /172.20.1.11:9866
2025-03-26 02:26:25,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742178_1354 src: /172.20.1.11:36662 dest: /172.20.1.12:9866
2025-03-26 02:26:25,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742178_1354 src: /172.20.1.12:37072 dest: /172.20.1.13:9866
2025-03-26 02:26:25,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37072, dest: /172.20.1.13:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742178_1354, duration(ns): 1392802
2025-03-26 02:26:25,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36662, dest: /172.20.1.12:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742178_1354, duration(ns): 2107564
2025-03-26 02:26:25,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742178_1354, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50550, dest: /172.20.1.11:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742178_1354, duration(ns): 2906840
2025-03-26 02:26:25,585 INFO terminating
2025-03-26 02:26:25,585 INFO terminating
2025-03-26 02:26:25,586 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742179_1355, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala._COPYING_
2025-03-26 02:26:25,592 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,592 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742179_1355 src: /172.20.1.10:51122 dest: /172.20.1.12:9866
2025-03-26 02:26:25,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742179_1355 src: /172.20.1.12:53984 dest: /172.20.1.11:9866
2025-03-26 02:26:25,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742179_1355 src: /172.20.1.11:44306 dest: /172.20.1.13:9866
2025-03-26 02:26:25,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44306, dest: /172.20.1.13:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742179_1355, duration(ns): 1131964
2025-03-26 02:26:25,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53984, dest: /172.20.1.11:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742179_1355, duration(ns): 1320904
2025-03-26 02:26:25,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742179_1355, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,598 INFO terminating
2025-03-26 02:26:25,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51122, dest: /172.20.1.12:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742179_1355, duration(ns): 1822436
2025-03-26 02:26:25,601 INFO terminating
2025-03-26 02:26:25,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,606 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742180_1356, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala._COPYING_
2025-03-26 02:26:25,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742180_1356 src: /172.20.1.10:50566 dest: /172.20.1.11:9866
2025-03-26 02:26:25,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742180_1356 src: /172.20.1.11:36664 dest: /172.20.1.12:9866
2025-03-26 02:26:25,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742180_1356 src: /172.20.1.12:37082 dest: /172.20.1.13:9866
2025-03-26 02:26:25,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37082, dest: /172.20.1.13:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742180_1356, duration(ns): 1057979
2025-03-26 02:26:25,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50566, dest: /172.20.1.11:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742180_1356, duration(ns): 1541695
2025-03-26 02:26:25,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36664, dest: /172.20.1.12:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742180_1356, duration(ns): 1260493
2025-03-26 02:26:25,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742180_1356, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,612 INFO terminating
2025-03-26 02:26:25,612 INFO terminating
2025-03-26 02:26:25,613 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,618 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742181_1357, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala._COPYING_
2025-03-26 02:26:25,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742181_1357 src: /172.20.1.10:47984 dest: /172.20.1.13:9866
2025-03-26 02:26:25,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742181_1357 src: /172.20.1.13:33290 dest: /172.20.1.12:9866
2025-03-26 02:26:25,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742181_1357 src: /172.20.1.12:53986 dest: /172.20.1.11:9866
2025-03-26 02:26:25,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53986, dest: /172.20.1.11:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742181_1357, duration(ns): 2565155
2025-03-26 02:26:25,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33290, dest: /172.20.1.12:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742181_1357, duration(ns): 2404277
2025-03-26 02:26:25,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742181_1357, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47984, dest: /172.20.1.13:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742181_1357, duration(ns): 3130632
2025-03-26 02:26:25,627 INFO terminating
2025-03-26 02:26:25,627 INFO terminating
2025-03-26 02:26:25,628 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,635 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742182_1358, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala._COPYING_
2025-03-26 02:26:25,635 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,635 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742182_1358 src: /172.20.1.10:47994 dest: /172.20.1.13:9866
2025-03-26 02:26:25,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742182_1358 src: /172.20.1.13:33300 dest: /172.20.1.12:9866
2025-03-26 02:26:25,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742182_1358 src: /172.20.1.12:53994 dest: /172.20.1.11:9866
2025-03-26 02:26:25,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:53994, dest: /172.20.1.11:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742182_1358, duration(ns): 956920
2025-03-26 02:26:25,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33300, dest: /172.20.1.12:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742182_1358, duration(ns): 1346017
2025-03-26 02:26:25,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742182_1358, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,641 INFO terminating
2025-03-26 02:26:25,642 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47994, dest: /172.20.1.13:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742182_1358, duration(ns): 1516567
2025-03-26 02:26:25,642 INFO terminating
2025-03-26 02:26:25,646 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742183_1359, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala._COPYING_
2025-03-26 02:26:25,646 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,646 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742183_1359 src: /172.20.1.10:51132 dest: /172.20.1.12:9866
2025-03-26 02:26:25,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742183_1359 src: /172.20.1.12:54002 dest: /172.20.1.11:9866
2025-03-26 02:26:25,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742183_1359 src: /172.20.1.11:44308 dest: /172.20.1.13:9866
2025-03-26 02:26:25,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51132, dest: /172.20.1.12:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742183_1359, duration(ns): 1670491
2025-03-26 02:26:25,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44308, dest: /172.20.1.13:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742183_1359, duration(ns): 979430
2025-03-26 02:26:25,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54002, dest: /172.20.1.11:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742183_1359, duration(ns): 1370376
2025-03-26 02:26:25,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742183_1359, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,651 INFO terminating
2025-03-26 02:26:25,652 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,652 INFO terminating
2025-03-26 02:26:25,655 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742184_1360, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala._COPYING_
2025-03-26 02:26:25,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742184_1360 src: /172.20.1.10:51146 dest: /172.20.1.12:9866
2025-03-26 02:26:25,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742184_1360 src: /172.20.1.12:37098 dest: /172.20.1.13:9866
2025-03-26 02:26:25,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742184_1360 src: /172.20.1.13:57778 dest: /172.20.1.11:9866
2025-03-26 02:26:25,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57778, dest: /172.20.1.11:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742184_1360, duration(ns): 719690
2025-03-26 02:26:25,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37098, dest: /172.20.1.13:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742184_1360, duration(ns): 984976
2025-03-26 02:26:25,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742184_1360, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,662 INFO terminating
2025-03-26 02:26:25,663 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51146, dest: /172.20.1.12:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742184_1360, duration(ns): 1755149
2025-03-26 02:26:25,663 INFO terminating
2025-03-26 02:26:25,666 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,666 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742185_1361, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala._COPYING_
2025-03-26 02:26:25,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742185_1361 src: /172.20.1.10:51156 dest: /172.20.1.12:9866
2025-03-26 02:26:25,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742185_1361 src: /172.20.1.11:44316 dest: /172.20.1.13:9866
2025-03-26 02:26:25,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742185_1361 src: /172.20.1.12:54010 dest: /172.20.1.11:9866
2025-03-26 02:26:25,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44316, dest: /172.20.1.13:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742185_1361, duration(ns): 882238
2025-03-26 02:26:25,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54010, dest: /172.20.1.11:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742185_1361, duration(ns): 1207321
2025-03-26 02:26:25,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742185_1361, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51156, dest: /172.20.1.12:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742185_1361, duration(ns): 1558489
2025-03-26 02:26:25,672 INFO terminating
2025-03-26 02:26:25,672 INFO terminating
2025-03-26 02:26:25,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742186_1362, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala._COPYING_
2025-03-26 02:26:25,679 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,679 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742186_1362 src: /172.20.1.10:48008 dest: /172.20.1.13:9866
2025-03-26 02:26:25,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742186_1362 src: /172.20.1.13:57792 dest: /172.20.1.11:9866
2025-03-26 02:26:25,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742186_1362 src: /172.20.1.11:36670 dest: /172.20.1.12:9866
2025-03-26 02:26:25,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36670, dest: /172.20.1.12:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742186_1362, duration(ns): 955452
2025-03-26 02:26:25,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742186_1362, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57792, dest: /172.20.1.11:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742186_1362, duration(ns): 1198287
2025-03-26 02:26:25,684 INFO terminating
2025-03-26 02:26:25,685 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48008, dest: /172.20.1.13:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742186_1362, duration(ns): 1795536
2025-03-26 02:26:25,685 INFO terminating
2025-03-26 02:26:25,689 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742187_1363, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_
2025-03-26 02:26:25,689 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,689 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742187_1363 src: /172.20.1.10:50574 dest: /172.20.1.11:9866
2025-03-26 02:26:25,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742187_1363 src: /172.20.1.11:36676 dest: /172.20.1.12:9866
2025-03-26 02:26:25,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742187_1363 src: /172.20.1.12:37104 dest: /172.20.1.13:9866
2025-03-26 02:26:25,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36676, dest: /172.20.1.12:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742187_1363, duration(ns): 1398030
2025-03-26 02:26:25,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37104, dest: /172.20.1.13:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742187_1363, duration(ns): 851126
2025-03-26 02:26:25,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742187_1363, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,694 INFO terminating
2025-03-26 02:26:25,695 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50574, dest: /172.20.1.11:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742187_1363, duration(ns): 1717420
2025-03-26 02:26:25,695 INFO terminating
2025-03-26 02:26:25,699 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742188_1364, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala._COPYING_
2025-03-26 02:26:25,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742188_1364 src: /172.20.1.10:48012 dest: /172.20.1.13:9866
2025-03-26 02:26:25,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742188_1364 src: /172.20.1.13:57800 dest: /172.20.1.11:9866
2025-03-26 02:26:25,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742188_1364 src: /172.20.1.11:36686 dest: /172.20.1.12:9866
2025-03-26 02:26:25,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36686, dest: /172.20.1.12:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742188_1364, duration(ns): 884333
2025-03-26 02:26:25,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57800, dest: /172.20.1.11:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742188_1364, duration(ns): 1055858
2025-03-26 02:26:25,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742188_1364, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,704 INFO terminating
2025-03-26 02:26:25,705 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48012, dest: /172.20.1.13:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742188_1364, duration(ns): 1299756
2025-03-26 02:26:25,705 INFO terminating
2025-03-26 02:26:25,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742189_1365, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala._COPYING_
2025-03-26 02:26:25,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742189_1365 src: /172.20.1.10:50584 dest: /172.20.1.11:9866
2025-03-26 02:26:25,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742189_1365 src: /172.20.1.11:36690 dest: /172.20.1.12:9866
2025-03-26 02:26:25,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742189_1365 src: /172.20.1.12:37112 dest: /172.20.1.13:9866
2025-03-26 02:26:25,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36690, dest: /172.20.1.12:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742189_1365, duration(ns): 1301953
2025-03-26 02:26:25,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37112, dest: /172.20.1.13:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742189_1365, duration(ns): 785147
2025-03-26 02:26:25,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742189_1365, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,714 INFO terminating
2025-03-26 02:26:25,715 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50584, dest: /172.20.1.11:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742189_1365, duration(ns): 1665923
2025-03-26 02:26:25,715 INFO terminating
2025-03-26 02:26:25,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742190_1366, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala._COPYING_
2025-03-26 02:26:25,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742190_1366 src: /172.20.1.10:50586 dest: /172.20.1.11:9866
2025-03-26 02:26:25,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742190_1366 src: /172.20.1.11:44320 dest: /172.20.1.13:9866
2025-03-26 02:26:25,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742190_1366 src: /172.20.1.13:33314 dest: /172.20.1.12:9866
2025-03-26 02:26:25,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33314, dest: /172.20.1.12:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742190_1366, duration(ns): 878298
2025-03-26 02:26:25,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742190_1366, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44320, dest: /172.20.1.13:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742190_1366, duration(ns): 1515724
2025-03-26 02:26:25,724 INFO terminating
2025-03-26 02:26:25,725 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50586, dest: /172.20.1.11:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742190_1366, duration(ns): 2252561
2025-03-26 02:26:25,725 INFO terminating
2025-03-26 02:26:25,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742191_1367, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala._COPYING_
2025-03-26 02:26:25,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742191_1367 src: /172.20.1.10:51168 dest: /172.20.1.12:9866
2025-03-26 02:26:25,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742191_1367 src: /172.20.1.12:54014 dest: /172.20.1.11:9866
2025-03-26 02:26:25,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742191_1367 src: /172.20.1.11:44334 dest: /172.20.1.13:9866
2025-03-26 02:26:25,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44334, dest: /172.20.1.13:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742191_1367, duration(ns): 1087217
2025-03-26 02:26:25,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742191_1367, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54014, dest: /172.20.1.11:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742191_1367, duration(ns): 2233460
2025-03-26 02:26:25,736 INFO terminating
2025-03-26 02:26:25,737 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51168, dest: /172.20.1.12:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742191_1367, duration(ns): 2656878
2025-03-26 02:26:25,737 INFO terminating
2025-03-26 02:26:25,741 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742192_1368, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala._COPYING_
2025-03-26 02:26:25,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742192_1368 src: /172.20.1.10:50596 dest: /172.20.1.11:9866
2025-03-26 02:26:25,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742192_1368 src: /172.20.1.11:36698 dest: /172.20.1.12:9866
2025-03-26 02:26:25,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742192_1368 src: /172.20.1.12:37116 dest: /172.20.1.13:9866
2025-03-26 02:26:25,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37116, dest: /172.20.1.13:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742192_1368, duration(ns): 667484
2025-03-26 02:26:25,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742192_1368, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:36698, dest: /172.20.1.12:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742192_1368, duration(ns): 1960457
2025-03-26 02:26:25,748 INFO terminating
2025-03-26 02:26:25,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50596, dest: /172.20.1.11:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742192_1368, duration(ns): 3561757
2025-03-26 02:26:25,749 INFO terminating
2025-03-26 02:26:25,750 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742193_1369, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala._COPYING_
2025-03-26 02:26:25,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742193_1369 src: /172.20.1.10:48026 dest: /172.20.1.13:9866
2025-03-26 02:26:25,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742193_1369 src: /172.20.1.13:33316 dest: /172.20.1.12:9866
2025-03-26 02:26:25,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742193_1369 src: /172.20.1.12:54030 dest: /172.20.1.11:9866
2025-03-26 02:26:25,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54030, dest: /172.20.1.11:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742193_1369, duration(ns): 720617
2025-03-26 02:26:25,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742193_1369, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33316, dest: /172.20.1.12:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742193_1369, duration(ns): 1590994
2025-03-26 02:26:25,760 INFO terminating
2025-03-26 02:26:25,763 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48026, dest: /172.20.1.13:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742193_1369, duration(ns): 3751394
2025-03-26 02:26:25,763 INFO terminating
2025-03-26 02:26:25,772 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742194_1370, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala._COPYING_
2025-03-26 02:26:25,772 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,772 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742194_1370 src: /172.20.1.10:50598 dest: /172.20.1.11:9866
2025-03-26 02:26:25,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742194_1370 src: /172.20.1.11:44350 dest: /172.20.1.13:9866
2025-03-26 02:26:25,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742194_1370 src: /172.20.1.13:33322 dest: /172.20.1.12:9866
2025-03-26 02:26:25,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741870_1046 to 172.20.1.11:9866
2025-03-26 02:26:25,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741869_1045 to 172.20.1.11:9866
2025-03-26 02:26:25,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741872_1048 to 172.20.1.11:9866
2025-03-26 02:26:25,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741871_1047 to 172.20.1.11:9866
2025-03-26 02:26:25,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33322, dest: /172.20.1.12:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742194_1370, duration(ns): 9223352
2025-03-26 02:26:25,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44350, dest: /172.20.1.13:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742194_1370, duration(ns): 21712993
2025-03-26 02:26:25,798 INFO terminating
2025-03-26 02:26:25,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50598, dest: /172.20.1.11:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742194_1370, duration(ns): 22259451
2025-03-26 02:26:25,799 INFO terminating
2025-03-26 02:26:25,800 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742194_1370, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742195_1371, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala._COPYING_
2025-03-26 02:26:25,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,804 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,804 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,804 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741872_1048 src: /172.20.1.12:54040 dest: /172.20.1.11:9866
2025-03-26 02:26:25,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741870_1046 src: /172.20.1.12:54036 dest: /172.20.1.11:9866
2025-03-26 02:26:25,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742195_1371 src: /172.20.1.10:51172 dest: /172.20.1.12:9866
2025-03-26 02:26:25,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741872_1048 (numBytes=2818) to /172.20.1.11:9866
2025-03-26 02:26:25,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741872_1048 src: /172.20.1.12:54040 dest: /172.20.1.11:9866 of size 2818
2025-03-26 02:26:25,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741870_1046 (numBytes=3212) to /172.20.1.11:9866
2025-03-26 02:26:25,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741870_1046 src: /172.20.1.12:54036 dest: /172.20.1.11:9866 of size 3212
2025-03-26 02:26:25,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741871_1047 src: /172.20.1.13:57820 dest: /172.20.1.11:9866
2025-03-26 02:26:25,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741869_1045 src: /172.20.1.13:57810 dest: /172.20.1.11:9866
2025-03-26 02:26:25,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741871_1047 (numBytes=3307) to /172.20.1.11:9866
2025-03-26 02:26:25,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741871_1047 src: /172.20.1.13:57820 dest: /172.20.1.11:9866 of size 3307
2025-03-26 02:26:25,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741869_1045 (numBytes=2368) to /172.20.1.11:9866
2025-03-26 02:26:25,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742195_1371 src: /172.20.1.12:37132 dest: /172.20.1.13:9866
2025-03-26 02:26:25,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37132, dest: /172.20.1.13:9866, bytes: 1721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742195_1371, duration(ns): 457028
2025-03-26 02:26:25,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741869_1045 src: /172.20.1.13:57810 dest: /172.20.1.11:9866 of size 2368
2025-03-26 02:26:25,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742195_1371, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51172, dest: /172.20.1.12:9866, bytes: 1721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742195_1371, duration(ns): 1223339
2025-03-26 02:26:25,836 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,836 INFO terminating
2025-03-26 02:26:25,840 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742196_1372, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala._COPYING_
2025-03-26 02:26:25,840 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,840 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,840 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,840 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,840 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,840 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742196_1372 src: /172.20.1.10:51188 dest: /172.20.1.12:9866
2025-03-26 02:26:25,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742196_1372 src: /172.20.1.12:37134 dest: /172.20.1.13:9866
2025-03-26 02:26:25,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37134, dest: /172.20.1.13:9866, bytes: 2906, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742196_1372, duration(ns): 741775
2025-03-26 02:26:25,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742196_1372, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51188, dest: /172.20.1.12:9866, bytes: 2906, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742196_1372, duration(ns): 1003172
2025-03-26 02:26:25,846 INFO terminating
2025-03-26 02:26:25,847 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,850 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742197_1373, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala._COPYING_
2025-03-26 02:26:25,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,850 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,850 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,850 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742197_1373 src: /172.20.1.10:51192 dest: /172.20.1.12:9866
2025-03-26 02:26:25,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742197_1373 src: /172.20.1.12:37142 dest: /172.20.1.13:9866
2025-03-26 02:26:25,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37142, dest: /172.20.1.13:9866, bytes: 2064, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742197_1373, duration(ns): 554459
2025-03-26 02:26:25,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742197_1373, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51192, dest: /172.20.1.12:9866, bytes: 2064, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742197_1373, duration(ns): 849386
2025-03-26 02:26:25,857 INFO terminating
2025-03-26 02:26:25,858 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,861 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742198_1374, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala._COPYING_
2025-03-26 02:26:25,861 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,861 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,861 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,861 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,861 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,861 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742198_1374 src: /172.20.1.10:51208 dest: /172.20.1.12:9866
2025-03-26 02:26:25,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742198_1374 src: /172.20.1.12:37156 dest: /172.20.1.13:9866
2025-03-26 02:26:25,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37156, dest: /172.20.1.13:9866, bytes: 1918, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742198_1374, duration(ns): 875486
2025-03-26 02:26:25,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51208, dest: /172.20.1.12:9866, bytes: 1918, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742198_1374, duration(ns): 805907
2025-03-26 02:26:25,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742198_1374, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,869 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,869 INFO terminating
2025-03-26 02:26:25,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742199_1375, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala._COPYING_
2025-03-26 02:26:25,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:25,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,873 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,873 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,873 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742199_1375 src: /172.20.1.10:48040 dest: /172.20.1.13:9866
2025-03-26 02:26:25,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742199_1375 src: /172.20.1.13:33330 dest: /172.20.1.12:9866
2025-03-26 02:26:25,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48040, dest: /172.20.1.13:9866, bytes: 1695, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742199_1375, duration(ns): 1030374
2025-03-26 02:26:25,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33330, dest: /172.20.1.12:9866, bytes: 1695, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742199_1375, duration(ns): 429487
2025-03-26 02:26:25,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742199_1375, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,877 INFO terminating
2025-03-26 02:26:25,878 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742200_1376, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala._COPYING_
2025-03-26 02:26:25,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:25,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,881 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,881 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,881 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742200_1376 src: /172.20.1.10:51210 dest: /172.20.1.12:9866
2025-03-26 02:26:25,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742200_1376 src: /172.20.1.12:37166 dest: /172.20.1.13:9866
2025-03-26 02:26:25,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37166, dest: /172.20.1.13:9866, bytes: 1851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742200_1376, duration(ns): 470785
2025-03-26 02:26:25,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742200_1376, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,887 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51210, dest: /172.20.1.12:9866, bytes: 1851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742200_1376, duration(ns): 1119626
2025-03-26 02:26:25,887 INFO terminating
2025-03-26 02:26:25,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742201_1377, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala._COPYING_
2025-03-26 02:26:25,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,891 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,891 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,891 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742201_1377 src: /172.20.1.10:51224 dest: /172.20.1.12:9866
2025-03-26 02:26:25,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742201_1377 src: /172.20.1.12:37176 dest: /172.20.1.13:9866
2025-03-26 02:26:25,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37176, dest: /172.20.1.13:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742201_1377, duration(ns): 402419
2025-03-26 02:26:25,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742201_1377, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,896 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51224, dest: /172.20.1.12:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742201_1377, duration(ns): 666294
2025-03-26 02:26:25,896 INFO terminating
2025-03-26 02:26:25,900 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742202_1378, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala._COPYING_
2025-03-26 02:26:25,900 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,900 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,900 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,900 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,900 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,900 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742202_1378 src: /172.20.1.10:48046 dest: /172.20.1.13:9866
2025-03-26 02:26:25,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742202_1378 src: /172.20.1.13:33346 dest: /172.20.1.12:9866
2025-03-26 02:26:25,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48046, dest: /172.20.1.13:9866, bytes: 1822, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742202_1378, duration(ns): 1146310
2025-03-26 02:26:25,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33346, dest: /172.20.1.12:9866, bytes: 1822, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742202_1378, duration(ns): 343041
2025-03-26 02:26:25,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742202_1378, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,904 INFO terminating
2025-03-26 02:26:25,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,909 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742203_1379, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala._COPYING_
2025-03-26 02:26:25,909 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:25,909 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,909 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,909 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,909 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,909 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742203_1379 src: /172.20.1.10:51232 dest: /172.20.1.12:9866
2025-03-26 02:26:25,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742203_1379 src: /172.20.1.12:37182 dest: /172.20.1.13:9866
2025-03-26 02:26:25,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37182, dest: /172.20.1.13:9866, bytes: 2248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742203_1379, duration(ns): 2187541
2025-03-26 02:26:25,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742203_1379, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51232, dest: /172.20.1.12:9866, bytes: 2248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742203_1379, duration(ns): 2560596
2025-03-26 02:26:25,915 INFO terminating
2025-03-26 02:26:25,916 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742204_1380, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala._COPYING_
2025-03-26 02:26:25,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,920 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,920 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,920 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742204_1380 src: /172.20.1.10:48050 dest: /172.20.1.13:9866
2025-03-26 02:26:25,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742204_1380 src: /172.20.1.13:33362 dest: /172.20.1.12:9866
2025-03-26 02:26:25,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33362, dest: /172.20.1.12:9866, bytes: 3245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742204_1380, duration(ns): 422930
2025-03-26 02:26:25,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742204_1380, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,926 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48050, dest: /172.20.1.13:9866, bytes: 3245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742204_1380, duration(ns): 1117411
2025-03-26 02:26:25,926 INFO terminating
2025-03-26 02:26:25,931 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742205_1381, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:26:25,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,931 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,931 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,931 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742205_1381 src: /172.20.1.10:48066 dest: /172.20.1.13:9866
2025-03-26 02:26:25,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742205_1381 src: /172.20.1.13:33366 dest: /172.20.1.12:9866
2025-03-26 02:26:25,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33366, dest: /172.20.1.12:9866, bytes: 3465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742205_1381, duration(ns): 512844
2025-03-26 02:26:25,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742205_1381, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,936 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48066, dest: /172.20.1.13:9866, bytes: 3465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742205_1381, duration(ns): 1222265
2025-03-26 02:26:25,936 INFO terminating
2025-03-26 02:26:25,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742206_1382, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala._COPYING_
2025-03-26 02:26:25,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,942 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,942 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,942 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742206_1382 src: /172.20.1.10:48068 dest: /172.20.1.13:9866
2025-03-26 02:26:25,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742206_1382 src: /172.20.1.13:33372 dest: /172.20.1.12:9866
2025-03-26 02:26:25,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33372, dest: /172.20.1.12:9866, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742206_1382, duration(ns): 576198
2025-03-26 02:26:25,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742206_1382, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48068, dest: /172.20.1.13:9866, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742206_1382, duration(ns): 1473559
2025-03-26 02:26:25,951 INFO terminating
2025-03-26 02:26:25,954 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,957 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742207_1383, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala._COPYING_
2025-03-26 02:26:25,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,957 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,957 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,957 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742207_1383 src: /172.20.1.10:48084 dest: /172.20.1.13:9866
2025-03-26 02:26:25,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742207_1383 src: /172.20.1.13:33384 dest: /172.20.1.12:9866
2025-03-26 02:26:25,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33384, dest: /172.20.1.12:9866, bytes: 3111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742207_1383, duration(ns): 601266
2025-03-26 02:26:25,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742207_1383, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:25,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48084, dest: /172.20.1.13:9866, bytes: 3111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742207_1383, duration(ns): 4909174
2025-03-26 02:26:25,973 INFO terminating
2025-03-26 02:26:25,974 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:25,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:25,979 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:25,979 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:25,979 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:25,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742208_1384, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:26:26,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742208_1384 src: /172.20.1.10:48094 dest: /172.20.1.13:9866
2025-03-26 02:26:26,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742208_1384 src: /172.20.1.13:33390 dest: /172.20.1.12:9866
2025-03-26 02:26:26,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33390, dest: /172.20.1.12:9866, bytes: 2167, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742208_1384, duration(ns): 423298
2025-03-26 02:26:26,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742208_1384, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,036 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48094, dest: /172.20.1.13:9866, bytes: 2167, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742208_1384, duration(ns): 4862796
2025-03-26 02:26:26,036 INFO terminating
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,039 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,039 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,041 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742209_1385, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala._COPYING_
2025-03-26 02:26:26,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,041 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,041 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,041 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742209_1385 src: /172.20.1.10:51244 dest: /172.20.1.12:9866
2025-03-26 02:26:26,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742209_1385 src: /172.20.1.12:37188 dest: /172.20.1.13:9866
2025-03-26 02:26:26,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37188, dest: /172.20.1.13:9866, bytes: 2408, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742209_1385, duration(ns): 559628
2025-03-26 02:26:26,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742209_1385, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51244, dest: /172.20.1.12:9866, bytes: 2408, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742209_1385, duration(ns): 1186695
2025-03-26 02:26:26,047 INFO terminating
2025-03-26 02:26:26,049 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742210_1386, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala._COPYING_
2025-03-26 02:26:26,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,052 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,052 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,052 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742210_1386 src: /172.20.1.10:51252 dest: /172.20.1.12:9866
2025-03-26 02:26:26,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742210_1386 src: /172.20.1.12:37198 dest: /172.20.1.13:9866
2025-03-26 02:26:26,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37198, dest: /172.20.1.13:9866, bytes: 2005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742210_1386, duration(ns): 364961
2025-03-26 02:26:26,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742210_1386, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51252, dest: /172.20.1.12:9866, bytes: 2005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742210_1386, duration(ns): 842111
2025-03-26 02:26:26,056 INFO terminating
2025-03-26 02:26:26,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742211_1387, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala._COPYING_
2025-03-26 02:26:26,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,064 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,064 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,064 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742211_1387 src: /172.20.1.10:48104 dest: /172.20.1.13:9866
2025-03-26 02:26:26,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742211_1387 src: /172.20.1.13:33406 dest: /172.20.1.12:9866
2025-03-26 02:26:26,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33406, dest: /172.20.1.12:9866, bytes: 3423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742211_1387, duration(ns): 437051
2025-03-26 02:26:26,073 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48104, dest: /172.20.1.13:9866, bytes: 3423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742211_1387, duration(ns): 832862
2025-03-26 02:26:26,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742211_1387, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,073 INFO terminating
2025-03-26 02:26:26,076 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,076 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,076 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,076 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,076 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,077 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742212_1388, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala._COPYING_
2025-03-26 02:26:26,077 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742212_1388 src: /172.20.1.10:51264 dest: /172.20.1.12:9866
2025-03-26 02:26:26,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742212_1388 src: /172.20.1.12:37212 dest: /172.20.1.13:9866
2025-03-26 02:26:26,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37212, dest: /172.20.1.13:9866, bytes: 9724, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742212_1388, duration(ns): 8147148
2025-03-26 02:26:26,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742212_1388, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,099 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51264, dest: /172.20.1.12:9866, bytes: 9724, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742212_1388, duration(ns): 8712047
2025-03-26 02:26:26,099 INFO terminating
2025-03-26 02:26:26,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742213_1389, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala._COPYING_
2025-03-26 02:26:26,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,102 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,102 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,102 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742213_1389 src: /172.20.1.10:48114 dest: /172.20.1.13:9866
2025-03-26 02:26:26,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742213_1389 src: /172.20.1.13:33412 dest: /172.20.1.12:9866
2025-03-26 02:26:26,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33412, dest: /172.20.1.12:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742213_1389, duration(ns): 325441
2025-03-26 02:26:26,106 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48114, dest: /172.20.1.13:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742213_1389, duration(ns): 705770
2025-03-26 02:26:26,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742213_1389, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,106 INFO terminating
2025-03-26 02:26:26,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742214_1390, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala._COPYING_
2025-03-26 02:26:26,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,111 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,111 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,111 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742214_1390 src: /172.20.1.10:48130 dest: /172.20.1.13:9866
2025-03-26 02:26:26,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742214_1390 src: /172.20.1.13:33428 dest: /172.20.1.12:9866
2025-03-26 02:26:26,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33428, dest: /172.20.1.12:9866, bytes: 1730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742214_1390, duration(ns): 327691
2025-03-26 02:26:26,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742214_1390, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,115 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48130, dest: /172.20.1.13:9866, bytes: 1730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742214_1390, duration(ns): 844708
2025-03-26 02:26:26,115 INFO terminating
2025-03-26 02:26:26,118 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742215_1391, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala._COPYING_
2025-03-26 02:26:26,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,118 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,118 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,118 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742215_1391 src: /172.20.1.10:51274 dest: /172.20.1.12:9866
2025-03-26 02:26:26,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742215_1391 src: /172.20.1.12:37216 dest: /172.20.1.13:9866
2025-03-26 02:26:26,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37216, dest: /172.20.1.13:9866, bytes: 2185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742215_1391, duration(ns): 383527
2025-03-26 02:26:26,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742215_1391, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,122 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51274, dest: /172.20.1.12:9866, bytes: 2185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742215_1391, duration(ns): 771148
2025-03-26 02:26:26,122 INFO terminating
2025-03-26 02:26:26,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,125 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,125 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,125 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742216_1392, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala._COPYING_
2025-03-26 02:26:26,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742216_1392 src: /172.20.1.10:48138 dest: /172.20.1.13:9866
2025-03-26 02:26:26,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742216_1392 src: /172.20.1.13:33444 dest: /172.20.1.12:9866
2025-03-26 02:26:26,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33444, dest: /172.20.1.12:9866, bytes: 1283, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742216_1392, duration(ns): 340396
2025-03-26 02:26:26,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742216_1392, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,130 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48138, dest: /172.20.1.13:9866, bytes: 1283, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742216_1392, duration(ns): 692987
2025-03-26 02:26:26,130 INFO terminating
2025-03-26 02:26:26,133 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742217_1393, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala._COPYING_
2025-03-26 02:26:26,133 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,133 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,133 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,133 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,133 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,133 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742217_1393 src: /172.20.1.10:51284 dest: /172.20.1.12:9866
2025-03-26 02:26:26,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742217_1393 src: /172.20.1.12:37228 dest: /172.20.1.13:9866
2025-03-26 02:26:26,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37228, dest: /172.20.1.13:9866, bytes: 4111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742217_1393, duration(ns): 353555
2025-03-26 02:26:26,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742217_1393, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,137 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51284, dest: /172.20.1.12:9866, bytes: 4111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742217_1393, duration(ns): 786003
2025-03-26 02:26:26,137 INFO terminating
2025-03-26 02:26:26,142 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742218_1394, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala._COPYING_
2025-03-26 02:26:26,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,142 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,142 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,142 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742218_1394 src: /172.20.1.10:48144 dest: /172.20.1.13:9866
2025-03-26 02:26:26,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742218_1394 src: /172.20.1.13:33450 dest: /172.20.1.12:9866
2025-03-26 02:26:26,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48144, dest: /172.20.1.13:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742218_1394, duration(ns): 912932
2025-03-26 02:26:26,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33450, dest: /172.20.1.12:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742218_1394, duration(ns): 387535
2025-03-26 02:26:26,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742218_1394, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,147 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,147 INFO terminating
2025-03-26 02:26:26,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742219_1395, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala._COPYING_
2025-03-26 02:26:26,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,151 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,151 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,151 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,151 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742219_1395 src: /172.20.1.10:48156 dest: /172.20.1.13:9866
2025-03-26 02:26:26,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742219_1395 src: /172.20.1.13:33458 dest: /172.20.1.12:9866
2025-03-26 02:26:26,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33458, dest: /172.20.1.12:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742219_1395, duration(ns): 379364
2025-03-26 02:26:26,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742219_1395, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,156 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48156, dest: /172.20.1.13:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742219_1395, duration(ns): 984759
2025-03-26 02:26:26,156 INFO terminating
2025-03-26 02:26:26,160 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742220_1396, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala._COPYING_
2025-03-26 02:26:26,160 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,160 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,160 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,160 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,160 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,160 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742220_1396 src: /172.20.1.10:48162 dest: /172.20.1.13:9866
2025-03-26 02:26:26,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742220_1396 src: /172.20.1.13:33462 dest: /172.20.1.12:9866
2025-03-26 02:26:26,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33462, dest: /172.20.1.12:9866, bytes: 4039, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742220_1396, duration(ns): 390371
2025-03-26 02:26:26,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742220_1396, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,164 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48162, dest: /172.20.1.13:9866, bytes: 4039, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742220_1396, duration(ns): 915360
2025-03-26 02:26:26,164 INFO terminating
2025-03-26 02:26:26,171 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742221_1397, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala._COPYING_
2025-03-26 02:26:26,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,171 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,171 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,171 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742221_1397 src: /172.20.1.10:51296 dest: /172.20.1.12:9866
2025-03-26 02:26:26,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742221_1397 src: /172.20.1.12:37244 dest: /172.20.1.13:9866
2025-03-26 02:26:26,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51296, dest: /172.20.1.12:9866, bytes: 2469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742221_1397, duration(ns): 856139
2025-03-26 02:26:26,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37244, dest: /172.20.1.13:9866, bytes: 2469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742221_1397, duration(ns): 382433
2025-03-26 02:26:26,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742221_1397, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,175 INFO terminating
2025-03-26 02:26:26,176 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,181 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742222_1398, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala._COPYING_
2025-03-26 02:26:26,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,181 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,181 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,181 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742222_1398 src: /172.20.1.10:48174 dest: /172.20.1.13:9866
2025-03-26 02:26:26,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742222_1398 src: /172.20.1.13:33468 dest: /172.20.1.12:9866
2025-03-26 02:26:26,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33468, dest: /172.20.1.12:9866, bytes: 2159, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742222_1398, duration(ns): 348558
2025-03-26 02:26:26,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742222_1398, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,185 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48174, dest: /172.20.1.13:9866, bytes: 2159, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742222_1398, duration(ns): 834189
2025-03-26 02:26:26,185 INFO terminating
2025-03-26 02:26:26,188 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742223_1399, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala._COPYING_
2025-03-26 02:26:26,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,188 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,188 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,188 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742223_1399 src: /172.20.1.10:51310 dest: /172.20.1.12:9866
2025-03-26 02:26:26,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742223_1399 src: /172.20.1.12:37248 dest: /172.20.1.13:9866
2025-03-26 02:26:26,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37248, dest: /172.20.1.13:9866, bytes: 4648, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742223_1399, duration(ns): 437311
2025-03-26 02:26:26,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51310, dest: /172.20.1.12:9866, bytes: 4648, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742223_1399, duration(ns): 908087
2025-03-26 02:26:26,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742223_1399, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,194 INFO terminating
2025-03-26 02:26:26,195 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,197 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,198 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742224_1400, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala._COPYING_
2025-03-26 02:26:26,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,198 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,198 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,198 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742224_1400 src: /172.20.1.10:48186 dest: /172.20.1.13:9866
2025-03-26 02:26:26,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742224_1400 src: /172.20.1.13:33480 dest: /172.20.1.12:9866
2025-03-26 02:26:26,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33480, dest: /172.20.1.12:9866, bytes: 2705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742224_1400, duration(ns): 358911
2025-03-26 02:26:26,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742224_1400, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,203 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48186, dest: /172.20.1.13:9866, bytes: 2705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742224_1400, duration(ns): 933875
2025-03-26 02:26:26,203 INFO terminating
2025-03-26 02:26:26,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742225_1401, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_
2025-03-26 02:26:26,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,206 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,206 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,206 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742225_1401 src: /172.20.1.10:48198 dest: /172.20.1.13:9866
2025-03-26 02:26:26,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742225_1401 src: /172.20.1.13:33494 dest: /172.20.1.12:9866
2025-03-26 02:26:26,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48198, dest: /172.20.1.13:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742225_1401, duration(ns): 852467
2025-03-26 02:26:26,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33494, dest: /172.20.1.12:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742225_1401, duration(ns): 372683
2025-03-26 02:26:26,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742225_1401, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,212 INFO terminating
2025-03-26 02:26:26,213 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742226_1402, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala._COPYING_
2025-03-26 02:26:26,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,216 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,216 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,216 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742226_1402 src: /172.20.1.10:48200 dest: /172.20.1.13:9866
2025-03-26 02:26:26,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742226_1402 src: /172.20.1.13:33500 dest: /172.20.1.12:9866
2025-03-26 02:26:26,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33500, dest: /172.20.1.12:9866, bytes: 1842, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742226_1402, duration(ns): 298714
2025-03-26 02:26:26,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742226_1402, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,220 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48200, dest: /172.20.1.13:9866, bytes: 1842, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742226_1402, duration(ns): 470035
2025-03-26 02:26:26,220 INFO terminating
2025-03-26 02:26:26,222 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,222 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,222 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,222 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,223 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742227_1403, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala._COPYING_
2025-03-26 02:26:26,223 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,223 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742227_1403 src: /172.20.1.10:48210 dest: /172.20.1.13:9866
2025-03-26 02:26:26,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742227_1403 src: /172.20.1.13:33506 dest: /172.20.1.12:9866
2025-03-26 02:26:26,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48210, dest: /172.20.1.13:9866, bytes: 1669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742227_1403, duration(ns): 875289
2025-03-26 02:26:26,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33506, dest: /172.20.1.12:9866, bytes: 1669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742227_1403, duration(ns): 405794
2025-03-26 02:26:26,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742227_1403, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,228 INFO terminating
2025-03-26 02:26:26,229 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,232 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742228_1404, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala._COPYING_
2025-03-26 02:26:26,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,232 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,232 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,232 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742228_1404 src: /172.20.1.10:51316 dest: /172.20.1.12:9866
2025-03-26 02:26:26,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742228_1404 src: /172.20.1.12:37252 dest: /172.20.1.13:9866
2025-03-26 02:26:26,235 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51316, dest: /172.20.1.12:9866, bytes: 1920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742228_1404, duration(ns): 764205
2025-03-26 02:26:26,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37252, dest: /172.20.1.13:9866, bytes: 1920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742228_1404, duration(ns): 343234
2025-03-26 02:26:26,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742228_1404, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,235 INFO terminating
2025-03-26 02:26:26,244 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742229_1405, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala._COPYING_
2025-03-26 02:26:26,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,244 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,244 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,244 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742229_1405 src: /172.20.1.10:48220 dest: /172.20.1.13:9866
2025-03-26 02:26:26,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742229_1405 src: /172.20.1.13:33512 dest: /172.20.1.12:9866
2025-03-26 02:26:26,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33512, dest: /172.20.1.12:9866, bytes: 5351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742229_1405, duration(ns): 511129
2025-03-26 02:26:26,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742229_1405, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,249 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48220, dest: /172.20.1.13:9866, bytes: 5351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742229_1405, duration(ns): 1073928
2025-03-26 02:26:26,249 INFO terminating
2025-03-26 02:26:26,255 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742230_1406, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala._COPYING_
2025-03-26 02:26:26,255 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,255 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,255 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,255 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,255 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,255 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742230_1406 src: /172.20.1.10:51322 dest: /172.20.1.12:9866
2025-03-26 02:26:26,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742230_1406 src: /172.20.1.12:37254 dest: /172.20.1.13:9866
2025-03-26 02:26:26,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51322, dest: /172.20.1.12:9866, bytes: 3444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742230_1406, duration(ns): 934404
2025-03-26 02:26:26,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37254, dest: /172.20.1.13:9866, bytes: 3444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742230_1406, duration(ns): 457721
2025-03-26 02:26:26,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742230_1406, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,259 INFO terminating
2025-03-26 02:26:26,260 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,263 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,263 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,263 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,264 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742231_1407, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_
2025-03-26 02:26:26,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742231_1407 src: /172.20.1.10:48228 dest: /172.20.1.13:9866
2025-03-26 02:26:26,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742231_1407 src: /172.20.1.13:33520 dest: /172.20.1.12:9866
2025-03-26 02:26:26,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48228, dest: /172.20.1.13:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742231_1407, duration(ns): 500698
2025-03-26 02:26:26,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33520, dest: /172.20.1.12:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742231_1407, duration(ns): 451836
2025-03-26 02:26:26,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742231_1407, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,267 INFO terminating
2025-03-26 02:26:26,268 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742232_1408, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala._COPYING_
2025-03-26 02:26:26,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,275 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,275 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,275 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742232_1408 src: /172.20.1.10:48240 dest: /172.20.1.13:9866
2025-03-26 02:26:26,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742232_1408 src: /172.20.1.13:33524 dest: /172.20.1.12:9866
2025-03-26 02:26:26,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48240, dest: /172.20.1.13:9866, bytes: 15338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742232_1408, duration(ns): 676857
2025-03-26 02:26:26,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33524, dest: /172.20.1.12:9866, bytes: 15338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742232_1408, duration(ns): 528084
2025-03-26 02:26:26,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742232_1408, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,283 INFO terminating
2025-03-26 02:26:26,284 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,289 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742233_1409, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_
2025-03-26 02:26:26,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,289 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,289 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,289 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742233_1409 src: /172.20.1.10:48254 dest: /172.20.1.13:9866
2025-03-26 02:26:26,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742233_1409 src: /172.20.1.13:33540 dest: /172.20.1.12:9866
2025-03-26 02:26:26,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33540, dest: /172.20.1.12:9866, bytes: 5661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742233_1409, duration(ns): 3080443
2025-03-26 02:26:26,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742233_1409, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,305 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48254, dest: /172.20.1.13:9866, bytes: 5661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742233_1409, duration(ns): 637531
2025-03-26 02:26:26,305 INFO terminating
2025-03-26 02:26:26,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742234_1410, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala._COPYING_
2025-03-26 02:26:26,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,308 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,308 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,308 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742234_1410 src: /172.20.1.10:51326 dest: /172.20.1.12:9866
2025-03-26 02:26:26,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742234_1410 src: /172.20.1.12:37270 dest: /172.20.1.13:9866
2025-03-26 02:26:26,313 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51326, dest: /172.20.1.12:9866, bytes: 3236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742234_1410, duration(ns): 930518
2025-03-26 02:26:26,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37270, dest: /172.20.1.13:9866, bytes: 3236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742234_1410, duration(ns): 477484
2025-03-26 02:26:26,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742234_1410, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,313 INFO terminating
2025-03-26 02:26:26,316 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742235_1411, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala._COPYING_
2025-03-26 02:26:26,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,316 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,316 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,316 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742235_1411 src: /172.20.1.10:48270 dest: /172.20.1.13:9866
2025-03-26 02:26:26,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742235_1411 src: /172.20.1.13:33550 dest: /172.20.1.12:9866
2025-03-26 02:26:26,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33550, dest: /172.20.1.12:9866, bytes: 2552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742235_1411, duration(ns): 701174
2025-03-26 02:26:26,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742235_1411, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48270, dest: /172.20.1.13:9866, bytes: 2552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742235_1411, duration(ns): 525922
2025-03-26 02:26:26,321 INFO terminating
2025-03-26 02:26:26,324 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742236_1412, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala._COPYING_
2025-03-26 02:26:26,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,324 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,324 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,324 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742236_1412 src: /172.20.1.10:51340 dest: /172.20.1.12:9866
2025-03-26 02:26:26,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742236_1412 src: /172.20.1.12:37286 dest: /172.20.1.13:9866
2025-03-26 02:26:26,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51340, dest: /172.20.1.12:9866, bytes: 8698, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742236_1412, duration(ns): 4140653
2025-03-26 02:26:26,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37286, dest: /172.20.1.13:9866, bytes: 8698, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742236_1412, duration(ns): 3604806
2025-03-26 02:26:26,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742236_1412, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,331 INFO terminating
2025-03-26 02:26:26,332 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742237_1413, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala._COPYING_
2025-03-26 02:26:26,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,342 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,342 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,342 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742237_1413 src: /172.20.1.10:48286 dest: /172.20.1.13:9866
2025-03-26 02:26:26,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742237_1413 src: /172.20.1.13:33552 dest: /172.20.1.12:9866
2025-03-26 02:26:26,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48286, dest: /172.20.1.13:9866, bytes: 2443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742237_1413, duration(ns): 1169298
2025-03-26 02:26:26,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33552, dest: /172.20.1.12:9866, bytes: 2443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742237_1413, duration(ns): 811593
2025-03-26 02:26:26,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742237_1413, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,346 INFO terminating
2025-03-26 02:26:26,347 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,351 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742238_1414, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala._COPYING_
2025-03-26 02:26:26,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,351 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,351 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,351 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742238_1414 src: /172.20.1.10:51350 dest: /172.20.1.12:9866
2025-03-26 02:26:26,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37298, dest: /172.20.1.13:9866, bytes: 4044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742238_1414, duration(ns): 377915
2025-03-26 02:26:26,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742238_1414, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742238_1414 src: /172.20.1.12:37298 dest: /172.20.1.13:9866
2025-03-26 02:26:26,355 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51350, dest: /172.20.1.12:9866, bytes: 4044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742238_1414, duration(ns): 516211
2025-03-26 02:26:26,355 INFO terminating
2025-03-26 02:26:26,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,408 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,408 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742239_1415, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala._COPYING_
2025-03-26 02:26:26,409 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742239_1415 src: /172.20.1.10:48296 dest: /172.20.1.13:9866
2025-03-26 02:26:26,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742239_1415 src: /172.20.1.13:33556 dest: /172.20.1.12:9866
2025-03-26 02:26:26,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48296, dest: /172.20.1.13:9866, bytes: 5410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742239_1415, duration(ns): 898117
2025-03-26 02:26:26,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33556, dest: /172.20.1.12:9866, bytes: 5410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742239_1415, duration(ns): 511523
2025-03-26 02:26:26,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742239_1415, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,414 INFO terminating
2025-03-26 02:26:26,415 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,418 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742240_1416, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala._COPYING_
2025-03-26 02:26:26,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,418 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,418 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,418 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742240_1416 src: /172.20.1.10:48306 dest: /172.20.1.13:9866
2025-03-26 02:26:26,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742240_1416 src: /172.20.1.13:33564 dest: /172.20.1.12:9866
2025-03-26 02:26:26,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48306, dest: /172.20.1.13:9866, bytes: 3440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742240_1416, duration(ns): 485509
2025-03-26 02:26:26,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33564, dest: /172.20.1.12:9866, bytes: 3440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742240_1416, duration(ns): 370889
2025-03-26 02:26:26,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742240_1416, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,421 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,421 INFO terminating
2025-03-26 02:26:26,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742241_1417, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_
2025-03-26 02:26:26,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,424 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,424 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,424 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742241_1417 src: /172.20.1.10:51364 dest: /172.20.1.12:9866
2025-03-26 02:26:26,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37306, dest: /172.20.1.13:9866, bytes: 11092, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742241_1417, duration(ns): 331445
2025-03-26 02:26:26,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742241_1417, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742241_1417 src: /172.20.1.12:37306 dest: /172.20.1.13:9866
2025-03-26 02:26:26,427 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51364, dest: /172.20.1.12:9866, bytes: 11092, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742241_1417, duration(ns): 529569
2025-03-26 02:26:26,427 INFO terminating
2025-03-26 02:26:26,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742242_1418, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala._COPYING_
2025-03-26 02:26:26,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,431 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,431 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,431 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742242_1418 src: /172.20.1.10:51370 dest: /172.20.1.12:9866
2025-03-26 02:26:26,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742242_1418 src: /172.20.1.12:37314 dest: /172.20.1.13:9866
2025-03-26 02:26:26,434 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51370, dest: /172.20.1.12:9866, bytes: 3139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742242_1418, duration(ns): 478337
2025-03-26 02:26:26,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37314, dest: /172.20.1.13:9866, bytes: 3139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742242_1418, duration(ns): 312243
2025-03-26 02:26:26,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742242_1418, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,434 INFO terminating
2025-03-26 02:26:26,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742243_1419, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala._COPYING_
2025-03-26 02:26:26,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,439 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,439 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,439 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742243_1419 src: /172.20.1.10:51376 dest: /172.20.1.12:9866
2025-03-26 02:26:26,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742243_1419 src: /172.20.1.12:37328 dest: /172.20.1.13:9866
2025-03-26 02:26:26,442 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51376, dest: /172.20.1.12:9866, bytes: 3234, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742243_1419, duration(ns): 501639
2025-03-26 02:26:26,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37328, dest: /172.20.1.13:9866, bytes: 3234, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742243_1419, duration(ns): 337941
2025-03-26 02:26:26,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742243_1419, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,442 INFO terminating
2025-03-26 02:26:26,447 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742244_1420, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_
2025-03-26 02:26:26,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,447 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,447 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,447 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742244_1420 src: /172.20.1.10:48322 dest: /172.20.1.13:9866
2025-03-26 02:26:26,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742244_1420 src: /172.20.1.13:33568 dest: /172.20.1.12:9866
2025-03-26 02:26:26,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48322, dest: /172.20.1.13:9866, bytes: 2178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742244_1420, duration(ns): 529623
2025-03-26 02:26:26,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33568, dest: /172.20.1.12:9866, bytes: 2178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742244_1420, duration(ns): 342140
2025-03-26 02:26:26,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742244_1420, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,450 INFO terminating
2025-03-26 02:26:26,452 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742244_1420 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_
2025-03-26 02:26:26,852 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,856 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742245_1421, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala._COPYING_
2025-03-26 02:26:26,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,856 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,856 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,856 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742245_1421 src: /172.20.1.10:51388 dest: /172.20.1.12:9866
2025-03-26 02:26:26,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742245_1421 src: /172.20.1.12:37340 dest: /172.20.1.13:9866
2025-03-26 02:26:26,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37340, dest: /172.20.1.13:9866, bytes: 1575, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742245_1421, duration(ns): 716244
2025-03-26 02:26:26,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742245_1421, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,860 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51388, dest: /172.20.1.12:9866, bytes: 1575, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742245_1421, duration(ns): 880365
2025-03-26 02:26:26,860 INFO terminating
2025-03-26 02:26:26,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742246_1422, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala._COPYING_
2025-03-26 02:26:26,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,864 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,864 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,864 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742246_1422 src: /172.20.1.10:48338 dest: /172.20.1.13:9866
2025-03-26 02:26:26,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742246_1422 src: /172.20.1.13:33578 dest: /172.20.1.12:9866
2025-03-26 02:26:26,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48338, dest: /172.20.1.13:9866, bytes: 3268, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742246_1422, duration(ns): 768755
2025-03-26 02:26:26,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33578, dest: /172.20.1.12:9866, bytes: 3268, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742246_1422, duration(ns): 592741
2025-03-26 02:26:26,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742246_1422, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,868 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,868 INFO terminating
2025-03-26 02:26:26,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742247_1423, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala._COPYING_
2025-03-26 02:26:26,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,871 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,871 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,871 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742247_1423 src: /172.20.1.10:51390 dest: /172.20.1.12:9866
2025-03-26 02:26:26,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742247_1423 src: /172.20.1.12:37354 dest: /172.20.1.13:9866
2025-03-26 02:26:26,874 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51390, dest: /172.20.1.12:9866, bytes: 2670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742247_1423, duration(ns): 458792
2025-03-26 02:26:26,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37354, dest: /172.20.1.13:9866, bytes: 2670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742247_1423, duration(ns): 281936
2025-03-26 02:26:26,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742247_1423, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,874 INFO terminating
2025-03-26 02:26:26,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742248_1424, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala._COPYING_
2025-03-26 02:26:26,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,878 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,878 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,878 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742248_1424 src: /172.20.1.10:51398 dest: /172.20.1.12:9866
2025-03-26 02:26:26,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742248_1424 src: /172.20.1.12:37364 dest: /172.20.1.13:9866
2025-03-26 02:26:26,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37364, dest: /172.20.1.13:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742248_1424, duration(ns): 359240
2025-03-26 02:26:26,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742248_1424, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,882 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51398, dest: /172.20.1.12:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742248_1424, duration(ns): 471547
2025-03-26 02:26:26,882 INFO terminating
2025-03-26 02:26:26,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742249_1425, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala._COPYING_
2025-03-26 02:26:26,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,885 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,885 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,885 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742249_1425 src: /172.20.1.10:48348 dest: /172.20.1.13:9866
2025-03-26 02:26:26,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742249_1425 src: /172.20.1.13:33592 dest: /172.20.1.12:9866
2025-03-26 02:26:26,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48348, dest: /172.20.1.13:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742249_1425, duration(ns): 702868
2025-03-26 02:26:26,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33592, dest: /172.20.1.12:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742249_1425, duration(ns): 574367
2025-03-26 02:26:26,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742249_1425, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,888 INFO terminating
2025-03-26 02:26:26,889 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742250_1426, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala._COPYING_
2025-03-26 02:26:26,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,891 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,891 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,891 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742250_1426 src: /172.20.1.10:51406 dest: /172.20.1.12:9866
2025-03-26 02:26:26,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742250_1426 src: /172.20.1.12:37380 dest: /172.20.1.13:9866
2025-03-26 02:26:26,894 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51406, dest: /172.20.1.12:9866, bytes: 5326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742250_1426, duration(ns): 467913
2025-03-26 02:26:26,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37380, dest: /172.20.1.13:9866, bytes: 5326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742250_1426, duration(ns): 269417
2025-03-26 02:26:26,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742250_1426, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,894 INFO terminating
2025-03-26 02:26:26,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742251_1427, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala._COPYING_
2025-03-26 02:26:26,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,897 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,897 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,897 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742251_1427 src: /172.20.1.10:48356 dest: /172.20.1.13:9866
2025-03-26 02:26:26,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33604, dest: /172.20.1.12:9866, bytes: 3737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742251_1427, duration(ns): 265255
2025-03-26 02:26:26,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742251_1427, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742251_1427 src: /172.20.1.13:33604 dest: /172.20.1.12:9866
2025-03-26 02:26:26,900 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48356, dest: /172.20.1.13:9866, bytes: 3737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742251_1427, duration(ns): 453783
2025-03-26 02:26:26,900 INFO terminating
2025-03-26 02:26:26,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742252_1428, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_
2025-03-26 02:26:26,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,907 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,907 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,907 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742252_1428 src: /172.20.1.10:51416 dest: /172.20.1.12:9866
2025-03-26 02:26:26,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742252_1428 src: /172.20.1.12:37392 dest: /172.20.1.13:9866
2025-03-26 02:26:26,912 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51416, dest: /172.20.1.12:9866, bytes: 4800, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742252_1428, duration(ns): 507350
2025-03-26 02:26:26,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37392, dest: /172.20.1.13:9866, bytes: 4800, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742252_1428, duration(ns): 344279
2025-03-26 02:26:26,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742252_1428, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,912 INFO terminating
2025-03-26 02:26:26,917 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742253_1429, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala._COPYING_
2025-03-26 02:26:26,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,917 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,917 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,917 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742253_1429 src: /172.20.1.10:48362 dest: /172.20.1.13:9866
2025-03-26 02:26:26,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48362, dest: /172.20.1.13:9866, bytes: 3780, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742253_1429, duration(ns): 472409
2025-03-26 02:26:26,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33610, dest: /172.20.1.12:9866, bytes: 3780, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742253_1429, duration(ns): 296277
2025-03-26 02:26:26,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742253_1429, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742253_1429 src: /172.20.1.13:33610 dest: /172.20.1.12:9866
2025-03-26 02:26:26,920 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,920 INFO terminating
2025-03-26 02:26:26,923 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742254_1430, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala._COPYING_
2025-03-26 02:26:26,923 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,923 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,923 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,923 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,923 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,923 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742254_1430 src: /172.20.1.10:48370 dest: /172.20.1.13:9866
2025-03-26 02:26:26,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742254_1430 src: /172.20.1.13:33618 dest: /172.20.1.12:9866
2025-03-26 02:26:26,926 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48370, dest: /172.20.1.13:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742254_1430, duration(ns): 480660
2025-03-26 02:26:26,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33618, dest: /172.20.1.12:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742254_1430, duration(ns): 331795
2025-03-26 02:26:26,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742254_1430, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,926 INFO terminating
2025-03-26 02:26:26,934 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742255_1431, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_
2025-03-26 02:26:26,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,934 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,934 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,934 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742255_1431 src: /172.20.1.10:48378 dest: /172.20.1.13:9866
2025-03-26 02:26:26,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742255_1431 src: /172.20.1.13:33632 dest: /172.20.1.12:9866
2025-03-26 02:26:26,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48378, dest: /172.20.1.13:9866, bytes: 6363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742255_1431, duration(ns): 573674
2025-03-26 02:26:26,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33632, dest: /172.20.1.12:9866, bytes: 6363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742255_1431, duration(ns): 376561
2025-03-26 02:26:26,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742255_1431, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,937 INFO terminating
2025-03-26 02:26:26,938 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742256_1432, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala._COPYING_
2025-03-26 02:26:26,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,942 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,942 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,942 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742256_1432 src: /172.20.1.10:48388 dest: /172.20.1.13:9866
2025-03-26 02:26:26,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742256_1432 src: /172.20.1.13:33648 dest: /172.20.1.12:9866
2025-03-26 02:26:26,945 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48388, dest: /172.20.1.13:9866, bytes: 3786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742256_1432, duration(ns): 612613
2025-03-26 02:26:26,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33648, dest: /172.20.1.12:9866, bytes: 3786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742256_1432, duration(ns): 402508
2025-03-26 02:26:26,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742256_1432, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,945 INFO terminating
2025-03-26 02:26:26,956 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742257_1433, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_
2025-03-26 02:26:26,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,956 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,956 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,956 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742257_1433 src: /172.20.1.10:51418 dest: /172.20.1.12:9866
2025-03-26 02:26:26,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742257_1433 src: /172.20.1.12:37408 dest: /172.20.1.13:9866
2025-03-26 02:26:26,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51418, dest: /172.20.1.12:9866, bytes: 4303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742257_1433, duration(ns): 798853
2025-03-26 02:26:26,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37408, dest: /172.20.1.13:9866, bytes: 4303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742257_1433, duration(ns): 404872
2025-03-26 02:26:26,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742257_1433, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,959 INFO terminating
2025-03-26 02:26:26,960 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,966 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742258_1434, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java._COPYING_
2025-03-26 02:26:26,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,966 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,966 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,966 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742258_1434 src: /172.20.1.10:48390 dest: /172.20.1.13:9866
2025-03-26 02:26:26,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742258_1434 src: /172.20.1.13:33654 dest: /172.20.1.12:9866
2025-03-26 02:26:26,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48390, dest: /172.20.1.13:9866, bytes: 4032, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742258_1434, duration(ns): 831190
2025-03-26 02:26:26,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33654, dest: /172.20.1.12:9866, bytes: 4032, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742258_1434, duration(ns): 417010
2025-03-26 02:26:26,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742258_1434, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,969 INFO terminating
2025-03-26 02:26:26,970 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,974 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,974 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,974 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742259_1435, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java._COPYING_
2025-03-26 02:26:26,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742259_1435 src: /172.20.1.10:51432 dest: /172.20.1.12:9866
2025-03-26 02:26:26,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742259_1435 src: /172.20.1.12:37412 dest: /172.20.1.13:9866
2025-03-26 02:26:26,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37412, dest: /172.20.1.13:9866, bytes: 3436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742259_1435, duration(ns): 319956
2025-03-26 02:26:26,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742259_1435, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51432, dest: /172.20.1.12:9866, bytes: 3436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742259_1435, duration(ns): 490792
2025-03-26 02:26:26,978 INFO terminating
2025-03-26 02:26:26,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742260_1436, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java._COPYING_
2025-03-26 02:26:26,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,981 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,981 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,981 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742260_1436 src: /172.20.1.10:48402 dest: /172.20.1.13:9866
2025-03-26 02:26:26,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33662, dest: /172.20.1.12:9866, bytes: 2411, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742260_1436, duration(ns): 284859
2025-03-26 02:26:26,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742260_1436, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742260_1436 src: /172.20.1.13:33662 dest: /172.20.1.12:9866
2025-03-26 02:26:26,984 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48402, dest: /172.20.1.13:9866, bytes: 2411, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742260_1436, duration(ns): 455052
2025-03-26 02:26:26,984 INFO terminating
2025-03-26 02:26:26,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742261_1437, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_
2025-03-26 02:26:26,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,987 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,987 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,987 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742261_1437 src: /172.20.1.10:48412 dest: /172.20.1.13:9866
2025-03-26 02:26:26,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33678, dest: /172.20.1.12:9866, bytes: 3708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742261_1437, duration(ns): 273688
2025-03-26 02:26:26,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742261_1437, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742261_1437 src: /172.20.1.13:33678 dest: /172.20.1.12:9866
2025-03-26 02:26:26,990 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48412, dest: /172.20.1.13:9866, bytes: 3708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742261_1437, duration(ns): 459308
2025-03-26 02:26:26,990 INFO terminating
2025-03-26 02:26:26,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742262_1438, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java._COPYING_
2025-03-26 02:26:26,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:26,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:26,993 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:26,993 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:26,993 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:26,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742262_1438 src: /172.20.1.10:51438 dest: /172.20.1.12:9866
2025-03-26 02:26:26,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742262_1438 src: /172.20.1.12:37422 dest: /172.20.1.13:9866
2025-03-26 02:26:26,996 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:26,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51438, dest: /172.20.1.12:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742262_1438, duration(ns): 744895
2025-03-26 02:26:26,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:37422, dest: /172.20.1.13:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742262_1438, duration(ns): 283444
2025-03-26 02:26:26,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742262_1438, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:26,996 INFO terminating
2025-03-26 02:26:27,000 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742263_1439, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_
2025-03-26 02:26:27,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,000 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,000 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,000 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742263_1439 src: /172.20.1.10:48420 dest: /172.20.1.13:9866
2025-03-26 02:26:27,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742263_1439 src: /172.20.1.13:33680 dest: /172.20.1.12:9866
2025-03-26 02:26:27,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48420, dest: /172.20.1.13:9866, bytes: 3387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742263_1439, duration(ns): 690125
2025-03-26 02:26:27,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:33680, dest: /172.20.1.12:9866, bytes: 3387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742263_1439, duration(ns): 417041
2025-03-26 02:26:27,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742263_1439, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742263_1439 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_
2025-03-26 02:26:27,009 INFO terminating
2025-03-26 02:26:27,410 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742264_1440, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_
2025-03-26 02:26:27,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,414 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,414 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,414 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742264_1440 src: /172.20.1.10:50382 dest: /172.20.1.12:9866
2025-03-26 02:26:27,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742264_1440 src: /172.20.1.12:59266 dest: /172.20.1.13:9866
2025-03-26 02:26:27,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50382, dest: /172.20.1.12:9866, bytes: 3631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742264_1440, duration(ns): 748595
2025-03-26 02:26:27,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59266, dest: /172.20.1.13:9866, bytes: 3631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742264_1440, duration(ns): 650392
2025-03-26 02:26:27,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742264_1440, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,417 INFO terminating
2025-03-26 02:26:27,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,421 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742265_1441, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java._COPYING_
2025-03-26 02:26:27,421 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,421 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,421 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,421 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,421 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,421 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742265_1441 src: /172.20.1.10:50394 dest: /172.20.1.12:9866
2025-03-26 02:26:27,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742265_1441 src: /172.20.1.12:59280 dest: /172.20.1.13:9866
2025-03-26 02:26:27,424 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50394, dest: /172.20.1.12:9866, bytes: 3580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742265_1441, duration(ns): 759064
2025-03-26 02:26:27,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59280, dest: /172.20.1.13:9866, bytes: 3580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742265_1441, duration(ns): 569677
2025-03-26 02:26:27,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742265_1441, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,424 INFO terminating
2025-03-26 02:26:27,427 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742266_1442, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java._COPYING_
2025-03-26 02:26:27,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,427 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,427 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,427 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742266_1442 src: /172.20.1.10:50408 dest: /172.20.1.12:9866
2025-03-26 02:26:27,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742266_1442 src: /172.20.1.12:59286 dest: /172.20.1.13:9866
2025-03-26 02:26:27,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59286, dest: /172.20.1.13:9866, bytes: 3223, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742266_1442, duration(ns): 511741
2025-03-26 02:26:27,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742266_1442, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,433 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50408, dest: /172.20.1.12:9866, bytes: 3223, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742266_1442, duration(ns): 648798
2025-03-26 02:26:27,433 INFO terminating
2025-03-26 02:26:27,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742267_1443, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java._COPYING_
2025-03-26 02:26:27,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,436 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,436 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,436 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742267_1443 src: /172.20.1.10:50412 dest: /172.20.1.12:9866
2025-03-26 02:26:27,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742267_1443 src: /172.20.1.12:59292 dest: /172.20.1.13:9866
2025-03-26 02:26:27,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59292, dest: /172.20.1.13:9866, bytes: 2239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742267_1443, duration(ns): 431221
2025-03-26 02:26:27,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742267_1443, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50412, dest: /172.20.1.12:9866, bytes: 2239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742267_1443, duration(ns): 1112380
2025-03-26 02:26:27,440 INFO terminating
2025-03-26 02:26:27,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742268_1444, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java._COPYING_
2025-03-26 02:26:27,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,443 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742268_1444 src: /172.20.1.10:50420 dest: /172.20.1.12:9866
2025-03-26 02:26:27,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742268_1444 src: /172.20.1.12:59308 dest: /172.20.1.13:9866
2025-03-26 02:26:27,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50420, dest: /172.20.1.12:9866, bytes: 2778, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742268_1444, duration(ns): 550483
2025-03-26 02:26:27,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59308, dest: /172.20.1.13:9866, bytes: 2778, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742268_1444, duration(ns): 336720
2025-03-26 02:26:27,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742268_1444, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,446 INFO terminating
2025-03-26 02:26:27,447 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,450 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742269_1445, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_
2025-03-26 02:26:27,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,450 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,450 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,450 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742269_1445 src: /172.20.1.10:33916 dest: /172.20.1.13:9866
2025-03-26 02:26:27,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49782, dest: /172.20.1.12:9866, bytes: 2602, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742269_1445, duration(ns): 368193
2025-03-26 02:26:27,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742269_1445, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742269_1445 src: /172.20.1.13:49782 dest: /172.20.1.12:9866
2025-03-26 02:26:27,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:33916, dest: /172.20.1.13:9866, bytes: 2602, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742269_1445, duration(ns): 493872
2025-03-26 02:26:27,453 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742269_1445 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_
2025-03-26 02:26:27,453 INFO terminating
2025-03-26 02:26:27,853 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742270_1446, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 02:26:27,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:27,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,857 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,857 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,857 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742270_1446 src: /172.20.1.10:50432 dest: /172.20.1.12:9866
2025-03-26 02:26:27,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742270_1446 src: /172.20.1.12:59316 dest: /172.20.1.13:9866
2025-03-26 02:26:27,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50432, dest: /172.20.1.12:9866, bytes: 3240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742270_1446, duration(ns): 806368
2025-03-26 02:26:27,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59316, dest: /172.20.1.13:9866, bytes: 3240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742270_1446, duration(ns): 657559
2025-03-26 02:26:27,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742270_1446, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,860 INFO terminating
2025-03-26 02:26:27,861 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742271_1447, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java._COPYING_
2025-03-26 02:26:27,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,865 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,865 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,865 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742271_1447 src: /172.20.1.10:50448 dest: /172.20.1.12:9866
2025-03-26 02:26:27,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742271_1447 src: /172.20.1.12:59322 dest: /172.20.1.13:9866
2025-03-26 02:26:27,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50448, dest: /172.20.1.12:9866, bytes: 3102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742271_1447, duration(ns): 998447
2025-03-26 02:26:27,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59322, dest: /172.20.1.13:9866, bytes: 3102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742271_1447, duration(ns): 628131
2025-03-26 02:26:27,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742271_1447, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,868 INFO terminating
2025-03-26 02:26:27,869 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,872 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742272_1448, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java._COPYING_
2025-03-26 02:26:27,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:27,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,872 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,872 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,872 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742272_1448 src: /172.20.1.10:33918 dest: /172.20.1.13:9866
2025-03-26 02:26:27,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742272_1448 src: /172.20.1.13:49796 dest: /172.20.1.12:9866
2025-03-26 02:26:27,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:33918, dest: /172.20.1.13:9866, bytes: 3773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742272_1448, duration(ns): 700280
2025-03-26 02:26:27,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49796, dest: /172.20.1.12:9866, bytes: 3773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742272_1448, duration(ns): 565188
2025-03-26 02:26:27,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742272_1448, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,877 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,877 INFO terminating
2025-03-26 02:26:27,880 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742273_1449, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java._COPYING_
2025-03-26 02:26:27,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,880 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,880 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,880 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742273_1449 src: /172.20.1.10:33932 dest: /172.20.1.13:9866
2025-03-26 02:26:27,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742273_1449 src: /172.20.1.13:49798 dest: /172.20.1.12:9866
2025-03-26 02:26:27,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49798, dest: /172.20.1.12:9866, bytes: 2761, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742273_1449, duration(ns): 561614
2025-03-26 02:26:27,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742273_1449, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,884 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:33932, dest: /172.20.1.13:9866, bytes: 2761, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742273_1449, duration(ns): 1041302
2025-03-26 02:26:27,884 INFO terminating
2025-03-26 02:26:27,887 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742274_1450, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java._COPYING_
2025-03-26 02:26:27,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,887 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,887 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,887 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742274_1450 src: /172.20.1.10:50456 dest: /172.20.1.12:9866
2025-03-26 02:26:27,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742274_1450 src: /172.20.1.12:59330 dest: /172.20.1.13:9866
2025-03-26 02:26:27,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59330, dest: /172.20.1.13:9866, bytes: 2415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742274_1450, duration(ns): 4630414
2025-03-26 02:26:27,895 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50456, dest: /172.20.1.12:9866, bytes: 2415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742274_1450, duration(ns): 4761826
2025-03-26 02:26:27,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742274_1450, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,895 INFO terminating
2025-03-26 02:26:27,904 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742275_1451, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java._COPYING_
2025-03-26 02:26:27,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,904 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,904 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,904 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742275_1451 src: /172.20.1.10:50472 dest: /172.20.1.12:9866
2025-03-26 02:26:27,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742275_1451 src: /172.20.1.12:59338 dest: /172.20.1.13:9866
2025-03-26 02:26:27,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59338, dest: /172.20.1.13:9866, bytes: 1913, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742275_1451, duration(ns): 684074
2025-03-26 02:26:27,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50472, dest: /172.20.1.12:9866, bytes: 1913, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742275_1451, duration(ns): 928371
2025-03-26 02:26:27,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742275_1451, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,911 INFO terminating
2025-03-26 02:26:27,912 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,916 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742276_1452, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java._COPYING_
2025-03-26 02:26:27,916 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,916 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,916 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,916 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,916 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,916 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742276_1452 src: /172.20.1.10:33938 dest: /172.20.1.13:9866
2025-03-26 02:26:27,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742276_1452 src: /172.20.1.13:49808 dest: /172.20.1.12:9866
2025-03-26 02:26:27,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49808, dest: /172.20.1.12:9866, bytes: 3157, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742276_1452, duration(ns): 649768
2025-03-26 02:26:27,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742276_1452, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,921 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:33938, dest: /172.20.1.13:9866, bytes: 3157, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742276_1452, duration(ns): 809738
2025-03-26 02:26:27,921 INFO terminating
2025-03-26 02:26:27,925 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742277_1453, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java._COPYING_
2025-03-26 02:26:27,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,925 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,925 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,925 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742277_1453 src: /172.20.1.10:50482 dest: /172.20.1.12:9866
2025-03-26 02:26:27,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742277_1453 src: /172.20.1.12:59348 dest: /172.20.1.13:9866
2025-03-26 02:26:27,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50482, dest: /172.20.1.12:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742277_1453, duration(ns): 1000803
2025-03-26 02:26:27,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59348, dest: /172.20.1.13:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742277_1453, duration(ns): 564710
2025-03-26 02:26:27,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742277_1453, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,929 INFO terminating
2025-03-26 02:26:27,930 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,934 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742278_1454, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java._COPYING_
2025-03-26 02:26:27,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,934 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,934 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,934 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742278_1454 src: /172.20.1.10:33954 dest: /172.20.1.13:9866
2025-03-26 02:26:27,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742278_1454 src: /172.20.1.13:49816 dest: /172.20.1.12:9866
2025-03-26 02:26:27,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:33954, dest: /172.20.1.13:9866, bytes: 2137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742278_1454, duration(ns): 635574
2025-03-26 02:26:27,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49816, dest: /172.20.1.12:9866, bytes: 2137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742278_1454, duration(ns): 468338
2025-03-26 02:26:27,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742278_1454, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,937 INFO terminating
2025-03-26 02:26:27,938 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742279_1455, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java._COPYING_
2025-03-26 02:26:27,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:27,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,943 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,943 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,943 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742279_1455 src: /172.20.1.10:50484 dest: /172.20.1.12:9866
2025-03-26 02:26:27,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742279_1455 src: /172.20.1.12:59350 dest: /172.20.1.13:9866
2025-03-26 02:26:27,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50484, dest: /172.20.1.12:9866, bytes: 2741, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742279_1455, duration(ns): 564252
2025-03-26 02:26:27,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59350, dest: /172.20.1.13:9866, bytes: 2741, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742279_1455, duration(ns): 366583
2025-03-26 02:26:27,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742279_1455, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,946 INFO terminating
2025-03-26 02:26:27,947 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,951 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742280_1456, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java._COPYING_
2025-03-26 02:26:27,951 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,951 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,951 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,951 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,951 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742280_1456 src: /172.20.1.10:50496 dest: /172.20.1.12:9866
2025-03-26 02:26:27,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742280_1456 src: /172.20.1.12:59356 dest: /172.20.1.13:9866
2025-03-26 02:26:27,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59356, dest: /172.20.1.13:9866, bytes: 2802, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742280_1456, duration(ns): 540577
2025-03-26 02:26:27,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742280_1456, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50496, dest: /172.20.1.12:9866, bytes: 2802, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742280_1456, duration(ns): 735439
2025-03-26 02:26:27,956 INFO terminating
2025-03-26 02:26:27,957 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742281_1457, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_
2025-03-26 02:26:27,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,960 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,960 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,960 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742281_1457 src: /172.20.1.10:33966 dest: /172.20.1.13:9866
2025-03-26 02:26:27,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742281_1457 src: /172.20.1.13:49820 dest: /172.20.1.12:9866
2025-03-26 02:26:27,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49820, dest: /172.20.1.12:9866, bytes: 2715, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742281_1457, duration(ns): 565098
2025-03-26 02:26:27,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742281_1457, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,964 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:33966, dest: /172.20.1.13:9866, bytes: 2715, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742281_1457, duration(ns): 781147
2025-03-26 02:26:27,964 INFO terminating
2025-03-26 02:26:27,967 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742282_1458, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java._COPYING_
2025-03-26 02:26:27,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:27,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,967 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,967 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,967 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742282_1458 src: /172.20.1.10:33980 dest: /172.20.1.13:9866
2025-03-26 02:26:27,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742282_1458 src: /172.20.1.13:49822 dest: /172.20.1.12:9866
2025-03-26 02:26:27,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:33980, dest: /172.20.1.13:9866, bytes: 2899, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742282_1458, duration(ns): 600648
2025-03-26 02:26:27,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49822, dest: /172.20.1.12:9866, bytes: 2899, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742282_1458, duration(ns): 356946
2025-03-26 02:26:27,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742282_1458, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,971 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,971 INFO terminating
2025-03-26 02:26:27,974 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742283_1459, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java._COPYING_
2025-03-26 02:26:27,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,974 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,974 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,974 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742283_1459 src: /172.20.1.10:50504 dest: /172.20.1.12:9866
2025-03-26 02:26:27,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742283_1459 src: /172.20.1.12:59362 dest: /172.20.1.13:9866
2025-03-26 02:26:27,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59362, dest: /172.20.1.13:9866, bytes: 2085, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742283_1459, duration(ns): 416330
2025-03-26 02:26:27,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742283_1459, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50504, dest: /172.20.1.12:9866, bytes: 2085, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742283_1459, duration(ns): 459696
2025-03-26 02:26:27,978 INFO terminating
2025-03-26 02:26:27,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742284_1460, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java._COPYING_
2025-03-26 02:26:27,983 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,983 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,983 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,983 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,983 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,983 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742284_1460 src: /172.20.1.10:50518 dest: /172.20.1.12:9866
2025-03-26 02:26:27,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742284_1460 src: /172.20.1.12:59364 dest: /172.20.1.13:9866
2025-03-26 02:26:27,987 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:27,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50518, dest: /172.20.1.12:9866, bytes: 3180, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742284_1460, duration(ns): 536663
2025-03-26 02:26:27,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59364, dest: /172.20.1.13:9866, bytes: 3180, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742284_1460, duration(ns): 492641
2025-03-26 02:26:27,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742284_1460, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,987 INFO terminating
2025-03-26 02:26:27,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742285_1461, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java._COPYING_
2025-03-26 02:26:27,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:27,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:27,991 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:27,991 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:27,991 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:27,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742285_1461 src: /172.20.1.10:33996 dest: /172.20.1.13:9866
2025-03-26 02:26:27,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742285_1461 src: /172.20.1.13:49826 dest: /172.20.1.12:9866
2025-03-26 02:26:27,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49826, dest: /172.20.1.12:9866, bytes: 2623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742285_1461, duration(ns): 339254
2025-03-26 02:26:27,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742285_1461, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:27,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:33996, dest: /172.20.1.13:9866, bytes: 2623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742285_1461, duration(ns): 526533
2025-03-26 02:26:27,994 INFO terminating
2025-03-26 02:26:27,995 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,002 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,002 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,002 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,003 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742286_1462, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java._COPYING_
2025-03-26 02:26:28,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742286_1462 src: /172.20.1.10:34000 dest: /172.20.1.13:9866
2025-03-26 02:26:28,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742286_1462 src: /172.20.1.13:49830 dest: /172.20.1.12:9866
2025-03-26 02:26:28,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49830, dest: /172.20.1.12:9866, bytes: 3973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742286_1462, duration(ns): 563676
2025-03-26 02:26:28,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742286_1462, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,007 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34000, dest: /172.20.1.13:9866, bytes: 3973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742286_1462, duration(ns): 757249
2025-03-26 02:26:28,007 INFO terminating
2025-03-26 02:26:28,011 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742287_1463, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java._COPYING_
2025-03-26 02:26:28,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:28,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,011 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,011 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,011 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742287_1463 src: /172.20.1.10:34002 dest: /172.20.1.13:9866
2025-03-26 02:26:28,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742287_1463 src: /172.20.1.13:49840 dest: /172.20.1.12:9866
2025-03-26 02:26:28,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34002, dest: /172.20.1.13:9866, bytes: 3265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742287_1463, duration(ns): 629716
2025-03-26 02:26:28,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49840, dest: /172.20.1.12:9866, bytes: 3265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742287_1463, duration(ns): 589777
2025-03-26 02:26:28,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742287_1463, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,015 INFO terminating
2025-03-26 02:26:28,016 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:28,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,019 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,019 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,019 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,020 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742288_1464, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java._COPYING_
2025-03-26 02:26:28,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742288_1464 src: /172.20.1.10:50536 dest: /172.20.1.12:9866
2025-03-26 02:26:28,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742288_1464 src: /172.20.1.12:59366 dest: /172.20.1.13:9866
2025-03-26 02:26:28,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59366, dest: /172.20.1.13:9866, bytes: 2238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742288_1464, duration(ns): 3379619
2025-03-26 02:26:28,027 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50536, dest: /172.20.1.12:9866, bytes: 2238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742288_1464, duration(ns): 3523635
2025-03-26 02:26:28,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742288_1464, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,027 INFO terminating
2025-03-26 02:26:28,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742289_1465, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_
2025-03-26 02:26:28,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,030 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,030 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,030 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742289_1465 src: /172.20.1.10:34018 dest: /172.20.1.13:9866
2025-03-26 02:26:28,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742289_1465 src: /172.20.1.13:49850 dest: /172.20.1.12:9866
2025-03-26 02:26:28,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49850, dest: /172.20.1.12:9866, bytes: 2546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742289_1465, duration(ns): 352788
2025-03-26 02:26:28,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742289_1465, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34018, dest: /172.20.1.13:9866, bytes: 2546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742289_1465, duration(ns): 634088
2025-03-26 02:26:28,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742289_1465 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_
2025-03-26 02:26:28,034 INFO terminating
2025-03-26 02:26:28,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742290_1466, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java._COPYING_
2025-03-26 02:26:28,438 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,438 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,438 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,438 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,438 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,438 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742290_1466 src: /172.20.1.10:34030 dest: /172.20.1.13:9866
2025-03-26 02:26:28,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742290_1466 src: /172.20.1.13:49862 dest: /172.20.1.12:9866
2025-03-26 02:26:28,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49862, dest: /172.20.1.12:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742290_1466, duration(ns): 538540
2025-03-26 02:26:28,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742290_1466, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,442 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34030, dest: /172.20.1.13:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742290_1466, duration(ns): 679331
2025-03-26 02:26:28,442 INFO terminating
2025-03-26 02:26:28,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742291_1467, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java._COPYING_
2025-03-26 02:26:28,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:28,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,445 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,445 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,445 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742291_1467 src: /172.20.1.10:50538 dest: /172.20.1.12:9866
2025-03-26 02:26:28,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742291_1467 src: /172.20.1.12:59376 dest: /172.20.1.13:9866
2025-03-26 02:26:28,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59376, dest: /172.20.1.13:9866, bytes: 5729, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742291_1467, duration(ns): 688821
2025-03-26 02:26:28,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742291_1467, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,449 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50538, dest: /172.20.1.12:9866, bytes: 5729, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742291_1467, duration(ns): 712959
2025-03-26 02:26:28,449 INFO terminating
2025-03-26 02:26:28,452 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742292_1468, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java._COPYING_
2025-03-26 02:26:28,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,452 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,452 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,452 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742292_1468 src: /172.20.1.10:50540 dest: /172.20.1.12:9866
2025-03-26 02:26:28,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742292_1468 src: /172.20.1.12:59382 dest: /172.20.1.13:9866
2025-03-26 02:26:28,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50540, dest: /172.20.1.12:9866, bytes: 2123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742292_1468, duration(ns): 794874
2025-03-26 02:26:28,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59382, dest: /172.20.1.13:9866, bytes: 2123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742292_1468, duration(ns): 520698
2025-03-26 02:26:28,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742292_1468, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,455 INFO terminating
2025-03-26 02:26:28,456 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,459 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742293_1469, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java._COPYING_
2025-03-26 02:26:28,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,459 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742293_1469 src: /172.20.1.10:50556 dest: /172.20.1.12:9866
2025-03-26 02:26:28,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742293_1469 src: /172.20.1.12:59384 dest: /172.20.1.13:9866
2025-03-26 02:26:28,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50556, dest: /172.20.1.12:9866, bytes: 3381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742293_1469, duration(ns): 521996
2025-03-26 02:26:28,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59384, dest: /172.20.1.13:9866, bytes: 3381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742293_1469, duration(ns): 332139
2025-03-26 02:26:28,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742293_1469, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,462 INFO terminating
2025-03-26 02:26:28,463 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,468 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742294_1470, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java._COPYING_
2025-03-26 02:26:28,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,468 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,468 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,468 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742294_1470 src: /172.20.1.10:50572 dest: /172.20.1.12:9866
2025-03-26 02:26:28,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742294_1470 src: /172.20.1.12:59390 dest: /172.20.1.13:9866
2025-03-26 02:26:28,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50572, dest: /172.20.1.12:9866, bytes: 1258, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742294_1470, duration(ns): 853611
2025-03-26 02:26:28,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59390, dest: /172.20.1.13:9866, bytes: 1258, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742294_1470, duration(ns): 637339
2025-03-26 02:26:28,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742294_1470, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,472 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,472 INFO terminating
2025-03-26 02:26:28,475 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742295_1471, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java._COPYING_
2025-03-26 02:26:28,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,475 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,475 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,475 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742295_1471 src: /172.20.1.10:34042 dest: /172.20.1.13:9866
2025-03-26 02:26:28,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742295_1471 src: /172.20.1.13:49872 dest: /172.20.1.12:9866
2025-03-26 02:26:28,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34042, dest: /172.20.1.13:9866, bytes: 3202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742295_1471, duration(ns): 527778
2025-03-26 02:26:28,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49872, dest: /172.20.1.12:9866, bytes: 3202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742295_1471, duration(ns): 370519
2025-03-26 02:26:28,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742295_1471, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,478 INFO terminating
2025-03-26 02:26:28,479 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,483 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742296_1472, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_
2025-03-26 02:26:28,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1, NODE_TOO_BUSY=1}
2025-03-26 02:26:28,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,483 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,483 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,483 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742296_1472 src: /172.20.1.10:34048 dest: /172.20.1.13:9866
2025-03-26 02:26:28,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742296_1472 src: /172.20.1.13:49888 dest: /172.20.1.12:9866
2025-03-26 02:26:28,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34048, dest: /172.20.1.13:9866, bytes: 2846, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742296_1472, duration(ns): 815722
2025-03-26 02:26:28,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49888, dest: /172.20.1.12:9866, bytes: 2846, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742296_1472, duration(ns): 449127
2025-03-26 02:26:28,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742296_1472, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,487 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,487 INFO terminating
2025-03-26 02:26:28,490 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742297_1473, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java._COPYING_
2025-03-26 02:26:28,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,490 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,490 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,490 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742297_1473 src: /172.20.1.10:34064 dest: /172.20.1.13:9866
2025-03-26 02:26:28,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49890, dest: /172.20.1.12:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742297_1473, duration(ns): 482738
2025-03-26 02:26:28,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742297_1473 src: /172.20.1.13:49890 dest: /172.20.1.12:9866
2025-03-26 02:26:28,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34064, dest: /172.20.1.13:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742297_1473, duration(ns): 638677
2025-03-26 02:26:28,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742297_1473, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,493 INFO terminating
2025-03-26 02:26:28,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,496 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,496 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,496 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742298_1474, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java._COPYING_
2025-03-26 02:26:28,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742298_1474 src: /172.20.1.10:34080 dest: /172.20.1.13:9866
2025-03-26 02:26:28,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742298_1474 src: /172.20.1.13:49906 dest: /172.20.1.12:9866
2025-03-26 02:26:28,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49906, dest: /172.20.1.12:9866, bytes: 3553, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742298_1474, duration(ns): 470537
2025-03-26 02:26:28,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742298_1474, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,500 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34080, dest: /172.20.1.13:9866, bytes: 3553, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742298_1474, duration(ns): 668984
2025-03-26 02:26:28,500 INFO terminating
2025-03-26 02:26:28,503 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742299_1475, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java._COPYING_
2025-03-26 02:26:28,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,503 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,503 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,503 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742299_1475 src: /172.20.1.10:34092 dest: /172.20.1.13:9866
2025-03-26 02:26:28,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742299_1475 src: /172.20.1.13:49918 dest: /172.20.1.12:9866
2025-03-26 02:26:28,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34092, dest: /172.20.1.13:9866, bytes: 2506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742299_1475, duration(ns): 876152
2025-03-26 02:26:28,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49918, dest: /172.20.1.12:9866, bytes: 2506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742299_1475, duration(ns): 328740
2025-03-26 02:26:28,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742299_1475, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,506 INFO terminating
2025-03-26 02:26:28,507 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742300_1476, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_
2025-03-26 02:26:28,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,510 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:26:28,510 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:26:28,510 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:26:28,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742300_1476 src: /172.20.1.10:50580 dest: /172.20.1.12:9866
2025-03-26 02:26:28,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742300_1476 src: /172.20.1.12:59398 dest: /172.20.1.13:9866
2025-03-26 02:26:28,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50580, dest: /172.20.1.12:9866, bytes: 5226, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742300_1476, duration(ns): 644589
2025-03-26 02:26:28,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59398, dest: /172.20.1.13:9866, bytes: 5226, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742300_1476, duration(ns): 369725
2025-03-26 02:26:28,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742300_1476, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742300_1476 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_
2025-03-26 02:26:28,513 INFO terminating
2025-03-26 02:26:28,915 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742301_1477, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java._COPYING_
2025-03-26 02:26:28,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742301_1477 src: /172.20.1.10:34098 dest: /172.20.1.13:9866
2025-03-26 02:26:28,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742301_1477 src: /172.20.1.13:53510 dest: /172.20.1.11:9866
2025-03-26 02:26:28,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742301_1477 src: /172.20.1.11:44942 dest: /172.20.1.12:9866
2025-03-26 02:26:28,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44942, dest: /172.20.1.12:9866, bytes: 2612, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742301_1477, duration(ns): 3549982
2025-03-26 02:26:28,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742301_1477, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53510, dest: /172.20.1.11:9866, bytes: 2612, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742301_1477, duration(ns): 4304407
2025-03-26 02:26:28,932 INFO terminating
2025-03-26 02:26:28,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34098, dest: /172.20.1.13:9866, bytes: 2612, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742301_1477, duration(ns): 5222422
2025-03-26 02:26:28,933 INFO terminating
2025-03-26 02:26:28,934 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742302_1478, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java._COPYING_
2025-03-26 02:26:28,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742302_1478 src: /172.20.1.10:50590 dest: /172.20.1.12:9866
2025-03-26 02:26:28,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742302_1478 src: /172.20.1.12:49760 dest: /172.20.1.11:9866
2025-03-26 02:26:28,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742302_1478 src: /172.20.1.11:49796 dest: /172.20.1.13:9866
2025-03-26 02:26:28,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49796, dest: /172.20.1.13:9866, bytes: 4317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742302_1478, duration(ns): 3361682
2025-03-26 02:26:28,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742302_1478, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49760, dest: /172.20.1.11:9866, bytes: 4317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742302_1478, duration(ns): 3869360
2025-03-26 02:26:28,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50590, dest: /172.20.1.12:9866, bytes: 4317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742302_1478, duration(ns): 5803961
2025-03-26 02:26:28,956 INFO terminating
2025-03-26 02:26:28,957 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,957 INFO terminating
2025-03-26 02:26:28,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742303_1479, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java._COPYING_
2025-03-26 02:26:28,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742303_1479 src: /172.20.1.10:34110 dest: /172.20.1.13:9866
2025-03-26 02:26:28,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742303_1479 src: /172.20.1.13:53520 dest: /172.20.1.11:9866
2025-03-26 02:26:28,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742303_1479 src: /172.20.1.11:44956 dest: /172.20.1.12:9866
2025-03-26 02:26:28,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44956, dest: /172.20.1.12:9866, bytes: 3304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742303_1479, duration(ns): 1362016
2025-03-26 02:26:28,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53520, dest: /172.20.1.11:9866, bytes: 3304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742303_1479, duration(ns): 1556976
2025-03-26 02:26:28,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742303_1479, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,975 INFO terminating
2025-03-26 02:26:28,976 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34110, dest: /172.20.1.13:9866, bytes: 3304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742303_1479, duration(ns): 2066261
2025-03-26 02:26:28,976 INFO terminating
2025-03-26 02:26:28,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742304_1480, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java._COPYING_
2025-03-26 02:26:28,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742304_1480 src: /172.20.1.10:50598 dest: /172.20.1.12:9866
2025-03-26 02:26:28,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742304_1480 src: /172.20.1.12:59410 dest: /172.20.1.13:9866
2025-03-26 02:26:28,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742304_1480 src: /172.20.1.13:53536 dest: /172.20.1.11:9866
2025-03-26 02:26:28,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53536, dest: /172.20.1.11:9866, bytes: 2450, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742304_1480, duration(ns): 1017030
2025-03-26 02:26:28,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742304_1480, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:28,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59410, dest: /172.20.1.13:9866, bytes: 2450, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742304_1480, duration(ns): 6051912
2025-03-26 02:26:28,991 INFO terminating
2025-03-26 02:26:28,993 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:28,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50598, dest: /172.20.1.12:9866, bytes: 2450, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742304_1480, duration(ns): 6353708
2025-03-26 02:26:28,993 INFO terminating
2025-03-26 02:26:28,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:28,999 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742305_1481, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java._COPYING_
2025-03-26 02:26:29,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742305_1481 src: /172.20.1.10:35364 dest: /172.20.1.11:9866
2025-03-26 02:26:29,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742305_1481 src: /172.20.1.11:44964 dest: /172.20.1.12:9866
2025-03-26 02:26:29,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742305_1481 src: /172.20.1.12:59420 dest: /172.20.1.13:9866
2025-03-26 02:26:29,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59420, dest: /172.20.1.13:9866, bytes: 2467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742305_1481, duration(ns): 789467
2025-03-26 02:26:29,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35364, dest: /172.20.1.11:9866, bytes: 2467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742305_1481, duration(ns): 1040676
2025-03-26 02:26:29,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44964, dest: /172.20.1.12:9866, bytes: 2467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742305_1481, duration(ns): 985885
2025-03-26 02:26:29,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742305_1481, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,003 INFO terminating
2025-03-26 02:26:29,004 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,004 INFO terminating
2025-03-26 02:26:29,007 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742306_1482, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java._COPYING_
2025-03-26 02:26:29,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742306_1482 src: /172.20.1.10:35368 dest: /172.20.1.11:9866
2025-03-26 02:26:29,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742306_1482 src: /172.20.1.11:49806 dest: /172.20.1.13:9866
2025-03-26 02:26:29,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742306_1482 src: /172.20.1.13:49928 dest: /172.20.1.12:9866
2025-03-26 02:26:29,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49806, dest: /172.20.1.13:9866, bytes: 3122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742306_1482, duration(ns): 1273790
2025-03-26 02:26:29,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49928, dest: /172.20.1.12:9866, bytes: 3122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742306_1482, duration(ns): 1050638
2025-03-26 02:26:29,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742306_1482, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,012 INFO terminating
2025-03-26 02:26:29,013 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35368, dest: /172.20.1.11:9866, bytes: 3122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742306_1482, duration(ns): 1409166
2025-03-26 02:26:29,013 INFO terminating
2025-03-26 02:26:29,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742307_1483, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java._COPYING_
2025-03-26 02:26:29,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742307_1483 src: /172.20.1.10:34112 dest: /172.20.1.13:9866
2025-03-26 02:26:29,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742307_1483 src: /172.20.1.13:53538 dest: /172.20.1.11:9866
2025-03-26 02:26:29,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742307_1483 src: /172.20.1.11:44966 dest: /172.20.1.12:9866
2025-03-26 02:26:29,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44966, dest: /172.20.1.12:9866, bytes: 2851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742307_1483, duration(ns): 2957279
2025-03-26 02:26:29,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742307_1483, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34112, dest: /172.20.1.13:9866, bytes: 2851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742307_1483, duration(ns): 3379407
2025-03-26 02:26:29,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53538, dest: /172.20.1.11:9866, bytes: 2851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742307_1483, duration(ns): 3155444
2025-03-26 02:26:29,023 INFO terminating
2025-03-26 02:26:29,023 INFO terminating
2025-03-26 02:26:29,026 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742308_1484, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java._COPYING_
2025-03-26 02:26:29,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742308_1484 src: /172.20.1.10:50600 dest: /172.20.1.12:9866
2025-03-26 02:26:29,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742308_1484 src: /172.20.1.12:59430 dest: /172.20.1.13:9866
2025-03-26 02:26:29,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742308_1484 src: /172.20.1.13:53540 dest: /172.20.1.11:9866
2025-03-26 02:26:29,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50600, dest: /172.20.1.12:9866, bytes: 2349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742308_1484, duration(ns): 1442418
2025-03-26 02:26:29,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59430, dest: /172.20.1.13:9866, bytes: 2349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742308_1484, duration(ns): 1243205
2025-03-26 02:26:29,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53540, dest: /172.20.1.11:9866, bytes: 2349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742308_1484, duration(ns): 1081616
2025-03-26 02:26:29,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742308_1484, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,041 INFO terminating
2025-03-26 02:26:29,041 INFO terminating
2025-03-26 02:26:29,042 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,049 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742309_1485, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java._COPYING_
2025-03-26 02:26:29,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742309_1485 src: /172.20.1.10:50604 dest: /172.20.1.12:9866
2025-03-26 02:26:29,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742309_1485 src: /172.20.1.12:59436 dest: /172.20.1.13:9866
2025-03-26 02:26:29,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742309_1485 src: /172.20.1.13:53552 dest: /172.20.1.11:9866
2025-03-26 02:26:29,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53552, dest: /172.20.1.11:9866, bytes: 2213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742309_1485, duration(ns): 888481
2025-03-26 02:26:29,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742309_1485, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50604, dest: /172.20.1.12:9866, bytes: 2213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742309_1485, duration(ns): 1854843
2025-03-26 02:26:29,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59436, dest: /172.20.1.13:9866, bytes: 2213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742309_1485, duration(ns): 1275864
2025-03-26 02:26:29,054 INFO terminating
2025-03-26 02:26:29,054 INFO terminating
2025-03-26 02:26:29,057 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742310_1486, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java._COPYING_
2025-03-26 02:26:29,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742310_1486 src: /172.20.1.10:35372 dest: /172.20.1.11:9866
2025-03-26 02:26:29,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742310_1486 src: /172.20.1.11:49816 dest: /172.20.1.13:9866
2025-03-26 02:26:29,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742310_1486 src: /172.20.1.13:49934 dest: /172.20.1.12:9866
2025-03-26 02:26:29,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35372, dest: /172.20.1.11:9866, bytes: 4024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742310_1486, duration(ns): 1615833
2025-03-26 02:26:29,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49816, dest: /172.20.1.13:9866, bytes: 4024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742310_1486, duration(ns): 1391715
2025-03-26 02:26:29,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49934, dest: /172.20.1.12:9866, bytes: 4024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742310_1486, duration(ns): 921884
2025-03-26 02:26:29,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742310_1486, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,065 INFO terminating
2025-03-26 02:26:29,065 INFO terminating
2025-03-26 02:26:29,066 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742311_1487, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java._COPYING_
2025-03-26 02:26:29,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742311_1487 src: /172.20.1.10:50616 dest: /172.20.1.12:9866
2025-03-26 02:26:29,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742311_1487 src: /172.20.1.12:59450 dest: /172.20.1.13:9866
2025-03-26 02:26:29,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742311_1487 src: /172.20.1.13:53564 dest: /172.20.1.11:9866
2025-03-26 02:26:29,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53564, dest: /172.20.1.11:9866, bytes: 2548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742311_1487, duration(ns): 686482
2025-03-26 02:26:29,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742311_1487, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50616, dest: /172.20.1.12:9866, bytes: 2548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742311_1487, duration(ns): 1195741
2025-03-26 02:26:29,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59450, dest: /172.20.1.13:9866, bytes: 2548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742311_1487, duration(ns): 938139
2025-03-26 02:26:29,074 INFO terminating
2025-03-26 02:26:29,074 INFO terminating
2025-03-26 02:26:29,075 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742312_1488, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_
2025-03-26 02:26:29,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742312_1488 src: /172.20.1.10:34116 dest: /172.20.1.13:9866
2025-03-26 02:26:29,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742312_1488 src: /172.20.1.12:49768 dest: /172.20.1.11:9866
2025-03-26 02:26:29,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742312_1488 src: /172.20.1.13:49938 dest: /172.20.1.12:9866
2025-03-26 02:26:29,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49768, dest: /172.20.1.11:9866, bytes: 3273, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742312_1488, duration(ns): 1294898
2025-03-26 02:26:29,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34116, dest: /172.20.1.13:9866, bytes: 3273, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742312_1488, duration(ns): 2310333
2025-03-26 02:26:29,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49938, dest: /172.20.1.12:9866, bytes: 3273, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742312_1488, duration(ns): 1996958
2025-03-26 02:26:29,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742312_1488, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,085 INFO terminating
2025-03-26 02:26:29,085 INFO terminating
2025-03-26 02:26:29,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,090 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742313_1489, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java._COPYING_
2025-03-26 02:26:29,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742313_1489 src: /172.20.1.10:35374 dest: /172.20.1.11:9866
2025-03-26 02:26:29,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742313_1489 src: /172.20.1.11:44982 dest: /172.20.1.12:9866
2025-03-26 02:26:29,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742313_1489 src: /172.20.1.12:59458 dest: /172.20.1.13:9866
2025-03-26 02:26:29,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44982, dest: /172.20.1.12:9866, bytes: 2758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742313_1489, duration(ns): 882412
2025-03-26 02:26:29,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59458, dest: /172.20.1.13:9866, bytes: 2758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742313_1489, duration(ns): 581505
2025-03-26 02:26:29,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742313_1489, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,094 INFO terminating
2025-03-26 02:26:29,095 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35374, dest: /172.20.1.11:9866, bytes: 2758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742313_1489, duration(ns): 1147581
2025-03-26 02:26:29,095 INFO terminating
2025-03-26 02:26:29,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742314_1490, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java._COPYING_
2025-03-26 02:26:29,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742314_1490 src: /172.20.1.10:34120 dest: /172.20.1.13:9866
2025-03-26 02:26:29,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742314_1490 src: /172.20.1.13:53576 dest: /172.20.1.11:9866
2025-03-26 02:26:29,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742314_1490 src: /172.20.1.11:44990 dest: /172.20.1.12:9866
2025-03-26 02:26:29,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44990, dest: /172.20.1.12:9866, bytes: 4577, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742314_1490, duration(ns): 919512
2025-03-26 02:26:29,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742314_1490, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34120, dest: /172.20.1.13:9866, bytes: 4577, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742314_1490, duration(ns): 1409834
2025-03-26 02:26:29,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53576, dest: /172.20.1.11:9866, bytes: 4577, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742314_1490, duration(ns): 1063108
2025-03-26 02:26:29,104 INFO terminating
2025-03-26 02:26:29,105 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,106 INFO terminating
2025-03-26 02:26:29,108 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742315_1491, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java._COPYING_
2025-03-26 02:26:29,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742315_1491 src: /172.20.1.10:35390 dest: /172.20.1.11:9866
2025-03-26 02:26:29,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742315_1491 src: /172.20.1.11:44992 dest: /172.20.1.12:9866
2025-03-26 02:26:29,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742315_1491 src: /172.20.1.12:59460 dest: /172.20.1.13:9866
2025-03-26 02:26:29,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:44992, dest: /172.20.1.12:9866, bytes: 1827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742315_1491, duration(ns): 814746
2025-03-26 02:26:29,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59460, dest: /172.20.1.13:9866, bytes: 1827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742315_1491, duration(ns): 611569
2025-03-26 02:26:29,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742315_1491, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,113 INFO terminating
2025-03-26 02:26:29,114 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35390, dest: /172.20.1.11:9866, bytes: 1827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742315_1491, duration(ns): 963293
2025-03-26 02:26:29,114 INFO terminating
2025-03-26 02:26:29,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742316_1492, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_
2025-03-26 02:26:29,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742316_1492 src: /172.20.1.10:35392 dest: /172.20.1.11:9866
2025-03-26 02:26:29,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742316_1492 src: /172.20.1.11:49828 dest: /172.20.1.13:9866
2025-03-26 02:26:29,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742316_1492 src: /172.20.1.13:49942 dest: /172.20.1.12:9866
2025-03-26 02:26:29,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49828, dest: /172.20.1.13:9866, bytes: 2627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742316_1492, duration(ns): 952843
2025-03-26 02:26:29,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49942, dest: /172.20.1.12:9866, bytes: 2627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742316_1492, duration(ns): 814659
2025-03-26 02:26:29,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742316_1492, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,124 INFO terminating
2025-03-26 02:26:29,125 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35392, dest: /172.20.1.11:9866, bytes: 2627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742316_1492, duration(ns): 1137030
2025-03-26 02:26:29,125 INFO terminating
2025-03-26 02:26:29,128 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742317_1493, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java._COPYING_
2025-03-26 02:26:29,128 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,128 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742317_1493 src: /172.20.1.10:50622 dest: /172.20.1.12:9866
2025-03-26 02:26:29,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742317_1493 src: /172.20.1.11:49842 dest: /172.20.1.13:9866
2025-03-26 02:26:29,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742317_1493 src: /172.20.1.12:49780 dest: /172.20.1.11:9866
2025-03-26 02:26:29,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49842, dest: /172.20.1.13:9866, bytes: 4114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742317_1493, duration(ns): 475194
2025-03-26 02:26:29,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742317_1493, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50622, dest: /172.20.1.12:9866, bytes: 4114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742317_1493, duration(ns): 966205
2025-03-26 02:26:29,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49780, dest: /172.20.1.11:9866, bytes: 4114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742317_1493, duration(ns): 612269
2025-03-26 02:26:29,132 INFO terminating
2025-03-26 02:26:29,132 INFO terminating
2025-03-26 02:26:29,135 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742318_1494, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java._COPYING_
2025-03-26 02:26:29,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742318_1494 src: /172.20.1.10:50638 dest: /172.20.1.12:9866
2025-03-26 02:26:29,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742318_1494 src: /172.20.1.12:59472 dest: /172.20.1.13:9866
2025-03-26 02:26:29,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742318_1494 src: /172.20.1.13:53580 dest: /172.20.1.11:9866
2025-03-26 02:26:29,139 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50638, dest: /172.20.1.12:9866, bytes: 2611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742318_1494, duration(ns): 869722
2025-03-26 02:26:29,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59472, dest: /172.20.1.13:9866, bytes: 2611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742318_1494, duration(ns): 805459
2025-03-26 02:26:29,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53580, dest: /172.20.1.11:9866, bytes: 2611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742318_1494, duration(ns): 585565
2025-03-26 02:26:29,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742318_1494, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,139 INFO terminating
2025-03-26 02:26:29,139 INFO terminating
2025-03-26 02:26:29,142 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742319_1495, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java._COPYING_
2025-03-26 02:26:29,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742319_1495 src: /172.20.1.10:34130 dest: /172.20.1.13:9866
2025-03-26 02:26:29,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742319_1495 src: /172.20.1.13:49952 dest: /172.20.1.12:9866
2025-03-26 02:26:29,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742319_1495 src: /172.20.1.12:49784 dest: /172.20.1.11:9866
2025-03-26 02:26:29,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49784, dest: /172.20.1.11:9866, bytes: 2390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742319_1495, duration(ns): 503301
2025-03-26 02:26:29,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49952, dest: /172.20.1.12:9866, bytes: 2390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742319_1495, duration(ns): 805681
2025-03-26 02:26:29,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742319_1495, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,146 INFO terminating
2025-03-26 02:26:29,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34130, dest: /172.20.1.13:9866, bytes: 2390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742319_1495, duration(ns): 1690676
2025-03-26 02:26:29,147 INFO terminating
2025-03-26 02:26:29,148 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742320_1496, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java._COPYING_
2025-03-26 02:26:29,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742320_1496 src: /172.20.1.10:35402 dest: /172.20.1.11:9866
2025-03-26 02:26:29,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742320_1496 src: /172.20.1.11:45008 dest: /172.20.1.12:9866
2025-03-26 02:26:29,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742320_1496 src: /172.20.1.12:59488 dest: /172.20.1.13:9866
2025-03-26 02:26:29,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59488, dest: /172.20.1.13:9866, bytes: 3047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742320_1496, duration(ns): 734825
2025-03-26 02:26:29,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742320_1496, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35402, dest: /172.20.1.11:9866, bytes: 3047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742320_1496, duration(ns): 1705806
2025-03-26 02:26:29,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45008, dest: /172.20.1.12:9866, bytes: 3047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742320_1496, duration(ns): 965710
2025-03-26 02:26:29,160 INFO terminating
2025-03-26 02:26:29,161 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,161 INFO terminating
2025-03-26 02:26:29,164 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742321_1497, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java._COPYING_
2025-03-26 02:26:29,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742321_1497 src: /172.20.1.10:35408 dest: /172.20.1.11:9866
2025-03-26 02:26:29,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742321_1497 src: /172.20.1.11:45014 dest: /172.20.1.12:9866
2025-03-26 02:26:29,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742321_1497 src: /172.20.1.12:59502 dest: /172.20.1.13:9866
2025-03-26 02:26:29,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59502, dest: /172.20.1.13:9866, bytes: 2317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742321_1497, duration(ns): 792666
2025-03-26 02:26:29,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742321_1497, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35408, dest: /172.20.1.11:9866, bytes: 2317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742321_1497, duration(ns): 1219449
2025-03-26 02:26:29,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45014, dest: /172.20.1.12:9866, bytes: 2317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742321_1497, duration(ns): 1033482
2025-03-26 02:26:29,169 INFO terminating
2025-03-26 02:26:29,169 INFO terminating
2025-03-26 02:26:29,170 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742322_1498, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java._COPYING_
2025-03-26 02:26:29,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742322_1498 src: /172.20.1.10:50642 dest: /172.20.1.12:9866
2025-03-26 02:26:29,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742322_1498 src: /172.20.1.12:59508 dest: /172.20.1.13:9866
2025-03-26 02:26:29,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742322_1498 src: /172.20.1.13:53586 dest: /172.20.1.11:9866
2025-03-26 02:26:29,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50642, dest: /172.20.1.12:9866, bytes: 2861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742322_1498, duration(ns): 956618
2025-03-26 02:26:29,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59508, dest: /172.20.1.13:9866, bytes: 2861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742322_1498, duration(ns): 747053
2025-03-26 02:26:29,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53586, dest: /172.20.1.11:9866, bytes: 2861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742322_1498, duration(ns): 481613
2025-03-26 02:26:29,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742322_1498, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,178 INFO terminating
2025-03-26 02:26:29,178 INFO terminating
2025-03-26 02:26:29,179 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,181 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742323_1499, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java._COPYING_
2025-03-26 02:26:29,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742323_1499 src: /172.20.1.10:50648 dest: /172.20.1.12:9866
2025-03-26 02:26:29,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742323_1499 src: /172.20.1.12:49786 dest: /172.20.1.11:9866
2025-03-26 02:26:29,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742323_1499 src: /172.20.1.11:49850 dest: /172.20.1.13:9866
2025-03-26 02:26:29,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50648, dest: /172.20.1.12:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742323_1499, duration(ns): 1000993
2025-03-26 02:26:29,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49850, dest: /172.20.1.13:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742323_1499, duration(ns): 535795
2025-03-26 02:26:29,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49786, dest: /172.20.1.11:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742323_1499, duration(ns): 642663
2025-03-26 02:26:29,185 INFO terminating
2025-03-26 02:26:29,186 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742323_1499, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,186 INFO terminating
2025-03-26 02:26:29,189 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742324_1500, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java._COPYING_
2025-03-26 02:26:29,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742324_1500 src: /172.20.1.10:50650 dest: /172.20.1.12:9866
2025-03-26 02:26:29,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742324_1500 src: /172.20.1.12:49792 dest: /172.20.1.11:9866
2025-03-26 02:26:29,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742324_1500 src: /172.20.1.11:49862 dest: /172.20.1.13:9866
2025-03-26 02:26:29,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49862, dest: /172.20.1.13:9866, bytes: 3947, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742324_1500, duration(ns): 609549
2025-03-26 02:26:29,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742324_1500, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50650, dest: /172.20.1.12:9866, bytes: 3947, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742324_1500, duration(ns): 1234753
2025-03-26 02:26:29,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49792, dest: /172.20.1.11:9866, bytes: 3947, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742324_1500, duration(ns): 757770
2025-03-26 02:26:29,194 INFO terminating
2025-03-26 02:26:29,194 INFO terminating
2025-03-26 02:26:29,195 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,198 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742325_1501, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 02:26:29,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742325_1501 src: /172.20.1.10:35416 dest: /172.20.1.11:9866
2025-03-26 02:26:29,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742325_1501 src: /172.20.1.11:45020 dest: /172.20.1.12:9866
2025-03-26 02:26:29,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742325_1501 src: /172.20.1.12:59516 dest: /172.20.1.13:9866
2025-03-26 02:26:29,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59516, dest: /172.20.1.13:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742325_1501, duration(ns): 749501
2025-03-26 02:26:29,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742325_1501, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45020, dest: /172.20.1.12:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742325_1501, duration(ns): 1370429
2025-03-26 02:26:29,203 INFO terminating
2025-03-26 02:26:29,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35416, dest: /172.20.1.11:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742325_1501, duration(ns): 1947851
2025-03-26 02:26:29,204 INFO terminating
2025-03-26 02:26:29,205 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742326_1502, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java._COPYING_
2025-03-26 02:26:29,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742326_1502 src: /172.20.1.10:50658 dest: /172.20.1.12:9866
2025-03-26 02:26:29,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742326_1502 src: /172.20.1.12:49794 dest: /172.20.1.11:9866
2025-03-26 02:26:29,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742326_1502 src: /172.20.1.11:49874 dest: /172.20.1.13:9866
2025-03-26 02:26:29,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50658, dest: /172.20.1.12:9866, bytes: 2630, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742326_1502, duration(ns): 1800668
2025-03-26 02:26:29,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49874, dest: /172.20.1.13:9866, bytes: 2630, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742326_1502, duration(ns): 699249
2025-03-26 02:26:29,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49794, dest: /172.20.1.11:9866, bytes: 2630, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742326_1502, duration(ns): 1378176
2025-03-26 02:26:29,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742326_1502, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,214 INFO terminating
2025-03-26 02:26:29,214 INFO terminating
2025-03-26 02:26:29,215 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742327_1503, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java._COPYING_
2025-03-26 02:26:29,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742327_1503 src: /172.20.1.10:50666 dest: /172.20.1.12:9866
2025-03-26 02:26:29,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742327_1503 src: /172.20.1.12:49804 dest: /172.20.1.11:9866
2025-03-26 02:26:29,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742327_1503 src: /172.20.1.11:49878 dest: /172.20.1.13:9866
2025-03-26 02:26:29,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49878, dest: /172.20.1.13:9866, bytes: 2309, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742327_1503, duration(ns): 680450
2025-03-26 02:26:29,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742327_1503, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50666, dest: /172.20.1.12:9866, bytes: 2309, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742327_1503, duration(ns): 1521324
2025-03-26 02:26:29,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49804, dest: /172.20.1.11:9866, bytes: 2309, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742327_1503, duration(ns): 855616
2025-03-26 02:26:29,224 INFO terminating
2025-03-26 02:26:29,224 INFO terminating
2025-03-26 02:26:29,225 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742328_1504, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java._COPYING_
2025-03-26 02:26:29,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742328_1504 src: /172.20.1.10:35432 dest: /172.20.1.11:9866
2025-03-26 02:26:29,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742328_1504 src: /172.20.1.11:49882 dest: /172.20.1.13:9866
2025-03-26 02:26:29,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742328_1504 src: /172.20.1.13:49960 dest: /172.20.1.12:9866
2025-03-26 02:26:29,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49960, dest: /172.20.1.12:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742328_1504, duration(ns): 1018434
2025-03-26 02:26:29,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742328_1504, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35432, dest: /172.20.1.11:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742328_1504, duration(ns): 1486205
2025-03-26 02:26:29,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49882, dest: /172.20.1.13:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742328_1504, duration(ns): 1188373
2025-03-26 02:26:29,238 INFO terminating
2025-03-26 02:26:29,238 INFO terminating
2025-03-26 02:26:29,239 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,243 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742329_1505, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java._COPYING_
2025-03-26 02:26:29,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742329_1505 src: /172.20.1.10:50682 dest: /172.20.1.12:9866
2025-03-26 02:26:29,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742329_1505 src: /172.20.1.12:49816 dest: /172.20.1.11:9866
2025-03-26 02:26:29,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742329_1505 src: /172.20.1.11:49888 dest: /172.20.1.13:9866
2025-03-26 02:26:29,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49888, dest: /172.20.1.13:9866, bytes: 2187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742329_1505, duration(ns): 981240
2025-03-26 02:26:29,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742329_1505, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49816, dest: /172.20.1.11:9866, bytes: 2187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742329_1505, duration(ns): 1204697
2025-03-26 02:26:29,249 INFO terminating
2025-03-26 02:26:29,250 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50682, dest: /172.20.1.12:9866, bytes: 2187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742329_1505, duration(ns): 2332380
2025-03-26 02:26:29,250 INFO terminating
2025-03-26 02:26:29,254 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742330_1506, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java._COPYING_
2025-03-26 02:26:29,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742330_1506 src: /172.20.1.10:34132 dest: /172.20.1.13:9866
2025-03-26 02:26:29,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742330_1506 src: /172.20.1.11:45026 dest: /172.20.1.12:9866
2025-03-26 02:26:29,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742330_1506 src: /172.20.1.13:53600 dest: /172.20.1.11:9866
2025-03-26 02:26:29,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45026, dest: /172.20.1.12:9866, bytes: 2422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742330_1506, duration(ns): 618518
2025-03-26 02:26:29,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742330_1506, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34132, dest: /172.20.1.13:9866, bytes: 2422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742330_1506, duration(ns): 1112655
2025-03-26 02:26:29,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53600, dest: /172.20.1.11:9866, bytes: 2422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742330_1506, duration(ns): 729623
2025-03-26 02:26:29,259 INFO terminating
2025-03-26 02:26:29,259 INFO terminating
2025-03-26 02:26:29,260 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,263 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742331_1507, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java._COPYING_
2025-03-26 02:26:29,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742331_1507 src: /172.20.1.10:50698 dest: /172.20.1.12:9866
2025-03-26 02:26:29,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742331_1507 src: /172.20.1.12:59532 dest: /172.20.1.13:9866
2025-03-26 02:26:29,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742331_1507 src: /172.20.1.13:53602 dest: /172.20.1.11:9866
2025-03-26 02:26:29,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53602, dest: /172.20.1.11:9866, bytes: 2270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742331_1507, duration(ns): 676006
2025-03-26 02:26:29,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742331_1507, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,269 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50698, dest: /172.20.1.12:9866, bytes: 2270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742331_1507, duration(ns): 1762055
2025-03-26 02:26:29,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59532, dest: /172.20.1.13:9866, bytes: 2270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742331_1507, duration(ns): 1446671
2025-03-26 02:26:29,269 INFO terminating
2025-03-26 02:26:29,269 INFO terminating
2025-03-26 02:26:29,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742332_1508, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_
2025-03-26 02:26:29,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742332_1508 src: /172.20.1.10:34146 dest: /172.20.1.13:9866
2025-03-26 02:26:29,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742332_1508 src: /172.20.1.13:53612 dest: /172.20.1.11:9866
2025-03-26 02:26:29,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742332_1508 src: /172.20.1.11:45040 dest: /172.20.1.12:9866
2025-03-26 02:26:29,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45040, dest: /172.20.1.12:9866, bytes: 3520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742332_1508, duration(ns): 2008612
2025-03-26 02:26:29,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742332_1508, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34146, dest: /172.20.1.13:9866, bytes: 3520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742332_1508, duration(ns): 2576750
2025-03-26 02:26:29,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53612, dest: /172.20.1.11:9866, bytes: 3520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742332_1508, duration(ns): 2262732
2025-03-26 02:26:29,279 INFO terminating
2025-03-26 02:26:29,279 INFO terminating
2025-03-26 02:26:29,280 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,292 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742333_1509, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java._COPYING_
2025-03-26 02:26:29,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742333_1509 src: /172.20.1.10:50714 dest: /172.20.1.12:9866
2025-03-26 02:26:29,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742333_1509 src: /172.20.1.12:49826 dest: /172.20.1.11:9866
2025-03-26 02:26:29,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742333_1509 src: /172.20.1.11:49900 dest: /172.20.1.13:9866
2025-03-26 02:26:29,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49900, dest: /172.20.1.13:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742333_1509, duration(ns): 718206
2025-03-26 02:26:29,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742333_1509, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50714, dest: /172.20.1.12:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742333_1509, duration(ns): 1772504
2025-03-26 02:26:29,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49826, dest: /172.20.1.11:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742333_1509, duration(ns): 894178
2025-03-26 02:26:29,297 INFO terminating
2025-03-26 02:26:29,297 INFO terminating
2025-03-26 02:26:29,298 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,301 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742334_1510, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_
2025-03-26 02:26:29,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742334_1510 src: /172.20.1.10:34152 dest: /172.20.1.13:9866
2025-03-26 02:26:29,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742334_1510 src: /172.20.1.13:53628 dest: /172.20.1.11:9866
2025-03-26 02:26:29,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742334_1510 src: /172.20.1.11:45050 dest: /172.20.1.12:9866
2025-03-26 02:26:29,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34152, dest: /172.20.1.13:9866, bytes: 1271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742334_1510, duration(ns): 2788268
2025-03-26 02:26:29,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45050, dest: /172.20.1.12:9866, bytes: 1271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742334_1510, duration(ns): 2308560
2025-03-26 02:26:29,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53628, dest: /172.20.1.11:9866, bytes: 1271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742334_1510, duration(ns): 2495500
2025-03-26 02:26:29,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742334_1510, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,307 INFO terminating
2025-03-26 02:26:29,307 INFO terminating
2025-03-26 02:26:29,308 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742335_1511, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java._COPYING_
2025-03-26 02:26:29,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742335_1511 src: /172.20.1.10:50720 dest: /172.20.1.12:9866
2025-03-26 02:26:29,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742335_1511 src: /172.20.1.12:59548 dest: /172.20.1.13:9866
2025-03-26 02:26:29,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742335_1511 src: /172.20.1.13:53636 dest: /172.20.1.11:9866
2025-03-26 02:26:29,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53636, dest: /172.20.1.11:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742335_1511, duration(ns): 1130749
2025-03-26 02:26:29,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742335_1511, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59548, dest: /172.20.1.13:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742335_1511, duration(ns): 1464359
2025-03-26 02:26:29,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50720, dest: /172.20.1.12:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742335_1511, duration(ns): 2413052
2025-03-26 02:26:29,321 INFO terminating
2025-03-26 02:26:29,321 INFO terminating
2025-03-26 02:26:29,322 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,331 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742336_1512, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java._COPYING_
2025-03-26 02:26:29,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742336_1512 src: /172.20.1.10:50728 dest: /172.20.1.12:9866
2025-03-26 02:26:29,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742336_1512 src: /172.20.1.11:49912 dest: /172.20.1.13:9866
2025-03-26 02:26:29,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742336_1512 src: /172.20.1.12:49838 dest: /172.20.1.11:9866
2025-03-26 02:26:29,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49912, dest: /172.20.1.13:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742336_1512, duration(ns): 912344
2025-03-26 02:26:29,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742336_1512, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50728, dest: /172.20.1.12:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742336_1512, duration(ns): 1570707
2025-03-26 02:26:29,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49838, dest: /172.20.1.11:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742336_1512, duration(ns): 1253615
2025-03-26 02:26:29,339 INFO terminating
2025-03-26 02:26:29,340 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,340 INFO terminating
2025-03-26 02:26:29,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,351 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742337_1513, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java._COPYING_
2025-03-26 02:26:29,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742337_1513 src: /172.20.1.10:34158 dest: /172.20.1.13:9866
2025-03-26 02:26:29,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742337_1513 src: /172.20.1.11:45066 dest: /172.20.1.12:9866
2025-03-26 02:26:29,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742337_1513 src: /172.20.1.13:53652 dest: /172.20.1.11:9866
2025-03-26 02:26:29,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45066, dest: /172.20.1.12:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742337_1513, duration(ns): 863879
2025-03-26 02:26:29,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742337_1513, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34158, dest: /172.20.1.13:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742337_1513, duration(ns): 1745099
2025-03-26 02:26:29,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53652, dest: /172.20.1.11:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742337_1513, duration(ns): 1572536
2025-03-26 02:26:29,356 INFO terminating
2025-03-26 02:26:29,356 INFO terminating
2025-03-26 02:26:29,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742338_1514, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java._COPYING_
2025-03-26 02:26:29,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742338_1514 src: /172.20.1.10:34164 dest: /172.20.1.13:9866
2025-03-26 02:26:29,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742338_1514 src: /172.20.1.13:53662 dest: /172.20.1.11:9866
2025-03-26 02:26:29,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742338_1514 src: /172.20.1.11:45070 dest: /172.20.1.12:9866
2025-03-26 02:26:29,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45070, dest: /172.20.1.12:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742338_1514, duration(ns): 894717
2025-03-26 02:26:29,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742338_1514, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34164, dest: /172.20.1.13:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742338_1514, duration(ns): 1358194
2025-03-26 02:26:29,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53662, dest: /172.20.1.11:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742338_1514, duration(ns): 1047098
2025-03-26 02:26:29,365 INFO terminating
2025-03-26 02:26:29,365 INFO terminating
2025-03-26 02:26:29,366 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742339_1515, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java._COPYING_
2025-03-26 02:26:29,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742339_1515 src: /172.20.1.10:34172 dest: /172.20.1.13:9866
2025-03-26 02:26:29,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742339_1515 src: /172.20.1.11:45076 dest: /172.20.1.12:9866
2025-03-26 02:26:29,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742339_1515 src: /172.20.1.13:53670 dest: /172.20.1.11:9866
2025-03-26 02:26:29,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45076, dest: /172.20.1.12:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742339_1515, duration(ns): 759180
2025-03-26 02:26:29,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742339_1515, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34172, dest: /172.20.1.13:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742339_1515, duration(ns): 1749344
2025-03-26 02:26:29,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53670, dest: /172.20.1.11:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742339_1515, duration(ns): 1283354
2025-03-26 02:26:29,374 INFO terminating
2025-03-26 02:26:29,374 INFO terminating
2025-03-26 02:26:29,375 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742340_1516, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_
2025-03-26 02:26:29,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742340_1516 src: /172.20.1.10:34180 dest: /172.20.1.13:9866
2025-03-26 02:26:29,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742340_1516 src: /172.20.1.12:49850 dest: /172.20.1.11:9866
2025-03-26 02:26:29,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742340_1516 src: /172.20.1.13:49964 dest: /172.20.1.12:9866
2025-03-26 02:26:29,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49850, dest: /172.20.1.11:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742340_1516, duration(ns): 565395
2025-03-26 02:26:29,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742340_1516, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34180, dest: /172.20.1.13:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742340_1516, duration(ns): 977939
2025-03-26 02:26:29,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49964, dest: /172.20.1.12:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742340_1516, duration(ns): 787988
2025-03-26 02:26:29,382 INFO terminating
2025-03-26 02:26:29,382 INFO terminating
2025-03-26 02:26:29,383 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,386 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742341_1517, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java._COPYING_
2025-03-26 02:26:29,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742341_1517 src: /172.20.1.10:50740 dest: /172.20.1.12:9866
2025-03-26 02:26:29,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742341_1517 src: /172.20.1.12:49866 dest: /172.20.1.11:9866
2025-03-26 02:26:29,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742341_1517 src: /172.20.1.11:49914 dest: /172.20.1.13:9866
2025-03-26 02:26:29,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49914, dest: /172.20.1.13:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742341_1517, duration(ns): 537180
2025-03-26 02:26:29,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49866, dest: /172.20.1.11:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742341_1517, duration(ns): 745752
2025-03-26 02:26:29,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742341_1517, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,390 INFO terminating
2025-03-26 02:26:29,391 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50740, dest: /172.20.1.12:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742341_1517, duration(ns): 1055547
2025-03-26 02:26:29,391 INFO terminating
2025-03-26 02:26:29,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742342_1518, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java._COPYING_
2025-03-26 02:26:29,394 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,394 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742342_1518 src: /172.20.1.10:35446 dest: /172.20.1.11:9866
2025-03-26 02:26:29,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742342_1518 src: /172.20.1.11:49918 dest: /172.20.1.13:9866
2025-03-26 02:26:29,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742342_1518 src: /172.20.1.13:49970 dest: /172.20.1.12:9866
2025-03-26 02:26:29,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35446, dest: /172.20.1.11:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742342_1518, duration(ns): 903492
2025-03-26 02:26:29,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49918, dest: /172.20.1.13:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742342_1518, duration(ns): 711082
2025-03-26 02:26:29,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49970, dest: /172.20.1.12:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742342_1518, duration(ns): 518763
2025-03-26 02:26:29,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742342_1518, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,398 INFO terminating
2025-03-26 02:26:29,398 INFO terminating
2025-03-26 02:26:29,405 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,408 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742343_1519, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java._COPYING_
2025-03-26 02:26:29,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742343_1519 src: /172.20.1.10:50744 dest: /172.20.1.12:9866
2025-03-26 02:26:29,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742343_1519 src: /172.20.1.12:49874 dest: /172.20.1.11:9866
2025-03-26 02:26:29,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742343_1519 src: /172.20.1.11:49920 dest: /172.20.1.13:9866
2025-03-26 02:26:29,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49920, dest: /172.20.1.13:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742343_1519, duration(ns): 826938
2025-03-26 02:26:29,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742343_1519, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50744, dest: /172.20.1.12:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742343_1519, duration(ns): 1426757
2025-03-26 02:26:29,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49874, dest: /172.20.1.11:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742343_1519, duration(ns): 1022526
2025-03-26 02:26:29,413 INFO terminating
2025-03-26 02:26:29,413 INFO terminating
2025-03-26 02:26:29,414 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,418 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742344_1520, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java._COPYING_
2025-03-26 02:26:29,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742344_1520 src: /172.20.1.10:50750 dest: /172.20.1.12:9866
2025-03-26 02:26:29,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742344_1520 src: /172.20.1.12:59564 dest: /172.20.1.13:9866
2025-03-26 02:26:29,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742344_1520 src: /172.20.1.13:53682 dest: /172.20.1.11:9866
2025-03-26 02:26:29,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53682, dest: /172.20.1.11:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742344_1520, duration(ns): 1031398
2025-03-26 02:26:29,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742344_1520, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50750, dest: /172.20.1.12:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742344_1520, duration(ns): 1582884
2025-03-26 02:26:29,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59564, dest: /172.20.1.13:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742344_1520, duration(ns): 1266175
2025-03-26 02:26:29,424 INFO terminating
2025-03-26 02:26:29,424 INFO terminating
2025-03-26 02:26:29,425 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742345_1521, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:26:29,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742345_1521 src: /172.20.1.10:50754 dest: /172.20.1.12:9866
2025-03-26 02:26:29,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742345_1521 src: /172.20.1.12:59576 dest: /172.20.1.13:9866
2025-03-26 02:26:29,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742345_1521 src: /172.20.1.13:53690 dest: /172.20.1.11:9866
2025-03-26 02:26:29,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50754, dest: /172.20.1.12:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742345_1521, duration(ns): 1138628
2025-03-26 02:26:29,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59576, dest: /172.20.1.13:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742345_1521, duration(ns): 998985
2025-03-26 02:26:29,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53690, dest: /172.20.1.11:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742345_1521, duration(ns): 777434
2025-03-26 02:26:29,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742345_1521, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,432 INFO terminating
2025-03-26 02:26:29,432 INFO terminating
2025-03-26 02:26:29,433 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742346_1522, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java._COPYING_
2025-03-26 02:26:29,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742346_1522 src: /172.20.1.10:50768 dest: /172.20.1.12:9866
2025-03-26 02:26:29,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742346_1522 src: /172.20.1.12:59584 dest: /172.20.1.13:9866
2025-03-26 02:26:29,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742346_1522 src: /172.20.1.13:53694 dest: /172.20.1.11:9866
2025-03-26 02:26:29,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59584, dest: /172.20.1.13:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742346_1522, duration(ns): 850521
2025-03-26 02:26:29,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53694, dest: /172.20.1.11:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742346_1522, duration(ns): 670028
2025-03-26 02:26:29,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742346_1522, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50768, dest: /172.20.1.12:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742346_1522, duration(ns): 1139579
2025-03-26 02:26:29,440 INFO terminating
2025-03-26 02:26:29,440 INFO terminating
2025-03-26 02:26:29,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,444 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742347_1523, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java._COPYING_
2025-03-26 02:26:29,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742347_1523 src: /172.20.1.10:50776 dest: /172.20.1.12:9866
2025-03-26 02:26:29,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742347_1523 src: /172.20.1.12:59600 dest: /172.20.1.13:9866
2025-03-26 02:26:29,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742347_1523 src: /172.20.1.13:53702 dest: /172.20.1.11:9866
2025-03-26 02:26:29,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53702, dest: /172.20.1.11:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742347_1523, duration(ns): 588844
2025-03-26 02:26:29,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742347_1523, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50776, dest: /172.20.1.12:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742347_1523, duration(ns): 1094759
2025-03-26 02:26:29,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59600, dest: /172.20.1.13:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742347_1523, duration(ns): 816613
2025-03-26 02:26:29,448 INFO terminating
2025-03-26 02:26:29,448 INFO terminating
2025-03-26 02:26:29,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742348_1524, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java._COPYING_
2025-03-26 02:26:29,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742348_1524 src: /172.20.1.10:35452 dest: /172.20.1.11:9866
2025-03-26 02:26:29,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742348_1524 src: /172.20.1.11:45084 dest: /172.20.1.12:9866
2025-03-26 02:26:29,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742348_1524 src: /172.20.1.12:59614 dest: /172.20.1.13:9866
2025-03-26 02:26:29,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45084, dest: /172.20.1.12:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742348_1524, duration(ns): 897504
2025-03-26 02:26:29,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59614, dest: /172.20.1.13:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742348_1524, duration(ns): 715379
2025-03-26 02:26:29,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742348_1524, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,455 INFO terminating
2025-03-26 02:26:29,456 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35452, dest: /172.20.1.11:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742348_1524, duration(ns): 1077447
2025-03-26 02:26:29,456 INFO terminating
2025-03-26 02:26:29,459 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742349_1525, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java._COPYING_
2025-03-26 02:26:29,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742349_1525 src: /172.20.1.10:35460 dest: /172.20.1.11:9866
2025-03-26 02:26:29,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742349_1525 src: /172.20.1.11:45100 dest: /172.20.1.12:9866
2025-03-26 02:26:29,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742349_1525 src: /172.20.1.12:59626 dest: /172.20.1.13:9866
2025-03-26 02:26:29,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35460, dest: /172.20.1.11:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742349_1525, duration(ns): 838242
2025-03-26 02:26:29,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45100, dest: /172.20.1.12:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742349_1525, duration(ns): 651819
2025-03-26 02:26:29,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59626, dest: /172.20.1.13:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742349_1525, duration(ns): 481690
2025-03-26 02:26:29,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742349_1525, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,463 INFO terminating
2025-03-26 02:26:29,463 INFO terminating
2025-03-26 02:26:29,464 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,471 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742350_1526, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java._COPYING_
2025-03-26 02:26:29,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742350_1526 src: /172.20.1.10:35468 dest: /172.20.1.11:9866
2025-03-26 02:26:29,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742350_1526 src: /172.20.1.11:49926 dest: /172.20.1.13:9866
2025-03-26 02:26:29,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49980, dest: /172.20.1.12:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742350_1526, duration(ns): 462288
2025-03-26 02:26:29,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742350_1526, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742350_1526 src: /172.20.1.13:49980 dest: /172.20.1.12:9866
2025-03-26 02:26:29,475 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35468, dest: /172.20.1.11:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742350_1526, duration(ns): 763534
2025-03-26 02:26:29,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49926, dest: /172.20.1.13:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742350_1526, duration(ns): 624631
2025-03-26 02:26:29,475 INFO terminating
2025-03-26 02:26:29,475 INFO terminating
2025-03-26 02:26:29,483 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742351_1527, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:26:29,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742351_1527 src: /172.20.1.10:34190 dest: /172.20.1.13:9866
2025-03-26 02:26:29,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742351_1527 src: /172.20.1.12:49888 dest: /172.20.1.11:9866
2025-03-26 02:26:29,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742351_1527 src: /172.20.1.13:49992 dest: /172.20.1.12:9866
2025-03-26 02:26:29,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34190, dest: /172.20.1.13:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742351_1527, duration(ns): 821684
2025-03-26 02:26:29,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49888, dest: /172.20.1.11:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742351_1527, duration(ns): 401204
2025-03-26 02:26:29,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49992, dest: /172.20.1.12:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742351_1527, duration(ns): 633405
2025-03-26 02:26:29,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742351_1527, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,486 INFO terminating
2025-03-26 02:26:29,486 INFO terminating
2025-03-26 02:26:29,487 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,490 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742352_1528, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java._COPYING_
2025-03-26 02:26:29,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742352_1528 src: /172.20.1.10:35472 dest: /172.20.1.11:9866
2025-03-26 02:26:29,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742352_1528 src: /172.20.1.11:45104 dest: /172.20.1.12:9866
2025-03-26 02:26:29,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742352_1528 src: /172.20.1.12:59640 dest: /172.20.1.13:9866
2025-03-26 02:26:29,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45104, dest: /172.20.1.12:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742352_1528, duration(ns): 2174322
2025-03-26 02:26:29,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59640, dest: /172.20.1.13:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742352_1528, duration(ns): 2004392
2025-03-26 02:26:29,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742352_1528, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,494 INFO terminating
2025-03-26 02:26:29,495 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35472, dest: /172.20.1.11:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742352_1528, duration(ns): 2331974
2025-03-26 02:26:29,495 INFO terminating
2025-03-26 02:26:29,501 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742353_1529, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java._COPYING_
2025-03-26 02:26:29,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742353_1529 src: /172.20.1.10:34192 dest: /172.20.1.13:9866
2025-03-26 02:26:29,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742353_1529 src: /172.20.1.12:49892 dest: /172.20.1.11:9866
2025-03-26 02:26:29,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742353_1529 src: /172.20.1.13:49998 dest: /172.20.1.12:9866
2025-03-26 02:26:29,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49892, dest: /172.20.1.11:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742353_1529, duration(ns): 403905
2025-03-26 02:26:29,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742353_1529, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34192, dest: /172.20.1.13:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742353_1529, duration(ns): 775340
2025-03-26 02:26:29,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:49998, dest: /172.20.1.12:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742353_1529, duration(ns): 597624
2025-03-26 02:26:29,505 INFO terminating
2025-03-26 02:26:29,505 INFO terminating
2025-03-26 02:26:29,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742354_1530, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:26:29,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742354_1530 src: /172.20.1.10:35476 dest: /172.20.1.11:9866
2025-03-26 02:26:29,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742354_1530 src: /172.20.1.11:49942 dest: /172.20.1.13:9866
2025-03-26 02:26:29,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742354_1530 src: /172.20.1.13:50010 dest: /172.20.1.12:9866
2025-03-26 02:26:29,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35476, dest: /172.20.1.11:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742354_1530, duration(ns): 798085
2025-03-26 02:26:29,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49942, dest: /172.20.1.13:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742354_1530, duration(ns): 651608
2025-03-26 02:26:29,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:50010, dest: /172.20.1.12:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742354_1530, duration(ns): 490427
2025-03-26 02:26:29,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742354_1530, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,512 INFO terminating
2025-03-26 02:26:29,513 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,513 INFO terminating
2025-03-26 02:26:29,516 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742355_1531, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java._COPYING_
2025-03-26 02:26:29,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742355_1531 src: /172.20.1.10:35478 dest: /172.20.1.11:9866
2025-03-26 02:26:29,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742355_1531 src: /172.20.1.11:49944 dest: /172.20.1.13:9866
2025-03-26 02:26:29,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742355_1531 src: /172.20.1.13:50022 dest: /172.20.1.12:9866
2025-03-26 02:26:29,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49944, dest: /172.20.1.13:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742355_1531, duration(ns): 3845243
2025-03-26 02:26:29,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:50022, dest: /172.20.1.12:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742355_1531, duration(ns): 3719216
2025-03-26 02:26:29,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742355_1531, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,522 INFO terminating
2025-03-26 02:26:29,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35478, dest: /172.20.1.11:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742355_1531, duration(ns): 4120136
2025-03-26 02:26:29,523 INFO terminating
2025-03-26 02:26:29,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742356_1532, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java._COPYING_
2025-03-26 02:26:29,526 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,526 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742356_1532 src: /172.20.1.10:35488 dest: /172.20.1.11:9866
2025-03-26 02:26:29,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742356_1532 src: /172.20.1.11:45106 dest: /172.20.1.12:9866
2025-03-26 02:26:29,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742356_1532 src: /172.20.1.12:59656 dest: /172.20.1.13:9866
2025-03-26 02:26:29,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45106, dest: /172.20.1.12:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742356_1532, duration(ns): 4538287
2025-03-26 02:26:29,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59656, dest: /172.20.1.13:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742356_1532, duration(ns): 4408469
2025-03-26 02:26:29,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742356_1532, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,533 INFO terminating
2025-03-26 02:26:29,534 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35488, dest: /172.20.1.11:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742356_1532, duration(ns): 4719189
2025-03-26 02:26:29,534 INFO terminating
2025-03-26 02:26:29,540 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742357_1533, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java._COPYING_
2025-03-26 02:26:29,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742357_1533 src: /172.20.1.10:35502 dest: /172.20.1.11:9866
2025-03-26 02:26:29,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742357_1533 src: /172.20.1.11:45112 dest: /172.20.1.12:9866
2025-03-26 02:26:29,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742357_1533 src: /172.20.1.12:59670 dest: /172.20.1.13:9866
2025-03-26 02:26:29,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45112, dest: /172.20.1.12:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742357_1533, duration(ns): 812566
2025-03-26 02:26:29,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59670, dest: /172.20.1.13:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742357_1533, duration(ns): 633221
2025-03-26 02:26:29,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742357_1533, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,543 INFO terminating
2025-03-26 02:26:29,544 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35502, dest: /172.20.1.11:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742357_1533, duration(ns): 920686
2025-03-26 02:26:29,544 INFO terminating
2025-03-26 02:26:29,552 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742358_1534, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java._COPYING_
2025-03-26 02:26:29,552 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,552 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742358_1534 src: /172.20.1.10:35512 dest: /172.20.1.11:9866
2025-03-26 02:26:29,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742358_1534 src: /172.20.1.11:45124 dest: /172.20.1.12:9866
2025-03-26 02:26:29,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742358_1534 src: /172.20.1.12:59674 dest: /172.20.1.13:9866
2025-03-26 02:26:29,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35512, dest: /172.20.1.11:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742358_1534, duration(ns): 1022005
2025-03-26 02:26:29,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45124, dest: /172.20.1.12:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742358_1534, duration(ns): 867949
2025-03-26 02:26:29,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59674, dest: /172.20.1.13:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742358_1534, duration(ns): 682871
2025-03-26 02:26:29,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742358_1534, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,556 INFO terminating
2025-03-26 02:26:29,556 INFO terminating
2025-03-26 02:26:29,558 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,567 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742359_1535, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java._COPYING_
2025-03-26 02:26:29,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742359_1535 src: /172.20.1.10:34200 dest: /172.20.1.13:9866
2025-03-26 02:26:29,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742359_1535 src: /172.20.1.11:45130 dest: /172.20.1.12:9866
2025-03-26 02:26:29,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742359_1535 src: /172.20.1.13:53718 dest: /172.20.1.11:9866
2025-03-26 02:26:29,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34200, dest: /172.20.1.13:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742359_1535, duration(ns): 1289775
2025-03-26 02:26:29,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45130, dest: /172.20.1.12:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742359_1535, duration(ns): 798911
2025-03-26 02:26:29,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53718, dest: /172.20.1.11:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742359_1535, duration(ns): 1025182
2025-03-26 02:26:29,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742359_1535, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,571 INFO terminating
2025-03-26 02:26:29,571 INFO terminating
2025-03-26 02:26:29,572 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,575 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742360_1536, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java._COPYING_
2025-03-26 02:26:29,575 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,575 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742360_1536 src: /172.20.1.10:35516 dest: /172.20.1.11:9866
2025-03-26 02:26:29,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742360_1536 src: /172.20.1.11:49960 dest: /172.20.1.13:9866
2025-03-26 02:26:29,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742360_1536 src: /172.20.1.13:50038 dest: /172.20.1.12:9866
2025-03-26 02:26:29,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:50038, dest: /172.20.1.12:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742360_1536, duration(ns): 662756
2025-03-26 02:26:29,579 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35516, dest: /172.20.1.11:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742360_1536, duration(ns): 1277145
2025-03-26 02:26:29,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49960, dest: /172.20.1.13:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742360_1536, duration(ns): 1158453
2025-03-26 02:26:29,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742360_1536, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,579 INFO terminating
2025-03-26 02:26:29,579 INFO terminating
2025-03-26 02:26:29,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742361_1537, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java._COPYING_
2025-03-26 02:26:29,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742361_1537 src: /172.20.1.10:35518 dest: /172.20.1.11:9866
2025-03-26 02:26:29,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742361_1537 src: /172.20.1.11:45132 dest: /172.20.1.12:9866
2025-03-26 02:26:29,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742361_1537 src: /172.20.1.12:59680 dest: /172.20.1.13:9866
2025-03-26 02:26:29,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45132, dest: /172.20.1.12:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742361_1537, duration(ns): 737033
2025-03-26 02:26:29,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59680, dest: /172.20.1.13:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742361_1537, duration(ns): 566634
2025-03-26 02:26:29,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742361_1537, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,587 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35518, dest: /172.20.1.11:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742361_1537, duration(ns): 932631
2025-03-26 02:26:29,587 INFO terminating
2025-03-26 02:26:29,587 INFO terminating
2025-03-26 02:26:29,591 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742362_1538, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java._COPYING_
2025-03-26 02:26:29,591 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,591 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742362_1538 src: /172.20.1.10:50784 dest: /172.20.1.12:9866
2025-03-26 02:26:29,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742362_1538 src: /172.20.1.12:49898 dest: /172.20.1.11:9866
2025-03-26 02:26:29,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742362_1538 src: /172.20.1.11:49966 dest: /172.20.1.13:9866
2025-03-26 02:26:29,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50784, dest: /172.20.1.12:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742362_1538, duration(ns): 897313
2025-03-26 02:26:29,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49966, dest: /172.20.1.13:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742362_1538, duration(ns): 470015
2025-03-26 02:26:29,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49898, dest: /172.20.1.11:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742362_1538, duration(ns): 627492
2025-03-26 02:26:29,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742362_1538, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,594 INFO terminating
2025-03-26 02:26:29,594 INFO terminating
2025-03-26 02:26:29,595 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742363_1539, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_
2025-03-26 02:26:29,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742363_1539 src: /172.20.1.10:34208 dest: /172.20.1.13:9866
2025-03-26 02:26:29,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742363_1539 src: /172.20.1.13:53722 dest: /172.20.1.11:9866
2025-03-26 02:26:29,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742363_1539 src: /172.20.1.11:45140 dest: /172.20.1.12:9866
2025-03-26 02:26:29,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34208, dest: /172.20.1.13:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742363_1539, duration(ns): 1241261
2025-03-26 02:26:29,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45140, dest: /172.20.1.12:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742363_1539, duration(ns): 534794
2025-03-26 02:26:29,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53722, dest: /172.20.1.11:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742363_1539, duration(ns): 645743
2025-03-26 02:26:29,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742363_1539, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,602 INFO terminating
2025-03-26 02:26:29,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,603 INFO terminating
2025-03-26 02:26:29,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742364_1540, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java._COPYING_
2025-03-26 02:26:29,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742364_1540 src: /172.20.1.10:34212 dest: /172.20.1.13:9866
2025-03-26 02:26:29,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742364_1540 src: /172.20.1.13:53738 dest: /172.20.1.11:9866
2025-03-26 02:26:29,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742364_1540 src: /172.20.1.11:45156 dest: /172.20.1.12:9866
2025-03-26 02:26:29,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45156, dest: /172.20.1.12:9866, bytes: 2645, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742364_1540, duration(ns): 511108
2025-03-26 02:26:29,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742364_1540, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34212, dest: /172.20.1.13:9866, bytes: 2645, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742364_1540, duration(ns): 1455242
2025-03-26 02:26:29,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53738, dest: /172.20.1.11:9866, bytes: 2645, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742364_1540, duration(ns): 630427
2025-03-26 02:26:29,611 INFO terminating
2025-03-26 02:26:29,611 INFO terminating
2025-03-26 02:26:29,612 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,618 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742365_1541, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java._COPYING_
2025-03-26 02:26:29,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742365_1541 src: /172.20.1.10:50800 dest: /172.20.1.12:9866
2025-03-26 02:26:29,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742365_1541 src: /172.20.1.12:59684 dest: /172.20.1.13:9866
2025-03-26 02:26:29,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742365_1541 src: /172.20.1.13:53740 dest: /172.20.1.11:9866
2025-03-26 02:26:29,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59684, dest: /172.20.1.13:9866, bytes: 4683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742365_1541, duration(ns): 891415
2025-03-26 02:26:29,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53740, dest: /172.20.1.11:9866, bytes: 4683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742365_1541, duration(ns): 547210
2025-03-26 02:26:29,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742365_1541, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,622 INFO terminating
2025-03-26 02:26:29,623 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50800, dest: /172.20.1.12:9866, bytes: 4683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742365_1541, duration(ns): 1098475
2025-03-26 02:26:29,623 INFO terminating
2025-03-26 02:26:29,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742366_1542, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java._COPYING_
2025-03-26 02:26:29,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742366_1542 src: /172.20.1.10:34218 dest: /172.20.1.13:9866
2025-03-26 02:26:29,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742366_1542 src: /172.20.1.13:53752 dest: /172.20.1.11:9866
2025-03-26 02:26:29,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742366_1542 src: /172.20.1.11:45168 dest: /172.20.1.12:9866
2025-03-26 02:26:29,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45168, dest: /172.20.1.12:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742366_1542, duration(ns): 2180927
2025-03-26 02:26:29,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34218, dest: /172.20.1.13:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742366_1542, duration(ns): 2734813
2025-03-26 02:26:29,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53752, dest: /172.20.1.11:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742366_1542, duration(ns): 2409914
2025-03-26 02:26:29,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742366_1542, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,632 INFO terminating
2025-03-26 02:26:29,632 INFO terminating
2025-03-26 02:26:29,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,650 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,651 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742367_1543, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_
2025-03-26 02:26:29,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742367_1543 src: /172.20.1.10:35522 dest: /172.20.1.11:9866
2025-03-26 02:26:29,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742367_1543 src: /172.20.1.11:45184 dest: /172.20.1.12:9866
2025-03-26 02:26:29,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742367_1543 src: /172.20.1.12:59688 dest: /172.20.1.13:9866
2025-03-26 02:26:29,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45184, dest: /172.20.1.12:9866, bytes: 1968, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742367_1543, duration(ns): 749137
2025-03-26 02:26:29,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59688, dest: /172.20.1.13:9866, bytes: 1968, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742367_1543, duration(ns): 545925
2025-03-26 02:26:29,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742367_1543, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,654 INFO terminating
2025-03-26 02:26:29,655 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35522, dest: /172.20.1.11:9866, bytes: 1968, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742367_1543, duration(ns): 919441
2025-03-26 02:26:29,655 INFO terminating
2025-03-26 02:26:29,658 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742368_1544, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java._COPYING_
2025-03-26 02:26:29,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742368_1544 src: /172.20.1.10:35532 dest: /172.20.1.11:9866
2025-03-26 02:26:29,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742368_1544 src: /172.20.1.11:49980 dest: /172.20.1.13:9866
2025-03-26 02:26:29,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742368_1544 src: /172.20.1.13:50052 dest: /172.20.1.12:9866
2025-03-26 02:26:29,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:50052, dest: /172.20.1.12:9866, bytes: 4506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742368_1544, duration(ns): 588439
2025-03-26 02:26:29,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742368_1544, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,662 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35532, dest: /172.20.1.11:9866, bytes: 4506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742368_1544, duration(ns): 905865
2025-03-26 02:26:29,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49980, dest: /172.20.1.13:9866, bytes: 4506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742368_1544, duration(ns): 770253
2025-03-26 02:26:29,662 INFO terminating
2025-03-26 02:26:29,662 INFO terminating
2025-03-26 02:26:29,666 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742369_1545, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java._COPYING_
2025-03-26 02:26:29,666 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,666 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742369_1545 src: /172.20.1.10:34226 dest: /172.20.1.13:9866
2025-03-26 02:26:29,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742369_1545 src: /172.20.1.13:53756 dest: /172.20.1.11:9866
2025-03-26 02:26:29,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742369_1545 src: /172.20.1.11:45188 dest: /172.20.1.12:9866
2025-03-26 02:26:29,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45188, dest: /172.20.1.12:9866, bytes: 2721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742369_1545, duration(ns): 558891
2025-03-26 02:26:29,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53756, dest: /172.20.1.11:9866, bytes: 2721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742369_1545, duration(ns): 731787
2025-03-26 02:26:29,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742369_1545, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,669 INFO terminating
2025-03-26 02:26:29,670 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34226, dest: /172.20.1.13:9866, bytes: 2721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742369_1545, duration(ns): 979302
2025-03-26 02:26:29,670 INFO terminating
2025-03-26 02:26:29,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742370_1546, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaTC.java._COPYING_
2025-03-26 02:26:29,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742370_1546 src: /172.20.1.10:35542 dest: /172.20.1.11:9866
2025-03-26 02:26:29,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742370_1546 src: /172.20.1.11:45204 dest: /172.20.1.12:9866
2025-03-26 02:26:29,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742370_1546 src: /172.20.1.12:59698 dest: /172.20.1.13:9866
2025-03-26 02:26:29,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35542, dest: /172.20.1.11:9866, bytes: 3473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742370_1546, duration(ns): 797205
2025-03-26 02:26:29,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45204, dest: /172.20.1.12:9866, bytes: 3473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742370_1546, duration(ns): 597889
2025-03-26 02:26:29,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59698, dest: /172.20.1.13:9866, bytes: 3473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742370_1546, duration(ns): 438226
2025-03-26 02:26:29,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742370_1546, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,677 INFO terminating
2025-03-26 02:26:29,677 INFO terminating
2025-03-26 02:26:29,682 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaTC.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742371_1547, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java._COPYING_
2025-03-26 02:26:29,686 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,686 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742371_1547 src: /172.20.1.10:35558 dest: /172.20.1.11:9866
2025-03-26 02:26:29,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742371_1547 src: /172.20.1.11:45220 dest: /172.20.1.12:9866
2025-03-26 02:26:29,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59700, dest: /172.20.1.13:9866, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742371_1547, duration(ns): 492581
2025-03-26 02:26:29,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742371_1547, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742371_1547 src: /172.20.1.12:59700 dest: /172.20.1.13:9866
2025-03-26 02:26:29,690 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35558, dest: /172.20.1.11:9866, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742371_1547, duration(ns): 794820
2025-03-26 02:26:29,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45220, dest: /172.20.1.12:9866, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742371_1547, duration(ns): 654983
2025-03-26 02:26:29,690 INFO terminating
2025-03-26 02:26:29,690 INFO terminating
2025-03-26 02:26:29,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742372_1548, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java._COPYING_
2025-03-26 02:26:29,694 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,694 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742372_1548 src: /172.20.1.10:50806 dest: /172.20.1.12:9866
2025-03-26 02:26:29,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742372_1548 src: /172.20.1.12:59704 dest: /172.20.1.13:9866
2025-03-26 02:26:29,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742372_1548 src: /172.20.1.13:53764 dest: /172.20.1.11:9866
2025-03-26 02:26:29,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50806, dest: /172.20.1.12:9866, bytes: 4979, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742372_1548, duration(ns): 933875
2025-03-26 02:26:29,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59704, dest: /172.20.1.13:9866, bytes: 4979, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742372_1548, duration(ns): 696052
2025-03-26 02:26:29,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53764, dest: /172.20.1.11:9866, bytes: 4979, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742372_1548, duration(ns): 472996
2025-03-26 02:26:29,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742372_1548, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,698 INFO terminating
2025-03-26 02:26:29,698 INFO terminating
2025-03-26 02:26:29,699 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,706 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,707 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742373_1549, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java._COPYING_
2025-03-26 02:26:29,707 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742373_1549 src: /172.20.1.10:50814 dest: /172.20.1.12:9866
2025-03-26 02:26:29,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742373_1549 src: /172.20.1.11:49992 dest: /172.20.1.13:9866
2025-03-26 02:26:29,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742373_1549 src: /172.20.1.12:49900 dest: /172.20.1.11:9866
2025-03-26 02:26:29,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49992, dest: /172.20.1.13:9866, bytes: 10904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742373_1549, duration(ns): 3473060
2025-03-26 02:26:29,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49900, dest: /172.20.1.11:9866, bytes: 10904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742373_1549, duration(ns): 3580094
2025-03-26 02:26:29,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742373_1549, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,714 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50814, dest: /172.20.1.12:9866, bytes: 10904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742373_1549, duration(ns): 3860192
2025-03-26 02:26:29,714 INFO terminating
2025-03-26 02:26:29,714 INFO terminating
2025-03-26 02:26:29,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742374_1550, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java._COPYING_
2025-03-26 02:26:29,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742374_1550 src: /172.20.1.10:50818 dest: /172.20.1.12:9866
2025-03-26 02:26:29,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742374_1550 src: /172.20.1.12:59706 dest: /172.20.1.13:9866
2025-03-26 02:26:29,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742374_1550 src: /172.20.1.13:53776 dest: /172.20.1.11:9866
2025-03-26 02:26:29,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53776, dest: /172.20.1.11:9866, bytes: 17432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742374_1550, duration(ns): 620286
2025-03-26 02:26:29,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742374_1550, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,724 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50818, dest: /172.20.1.12:9866, bytes: 17432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742374_1550, duration(ns): 1038300
2025-03-26 02:26:29,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59706, dest: /172.20.1.13:9866, bytes: 17432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742374_1550, duration(ns): 834328
2025-03-26 02:26:29,724 INFO terminating
2025-03-26 02:26:29,724 INFO terminating
2025-03-26 02:26:29,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742375_1551, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java._COPYING_
2025-03-26 02:26:29,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742375_1551 src: /172.20.1.10:35568 dest: /172.20.1.11:9866
2025-03-26 02:26:29,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742375_1551 src: /172.20.1.11:50006 dest: /172.20.1.13:9866
2025-03-26 02:26:29,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742375_1551 src: /172.20.1.13:50062 dest: /172.20.1.12:9866
2025-03-26 02:26:29,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:50006, dest: /172.20.1.13:9866, bytes: 4187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742375_1551, duration(ns): 577136
2025-03-26 02:26:29,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:50062, dest: /172.20.1.12:9866, bytes: 4187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742375_1551, duration(ns): 419696
2025-03-26 02:26:29,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742375_1551, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,732 INFO terminating
2025-03-26 02:26:29,733 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35568, dest: /172.20.1.11:9866, bytes: 4187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742375_1551, duration(ns): 751595
2025-03-26 02:26:29,733 INFO terminating
2025-03-26 02:26:29,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742376_1552, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java._COPYING_
2025-03-26 02:26:29,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742376_1552 src: /172.20.1.10:35580 dest: /172.20.1.11:9866
2025-03-26 02:26:29,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742376_1552 src: /172.20.1.11:50008 dest: /172.20.1.13:9866
2025-03-26 02:26:29,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742376_1552 src: /172.20.1.13:50064 dest: /172.20.1.12:9866
2025-03-26 02:26:29,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:50008, dest: /172.20.1.13:9866, bytes: 2898, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742376_1552, duration(ns): 566535
2025-03-26 02:26:29,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:50064, dest: /172.20.1.12:9866, bytes: 2898, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742376_1552, duration(ns): 392241
2025-03-26 02:26:29,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742376_1552, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,739 INFO terminating
2025-03-26 02:26:29,742 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35580, dest: /172.20.1.11:9866, bytes: 2898, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742376_1552, duration(ns): 724439
2025-03-26 02:26:29,742 INFO terminating
2025-03-26 02:26:29,752 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742377_1553, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java._COPYING_
2025-03-26 02:26:29,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742377_1553 src: /172.20.1.10:50828 dest: /172.20.1.12:9866
2025-03-26 02:26:29,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742377_1553 src: /172.20.1.12:59716 dest: /172.20.1.13:9866
2025-03-26 02:26:29,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742377_1553 src: /172.20.1.13:53778 dest: /172.20.1.11:9866
2025-03-26 02:26:29,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53778, dest: /172.20.1.11:9866, bytes: 16348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742377_1553, duration(ns): 1367072
2025-03-26 02:26:29,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742377_1553, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,757 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50828, dest: /172.20.1.12:9866, bytes: 16348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742377_1553, duration(ns): 1898827
2025-03-26 02:26:29,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59716, dest: /172.20.1.13:9866, bytes: 16348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742377_1553, duration(ns): 1631053
2025-03-26 02:26:29,757 INFO terminating
2025-03-26 02:26:29,757 INFO terminating
2025-03-26 02:26:29,770 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742378_1554, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_
2025-03-26 02:26:29,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742378_1554 src: /172.20.1.10:35592 dest: /172.20.1.11:9866
2025-03-26 02:26:29,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742378_1554 src: /172.20.1.11:45228 dest: /172.20.1.12:9866
2025-03-26 02:26:29,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742378_1554 src: /172.20.1.12:59722 dest: /172.20.1.13:9866
2025-03-26 02:26:29,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45228, dest: /172.20.1.12:9866, bytes: 5473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742378_1554, duration(ns): 731764
2025-03-26 02:26:29,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59722, dest: /172.20.1.13:9866, bytes: 5473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742378_1554, duration(ns): 550994
2025-03-26 02:26:29,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742378_1554, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,774 INFO terminating
2025-03-26 02:26:29,777 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35592, dest: /172.20.1.11:9866, bytes: 5473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742378_1554, duration(ns): 974275
2025-03-26 02:26:29,777 INFO terminating
2025-03-26 02:26:29,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742379_1555, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java._COPYING_
2025-03-26 02:26:29,780 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,780 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742379_1555 src: /172.20.1.10:35606 dest: /172.20.1.11:9866
2025-03-26 02:26:29,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742379_1555 src: /172.20.1.11:50018 dest: /172.20.1.13:9866
2025-03-26 02:26:29,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742379_1555 src: /172.20.1.13:50066 dest: /172.20.1.12:9866
2025-03-26 02:26:29,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:50018, dest: /172.20.1.13:9866, bytes: 4663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742379_1555, duration(ns): 835201
2025-03-26 02:26:29,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:50066, dest: /172.20.1.12:9866, bytes: 4663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742379_1555, duration(ns): 727102
2025-03-26 02:26:29,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742379_1555, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,784 INFO terminating
2025-03-26 02:26:29,785 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35606, dest: /172.20.1.11:9866, bytes: 4663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742379_1555, duration(ns): 1056850
2025-03-26 02:26:29,785 INFO terminating
2025-03-26 02:26:29,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742380_1556, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_
2025-03-26 02:26:29,793 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,793 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742380_1556 src: /172.20.1.10:50838 dest: /172.20.1.12:9866
2025-03-26 02:26:29,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742380_1556 src: /172.20.1.12:49902 dest: /172.20.1.11:9866
2025-03-26 02:26:29,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742380_1556 src: /172.20.1.11:50024 dest: /172.20.1.13:9866
2025-03-26 02:26:29,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50838, dest: /172.20.1.12:9866, bytes: 3479, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742380_1556, duration(ns): 1150764
2025-03-26 02:26:29,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:50024, dest: /172.20.1.13:9866, bytes: 3479, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742380_1556, duration(ns): 769871
2025-03-26 02:26:29,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49902, dest: /172.20.1.11:9866, bytes: 3479, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742380_1556, duration(ns): 881868
2025-03-26 02:26:29,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742380_1556, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,801 INFO terminating
2025-03-26 02:26:29,801 INFO terminating
2025-03-26 02:26:29,802 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742381_1557, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_
2025-03-26 02:26:29,807 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,807 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742381_1557 src: /172.20.1.10:34242 dest: /172.20.1.13:9866
2025-03-26 02:26:29,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742381_1557 src: /172.20.1.13:50078 dest: /172.20.1.12:9866
2025-03-26 02:26:29,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742381_1557 src: /172.20.1.12:49906 dest: /172.20.1.11:9866
2025-03-26 02:26:29,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49906, dest: /172.20.1.11:9866, bytes: 3285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742381_1557, duration(ns): 440413
2025-03-26 02:26:29,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:50078, dest: /172.20.1.12:9866, bytes: 3285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742381_1557, duration(ns): 720709
2025-03-26 02:26:29,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742381_1557, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,810 INFO terminating
2025-03-26 02:26:29,811 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34242, dest: /172.20.1.13:9866, bytes: 3285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742381_1557, duration(ns): 955167
2025-03-26 02:26:29,811 INFO terminating
2025-03-26 02:26:29,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742382_1558, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java._COPYING_
2025-03-26 02:26:29,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742382_1558 src: /172.20.1.10:50854 dest: /172.20.1.12:9866
2025-03-26 02:26:29,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742382_1558 src: /172.20.1.12:49912 dest: /172.20.1.11:9866
2025-03-26 02:26:29,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742382_1558 src: /172.20.1.11:50026 dest: /172.20.1.13:9866
2025-03-26 02:26:29,817 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50854, dest: /172.20.1.12:9866, bytes: 2742, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742382_1558, duration(ns): 892603
2025-03-26 02:26:29,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:50026, dest: /172.20.1.13:9866, bytes: 2742, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742382_1558, duration(ns): 572229
2025-03-26 02:26:29,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49912, dest: /172.20.1.11:9866, bytes: 2742, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742382_1558, duration(ns): 670035
2025-03-26 02:26:29,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742382_1558, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,817 INFO terminating
2025-03-26 02:26:29,817 INFO terminating
2025-03-26 02:26:29,823 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742383_1559, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java._COPYING_
2025-03-26 02:26:29,823 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,823 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742383_1559 src: /172.20.1.10:50856 dest: /172.20.1.12:9866
2025-03-26 02:26:29,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742383_1559 src: /172.20.1.12:49922 dest: /172.20.1.11:9866
2025-03-26 02:26:29,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742383_1559 src: /172.20.1.11:50032 dest: /172.20.1.13:9866
2025-03-26 02:26:29,826 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50856, dest: /172.20.1.12:9866, bytes: 6228, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742383_1559, duration(ns): 906354
2025-03-26 02:26:29,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:50032, dest: /172.20.1.13:9866, bytes: 6228, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742383_1559, duration(ns): 493317
2025-03-26 02:26:29,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49922, dest: /172.20.1.11:9866, bytes: 6228, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742383_1559, duration(ns): 659983
2025-03-26 02:26:29,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742383_1559, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,826 INFO terminating
2025-03-26 02:26:29,826 INFO terminating
2025-03-26 02:26:29,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742384_1560, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_
2025-03-26 02:26:29,833 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,833 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742384_1560 src: /172.20.1.10:35620 dest: /172.20.1.11:9866
2025-03-26 02:26:29,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742384_1560 src: /172.20.1.11:50040 dest: /172.20.1.13:9866
2025-03-26 02:26:29,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742384_1560 src: /172.20.1.13:50092 dest: /172.20.1.12:9866
2025-03-26 02:26:29,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:50092, dest: /172.20.1.12:9866, bytes: 1121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742384_1560, duration(ns): 664166
2025-03-26 02:26:29,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742384_1560, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,837 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:35620, dest: /172.20.1.11:9866, bytes: 1121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742384_1560, duration(ns): 1329270
2025-03-26 02:26:29,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:50040, dest: /172.20.1.13:9866, bytes: 1121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742384_1560, duration(ns): 845189
2025-03-26 02:26:29,837 INFO terminating
2025-03-26 02:26:29,837 INFO terminating
2025-03-26 02:26:29,841 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742385_1561, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java._COPYING_
2025-03-26 02:26:29,841 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,841 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742385_1561 src: /172.20.1.10:34258 dest: /172.20.1.13:9866
2025-03-26 02:26:29,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742385_1561 src: /172.20.1.11:45234 dest: /172.20.1.12:9866
2025-03-26 02:26:29,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742385_1561 src: /172.20.1.13:53788 dest: /172.20.1.11:9866
2025-03-26 02:26:29,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45234, dest: /172.20.1.12:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742385_1561, duration(ns): 856405
2025-03-26 02:26:29,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742385_1561, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34258, dest: /172.20.1.13:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742385_1561, duration(ns): 1260525
2025-03-26 02:26:29,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53788, dest: /172.20.1.11:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742385_1561, duration(ns): 1032373
2025-03-26 02:26:29,845 INFO terminating
2025-03-26 02:26:29,845 INFO terminating
2025-03-26 02:26:29,846 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,849 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742386_1562, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java._COPYING_
2025-03-26 02:26:29,849 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,849 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742386_1562 src: /172.20.1.10:50864 dest: /172.20.1.12:9866
2025-03-26 02:26:29,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742386_1562 src: /172.20.1.12:59726 dest: /172.20.1.13:9866
2025-03-26 02:26:29,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742386_1562 src: /172.20.1.13:53790 dest: /172.20.1.11:9866
2025-03-26 02:26:29,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50864, dest: /172.20.1.12:9866, bytes: 4153, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742386_1562, duration(ns): 1359726
2025-03-26 02:26:29,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59726, dest: /172.20.1.13:9866, bytes: 4153, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742386_1562, duration(ns): 1144421
2025-03-26 02:26:29,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53790, dest: /172.20.1.11:9866, bytes: 4153, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742386_1562, duration(ns): 664821
2025-03-26 02:26:29,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742386_1562, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,853 INFO terminating
2025-03-26 02:26:29,853 INFO terminating
2025-03-26 02:26:29,854 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742387_1563, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java._COPYING_
2025-03-26 02:26:29,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742387_1563 src: /172.20.1.10:50876 dest: /172.20.1.12:9866
2025-03-26 02:26:29,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742387_1563 src: /172.20.1.11:50054 dest: /172.20.1.13:9866
2025-03-26 02:26:29,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742387_1563 src: /172.20.1.12:49934 dest: /172.20.1.11:9866
2025-03-26 02:26:29,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:50054, dest: /172.20.1.13:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742387_1563, duration(ns): 488387
2025-03-26 02:26:29,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742387_1563, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,861 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50876, dest: /172.20.1.12:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742387_1563, duration(ns): 897076
2025-03-26 02:26:29,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:49934, dest: /172.20.1.11:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742387_1563, duration(ns): 646776
2025-03-26 02:26:29,861 INFO terminating
2025-03-26 02:26:29,861 INFO terminating
2025-03-26 02:26:29,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742388_1564, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java._COPYING_
2025-03-26 02:26:29,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742388_1564 src: /172.20.1.10:34266 dest: /172.20.1.13:9866
2025-03-26 02:26:29,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742388_1564 src: /172.20.1.13:53800 dest: /172.20.1.11:9866
2025-03-26 02:26:29,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742388_1564 src: /172.20.1.11:45250 dest: /172.20.1.12:9866
2025-03-26 02:26:29,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45250, dest: /172.20.1.12:9866, bytes: 5118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742388_1564, duration(ns): 631404
2025-03-26 02:26:29,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53800, dest: /172.20.1.11:9866, bytes: 5118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742388_1564, duration(ns): 728069
2025-03-26 02:26:29,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742388_1564, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,868 INFO terminating
2025-03-26 02:26:29,869 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34266, dest: /172.20.1.13:9866, bytes: 5118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742388_1564, duration(ns): 1037850
2025-03-26 02:26:29,869 INFO terminating
2025-03-26 02:26:29,872 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742389_1565, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java._COPYING_
2025-03-26 02:26:29,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742389_1565 src: /172.20.1.10:50880 dest: /172.20.1.12:9866
2025-03-26 02:26:29,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742389_1565 src: /172.20.1.12:59736 dest: /172.20.1.13:9866
2025-03-26 02:26:29,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742389_1565 src: /172.20.1.13:53816 dest: /172.20.1.11:9866
2025-03-26 02:26:29,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59736, dest: /172.20.1.13:9866, bytes: 2485, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742389_1565, duration(ns): 4730383
2025-03-26 02:26:29,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53816, dest: /172.20.1.11:9866, bytes: 2485, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742389_1565, duration(ns): 4421751
2025-03-26 02:26:29,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742389_1565, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,881 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50880, dest: /172.20.1.12:9866, bytes: 2485, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742389_1565, duration(ns): 5031365
2025-03-26 02:26:29,881 INFO terminating
2025-03-26 02:26:29,881 INFO terminating
2025-03-26 02:26:29,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742390_1566, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java._COPYING_
2025-03-26 02:26:29,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742390_1566 src: /172.20.1.10:50892 dest: /172.20.1.12:9866
2025-03-26 02:26:29,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742390_1566 src: /172.20.1.12:59742 dest: /172.20.1.13:9866
2025-03-26 02:26:29,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742390_1566 src: /172.20.1.13:53818 dest: /172.20.1.11:9866
2025-03-26 02:26:29,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59742, dest: /172.20.1.13:9866, bytes: 4343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742390_1566, duration(ns): 815803
2025-03-26 02:26:29,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53818, dest: /172.20.1.11:9866, bytes: 4343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742390_1566, duration(ns): 617035
2025-03-26 02:26:29,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742390_1566, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,889 INFO terminating
2025-03-26 02:26:29,890 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50892, dest: /172.20.1.12:9866, bytes: 4343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742390_1566, duration(ns): 1085233
2025-03-26 02:26:29,890 INFO terminating
2025-03-26 02:26:29,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742391_1567, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_
2025-03-26 02:26:29,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742391_1567 src: /172.20.1.10:34278 dest: /172.20.1.13:9866
2025-03-26 02:26:29,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742391_1567 src: /172.20.1.11:45260 dest: /172.20.1.12:9866
2025-03-26 02:26:29,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742391_1567 src: /172.20.1.13:53826 dest: /172.20.1.11:9866
2025-03-26 02:26:29,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45260, dest: /172.20.1.12:9866, bytes: 7759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742391_1567, duration(ns): 683470
2025-03-26 02:26:29,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34278, dest: /172.20.1.13:9866, bytes: 7759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742391_1567, duration(ns): 1204577
2025-03-26 02:26:29,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53826, dest: /172.20.1.11:9866, bytes: 7759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742391_1567, duration(ns): 879291
2025-03-26 02:26:29,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742391_1567, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,898 INFO terminating
2025-03-26 02:26:29,898 INFO terminating
2025-03-26 02:26:29,899 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:29,904 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742392_1568, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scripts/getGpusResources.sh._COPYING_
2025-03-26 02:26:29,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:29,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742392_1568 src: /172.20.1.10:50896 dest: /172.20.1.12:9866
2025-03-26 02:26:29,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742392_1568 src: /172.20.1.12:59746 dest: /172.20.1.13:9866
2025-03-26 02:26:29,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073742392_1568 src: /172.20.1.13:53834 dest: /172.20.1.11:9866
2025-03-26 02:26:29,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:53834, dest: /172.20.1.11:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 3bda9607-08c1-4368-b60c-1744aad33afb, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742392_1568, duration(ns): 598436
2025-03-26 02:26:29,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50896, dest: /172.20.1.12:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: 22bd61df-69f7-43b2-b990-c531a31b5f9e, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742392_1568, duration(ns): 1091934
2025-03-26 02:26:29,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:59746, dest: /172.20.1.13:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_67606808_1, offset: 0, srvID: e739152d-7034-4d09-8901-eb5c4e443829, blockid: BP-1623173709-172.20.1.10-1742955953500:blk_1073742392_1568, duration(ns): 866372
2025-03-26 02:26:29,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623173709-172.20.1.10-1742955953500:blk_1073742392_1568, type=LAST_IN_PIPELINE terminating
2025-03-26 02:26:29,908 INFO terminating
2025-03-26 02:26:29,908 INFO terminating
2025-03-26 02:26:29,909 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scripts/getGpusResources.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_67606808_1
2025-03-26 02:26:31,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741881_1057 to 172.20.1.11:9866
2025-03-26 02:26:31,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741882_1058 to 172.20.1.11:9866
2025-03-26 02:26:31,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741883_1059 to 172.20.1.11:9866
2025-03-26 02:26:31,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741884_1060 to 172.20.1.11:9866
2025-03-26 02:26:31,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741881_1057 src: /172.20.1.13:53848 dest: /172.20.1.11:9866
2025-03-26 02:26:31,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741881_1057 (numBytes=1512) to /172.20.1.11:9866
2025-03-26 02:26:31,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741882_1058 (numBytes=1791) to /172.20.1.11:9866
2025-03-26 02:26:31,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741882_1058 src: /172.20.1.13:53852 dest: /172.20.1.11:9866
2025-03-26 02:26:31,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741883_1059 (numBytes=2246) to /172.20.1.11:9866
2025-03-26 02:26:31,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741884_1060 (numBytes=2530) to /172.20.1.11:9866
2025-03-26 02:26:31,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741883_1059 src: /172.20.1.12:49942 dest: /172.20.1.11:9866
2025-03-26 02:26:31,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741884_1060 src: /172.20.1.12:49944 dest: /172.20.1.11:9866
2025-03-26 02:26:31,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741881_1057 src: /172.20.1.13:53848 dest: /172.20.1.11:9866 of size 1512
2025-03-26 02:26:31,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741882_1058 src: /172.20.1.13:53852 dest: /172.20.1.11:9866 of size 1791
2025-03-26 02:26:31,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741884_1060 src: /172.20.1.12:49944 dest: /172.20.1.11:9866 of size 2530
2025-03-26 02:26:31,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741883_1059 src: /172.20.1.12:49942 dest: /172.20.1.11:9866 of size 2246
2025-03-26 02:26:32,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:32,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:34,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741887_1063 (numBytes=1789) to /172.20.1.11:9866
2025-03-26 02:26:34,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741889_1065 (numBytes=1712) to /172.20.1.11:9866
2025-03-26 02:26:34,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741887_1063 to 172.20.1.11:9866
2025-03-26 02:26:34,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741889_1065 to 172.20.1.11:9866
2025-03-26 02:26:34,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741887_1063 src: /172.20.1.13:53868 dest: /172.20.1.11:9866
2025-03-26 02:26:34,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741889_1065 src: /172.20.1.13:53880 dest: /172.20.1.11:9866
2025-03-26 02:26:34,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741888_1064 to 172.20.1.11:9866
2025-03-26 02:26:34,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741889_1065 src: /172.20.1.13:53880 dest: /172.20.1.11:9866 of size 1712
2025-03-26 02:26:34,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741890_1066 to 172.20.1.11:9866
2025-03-26 02:26:34,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741887_1063 src: /172.20.1.13:53868 dest: /172.20.1.11:9866 of size 1789
2025-03-26 02:26:34,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741888_1064 (numBytes=2341) to /172.20.1.11:9866
2025-03-26 02:26:34,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741890_1066 (numBytes=1513) to /172.20.1.11:9866
2025-03-26 02:26:34,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741890_1066 src: /172.20.1.12:49948 dest: /172.20.1.11:9866 of size 1513
2025-03-26 02:26:34,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741890_1066 src: /172.20.1.12:49948 dest: /172.20.1.11:9866
2025-03-26 02:26:34,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741888_1064 src: /172.20.1.12:49962 dest: /172.20.1.11:9866 of size 2341
2025-03-26 02:26:34,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741888_1064 src: /172.20.1.12:49962 dest: /172.20.1.11:9866
2025-03-26 02:26:35,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:35,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:37,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741893_1069 to 172.20.1.11:9866
2025-03-26 02:26:37,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741894_1070 to 172.20.1.11:9866
2025-03-26 02:26:37,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741893_1069 (numBytes=2591) to /172.20.1.11:9866
2025-03-26 02:26:37,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741894_1070 (numBytes=784) to /172.20.1.11:9866
2025-03-26 02:26:37,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741895_1071 to 172.20.1.11:9866
2025-03-26 02:26:37,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741896_1072 to 172.20.1.11:9866
2025-03-26 02:26:37,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741894_1070 src: /172.20.1.13:36922 dest: /172.20.1.11:9866
2025-03-26 02:26:37,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741895_1071 (numBytes=2150) to /172.20.1.11:9866
2025-03-26 02:26:37,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741896_1072 (numBytes=1511) to /172.20.1.11:9866
2025-03-26 02:26:37,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741893_1069 src: /172.20.1.13:36916 dest: /172.20.1.11:9866 of size 2591
2025-03-26 02:26:37,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741894_1070 src: /172.20.1.13:36922 dest: /172.20.1.11:9866 of size 784
2025-03-26 02:26:37,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741893_1069 src: /172.20.1.13:36916 dest: /172.20.1.11:9866
2025-03-26 02:26:37,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741895_1071 src: /172.20.1.12:50576 dest: /172.20.1.11:9866
2025-03-26 02:26:37,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741895_1071 src: /172.20.1.12:50576 dest: /172.20.1.11:9866 of size 2150
2025-03-26 02:26:37,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741896_1072 src: /172.20.1.12:50578 dest: /172.20.1.11:9866 of size 1511
2025-03-26 02:26:37,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741896_1072 src: /172.20.1.12:50578 dest: /172.20.1.11:9866
2025-03-26 02:26:38,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:38,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:38,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:38,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:40,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741900_1076 to 172.20.1.11:9866
2025-03-26 02:26:40,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741902_1078 to 172.20.1.11:9866
2025-03-26 02:26:40,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741899_1075 to 172.20.1.11:9866
2025-03-26 02:26:40,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741901_1077 to 172.20.1.11:9866
2025-03-26 02:26:40,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741900_1076 (numBytes=1921) to /172.20.1.11:9866
2025-03-26 02:26:40,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741902_1078 (numBytes=2277) to /172.20.1.11:9866
2025-03-26 02:26:40,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741902_1078 src: /172.20.1.13:36926 dest: /172.20.1.11:9866
2025-03-26 02:26:40,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741899_1075 (numBytes=1280) to /172.20.1.11:9866
2025-03-26 02:26:40,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741901_1077 (numBytes=2083) to /172.20.1.11:9866
2025-03-26 02:26:40,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741900_1076 src: /172.20.1.13:36924 dest: /172.20.1.11:9866
2025-03-26 02:26:40,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741902_1078 src: /172.20.1.13:36926 dest: /172.20.1.11:9866 of size 2277
2025-03-26 02:26:40,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741899_1075 src: /172.20.1.12:50592 dest: /172.20.1.11:9866
2025-03-26 02:26:40,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741900_1076 src: /172.20.1.13:36924 dest: /172.20.1.11:9866 of size 1921
2025-03-26 02:26:40,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741899_1075 src: /172.20.1.12:50592 dest: /172.20.1.11:9866 of size 1280
2025-03-26 02:26:40,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741901_1077 src: /172.20.1.12:50606 dest: /172.20.1.11:9866
2025-03-26 02:26:40,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741901_1077 src: /172.20.1.12:50606 dest: /172.20.1.11:9866 of size 2083
2025-03-26 02:26:41,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:41,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:41,042 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:41,042 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:43,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741905_1081 to 172.20.1.11:9866
2025-03-26 02:26:43,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741906_1082 to 172.20.1.11:9866
2025-03-26 02:26:43,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741907_1083 to 172.20.1.11:9866
2025-03-26 02:26:43,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741905_1081 (numBytes=2049) to /172.20.1.11:9866
2025-03-26 02:26:43,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741906_1082 (numBytes=1839) to /172.20.1.11:9866
2025-03-26 02:26:43,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741908_1084 to 172.20.1.11:9866
2025-03-26 02:26:43,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741905_1081 src: /172.20.1.13:36942 dest: /172.20.1.11:9866
2025-03-26 02:26:43,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741906_1082 src: /172.20.1.13:36958 dest: /172.20.1.11:9866
2025-03-26 02:26:43,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741907_1083 (numBytes=1989) to /172.20.1.11:9866
2025-03-26 02:26:43,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741908_1084 (numBytes=2181) to /172.20.1.11:9866
2025-03-26 02:26:43,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741906_1082 src: /172.20.1.13:36958 dest: /172.20.1.11:9866 of size 1839
2025-03-26 02:26:43,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741907_1083 src: /172.20.1.12:50614 dest: /172.20.1.11:9866
2025-03-26 02:26:43,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741908_1084 src: /172.20.1.12:50622 dest: /172.20.1.11:9866
2025-03-26 02:26:43,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741905_1081 src: /172.20.1.13:36942 dest: /172.20.1.11:9866 of size 2049
2025-03-26 02:26:43,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741907_1083 src: /172.20.1.12:50614 dest: /172.20.1.11:9866 of size 1989
2025-03-26 02:26:43,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741908_1084 src: /172.20.1.12:50622 dest: /172.20.1.11:9866 of size 2181
2025-03-26 02:26:44,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:44,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:44,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:44,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:46,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741911_1087 to 172.20.1.11:9866
2025-03-26 02:26:46,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741912_1088 to 172.20.1.11:9866
2025-03-26 02:26:46,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741913_1089 to 172.20.1.11:9866
2025-03-26 02:26:46,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741914_1090 to 172.20.1.11:9866
2025-03-26 02:26:46,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741911_1087 src: /172.20.1.12:50626 dest: /172.20.1.11:9866
2025-03-26 02:26:46,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741912_1088 src: /172.20.1.12:50624 dest: /172.20.1.11:9866
2025-03-26 02:26:46,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741911_1087 (numBytes=1789) to /172.20.1.11:9866
2025-03-26 02:26:46,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741912_1088 (numBytes=1486) to /172.20.1.11:9866
2025-03-26 02:26:46,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741913_1089 (numBytes=2104) to /172.20.1.11:9866
2025-03-26 02:26:46,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741914_1090 (numBytes=1850) to /172.20.1.11:9866
2025-03-26 02:26:46,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741911_1087 src: /172.20.1.12:50626 dest: /172.20.1.11:9866 of size 1789
2025-03-26 02:26:46,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741912_1088 src: /172.20.1.12:50624 dest: /172.20.1.11:9866 of size 1486
2025-03-26 02:26:46,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741914_1090 src: /172.20.1.13:36978 dest: /172.20.1.11:9866 of size 1850
2025-03-26 02:26:46,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741914_1090 src: /172.20.1.13:36978 dest: /172.20.1.11:9866
2025-03-26 02:26:46,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741913_1089 src: /172.20.1.13:36968 dest: /172.20.1.11:9866 of size 2104
2025-03-26 02:26:46,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741913_1089 src: /172.20.1.13:36968 dest: /172.20.1.11:9866
2025-03-26 02:26:47,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:47,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:47,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:47,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:49,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741917_1093 to 172.20.1.11:9866
2025-03-26 02:26:49,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741919_1095 to 172.20.1.11:9866
2025-03-26 02:26:49,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741917_1093 (numBytes=3185) to /172.20.1.11:9866
2025-03-26 02:26:49,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741919_1095 (numBytes=784) to /172.20.1.11:9866
2025-03-26 02:26:49,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741917_1093 src: /172.20.1.13:44168 dest: /172.20.1.11:9866 of size 3185
2025-03-26 02:26:49,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741919_1095 src: /172.20.1.13:44166 dest: /172.20.1.11:9866 of size 784
2025-03-26 02:26:49,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741917_1093 src: /172.20.1.13:44168 dest: /172.20.1.11:9866
2025-03-26 02:26:49,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741919_1095 src: /172.20.1.13:44166 dest: /172.20.1.11:9866
2025-03-26 02:26:49,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741918_1094 (numBytes=1717) to /172.20.1.11:9866
2025-03-26 02:26:49,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741920_1096 (numBytes=3339) to /172.20.1.11:9866
2025-03-26 02:26:49,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741918_1094 to 172.20.1.11:9866
2025-03-26 02:26:49,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741920_1096 to 172.20.1.11:9866
2025-03-26 02:26:49,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741918_1094 src: /172.20.1.12:43164 dest: /172.20.1.11:9866
2025-03-26 02:26:49,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741920_1096 src: /172.20.1.12:43166 dest: /172.20.1.11:9866
2025-03-26 02:26:49,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741918_1094 src: /172.20.1.12:43164 dest: /172.20.1.11:9866 of size 1717
2025-03-26 02:26:49,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741920_1096 src: /172.20.1.12:43166 dest: /172.20.1.11:9866 of size 3339
2025-03-26 02:26:50,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:50,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:50,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:50,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:50,797 DEBUG org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-26 02:26:50,822 DEBUG org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-26 02:26:50,859 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-26 02:26:50,862 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-26 02:26:50,862 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-26 02:26:50,863 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-26 02:26:50,863 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-26 02:26:50,863 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-26 02:26:50,872 DEBUG org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-26 02:26:50,882 DEBUG org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-26 02:26:50,883 DEBUG org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-26 02:26:50,883 DEBUG org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-26 02:26:50,883 DEBUG org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-26 02:26:50,883 DEBUG org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-26 02:26:50,883 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-26 02:26:50,884 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-26 02:26:50,928 DEBUG org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-26 02:26:50,931 DEBUG org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-26 02:26:50,931 DEBUG org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-26 02:26:50,933 DEBUG org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-26 02:26:50,933 DEBUG org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-26 02:26:50,934 DEBUG org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.000s
2025-03-26 02:26:50,934 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:26:50,934 DEBUG org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-26 02:26:50,934 DEBUG org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-26 02:26:50,935 DEBUG org.apache.hadoop.fs.FileSystem: Loading filesystems
2025-03-26 02:26:50,935 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Creating FS file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:26:50,940 DEBUG org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.fs.LocalFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:50,942 DEBUG org.apache.hadoop.fs.FileSystem: viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:50,944 DEBUG org.apache.hadoop.fs.FileSystem: har:// = class org.apache.hadoop.fs.HarFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:50,945 DEBUG org.apache.hadoop.fs.FileSystem: http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:50,945 DEBUG org.apache.hadoop.fs.FileSystem: https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:50,948 DEBUG org.apache.hadoop.fs.FileSystem: hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:50,951 DEBUG org.apache.hadoop.fs.FileSystem: webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:50,952 DEBUG org.apache.hadoop.fs.FileSystem: nullscan:// = class org.apache.hadoop.hive.ql.io.NullScanFileSystem from /spark/jars/hive-exec-2.3.9-core.jar
2025-03-26 02:26:50,952 DEBUG org.apache.hadoop.fs.FileSystem: swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:26:50,953 DEBUG org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 02:26:50,953 DEBUG org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem from /spark/jars/hive-exec-2.3.9-core.jar
2025-03-26 02:26:50,953 DEBUG org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 02:26:50,970 DEBUG org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 02:26:50,970 DEBUG org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 02:26:50,972 DEBUG org.apache.hadoop.fs.FileSystem: Creating FS file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.037s
2025-03-26 02:26:50,973 DEBUG org.apache.hadoop.fs.Globber: Created Globber for path=file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar, symlinks=true
2025-03-26 02:26:50,973 DEBUG org.apache.hadoop.fs.Globber: Filesystem glob /spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:26:50,973 DEBUG org.apache.hadoop.fs.Globber: Pattern: /spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:26:50,973 DEBUG org.apache.hadoop.fs.Globber: Starting: glob file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:26:50,988 DEBUG org.apache.hadoop.fs.Globber: Component spark, patterned=false
2025-03-26 02:26:50,990 DEBUG org.apache.hadoop.fs.Globber: Component examples, patterned=false
2025-03-26 02:26:50,990 DEBUG org.apache.hadoop.fs.Globber: Component jars, patterned=false
2025-03-26 02:26:50,992 DEBUG org.apache.hadoop.fs.Globber: Component spark-examples_2.12-3.3.2.jar, patterned=false
2025-03-26 02:26:50,993 DEBUG org.apache.hadoop.fs.Globber: glob file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.020s
2025-03-26 02:26:51,055 DEBUG org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.YarnClientImpl entered state INITED
2025-03-26 02:26:51,082 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.10:8032
2025-03-26 02:26:51,083 DEBUG org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.RMProxy$1@184497d1] java.lang.Exception at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852) at org.apache.hadoop.yarn.client.RMProxy.getProxy(RMProxy.java:145) at org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider.init(DefaultNoHARMFailoverProxyProvider.java:65) at org.apache.hadoop.yarn.client.RMProxy.createNonHaRMFailoverProxyProvider(RMProxy.java:172) at org.apache.hadoop.yarn.client.RMProxy.newProxyInstance(RMProxy.java:132) at org.apache.hadoop.yarn.client.RMProxy.createRMProxy(RMProxy.java:103) at org.apache.hadoop.yarn.client.ClientRMProxy.createRMProxy(ClientRMProxy.java:73) at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceStart(YarnClientImpl.java:242) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194) at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:192) at org.apache.spark.deploy.yarn.Client.run(Client.scala:1327) at org.apache.spark.deploy.yarn.YarnClusterApplication.start(Client.scala:1764) at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958) at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180) at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203) at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90) at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046) at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055) at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2025-03-26 02:26:51,084 DEBUG org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ApplicationClientProtocol
2025-03-26 02:26:51,084 DEBUG org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 02:26:51,100 DEBUG org.apache.hadoop.ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker@3bde62ff
2025-03-26 02:26:51,103 DEBUG org.apache.hadoop.ipc.Client: getting client out of cache: Client-3b23f13e1091407a8b325b1c8baf943a
2025-03-26 02:26:51,158 DEBUG org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.YarnClientImpl is started
2025-03-26 02:26:51,197 DEBUG org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 02:26:51,198 DEBUG org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.10:8032
2025-03-26 02:26:51,199 DEBUG org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.10:8032
2025-03-26 02:26:51,210 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:8032 from root: starting, having connections 1
2025-03-26 02:26:51,211 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:8032 from root sending #0 org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getClusterMetrics
2025-03-26 02:26:51,226 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:8032 from root got value #0
2025-03-26 02:26:51,226 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getClusterMetrics took 51ms
2025-03-26 02:26:51,228 DEBUG org.apache.spark.deploy.yarn.Client: Requesting a new application from cluster with 3 NodeManagers
2025-03-26 02:26:51,239 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:8032 from root sending #1 org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getNewApplication
2025-03-26 02:26:51,248 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2025-03-26 02:26:51,251 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:8032 from root got value #1
2025-03-26 02:26:51,251 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getNewApplication took 12ms
2025-03-26 02:26:51,254 DEBUG org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for hdfs://master:9000: duration 0:00.000s
2025-03-26 02:26:51,254 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for hdfs://master:9000
2025-03-26 02:26:51,255 DEBUG org.apache.hadoop.fs.FileSystem: FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2025-03-26 02:26:51,255 DEBUG org.apache.hadoop.fs.FileSystem: Looking for FS supporting hdfs
2025-03-26 02:26:51,255 DEBUG org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 02:26:51,255 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Creating FS hdfs://master:9000
2025-03-26 02:26:51,255 DEBUG org.apache.hadoop.fs.FileSystem: looking for configuration option fs.hdfs.impl
2025-03-26 02:26:51,263 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.domain.socket.data.traffic = false
2025-03-26 02:26:51,263 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.read.shortcircuit = false
2025-03-26 02:26:51,263 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.use.legacy.blockreader.local = false
2025-03-26 02:26:51,263 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.domain.socket.path =
2025-03-26 02:26:51,265 DEBUG org.apache.hadoop.hdfs.DFSClient: Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2025-03-26 02:26:51,267 DEBUG org.apache.hadoop.io.retry.RetryUtils: multipleLinearRandomRetry = null
2025-03-26 02:26:51,270 DEBUG org.apache.hadoop.ipc.Client: getting client out of cache: Client-3b23f13e1091407a8b325b1c8baf943a
2025-03-26 02:26:51,417 DEBUG org.apache.hadoop.util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
2025-03-26 02:26:51,419 DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2025-03-26 02:26:51,421 DEBUG org.apache.hadoop.fs.FileSystem: Creating FS hdfs://master:9000: duration 0:00.165s
2025-03-26 02:26:51,456 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:26:51,456 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:26:51,459 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
2025-03-26 02:26:51,459 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE
2025-03-26 02:26:51,459 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-mb'
2025-03-26 02:26:51,459 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-mb'
2025-03-26 02:26:51,459 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-vcores'
2025-03-26 02:26:51,459 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-vcores'
2025-03-26 02:26:51,462 INFO org.apache.spark.deploy.yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
2025-03-26 02:26:51,465 DEBUG org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.10:9000
2025-03-26 02:26:51,465 DEBUG org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.10:9000
2025-03-26 02:26:51,465 DEBUG org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 02:26:51,466 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:9000 from root sending #2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete
2025-03-26 02:26:51,466 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:9000 from root: starting, having connections 2
2025-03-26 02:26:51,469 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:9000 from root got value #2
2025-03-26 02:26:51,469 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: delete took 4ms
2025-03-26 02:26:51,471 INFO org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-26 02:26:51,472 INFO org.apache.spark.util.ShutdownHookManager: Deleting directory /tmp/spark-6dd6bbb7-79ea-4f58-98cc-2a498d7f33ac
2025-03-26 02:26:51,473 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (root (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 202608f3
2025-03-26 02:26:51,473 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 384077b6
2025-03-26 02:26:51,473 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:1518)); Key: (root (auth:SIMPLE))@hdfs://master:9000; URI: hdfs://master:9000; Object Identity Hash: 4c19b7f1
2025-03-26 02:26:51,473 DEBUG org.apache.hadoop.ipc.Client: stopping client from cache: Client-3b23f13e1091407a8b325b1c8baf943a
2025-03-26 02:26:51,474 DEBUG org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.004 seconds; Timeouts: 0
2025-03-26 02:26:51,482 DEBUG org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
2025-03-26 02:26:52,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741924_1100 to 172.20.1.11:9866
2025-03-26 02:26:52,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741925_1101 to 172.20.1.11:9866
2025-03-26 02:26:52,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741924_1100 (numBytes=1600) to /172.20.1.11:9866
2025-03-26 02:26:52,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741925_1101 (numBytes=2653) to /172.20.1.11:9866
2025-03-26 02:26:52,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741925_1101 src: /172.20.1.13:44192 dest: /172.20.1.11:9866
2025-03-26 02:26:52,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741925_1101 src: /172.20.1.13:44192 dest: /172.20.1.11:9866 of size 2653
2025-03-26 02:26:52,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741924_1100 src: /172.20.1.13:44200 dest: /172.20.1.11:9866
2025-03-26 02:26:52,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741923_1099 to 172.20.1.11:9866
2025-03-26 02:26:52,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741926_1102 to 172.20.1.11:9866
2025-03-26 02:26:52,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741924_1100 src: /172.20.1.13:44200 dest: /172.20.1.11:9866 of size 1600
2025-03-26 02:26:52,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741926_1102 src: /172.20.1.12:43180 dest: /172.20.1.11:9866
2025-03-26 02:26:52,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741923_1099 (numBytes=1610) to /172.20.1.11:9866
2025-03-26 02:26:52,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741926_1102 (numBytes=1646) to /172.20.1.11:9866
2025-03-26 02:26:52,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741926_1102 src: /172.20.1.12:43180 dest: /172.20.1.11:9866 of size 1646
2025-03-26 02:26:52,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741923_1099 src: /172.20.1.12:43184 dest: /172.20.1.11:9866
2025-03-26 02:26:52,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741923_1099 src: /172.20.1.12:43184 dest: /172.20.1.11:9866 of size 1610
2025-03-26 02:26:53,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:53,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:53,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:53,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:55,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741931_1107 to 172.20.1.11:9866
2025-03-26 02:26:55,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741932_1108 to 172.20.1.11:9866
2025-03-26 02:26:55,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741931_1107 src: /172.20.1.13:44204 dest: /172.20.1.11:9866
2025-03-26 02:26:55,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741931_1107 (numBytes=1395) to /172.20.1.11:9866
2025-03-26 02:26:55,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741932_1108 (numBytes=3904) to /172.20.1.11:9866
2025-03-26 02:26:55,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741931_1107 src: /172.20.1.13:44204 dest: /172.20.1.11:9866 of size 1395
2025-03-26 02:26:55,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741929_1105 to 172.20.1.11:9866
2025-03-26 02:26:55,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741930_1106 to 172.20.1.11:9866
2025-03-26 02:26:55,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741932_1108 src: /172.20.1.13:44214 dest: /172.20.1.11:9866 of size 3904
2025-03-26 02:26:55,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741932_1108 src: /172.20.1.13:44214 dest: /172.20.1.11:9866
2025-03-26 02:26:55,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741929_1105 (numBytes=1934) to /172.20.1.11:9866
2025-03-26 02:26:55,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741930_1106 (numBytes=1863) to /172.20.1.11:9866
2025-03-26 02:26:55,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741929_1105 src: /172.20.1.12:43192 dest: /172.20.1.11:9866 of size 1934
2025-03-26 02:26:55,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741930_1106 src: /172.20.1.12:43190 dest: /172.20.1.11:9866 of size 1863
2025-03-26 02:26:55,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741929_1105 src: /172.20.1.12:43192 dest: /172.20.1.11:9866
2025-03-26 02:26:55,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741930_1106 src: /172.20.1.12:43190 dest: /172.20.1.11:9866
2025-03-26 02:26:56,047 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:56,047 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:56,047 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:56,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:58,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741937_1113 to 172.20.1.11:9866
2025-03-26 02:26:58,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741938_1114 to 172.20.1.11:9866
2025-03-26 02:26:58,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741938_1114 (numBytes=1978) to /172.20.1.11:9866
2025-03-26 02:26:58,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741938_1114 src: /172.20.1.13:60700 dest: /172.20.1.11:9866
2025-03-26 02:26:58,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741937_1113 (numBytes=2654) to /172.20.1.11:9866
2025-03-26 02:26:58,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741937_1113 src: /172.20.1.13:60706 dest: /172.20.1.11:9866 of size 2654
2025-03-26 02:26:58,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741938_1114 src: /172.20.1.13:60700 dest: /172.20.1.11:9866 of size 1978
2025-03-26 02:26:58,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741937_1113 src: /172.20.1.13:60706 dest: /172.20.1.11:9866
2025-03-26 02:26:58,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741935_1111 to 172.20.1.11:9866
2025-03-26 02:26:58,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741936_1112 to 172.20.1.11:9866
2025-03-26 02:26:58,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741935_1111 src: /172.20.1.12:56850 dest: /172.20.1.11:9866
2025-03-26 02:26:58,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741935_1111 (numBytes=1885) to /172.20.1.11:9866
2025-03-26 02:26:58,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741936_1112 (numBytes=1956) to /172.20.1.11:9866
2025-03-26 02:26:58,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741935_1111 src: /172.20.1.12:56850 dest: /172.20.1.11:9866 of size 1885
2025-03-26 02:26:58,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741936_1112 src: /172.20.1.12:56866 dest: /172.20.1.11:9866
2025-03-26 02:26:58,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741936_1112 src: /172.20.1.12:56866 dest: /172.20.1.11:9866 of size 1956
2025-03-26 02:26:59,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:59,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:59,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:26:59,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:00,869 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 3467
2025-03-26 02:27:00,869 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2025-03-26 02:27:00,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.20.1.10
2025-03-26 02:27:00,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3468 Total time for transactions(ms): 79 Number of transactions batched in Syncs: 786 Number of syncs: 2682 SyncTimes(ms): 996
2025-03-26 02:27:00,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3468 Total time for transactions(ms): 79 Number of transactions batched in Syncs: 786 Number of syncs: 2683 SyncTimes(ms): 997
2025-03-26 02:27:00,871 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000003468
2025-03-26 02:27:00,884 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3469
2025-03-26 02:27:00,919 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2025-03-26 02:27:00,920 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master:9870/imagetransfer?getimage=1&txid=0&storageInfo=-66:1390501960:1742955953500:CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778&bootstrapstandby=false
2025-03-26 02:27:00,963 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/name/current/fsimage_0000000000000000000, fileSize: 399. Sent total: 399 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:27:00,976 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.01s. The file download took 0.01s at 0.00 KB/s. Synchronous (fsync) write to disk of /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000000000 took 0.00s.
2025-03-26 02:27:00,976 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 399 bytes.
2025-03-26 02:27:00,981 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master:9870/imagetransfer?getedit=1&startTxId=1&endTxId=3468&storageInfo=-66:1390501960:1742955953500:CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778
2025-03-26 02:27:00,984 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000003468, fileSize: 478231. Sent total: 478231 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:27:00,987 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 467000.00 KB/s. Synchronous (fsync) write to disk of /data/tmp/dfs/namesecondary/current/edits_tmp_0000000000000000001-0000000000000003468_0000000000007354923 took 0.00s.
2025-03-26 02:27:00,988 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000003468_0000000000007354923 size 0 bytes.
2025-03-26 02:27:01,034 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2025-03-26 02:27:01,039 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
2025-03-26 02:27:01,043 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-26 02:27:01,047 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/tmp/dfs/namesecondary/current/fsimage_0000000000000000000
2025-03-26 02:27:01,047 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2025-03-26 02:27:01,047 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2025-03-26 02:27:01,051 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2025-03-26 02:27:01,055 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468 expecting start txid #1
2025-03-26 02:27:01,055 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468 maxTxnsToRead = 9223372036854775807
2025-03-26 02:27:01,248 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded 1 edits file(s) (the last named /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468) of total size 478231.0, total edits 3468.0, total load time 183.0 ms
2025-03-26 02:27:01,270 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003468 using no compression
2025-03-26 02:27:01,327 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003468 of size 54040 bytes saved in 0 seconds .
2025-03-26 02:27:01,329 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/namesecondary
2025-03-26 02:27:01,340 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/namesecondary
2025-03-26 02:27:01,360 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2025-03-26 02:27:01,361 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/namesecondary/current/fsimage_0000000000000003468, fileSize: 54040. Sent total: 54040 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:27:01,364 INFO org.apache.hadoop.hdfs.server.namenode.ImageServlet: Rejecting a fsimage due to small time delta and txnid delta. Time since previous checkpoint is 67 expecting at least 2700 txnid delta since previous checkpoint is 3468 expecting at least 1000000
2025-03-26 02:27:01,369 WARN [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:25:59 GMT 2025 Last Checkpoint        : -- (7294 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 54040
2025-03-26 02:27:01,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741942_1118 to 172.20.1.11:9866
2025-03-26 02:27:01,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741943_1119 to 172.20.1.11:9866
2025-03-26 02:27:01,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741942_1118 src: /172.20.1.13:60722 dest: /172.20.1.11:9866
2025-03-26 02:27:01,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741942_1118 (numBytes=1343) to /172.20.1.11:9866
2025-03-26 02:27:01,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741943_1119 (numBytes=1483) to /172.20.1.11:9866
2025-03-26 02:27:01,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741942_1118 src: /172.20.1.13:60722 dest: /172.20.1.11:9866 of size 1343
2025-03-26 02:27:01,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741943_1119 src: /172.20.1.13:60732 dest: /172.20.1.11:9866 of size 1483
2025-03-26 02:27:01,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741943_1119 src: /172.20.1.13:60732 dest: /172.20.1.11:9866
2025-03-26 02:27:01,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741941_1117 (numBytes=1677) to /172.20.1.11:9866
2025-03-26 02:27:01,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741944_1120 (numBytes=1580) to /172.20.1.11:9866
2025-03-26 02:27:01,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741941_1117 to 172.20.1.11:9866
2025-03-26 02:27:01,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741944_1120 to 172.20.1.11:9866
2025-03-26 02:27:01,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741944_1120 src: /172.20.1.12:56878 dest: /172.20.1.11:9866
2025-03-26 02:27:01,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741944_1120 src: /172.20.1.12:56878 dest: /172.20.1.11:9866 of size 1580
2025-03-26 02:27:01,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741941_1117 src: /172.20.1.12:56880 dest: /172.20.1.11:9866
2025-03-26 02:27:01,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741941_1117 src: /172.20.1.12:56880 dest: /172.20.1.11:9866 of size 1677
2025-03-26 02:27:02,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:02,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:02,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:02,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:04,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741947_1123 to 172.20.1.11:9866
2025-03-26 02:27:04,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741948_1124 to 172.20.1.11:9866
2025-03-26 02:27:04,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741948_1124 (numBytes=2402) to /172.20.1.11:9866
2025-03-26 02:27:04,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741947_1123 src: /172.20.1.13:60746 dest: /172.20.1.11:9866
2025-03-26 02:27:04,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741948_1124 src: /172.20.1.13:60740 dest: /172.20.1.11:9866
2025-03-26 02:27:04,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741947_1123 src: /172.20.1.13:60746 dest: /172.20.1.11:9866 of size 2936
2025-03-26 02:27:04,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741948_1124 src: /172.20.1.13:60740 dest: /172.20.1.11:9866 of size 2402
2025-03-26 02:27:04,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741949_1125 to 172.20.1.11:9866
2025-03-26 02:27:04,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741950_1126 to 172.20.1.11:9866
2025-03-26 02:27:04,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741949_1125 src: /172.20.1.12:56886 dest: /172.20.1.11:9866
2025-03-26 02:27:04,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741947_1123 (numBytes=2936) to /172.20.1.11:9866
2025-03-26 02:27:04,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741949_1125 src: /172.20.1.12:56886 dest: /172.20.1.11:9866 of size 2121
2025-03-26 02:27:04,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741950_1126 src: /172.20.1.12:56902 dest: /172.20.1.11:9866 of size 1496
2025-03-26 02:27:04,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741950_1126 src: /172.20.1.12:56902 dest: /172.20.1.11:9866
2025-03-26 02:27:04,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741949_1125 (numBytes=2121) to /172.20.1.11:9866
2025-03-26 02:27:04,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741950_1126 (numBytes=1496) to /172.20.1.11:9866
2025-03-26 02:27:05,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:05,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:05,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:05,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:07,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741953_1129 to 172.20.1.11:9866
2025-03-26 02:27:07,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741955_1131 to 172.20.1.11:9866
2025-03-26 02:27:07,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741953_1129 src: /172.20.1.13:60254 dest: /172.20.1.11:9866 of size 1477
2025-03-26 02:27:07,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741953_1129 src: /172.20.1.13:60254 dest: /172.20.1.11:9866
2025-03-26 02:27:07,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741953_1129 (numBytes=1477) to /172.20.1.11:9866
2025-03-26 02:27:07,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741955_1131 (numBytes=2855) to /172.20.1.11:9866
2025-03-26 02:27:07,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741954_1130 to 172.20.1.11:9866
2025-03-26 02:27:07,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741956_1132 to 172.20.1.11:9866
2025-03-26 02:27:07,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741955_1131 src: /172.20.1.13:60268 dest: /172.20.1.11:9866 of size 2855
2025-03-26 02:27:07,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741955_1131 src: /172.20.1.13:60268 dest: /172.20.1.11:9866
2025-03-26 02:27:07,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741956_1132 src: /172.20.1.12:39204 dest: /172.20.1.11:9866 of size 2661
2025-03-26 02:27:07,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741954_1130 src: /172.20.1.12:39202 dest: /172.20.1.11:9866
2025-03-26 02:27:07,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741956_1132 src: /172.20.1.12:39204 dest: /172.20.1.11:9866
2025-03-26 02:27:07,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741954_1130 (numBytes=2042) to /172.20.1.11:9866
2025-03-26 02:27:07,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741956_1132 (numBytes=2661) to /172.20.1.11:9866
2025-03-26 02:27:07,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741954_1130 src: /172.20.1.12:39202 dest: /172.20.1.11:9866 of size 2042
2025-03-26 02:27:08,051 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:08,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:08,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:08,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:10,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741960_1136 to 172.20.1.11:9866
2025-03-26 02:27:10,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=e739152d-7034-4d09-8901-eb5c4e443829, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741961_1137 to 172.20.1.11:9866
2025-03-26 02:27:10,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741959_1135 to 172.20.1.11:9866
2025-03-26 02:27:10,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741960_1136 src: /172.20.1.13:60272 dest: /172.20.1.11:9866
2025-03-26 02:27:10,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741961_1137 src: /172.20.1.13:60276 dest: /172.20.1.11:9866
2025-03-26 02:27:10,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=22bd61df-69f7-43b2-b990-c531a31b5f9e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a1dabc16-eb08-4daa-a1a9-870ff4c03778;nsid=1390501960;c=1742955953500) Starting thread to transfer BP-1623173709-172.20.1.10-1742955953500:blk_1073741962_1138 to 172.20.1.11:9866
2025-03-26 02:27:10,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741960_1136 src: /172.20.1.13:60272 dest: /172.20.1.11:9866 of size 1990
2025-03-26 02:27:10,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741961_1137 (numBytes=2841) to /172.20.1.11:9866
2025-03-26 02:27:10,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741961_1137 src: /172.20.1.13:60276 dest: /172.20.1.11:9866 of size 2841
2025-03-26 02:27:10,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741960_1136 (numBytes=1990) to /172.20.1.11:9866
2025-03-26 02:27:10,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741959_1135 src: /172.20.1.12:39212 dest: /172.20.1.11:9866
2025-03-26 02:27:10,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741959_1135 (numBytes=2591) to /172.20.1.11:9866
2025-03-26 02:27:10,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623173709-172.20.1.10-1742955953500:blk_1073741962_1138 (numBytes=1868) to /172.20.1.11:9866
2025-03-26 02:27:10,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741959_1135 src: /172.20.1.12:39212 dest: /172.20.1.11:9866 of size 2591
2025-03-26 02:27:10,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623173709-172.20.1.10-1742955953500:blk_1073741962_1138 src: /172.20.1.12:39220 dest: /172.20.1.11:9866
2025-03-26 02:27:10,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623173709-172.20.1.10-1742955953500:blk_1073741962_1138 src: /172.20.1.12:39220 dest: /172.20.1.11:9866 of size 1868
2025-03-26 02:27:11,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:11,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:11,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:27:11,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
