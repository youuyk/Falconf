program=ml.DeveloperApiExample
SPARKLORD_MODE=CONFIG_INJECTION
cpu_cores=2
cpu_util=200
memory=4g
config_file_name=spark-defaults.conf
config_key=spark.shuffle.push.maxRetainedMergerLocations
config_value=5

2025-03-26 04:58:43,003 INFO [main] org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/172.20.1.14
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.3.4
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z
STARTUP_MSG:   java = 1.8.0_432
************************************************************/
2025-03-26 04:58:43,007 INFO [main] org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 04:58:43,069 INFO [main] org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2025-03-26 04:58:43,144 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 04:58:43,204 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 04:58:43,204 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2025-03-26 04:58:43,213 INFO [main] org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://master:9000
2025-03-26 04:58:43,213 INFO [main] org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use master:9000 to access this namenode/service.
2025-03-26 04:58:43,334 INFO [org.apache.hadoop.util.JvmPauseMonitor$Monitor@865dd6] org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 04:58:43,343 INFO [main] org.apache.hadoop.hdfs.DFSUtil: Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-03-26 04:58:43,345 INFO [main] org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2025-03-26 04:58:43,352 INFO [main] org.eclipse.jetty.util.log: Logging initialized @620ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 04:58:43,409 WARN [main] org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 04:58:43,416 INFO [main] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2025-03-26 04:58:43,420 INFO [main] org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 04:58:43,421 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2025-03-26 04:58:43,421 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 04:58:43,421 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 04:58:43,422 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2025-03-26 04:58:43,422 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-03-26 04:58:43,423 INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-03-26 04:58:43,439 INFO [main] org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2025-03-26 04:58:43,443 INFO [main] org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2025-03-26 04:58:43,444 INFO [main] org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 04:58:43,456 INFO [main] org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 04:58:43,456 INFO [main] org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 04:58:43,456 INFO [main] org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 04:58:43,467 WARN [main] org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 04:58:43,468 INFO [main] org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b4c50bc{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 04:58:43,469 INFO [main] org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@79207381{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 04:58:43,506 INFO [main] org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@c7045b9{hdfs,/,file:///hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/hdfs}
2025-03-26 04:58:43,510 INFO [main] org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@17503f6b{HTTP/1.1, (http/1.1)}{0.0.0.0:9870}
2025-03-26 04:58:43,511 INFO [main] org.eclipse.jetty.server.Server: Started @779ms
2025-03-26 04:58:43,676 WARN [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-03-26 04:58:43,676 WARN [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-03-26 04:58:43,701 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2025-03-26 04:58:43,722 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2025-03-26 04:58:43,723 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2025-03-26 04:58:43,723 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2025-03-26 04:58:43,725 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)
2025-03-26 04:58:43,725 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup             = supergroup
2025-03-26 04:58:43,725 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled    = true
2025-03-26 04:58:43,726 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isStoragePolicyEnabled = true
2025-03-26 04:58:43,726 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2025-03-26 04:58:43,742 INFO [main] org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 04:58:43,745 INFO [main] org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.15" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 04:58:43,745 INFO [main] org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.16" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 04:58:43,745 INFO [main] org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.17" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 04:58:43,747 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-26 04:58:43,747 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-26 04:58:43,748 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-26 04:58:43,748 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2025 Mar 26 04:58:43
2025-03-26 04:58:43,749 INFO [main] org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2025-03-26 04:58:43,749 INFO [main] org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 04:58:43,750 INFO [main] org.apache.hadoop.util.GSet: 2.0% max memory 910.5 MB = 18.2 MB
2025-03-26 04:58:43,750 INFO [main] org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2025-03-26 04:58:43,754 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Storage policy satisfier is disabled
2025-03-26 04:58:43,754 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2025-03-26 04:58:43,757 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
2025-03-26 04:58:43,757 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2025-03-26 04:58:43,757 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2025-03-26 04:58:43,758 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2025-03-26 04:58:43,758 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2025-03-26 04:58:43,758 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2025-03-26 04:58:43,758 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2025-03-26 04:58:43,758 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2025-03-26 04:58:43,758 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2025-03-26 04:58:43,758 INFO [main] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2025-03-26 04:58:43,769 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2025-03-26 04:58:43,769 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2025-03-26 04:58:43,769 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2025-03-26 04:58:43,769 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2025-03-26 04:58:43,776 INFO [main] org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2025-03-26 04:58:43,776 INFO [main] org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 04:58:43,776 INFO [main] org.apache.hadoop.util.GSet: 1.0% max memory 910.5 MB = 9.1 MB
2025-03-26 04:58:43,776 INFO [main] org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2025-03-26 04:58:43,777 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? true
2025-03-26 04:58:43,777 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2025-03-26 04:58:43,777 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2025-03-26 04:58:43,777 INFO [main] org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2025-03-26 04:58:43,781 INFO [main] org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-03-26 04:58:43,781 INFO [main] org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2025-03-26 04:58:43,783 INFO [main] org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2025-03-26 04:58:43,783 INFO [main] org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 04:58:43,784 INFO [main] org.apache.hadoop.util.GSet: 0.25% max memory 910.5 MB = 2.3 MB
2025-03-26 04:58:43,784 INFO [main] org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2025-03-26 04:58:43,796 INFO [main] org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-26 04:58:43,796 INFO [main] org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2025-03-26 04:58:43,796 INFO [main] org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-26 04:58:43,800 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2025-03-26 04:58:43,800 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2025-03-26 04:58:43,801 INFO [main] org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2025-03-26 04:58:43,801 INFO [main] org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 04:58:43,801 INFO [main] org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 910.5 MB = 279.7 KB
2025-03-26 04:58:43,801 INFO [main] org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2025-03-26 04:58:44,056 INFO [main] org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/name/in_use.lock acquired by nodename 260@master
2025-03-26 04:58:44,072 INFO [main] org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/tmp/dfs/name/current
2025-03-26 04:58:44,072 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2025-03-26 04:58:44,073 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2025-03-26 04:58:44,107 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2025-03-26 04:58:44,110 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
2025-03-26 04:58:44,113 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-26 04:58:44,116 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2025-03-26 04:58:44,116 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/tmp/dfs/name/current/fsimage_0000000000000000000
2025-03-26 04:58:44,119 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2025-03-26 04:58:44,119 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2025-03-26 04:58:44,596 INFO [main] org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2025-03-26 04:58:44,596 INFO [main] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 794 msecs
2025-03-26 04:58:44,687 INFO [main] org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master:9000
2025-03-26 04:58:44,687 INFO [main] org.apache.hadoop.hdfs.server.namenode.NameNode: Enable NameNode state context:false
2025-03-26 04:58:44,693 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 04:58:44,701 INFO [Socket Reader #1 for port 9000] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2025-03-26 04:58:44,930 INFO [Listener at master/9000] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2025-03-26 04:58:44,938 INFO [Listener at master/9000] org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2025-03-26 04:58:44,943 INFO [Listener at master/9000] org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor: Initialized the Default Decommission and Maintenance monitor
2025-03-26 04:58:44,965 INFO [MarkedDeleteBlockScrubberThread] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Start MarkedDeleteBlockScrubber thread
2025-03-26 04:58:44,966 INFO [Listener at master/9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2025-03-26 04:58:44,967 INFO [Listener at master/9000] org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2025-03-26 04:58:44,967 INFO [Listener at master/9000] org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2025-03-26 04:58:44,967 INFO [Listener at master/9000] org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2025-03-26 04:58:44,983 INFO [Reconstruction Queue Initializer] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2025-03-26 04:58:44,983 INFO [Reconstruction Queue Initializer] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2025-03-26 04:58:44,983 INFO [Reconstruction Queue Initializer] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2025-03-26 04:58:44,983 INFO [Reconstruction Queue Initializer] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2025-03-26 04:58:44,983 INFO [Reconstruction Queue Initializer] org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2025-03-26 04:58:44,983 INFO [Reconstruction Queue Initializer] org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2025-03-26 04:58:44,993 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 04:58:44,994 INFO [IPC Server listener on 9000] org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2025-03-26 04:58:44,996 INFO [Listener at master/9000] org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master/172.20.1.14:9000
2025-03-26 04:58:44,998 INFO [Listener at master/9000] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2025-03-26 04:58:44,998 INFO [Listener at master/9000] org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 12 thread(s)
2025-03-26 04:58:45,004 INFO [Listener at master/9000] org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2025-03-26 04:58:45,012 INFO [CacheReplicationMonitor(614536250)] org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2025-03-26 04:58:48,342 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.15:9866, datanodeUuid=b1d5a5fd-b621-43d0-b31a-5a3e4c225aef, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-748e7e85-1eef-429d-8740-387b9d6355b0;nsid=710051680;c=1742965121137) storage b1d5a5fd-b621-43d0-b31a-5a3e4c225aef
2025-03-26 04:58:48,343 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.15:9866
2025-03-26 04:58:48,343 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN b1d5a5fd-b621-43d0-b31a-5a3e4c225aef (172.20.1.15:9866).
2025-03-26 04:58:48,394 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-604623a5-4685-4266-8f21-7caa9bdedd74 for DN 172.20.1.15:9866
2025-03-26 04:58:48,417 INFO [Block report processor] BlockStateChange: BLOCK* processReport 0x96d6ff6435669535 with lease ID 0x2f7e3e8fdea0dcb5: Processing first storage report for DS-604623a5-4685-4266-8f21-7caa9bdedd74 from datanode DatanodeRegistration(172.20.1.15:9866, datanodeUuid=b1d5a5fd-b621-43d0-b31a-5a3e4c225aef, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-748e7e85-1eef-429d-8740-387b9d6355b0;nsid=710051680;c=1742965121137)
2025-03-26 04:58:48,418 INFO [Block report processor] BlockStateChange: BLOCK* processReport 0x96d6ff6435669535 with lease ID 0x2f7e3e8fdea0dcb5: from storage DS-604623a5-4685-4266-8f21-7caa9bdedd74 node DatanodeRegistration(172.20.1.15:9866, datanodeUuid=b1d5a5fd-b621-43d0-b31a-5a3e4c225aef, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-748e7e85-1eef-429d-8740-387b9d6355b0;nsid=710051680;c=1742965121137), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2025-03-26 04:58:48,650 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.17:9866, datanodeUuid=00ff9403-ae57-4c78-80d1-76f1c8be0f76, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-748e7e85-1eef-429d-8740-387b9d6355b0;nsid=710051680;c=1742965121137) storage 00ff9403-ae57-4c78-80d1-76f1c8be0f76
2025-03-26 04:58:48,650 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.17:9866
2025-03-26 04:58:48,650 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 00ff9403-ae57-4c78-80d1-76f1c8be0f76 (172.20.1.17:9866).
2025-03-26 04:58:48,657 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.16:9866, datanodeUuid=c0ae95a1-812a-431c-b392-f059c7241f91, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-748e7e85-1eef-429d-8740-387b9d6355b0;nsid=710051680;c=1742965121137) storage c0ae95a1-812a-431c-b392-f059c7241f91
2025-03-26 04:58:48,658 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.16:9866
2025-03-26 04:58:48,658 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN c0ae95a1-812a-431c-b392-f059c7241f91 (172.20.1.16:9866).
2025-03-26 04:58:48,676 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-631da53a-bae6-46e9-8d54-74d0e4eff5e3 for DN 172.20.1.17:9866
2025-03-26 04:58:48,684 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3e152f59-1471-48e1-99b1-1ee2c8c13cca for DN 172.20.1.16:9866
2025-03-26 04:58:48,691 INFO [Block report processor] BlockStateChange: BLOCK* processReport 0x3524fa5cb7a2247f with lease ID 0x2f7e3e8fdea0dcb6: Processing first storage report for DS-631da53a-bae6-46e9-8d54-74d0e4eff5e3 from datanode DatanodeRegistration(172.20.1.17:9866, datanodeUuid=00ff9403-ae57-4c78-80d1-76f1c8be0f76, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-748e7e85-1eef-429d-8740-387b9d6355b0;nsid=710051680;c=1742965121137)
2025-03-26 04:58:48,692 INFO [Block report processor] BlockStateChange: BLOCK* processReport 0x3524fa5cb7a2247f with lease ID 0x2f7e3e8fdea0dcb6: from storage DS-631da53a-bae6-46e9-8d54-74d0e4eff5e3 node DatanodeRegistration(172.20.1.17:9866, datanodeUuid=00ff9403-ae57-4c78-80d1-76f1c8be0f76, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-748e7e85-1eef-429d-8740-387b9d6355b0;nsid=710051680;c=1742965121137), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-26 04:58:48,700 INFO [Block report processor] BlockStateChange: BLOCK* processReport 0xfa80ce0bc7893bd with lease ID 0x2f7e3e8fdea0dcb7: Processing first storage report for DS-3e152f59-1471-48e1-99b1-1ee2c8c13cca from datanode DatanodeRegistration(172.20.1.16:9866, datanodeUuid=c0ae95a1-812a-431c-b392-f059c7241f91, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-748e7e85-1eef-429d-8740-387b9d6355b0;nsid=710051680;c=1742965121137)
2025-03-26 04:58:48,700 INFO [Block report processor] BlockStateChange: BLOCK* processReport 0xfa80ce0bc7893bd with lease ID 0x2f7e3e8fdea0dcb7: from storage DS-3e152f59-1471-48e1-99b1-1ee2c8c13cca node DatanodeRegistration(172.20.1.16:9866, datanodeUuid=c0ae95a1-812a-431c-b392-f059c7241f91, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-748e7e85-1eef-429d-8740-387b9d6355b0;nsid=710051680;c=1742965121137), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-26 04:58:58,210 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:58:58,210 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:58:58,213 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /file.txt._COPYING_
2025-03-26 04:58:58,474 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /file.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1202729548_1
2025-03-26 04:58:59,904 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:58:59,904 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:58:59,904 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /cluster.txt._COPYING_
2025-03-26 04:58:59,971 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /cluster.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1898567554_1
2025-03-26 04:59:01,351 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:01,351 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:01,352 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /page.txt._COPYING_
2025-03-26 04:59:01,418 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /page.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-505907352_1
2025-03-26 04:59:02,757 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:02,757 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:02,758 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /lr_test.txt._COPYING_
2025-03-26 04:59:02,822 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /lr_test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_786207109_1
2025-03-26 04:59:05,606 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,606 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,607 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/graphx/users.txt._COPYING_
2025-03-26 04:59:05,663 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/graphx/users.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,673 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,673 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,674 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/graphx/followers.txt._COPYING_
2025-03-26 04:59:05,686 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/graphx/followers.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,705 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,705 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,705 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_fpgrowth.txt._COPYING_
2025-03-26 04:59:05,719 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_fpgrowth.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,727 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,728 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,728 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/pagerank_data.txt._COPYING_
2025-03-26 04:59:05,743 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/pagerank_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,751 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,751 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,752 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/streaming_kmeans_data_test.txt._COPYING_
2025-03-26 04:59:05,769 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/streaming_kmeans_data_test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,776 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,776 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,776 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/sample_lda_data.txt._COPYING_
2025-03-26 04:59:05,789 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_lda_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,799 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,799 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,799 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/als/test.data._COPYING_
2025-03-26 04:59:05,813 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/als/test.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,822 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,822 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,822 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/mllib/als/sample_movielens_ratings.txt._COPYING_
2025-03-26 04:59:05,833 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/als/sample_movielens_ratings.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,842 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,842 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,842 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_kmeans_data.txt._COPYING_
2025-03-26 04:59:05,852 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_kmeans_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,864 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,864 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,864 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/ridge-data/lpsa.data._COPYING_
2025-03-26 04:59:05,877 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/ridge-data/lpsa.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,884 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,884 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,884 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/gmm_data.txt._COPYING_
2025-03-26 04:59:05,896 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/gmm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,904 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,904 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,904 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_lda_libsvm_data.txt._COPYING_
2025-03-26 04:59:05,918 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_lda_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,929 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,929 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,930 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_libsvm_data.txt._COPYING_
2025-03-26 04:59:05,944 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,950 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,950 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,950 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/sample_movielens_data.txt._COPYING_
2025-03-26 04:59:05,962 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_movielens_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,969 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,969 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,970 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/sample_svm_data.txt._COPYING_
2025-03-26 04:59:05,982 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_svm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:05,999 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,999 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:05,999 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/license.txt._COPYING_
2025-03-26 04:59:06,010 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/license.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,029 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,030 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,030 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/multi-channel/grayscale.jpg._COPYING_
2025-03-26 04:59:06,042 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/grayscale.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,051 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,051 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,051 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png._COPYING_
2025-03-26 04:59:06,064 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,074 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,074 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,074 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/multi-channel/BGRA.png._COPYING_
2025-03-26 04:59:06,086 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/BGRA.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,093 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,093 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,093 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/multi-channel/chr30.4.184.jpg._COPYING_
2025-03-26 04:59:06,104 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/chr30.4.184.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,112 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,112 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,112 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/license.txt._COPYING_
2025-03-26 04:59:06,126 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/license.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,137 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,137 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,137 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg._COPYING_
2025-03-26 04:59:06,149 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,157 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,157 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,157 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/images/origin/kittens/DP802813.jpg._COPYING_
2025-03-26 04:59:06,168 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/DP802813.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,174 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,174 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,174 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/kittens/DP153539.jpg._COPYING_
2025-03-26 04:59:06,183 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/DP153539.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,191 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,192 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,192 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/kittens/not-image.txt._COPYING_
2025-03-26 04:59:06,204 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/not-image.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,210 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,210 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,210 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/images/origin/kittens/54893.jpg._COPYING_
2025-03-26 04:59:06,224 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/54893.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,235 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,235 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,235 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_linear_regression_data.txt._COPYING_
2025-03-26 04:59:06,245 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_linear_regression_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,252 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,252 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,253 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/sample_binary_classification_data.txt._COPYING_
2025-03-26 04:59:06,264 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_binary_classification_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,272 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,272 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,272 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/mllib/sample_multiclass_classification_data.txt._COPYING_
2025-03-26 04:59:06,285 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_multiclass_classification_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,290 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,290 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,290 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/sample_isotonic_regression_libsvm_data.txt._COPYING_
2025-03-26 04:59:06,300 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_isotonic_regression_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,308 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,308 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,308 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/pic_data.txt._COPYING_
2025-03-26 04:59:06,318 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/pic_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,328 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,328 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,328 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/kmeans_data.txt._COPYING_
2025-03-26 04:59:06,338 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/kmeans_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:06,345 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,345 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:06,345 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/streaming/AFINN-111.txt._COPYING_
2025-03-26 04:59:06,356 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/streaming/AFINN-111.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1609325105_1
2025-03-26 04:59:07,795 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,796 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,796 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,796 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:07,796 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:07,796 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:07,796 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/jars/scopt_2.12-3.7.1.jar._COPYING_
2025-03-26 04:59:07,854 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/jars/scopt_2.12-3.7.1.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:07,865 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,865 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,865 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,865 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:07,865 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:07,865 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:07,865 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/jars/spark-examples_2.12-3.3.2.jar._COPYING_
2025-03-26 04:59:07,882 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/jars/spark-examples_2.12-3.3.2.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:07,901 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,901 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,901 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,901 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:07,901 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:07,901 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:07,901 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/wordcount.py._COPYING_
2025-03-26 04:59:07,910 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:07,927 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,927 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,927 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,927 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:07,927 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:07,927 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:07,927 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/transitive_closure.py._COPYING_
2025-03-26 04:59:07,934 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/transitive_closure.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:07,941 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,941 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,941 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:07,941 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:07,941 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:07,941 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:07,941 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_
2025-03-26 04:59:07,951 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741866_1042 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_
2025-03-26 04:59:08,354 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,373 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,373 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,374 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,374 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,374 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,374 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,374 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/pi.py._COPYING_
2025-03-26 04:59:08,387 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/pi.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,395 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,395 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,395 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,395 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,395 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,395 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,395 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/sort.py._COPYING_
2025-03-26 04:59:08,404 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sort.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,412 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,413 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,413 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,413 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,413 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,413 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,413 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/status_api_demo.py._COPYING_
2025-03-26 04:59:08,421 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/status_api_demo.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,430 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,430 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,430 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,430 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,430 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,430 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,430 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/avro_inputformat.py._COPYING_
2025-03-26 04:59:08,439 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/avro_inputformat.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,444 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,444 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,445 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,445 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,445 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,445 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,445 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/logistic_regression.py._COPYING_
2025-03-26 04:59:08,451 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/logistic_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,459 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,459 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,459 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,459 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,459 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,459 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,459 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/kmeans.py._COPYING_
2025-03-26 04:59:08,467 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/kmeans.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,482 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,482 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,483 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,483 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,483 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,483 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,483 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/svd_example.py._COPYING_
2025-03-26 04:59:08,492 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/svd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,501 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,502 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,502 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,502 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,502 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,502 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,502 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/random_forest_regression_example.py._COPYING_
2025-03-26 04:59:08,509 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_forest_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,518 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,518 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,518 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,518 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,518 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,518 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,518 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/streaming_linear_regression_example.py._COPYING_
2025-03-26 04:59:08,526 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/streaming_linear_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,536 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,536 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,536 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,536 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,536 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,536 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,536 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/recommendation_example.py._COPYING_
2025-03-26 04:59:08,544 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/recommendation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,553 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,553 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,553 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,553 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,553 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,553 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,554 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/random_forest_classification_example.py._COPYING_
2025-03-26 04:59:08,560 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_forest_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,568 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,568 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,569 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,569 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,569 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,569 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,569 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/gaussian_mixture_model.py._COPYING_
2025-03-26 04:59:08,575 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gaussian_mixture_model.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,583 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,583 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,583 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,583 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,583 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,583 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,583 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/stratified_sampling_example.py._COPYING_
2025-03-26 04:59:08,589 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/stratified_sampling_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,605 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,605 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,605 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,605 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,605 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,605 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,605 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/tf_idf_example.py._COPYING_
2025-03-26 04:59:08,611 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/tf_idf_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,616 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,616 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,616 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,616 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,616 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,616 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,616 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/bisecting_k_means_example.py._COPYING_
2025-03-26 04:59:08,623 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/bisecting_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,631 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,631 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,631 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,631 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,631 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,631 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,631 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/logistic_regression.py._COPYING_
2025-03-26 04:59:08,640 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/logistic_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,645 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,645 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,645 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,645 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,645 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,645 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,645 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/naive_bayes_example.py._COPYING_
2025-03-26 04:59:08,651 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/naive_bayes_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,659 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,659 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,659 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,659 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,659 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,659 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,659 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/streaming_k_means_example.py._COPYING_
2025-03-26 04:59:08,666 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/streaming_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,671 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,671 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,671 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,671 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,671 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,671 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,671 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py._COPYING_
2025-03-26 04:59:08,679 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,688 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,688 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,688 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,688 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,688 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,688 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,688 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/decision_tree_classification_example.py._COPYING_
2025-03-26 04:59:08,696 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/decision_tree_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,703 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,703 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,703 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,703 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,703 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,703 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,703 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/word2vec.py._COPYING_
2025-03-26 04:59:08,710 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/word2vec.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,715 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,715 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,715 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,716 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,716 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,716 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,716 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/isotonic_regression_example.py._COPYING_
2025-03-26 04:59:08,722 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/isotonic_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,729 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,730 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,730 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,730 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,730 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,730 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,730 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/pca_rowmatrix_example.py._COPYING_
2025-03-26 04:59:08,736 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/pca_rowmatrix_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,742 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,742 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,742 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,742 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,742 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,742 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,742 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/kmeans.py._COPYING_
2025-03-26 04:59:08,748 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/kmeans.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,752 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,752 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,752 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,752 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,752 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,752 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,752 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/power_iteration_clustering_example.py._COPYING_
2025-03-26 04:59:08,758 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/power_iteration_clustering_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,763 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,764 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,764 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,764 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,764 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,764 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,764 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/gradient_boosting_regression_example.py._COPYING_
2025-03-26 04:59:08,771 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gradient_boosting_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,777 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,777 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,777 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,777 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,777 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,777 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,777 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/hypothesis_testing_example.py._COPYING_
2025-03-26 04:59:08,785 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/hypothesis_testing_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,794 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,795 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,795 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,795 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,795 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,795 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,795 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/__init__.py._COPYING_
2025-03-26 04:59:08,801 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,811 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,811 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,811 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,811 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,811 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,811 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,811 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py._COPYING_
2025-03-26 04:59:08,818 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,824 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,824 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,824 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,824 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,824 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,824 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,824 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/summary_statistics_example.py._COPYING_
2025-03-26 04:59:08,830 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/summary_statistics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,835 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,835 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,835 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,835 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,835 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,835 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,835 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/decision_tree_regression_example.py._COPYING_
2025-03-26 04:59:08,841 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/decision_tree_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,847 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,847 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,847 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,847 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,847 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,847 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,847 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/word2vec_example.py._COPYING_
2025-03-26 04:59:08,853 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/word2vec_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,860 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,860 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,860 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,860 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,860 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,860 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,860 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/fpgrowth_example.py._COPYING_
2025-03-26 04:59:08,866 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/fpgrowth_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,875 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,875 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,875 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,875 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,875 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,875 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,875 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/correlations_example.py._COPYING_
2025-03-26 04:59:08,881 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/correlations_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,887 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,887 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,887 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,887 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,887 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,887 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,887 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/binary_classification_metrics_example.py._COPYING_
2025-03-26 04:59:08,894 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/binary_classification_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,901 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,901 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,901 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,901 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,901 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,901 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,901 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/multi_label_metrics_example.py._COPYING_
2025-03-26 04:59:08,906 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/multi_label_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,911 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,911 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,911 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,911 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,911 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,911 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,911 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py._COPYING_
2025-03-26 04:59:08,916 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,930 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,930 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,930 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,930 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,930 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,930 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,930 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/gradient_boosting_classification_example.py._COPYING_
2025-03-26 04:59:08,937 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gradient_boosting_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,942 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,942 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,942 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,942 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,942 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,942 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,942 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/correlations.py._COPYING_
2025-03-26 04:59:08,951 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/correlations.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,955 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,955 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,956 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,956 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,956 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,956 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,956 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/gaussian_mixture_example.py._COPYING_
2025-03-26 04:59:08,962 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gaussian_mixture_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,969 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,970 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,970 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,970 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,974 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,974 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,974 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,974 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,974 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,974 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,974 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/k_means_example.py._COPYING_
2025-03-26 04:59:08,986 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:08,996 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,996 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,996 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:08,996 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:08,996 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:08,996 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:08,996 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/ranking_metrics_example.py._COPYING_
2025-03-26 04:59:09,005 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/ranking_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,009 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,009 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,009 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,009 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,009 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,009 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,009 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/multi_class_metrics_example.py._COPYING_
2025-03-26 04:59:09,015 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/multi_class_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,021 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,021 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,021 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,021 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,021 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,021 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,021 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/linear_regression_with_sgd_example.py._COPYING_
2025-03-26 04:59:09,028 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/linear_regression_with_sgd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,036 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,036 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,036 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,036 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,036 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,036 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,036 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/standard_scaler_example.py._COPYING_
2025-03-26 04:59:09,042 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/standard_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,048 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,049 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,049 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,049 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,049 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,049 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,049 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/kernel_density_estimation_example.py._COPYING_
2025-03-26 04:59:09,055 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/kernel_density_estimation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,064 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,064 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,064 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,064 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,064 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,064 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,064 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/regression_metrics_example.py._COPYING_
2025-03-26 04:59:09,072 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/regression_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,078 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,078 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,078 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,078 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,078 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,078 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,078 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/svm_with_sgd_example.py._COPYING_
2025-03-26 04:59:09,084 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/svm_with_sgd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,090 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,090 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,090 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,090 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,090 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,090 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,090 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/normalizer_example.py._COPYING_
2025-03-26 04:59:09,096 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/normalizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,100 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,100 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,100 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,100 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,100 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,100 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,101 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/random_rdd_generation.py._COPYING_
2025-03-26 04:59:09,106 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_rdd_generation.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,110 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,110 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,110 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,110 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,110 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,110 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,110 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/sampled_rdds.py._COPYING_
2025-03-26 04:59:09,117 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/sampled_rdds.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,123 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,123 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,123 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,123 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,123 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,123 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,123 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/elementwise_product_example.py._COPYING_
2025-03-26 04:59:09,128 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/elementwise_product_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,134 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,134 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,134 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,134 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,134 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,134 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,134 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/__init__.py._COPYING_
2025-03-26 04:59:09,139 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,144 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,144 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,144 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,144 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,144 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,144 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,144 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/pagerank.py._COPYING_
2025-03-26 04:59:09,154 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/pagerank.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,171 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,171 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,171 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,171 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,171 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,171 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,171 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/fm_regressor_example.py._COPYING_
2025-03-26 04:59:09,178 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fm_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,185 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,185 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,185 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,185 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,185 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,185 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,185 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/string_indexer_example.py._COPYING_
2025-03-26 04:59:09,191 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/string_indexer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,199 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,199 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,199 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,200 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,200 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,200 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,200 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/vector_assembler_example.py._COPYING_
2025-03-26 04:59:09,207 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_assembler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,211 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,211 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,211 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,211 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,211 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,211 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,211 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/robust_scaler_example.py._COPYING_
2025-03-26 04:59:09,219 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/robust_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,223 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,223 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,223 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,223 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,223 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,223 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,223 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_
2025-03-26 04:59:09,229 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,234 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,234 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,234 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,234 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,234 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,234 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,234 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/vector_indexer_example.py._COPYING_
2025-03-26 04:59:09,240 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_indexer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,244 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,244 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,244 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,244 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,244 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,244 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,244 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/variance_threshold_selector_example.py._COPYING_
2025-03-26 04:59:09,250 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/variance_threshold_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,253 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,254 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,254 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,254 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,254 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,254 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,254 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/feature_hasher_example.py._COPYING_
2025-03-26 04:59:09,260 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/feature_hasher_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,269 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,269 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,269 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,269 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,269 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,269 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,269 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_
2025-03-26 04:59:09,275 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,281 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,281 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,281 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,281 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,281 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,281 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,281 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/tf_idf_example.py._COPYING_
2025-03-26 04:59:09,288 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/tf_idf_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,293 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,293 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,293 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,293 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,293 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,293 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,293 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/stopwords_remover_example.py._COPYING_
2025-03-26 04:59:09,299 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/stopwords_remover_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,302 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,302 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,302 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,302 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,302 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,302 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,302 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/cross_validator.py._COPYING_
2025-03-26 04:59:09,309 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/cross_validator.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,314 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,314 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,314 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,314 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,314 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,314 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,314 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py._COPYING_
2025-03-26 04:59:09,320 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,324 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,324 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,324 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,324 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,324 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,324 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,324 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/bisecting_k_means_example.py._COPYING_
2025-03-26 04:59:09,332 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bisecting_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,341 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,341 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,341 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,341 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,341 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,341 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,341 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/correlation_example.py._COPYING_
2025-03-26 04:59:09,347 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/correlation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,350 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,350 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,350 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,350 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:09,350 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:09,350 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:09,351 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/kmeans_example.py._COPYING_
2025-03-26 04:59:09,356 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/kmeans_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,359 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,359 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,360 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py._COPYING_
2025-03-26 04:59:09,367 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,371 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,371 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,372 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/naive_bayes_example.py._COPYING_
2025-03-26 04:59:09,382 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/naive_bayes_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,423 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,423 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,423 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/count_vectorizer_example.py._COPYING_
2025-03-26 04:59:09,445 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/count_vectorizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,453 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,453 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,453 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/decision_tree_classification_example.py._COPYING_
2025-03-26 04:59:09,469 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/decision_tree_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,479 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,479 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,479 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/isotonic_regression_example.py._COPYING_
2025-03-26 04:59:09,491 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/isotonic_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,496 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,496 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,496 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/sql_transformer.py._COPYING_
2025-03-26 04:59:09,505 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/sql_transformer.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,510 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,510 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,510 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/polynomial_expansion_example.py._COPYING_
2025-03-26 04:59:09,518 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/polynomial_expansion_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,523 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,523 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,523 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/bucketizer_example.py._COPYING_
2025-03-26 04:59:09,531 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bucketizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,536 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,536 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,536 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/univariate_feature_selector_example.py._COPYING_
2025-03-26 04:59:09,548 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/univariate_feature_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,553 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,553 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,553 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/power_iteration_clustering_example.py._COPYING_
2025-03-26 04:59:09,565 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/power_iteration_clustering_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,569 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,569 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,569 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/als_example.py._COPYING_
2025-03-26 04:59:09,577 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/als_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,581 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,581 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,581 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/logistic_regression_summary_example.py._COPYING_
2025-03-26 04:59:09,590 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/logistic_regression_summary_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,599 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,599 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,599 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/summarizer_example.py._COPYING_
2025-03-26 04:59:09,607 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/summarizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,611 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,611 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,611 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/vector_slicer_example.py._COPYING_
2025-03-26 04:59:09,619 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_slicer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,623 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,623 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,623 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/imputer_example.py._COPYING_
2025-03-26 04:59:09,632 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/imputer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,637 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,637 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,637 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/onehot_encoder_example.py._COPYING_
2025-03-26 04:59:09,647 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/onehot_encoder_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,653 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,653 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,653 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/linearsvc.py._COPYING_
2025-03-26 04:59:09,661 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/linearsvc.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,671 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,671 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,671 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_
2025-03-26 04:59:09,679 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,683 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,683 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,683 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/fm_classifier_example.py._COPYING_
2025-03-26 04:59:09,692 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fm_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,696 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,696 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,696 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/decision_tree_regression_example.py._COPYING_
2025-03-26 04:59:09,705 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/decision_tree_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,712 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,712 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,712 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/word2vec_example.py._COPYING_
2025-03-26 04:59:09,720 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/word2vec_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,723 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,723 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,724 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/fpgrowth_example.py._COPYING_
2025-03-26 04:59:09,730 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fpgrowth_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,733 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,734 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,734 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/pipeline_example.py._COPYING_
2025-03-26 04:59:09,740 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/pipeline_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,744 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,744 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,744 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/logistic_regression_with_elastic_net.py._COPYING_
2025-03-26 04:59:09,751 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/logistic_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,756 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,756 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,756 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/train_validation_split.py._COPYING_
2025-03-26 04:59:09,768 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/train_validation_split.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,772 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,772 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,772 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/interaction_example.py._COPYING_
2025-03-26 04:59:09,782 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/interaction_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,785 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,785 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,785 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/random_forest_classifier_example.py._COPYING_
2025-03-26 04:59:09,793 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/random_forest_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,798 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,798 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,798 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/quantile_discretizer_example.py._COPYING_
2025-03-26 04:59:09,805 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/quantile_discretizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,808 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,808 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,808 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/aft_survival_regression.py._COPYING_
2025-03-26 04:59:09,816 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/aft_survival_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,821 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,821 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,821 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/estimator_transformer_param_example.py._COPYING_
2025-03-26 04:59:09,828 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/estimator_transformer_param_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,835 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,835 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,836 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/__init__,py._COPYING_
2025-03-26 04:59:09,843 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/__init__,py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,847 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,847 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,847 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/chi_square_test_example.py._COPYING_
2025-03-26 04:59:09,855 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/chi_square_test_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,858 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,858 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,858 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/multilayer_perceptron_classification.py._COPYING_
2025-03-26 04:59:09,866 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/multilayer_perceptron_classification.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,872 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,872 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,872 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/dataframe_example.py._COPYING_
2025-03-26 04:59:09,879 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/dataframe_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,886 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,886 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,886 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/prefixspan_example.py._COPYING_
2025-03-26 04:59:09,892 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/prefixspan_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,896 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,896 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,896 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/index_to_string_example.py._COPYING_
2025-03-26 04:59:09,902 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/index_to_string_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,909 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,909 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,909 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/one_vs_rest_example.py._COPYING_
2025-03-26 04:59:09,915 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/one_vs_rest_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,921 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,921 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,921 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/chisq_selector_example.py._COPYING_
2025-03-26 04:59:09,928 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/chisq_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,931 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,932 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,932 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/gaussian_mixture_example.py._COPYING_
2025-03-26 04:59:09,938 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gaussian_mixture_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,942 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,942 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,942 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/pca_example.py._COPYING_
2025-03-26 04:59:09,951 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/pca_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,955 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,955 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,955 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1153, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/generalized_linear_regression_example.py._COPYING_
2025-03-26 04:59:09,964 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/generalized_linear_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,973 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,973 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,973 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1154, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/lda_example.py._COPYING_
2025-03-26 04:59:09,980 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/lda_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:09,992 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,992 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:09,993 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1155, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/min_max_scaler_example.py._COPYING_
2025-03-26 04:59:10,002 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/min_max_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,007 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,007 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,008 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1156, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_
2025-03-26 04:59:10,015 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,020 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,020 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,020 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1157, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/standard_scaler_example.py._COPYING_
2025-03-26 04:59:10,027 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/standard_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,032 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,032 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,032 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1158, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/tokenizer_example.py._COPYING_
2025-03-26 04:59:10,038 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/tokenizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,042 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,042 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,042 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1159, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/rformula_example.py._COPYING_
2025-03-26 04:59:10,049 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/rformula_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,053 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,053 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,053 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1160, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/normalizer_example.py._COPYING_
2025-03-26 04:59:10,059 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/normalizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,076 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,076 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,076 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1161, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/n_gram_example.py._COPYING_
2025-03-26 04:59:10,084 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/n_gram_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,089 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,089 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,089 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1162, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/dct_example.py._COPYING_
2025-03-26 04:59:10,095 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/dct_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,099 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,099 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,099 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1163, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/min_hash_lsh_example.py._COPYING_
2025-03-26 04:59:10,105 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/min_hash_lsh_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,108 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,108 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,108 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1164, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py._COPYING_
2025-03-26 04:59:10,117 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,120 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,120 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,121 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1165, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/binarizer_example.py._COPYING_
2025-03-26 04:59:10,127 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/binarizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,131 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,131 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,131 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1166, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/elementwise_product_example.py._COPYING_
2025-03-26 04:59:10,138 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/elementwise_product_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,145 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,145 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,146 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1167, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/max_abs_scaler_example.py._COPYING_
2025-03-26 04:59:10,152 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/max_abs_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,157 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,157 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,157 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1168, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/als.py._COPYING_
2025-03-26 04:59:10,163 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/als.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,168 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,168 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,168 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1169, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/hive.py._COPYING_
2025-03-26 04:59:10,181 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/hive.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,186 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,186 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,187 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1170, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/sql/__init__.py._COPYING_
2025-03-26 04:59:10,195 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,198 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,198 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,198 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1171, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/datasource.py._COPYING_
2025-03-26 04:59:10,205 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/datasource.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,208 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,208 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,208 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1172, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/sql/basic.py._COPYING_
2025-03-26 04:59:10,214 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/basic.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,221 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,221 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,221 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1173, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/arrow.py._COPYING_
2025-03-26 04:59:10,227 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/arrow.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,232 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,232 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,232 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1174, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/streaming/structured_sessionization.py._COPYING_
2025-03-26 04:59:10,242 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_sessionization.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,245 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,245 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,245 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1175, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py._COPYING_
2025-03-26 04:59:10,251 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,258 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,258 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,258 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1176, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/sql/streaming/__init__,py._COPYING_
2025-03-26 04:59:10,265 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/__init__,py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,268 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,268 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,268 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1177, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount.py._COPYING_
2025-03-26 04:59:10,274 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,278 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,278 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,278 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1178, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py._COPYING_
2025-03-26 04:59:10,300 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,310 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,310 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,310 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1179, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/streaming/queue_stream.py._COPYING_
2025-03-26 04:59:10,321 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/queue_stream.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,324 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,324 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,324 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1180, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/streaming/network_wordcount.py._COPYING_
2025-03-26 04:59:10,332 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,335 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,335 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,335 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1181, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/streaming/__init__.py._COPYING_
2025-03-26 04:59:10,343 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,348 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,348 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,349 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1182, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/streaming/sql_network_wordcount.py._COPYING_
2025-03-26 04:59:10,355 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/sql_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,358 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,358 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,359 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1183, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/streaming/hdfs_wordcount.py._COPYING_
2025-03-26 04:59:10,365 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/hdfs_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,370 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,370 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,370 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1184, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/network_wordjoinsentiments.py._COPYING_
2025-03-26 04:59:10,378 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/network_wordjoinsentiments.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,382 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,382 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,382 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1185, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_
2025-03-26 04:59:10,388 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,393 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,393 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,393 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1186, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/recoverable_network_wordcount.py._COPYING_
2025-03-26 04:59:10,402 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/recoverable_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,410 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,410 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,410 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1187, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/data-manipulation.R._COPYING_
2025-03-26 04:59:10,422 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/data-manipulation.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,426 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,426 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,426 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1188, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/RSparkSQLExample.R._COPYING_
2025-03-26 04:59:10,433 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/RSparkSQLExample.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,438 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,438 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,438 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1189, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/als.R._COPYING_
2025-03-26 04:59:10,444 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/als.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,450 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,450 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,450 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1190, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/ml.R._COPYING_
2025-03-26 04:59:10,457 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/ml.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,461 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,461 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,462 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1191, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/prefixSpan.R._COPYING_
2025-03-26 04:59:10,471 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/prefixSpan.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,481 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,481 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,481 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1192, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_
2025-03-26 04:59:10,490 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742016_1192 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_
2025-03-26 04:59:10,894 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,903 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,903 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,903 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1193, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/lm_with_elastic_net.R._COPYING_
2025-03-26 04:59:10,918 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/lm_with_elastic_net.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,924 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,924 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,925 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1194, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/naiveBayes.R._COPYING_
2025-03-26 04:59:10,933 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/naiveBayes.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,937 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,937 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,937 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1195, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/decisionTree.R._COPYING_
2025-03-26 04:59:10,949 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/decisionTree.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,954 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,954 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,954 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1196, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/lda.R._COPYING_
2025-03-26 04:59:10,967 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/lda.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,971 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,971 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,971 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1197, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/survreg.R._COPYING_
2025-03-26 04:59:10,980 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/survreg.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:10,984 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,984 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:10,984 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1198, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/svmLinear.R._COPYING_
2025-03-26 04:59:10,994 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/svmLinear.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,002 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,002 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,002 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1199, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/isoreg.R._COPYING_
2025-03-26 04:59:11,013 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/isoreg.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,018 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,018 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,018 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742024_1200, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/bisectingKmeans.R._COPYING_
2025-03-26 04:59:11,026 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/bisectingKmeans.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,030 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,030 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,030 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742025_1201, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/mlp.R._COPYING_
2025-03-26 04:59:11,038 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/mlp.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,041 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,041 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,041 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742026_1202, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/fpm.R._COPYING_
2025-03-26 04:59:11,048 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fpm.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,053 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,053 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,053 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742027_1203, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/glm.R._COPYING_
2025-03-26 04:59:11,061 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/glm.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,064 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,064 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,064 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742028_1204, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/randomForest.R._COPYING_
2025-03-26 04:59:11,070 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/randomForest.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,077 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,077 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,077 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742029_1205, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/gaussianMixture.R._COPYING_
2025-03-26 04:59:11,085 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/gaussianMixture.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,088 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,088 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,088 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742030_1206, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/fmClassifier.R._COPYING_
2025-03-26 04:59:11,094 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fmClassifier.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,097 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,097 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,097 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742031_1207, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/gbt.R._COPYING_
2025-03-26 04:59:11,104 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/gbt.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,107 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,107 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,108 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742032_1208, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/fmRegressor.R._COPYING_
2025-03-26 04:59:11,113 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fmRegressor.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,117 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,117 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,117 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742033_1209, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/kmeans.R._COPYING_
2025-03-26 04:59:11,129 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/kmeans.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,132 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,132 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,132 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742034_1210, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/kstest.R._COPYING_
2025-03-26 04:59:11,138 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/kstest.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,142 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,142 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,142 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742035_1211, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/logit.R._COPYING_
2025-03-26 04:59:11,148 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/logit.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,152 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,152 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,152 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742036_1212, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/dataframe.R._COPYING_
2025-03-26 04:59:11,161 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/dataframe.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,165 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,165 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,165 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742037_1213, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/streaming/structured_network_wordcount.R._COPYING_
2025-03-26 04:59:11,171 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/streaming/structured_network_wordcount.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,176 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,176 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,176 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742038_1214, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/kv1.txt._COPYING_
2025-03-26 04:59:11,182 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/kv1.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,188 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,188 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,188 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742039_1215, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/dir1/file1.parquet._COPYING_
2025-03-26 04:59:11,195 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/file1.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,199 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,199 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,199 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742040_1216, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/dir1/file3.json._COPYING_
2025-03-26 04:59:11,207 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/file3.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,214 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,214 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,214 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742041_1217, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/dir1/dir2/file2.parquet._COPYING_
2025-03-26 04:59:11,222 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/dir2/file2.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,225 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,225 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,225 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742042_1218, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/user.avsc._COPYING_
2025-03-26 04:59:11,230 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/user.avsc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,233 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,233 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,234 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742043_1219, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/people.csv._COPYING_
2025-03-26 04:59:11,242 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,246 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,246 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,247 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742044_1220, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/full_user.avsc._COPYING_
2025-03-26 04:59:11,254 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/full_user.avsc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,259 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,259 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,259 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742045_1221, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/users.avro._COPYING_
2025-03-26 04:59:11,267 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.avro._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,278 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,278 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,278 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742046_1222, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider._COPYING_
2025-03-26 04:59:11,285 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,290 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,290 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,291 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742047_1223, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider._COPYING_
2025-03-26 04:59:11,299 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,302 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,302 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,303 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742048_1224, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/users.parquet._COPYING_
2025-03-26 04:59:11,308 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,312 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,312 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,313 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742049_1225, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/users.orc._COPYING_
2025-03-26 04:59:11,319 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.orc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,324 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,324 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,324 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742050_1226, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/people.txt._COPYING_
2025-03-26 04:59:11,330 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,333 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,333 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,333 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742051_1227, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/people.json._COPYING_
2025-03-26 04:59:11,341 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,345 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,345 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,345 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742052_1228, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/employees.json._COPYING_
2025-03-26 04:59:11,354 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/employees.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,365 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,365 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,365 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742053_1229, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala._COPYING_
2025-03-26 04:59:11,372 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,379 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,379 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,379 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742054_1230, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala._COPYING_
2025-03-26 04:59:11,385 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,389 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,389 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,389 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742055_1231, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_
2025-03-26 04:59:11,394 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,398 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,398 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,398 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742056_1232, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala._COPYING_
2025-03-26 04:59:11,404 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,407 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,407 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,407 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742057_1233, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala._COPYING_
2025-03-26 04:59:11,414 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,418 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,418 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,418 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742058_1234, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala._COPYING_
2025-03-26 04:59:11,424 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,427 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,427 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,427 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742059_1235, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala._COPYING_
2025-03-26 04:59:11,433 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,437 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,437 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,437 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742060_1236, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala._COPYING_
2025-03-26 04:59:11,443 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,446 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,446 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,447 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742061_1237, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala._COPYING_
2025-03-26 04:59:11,453 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,459 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,459 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,459 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742062_1238, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala._COPYING_
2025-03-26 04:59:11,466 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,471 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,471 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,471 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742063_1239, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala._COPYING_
2025-03-26 04:59:11,486 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,489 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,489 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,489 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742064_1240, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala._COPYING_
2025-03-26 04:59:11,496 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,499 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,499 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,499 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742065_1241, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala._COPYING_
2025-03-26 04:59:11,510 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,516 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,516 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,516 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742066_1242, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala._COPYING_
2025-03-26 04:59:11,525 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,536 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,536 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,536 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742067_1243, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala._COPYING_
2025-03-26 04:59:11,544 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,548 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,548 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,548 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742068_1244, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala._COPYING_
2025-03-26 04:59:11,555 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,560 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,560 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,560 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742069_1245, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala._COPYING_
2025-03-26 04:59:11,568 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,572 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,572 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,573 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742070_1246, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala._COPYING_
2025-03-26 04:59:11,583 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,588 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,588 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,588 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742071_1247, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala._COPYING_
2025-03-26 04:59:11,598 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,602 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,602 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,602 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742072_1248, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala._COPYING_
2025-03-26 04:59:11,615 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,619 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,619 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,619 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742073_1249, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala._COPYING_
2025-03-26 04:59:11,626 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,629 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,629 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,629 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742074_1250, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala._COPYING_
2025-03-26 04:59:11,636 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,641 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,641 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,641 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742075_1251, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala._COPYING_
2025-03-26 04:59:11,648 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,662 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,662 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,662 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742076_1252, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala._COPYING_
2025-03-26 04:59:11,672 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,676 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,676 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,676 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742077_1253, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala._COPYING_
2025-03-26 04:59:11,687 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,703 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,703 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,703 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742078_1254, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala._COPYING_
2025-03-26 04:59:11,713 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,718 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,718 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,718 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742079_1255, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala._COPYING_
2025-03-26 04:59:11,726 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,734 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,734 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,735 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742080_1256, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala._COPYING_
2025-03-26 04:59:11,760 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,766 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,766 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,766 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742081_1257, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala._COPYING_
2025-03-26 04:59:11,777 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,781 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,781 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,781 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742082_1258, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 04:59:11,788 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,793 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,793 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,793 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742083_1259, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala._COPYING_
2025-03-26 04:59:11,801 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,805 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,805 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,805 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742084_1260, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala._COPYING_
2025-03-26 04:59:11,811 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,820 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,820 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,820 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742085_1261, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala._COPYING_
2025-03-26 04:59:11,826 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,841 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,841 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,841 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742086_1262, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala._COPYING_
2025-03-26 04:59:11,847 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,851 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,851 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,851 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742087_1263, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala._COPYING_
2025-03-26 04:59:11,859 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,863 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,863 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,863 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742088_1264, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala._COPYING_
2025-03-26 04:59:11,878 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,886 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,886 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,887 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742089_1265, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala._COPYING_
2025-03-26 04:59:11,893 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,897 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,897 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,897 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742090_1266, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala._COPYING_
2025-03-26 04:59:11,907 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,912 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,912 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,912 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742091_1267, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala._COPYING_
2025-03-26 04:59:11,930 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,935 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,935 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,935 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742092_1268, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala._COPYING_
2025-03-26 04:59:11,942 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,971 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,971 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,971 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,971 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,974 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,974 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,974 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742093_1269, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala._COPYING_
2025-03-26 04:59:11,982 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:11,986 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,986 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:11,986 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742094_1270, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala._COPYING_
2025-03-26 04:59:11,999 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,003 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,003 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,003 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742095_1271, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala._COPYING_
2025-03-26 04:59:12,010 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,014 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,014 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,014 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742096_1272, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala._COPYING_
2025-03-26 04:59:12,025 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,029 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,029 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,029 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742097_1273, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala._COPYING_
2025-03-26 04:59:12,035 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,039 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,039 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,039 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742098_1274, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala._COPYING_
2025-03-26 04:59:12,045 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,049 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,049 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,049 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742099_1275, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala._COPYING_
2025-03-26 04:59:12,055 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,060 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,060 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,060 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742100_1276, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala._COPYING_
2025-03-26 04:59:12,071 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,075 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,075 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,075 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742101_1277, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala._COPYING_
2025-03-26 04:59:12,081 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,085 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,085 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,085 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742102_1278, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala._COPYING_
2025-03-26 04:59:12,091 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,095 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,096 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,096 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742103_1279, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala._COPYING_
2025-03-26 04:59:12,105 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,109 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,109 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,109 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742104_1280, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala._COPYING_
2025-03-26 04:59:12,115 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,120 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,120 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,120 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742105_1281, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala._COPYING_
2025-03-26 04:59:12,128 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,133 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,133 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,133 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742106_1282, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala._COPYING_
2025-03-26 04:59:12,143 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,147 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,147 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,147 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742107_1283, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala._COPYING_
2025-03-26 04:59:12,155 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,162 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,162 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,162 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742108_1284, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala._COPYING_
2025-03-26 04:59:12,170 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,174 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,174 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,174 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742109_1285, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala._COPYING_
2025-03-26 04:59:12,181 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,185 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,185 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,185 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742110_1286, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala._COPYING_
2025-03-26 04:59:12,195 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,200 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,200 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,200 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742111_1287, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala._COPYING_
2025-03-26 04:59:12,221 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,225 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,225 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,225 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742112_1288, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala._COPYING_
2025-03-26 04:59:12,233 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,239 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,239 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,239 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742113_1289, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala._COPYING_
2025-03-26 04:59:12,246 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,253 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,253 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,253 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742114_1290, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala._COPYING_
2025-03-26 04:59:12,265 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,270 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,270 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,271 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742115_1291, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala._COPYING_
2025-03-26 04:59:12,284 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,288 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,288 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,288 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742116_1292, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala._COPYING_
2025-03-26 04:59:12,295 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,298 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,298 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,298 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742117_1293, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala._COPYING_
2025-03-26 04:59:12,306 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,309 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,309 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,309 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742118_1294, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala._COPYING_
2025-03-26 04:59:12,315 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,318 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,318 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,319 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742119_1295, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala._COPYING_
2025-03-26 04:59:12,324 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,331 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,331 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,331 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742120_1296, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala._COPYING_
2025-03-26 04:59:12,336 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,339 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,339 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,339 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742121_1297, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala._COPYING_
2025-03-26 04:59:12,345 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,349 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,349 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,349 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742122_1298, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala._COPYING_
2025-03-26 04:59:12,354 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,361 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,361 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,361 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,361 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,361 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,361 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,361 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742123_1299, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala._COPYING_
2025-03-26 04:59:12,366 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,370 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,370 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,370 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,370 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,370 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,370 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,370 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742124_1300, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala._COPYING_
2025-03-26 04:59:12,374 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,377 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,377 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,377 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,377 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,377 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,377 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,377 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742125_1301, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala._COPYING_
2025-03-26 04:59:12,383 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,386 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,386 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,386 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,386 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,386 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,386 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,386 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742126_1302, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala._COPYING_
2025-03-26 04:59:12,390 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,393 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,393 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,393 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,393 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,393 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,393 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,393 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742127_1303, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala._COPYING_
2025-03-26 04:59:12,396 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,399 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,399 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,399 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,399 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,399 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,399 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,399 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742128_1304, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_
2025-03-26 04:59:12,409 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,412 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,412 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,412 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,412 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,412 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,412 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,412 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742129_1305, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala._COPYING_
2025-03-26 04:59:12,416 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,420 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,420 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,420 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,420 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,420 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,420 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,420 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742130_1306, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala._COPYING_
2025-03-26 04:59:12,426 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,429 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,429 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,429 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,429 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,429 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,429 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,429 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742131_1307, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala._COPYING_
2025-03-26 04:59:12,433 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,436 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,436 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,436 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,436 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,436 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,437 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,437 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742132_1308, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala._COPYING_
2025-03-26 04:59:12,441 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,445 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,445 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,445 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,445 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,445 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,445 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,445 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742133_1309, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala._COPYING_
2025-03-26 04:59:12,454 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,468 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,468 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,468 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,468 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,468 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,468 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,468 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742134_1310, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala._COPYING_
2025-03-26 04:59:12,478 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,481 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,481 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,481 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,481 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,481 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,481 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,481 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742135_1311, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala._COPYING_
2025-03-26 04:59:12,486 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,492 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,492 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,492 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,492 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,492 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,492 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,492 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742136_1312, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala._COPYING_
2025-03-26 04:59:12,496 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,500 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,500 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,500 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,500 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,500 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,500 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,500 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742137_1313, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala._COPYING_
2025-03-26 04:59:12,504 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,512 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,512 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,512 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,512 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,512 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,512 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,512 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742138_1314, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_
2025-03-26 04:59:12,519 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742138_1314 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_
2025-03-26 04:59:12,921 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,942 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,942 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,942 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,942 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,942 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,943 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,943 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742139_1315, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala._COPYING_
2025-03-26 04:59:12,952 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,961 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,961 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,961 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,961 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,961 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,961 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,961 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742140_1316, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala._COPYING_
2025-03-26 04:59:12,966 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,970 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,970 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,970 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,970 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,970 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,970 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,970 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742141_1317, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala._COPYING_
2025-03-26 04:59:12,974 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,977 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,977 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,977 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,977 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,977 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,977 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,977 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742142_1318, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala._COPYING_
2025-03-26 04:59:12,982 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,986 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,986 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,986 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,986 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,986 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,986 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,986 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742143_1319, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala._COPYING_
2025-03-26 04:59:12,991 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:12,994 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,994 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,994 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:12,994 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:12,994 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:12,994 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:12,994 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742144_1320, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_
2025-03-26 04:59:13,009 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,012 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,012 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,013 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,013 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,013 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,013 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,013 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1321, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala._COPYING_
2025-03-26 04:59:13,025 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,030 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,030 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,030 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,030 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,030 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,030 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,030 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1322, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala._COPYING_
2025-03-26 04:59:13,035 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,038 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,038 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,038 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,038 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,038 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,038 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,038 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1323, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 04:59:13,043 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,050 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,050 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,050 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,050 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,050 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,050 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,050 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1324, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala._COPYING_
2025-03-26 04:59:13,055 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,059 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,059 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,059 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,059 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,059 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,059 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,059 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1325, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala._COPYING_
2025-03-26 04:59:13,069 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,073 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,073 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,073 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,073 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,073 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,073 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,073 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1326, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala._COPYING_
2025-03-26 04:59:13,079 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,083 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,083 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,083 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,083 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,083 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,083 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,083 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1327, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala._COPYING_
2025-03-26 04:59:13,089 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,096 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,096 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,096 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,096 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,096 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,096 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,096 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1328, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala._COPYING_
2025-03-26 04:59:13,102 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,111 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,111 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,111 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,111 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,111 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,111 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,112 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1329, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala._COPYING_
2025-03-26 04:59:13,123 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,130 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,130 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,130 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,130 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,130 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,130 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,130 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1330, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala._COPYING_
2025-03-26 04:59:13,136 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,140 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,140 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,140 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,140 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,140 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,140 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,141 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1331, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 04:59:13,147 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,150 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,151 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,151 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,151 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,151 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,151 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,151 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1332, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala._COPYING_
2025-03-26 04:59:13,161 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,166 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,166 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,166 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,166 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,166 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,166 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,166 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1333, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala._COPYING_
2025-03-26 04:59:13,177 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,182 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,182 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,182 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,182 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,182 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,182 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,182 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1334, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala._COPYING_
2025-03-26 04:59:13,188 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,192 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,192 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,192 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,192 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,192 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,192 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,192 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1335, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala._COPYING_
2025-03-26 04:59:13,198 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,203 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,203 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,203 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,203 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,203 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,203 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,203 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1336, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala._COPYING_
2025-03-26 04:59:13,214 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,219 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,219 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,219 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,219 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,219 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,219 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,219 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1337, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala._COPYING_
2025-03-26 04:59:13,225 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,228 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,228 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,228 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,228 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,228 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,228 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,229 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1338, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala._COPYING_
2025-03-26 04:59:13,236 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,240 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,241 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,241 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,241 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,241 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,241 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,241 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1339, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala._COPYING_
2025-03-26 04:59:13,247 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,250 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,250 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,250 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,250 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,250 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,250 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,250 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1340, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala._COPYING_
2025-03-26 04:59:13,257 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,261 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,261 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,261 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,261 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,261 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,261 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,261 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1341, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala._COPYING_
2025-03-26 04:59:13,268 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,272 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,272 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,272 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,272 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,272 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,272 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,272 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1342, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala._COPYING_
2025-03-26 04:59:13,287 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,291 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,291 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,291 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,291 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,291 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,291 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,291 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1343, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala._COPYING_
2025-03-26 04:59:13,298 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,303 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,303 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,303 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,303 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,303 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,303 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,303 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1344, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala._COPYING_
2025-03-26 04:59:13,311 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,315 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,315 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,315 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,315 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,315 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,315 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,315 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1345, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala._COPYING_
2025-03-26 04:59:13,321 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,326 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,326 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,326 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,326 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,326 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,326 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,326 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1346, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala._COPYING_
2025-03-26 04:59:13,334 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,337 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,338 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,338 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,338 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,338 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,338 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,338 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1347, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala._COPYING_
2025-03-26 04:59:13,343 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,346 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,347 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,347 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,347 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,347 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,347 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,347 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1348, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala._COPYING_
2025-03-26 04:59:13,351 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,356 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,356 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,356 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,356 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,356 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,356 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,356 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742173_1349, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala._COPYING_
2025-03-26 04:59:13,362 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,365 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,365 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,365 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,365 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,365 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,365 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,365 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742174_1350, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala._COPYING_
2025-03-26 04:59:13,370 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,373 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,373 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,373 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,373 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,373 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,373 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,374 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742175_1351, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala._COPYING_
2025-03-26 04:59:13,379 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,390 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,390 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,390 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,390 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,390 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,390 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,390 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742176_1352, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala._COPYING_
2025-03-26 04:59:13,397 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,400 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,400 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,400 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,400 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,400 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,400 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,401 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742177_1353, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala._COPYING_
2025-03-26 04:59:13,407 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,410 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,410 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,410 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,410 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,410 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,410 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,410 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742178_1354, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala._COPYING_
2025-03-26 04:59:13,416 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,420 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,420 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,420 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,420 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,420 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,420 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,420 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742179_1355, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala._COPYING_
2025-03-26 04:59:13,425 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,428 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,428 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,428 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,428 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,428 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,428 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,428 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742180_1356, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala._COPYING_
2025-03-26 04:59:13,433 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,436 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,436 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,436 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,436 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,436 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,437 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,437 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742181_1357, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala._COPYING_
2025-03-26 04:59:13,443 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,448 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,448 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,448 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,448 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,448 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,448 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,448 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742182_1358, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala._COPYING_
2025-03-26 04:59:13,452 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,455 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,455 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,455 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,455 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,455 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,455 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,455 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742183_1359, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala._COPYING_
2025-03-26 04:59:13,460 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,462 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,462 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,462 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,463 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,463 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,463 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,463 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742184_1360, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala._COPYING_
2025-03-26 04:59:13,467 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,470 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,470 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,470 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,470 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,470 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,470 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,470 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742185_1361, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala._COPYING_
2025-03-26 04:59:13,476 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,479 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,480 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,480 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,480 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,480 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,480 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,480 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742186_1362, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala._COPYING_
2025-03-26 04:59:13,484 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,489 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,489 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,489 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,489 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,489 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,489 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,489 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742187_1363, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_
2025-03-26 04:59:13,497 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742187_1363 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_
2025-03-26 04:59:13,898 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,901 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,901 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,901 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,901 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,901 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,901 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,901 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742188_1364, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala._COPYING_
2025-03-26 04:59:13,907 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,915 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,915 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,915 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,915 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,915 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,915 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,915 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742189_1365, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala._COPYING_
2025-03-26 04:59:13,924 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,927 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,927 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,927 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,927 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,927 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,928 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,928 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742190_1366, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala._COPYING_
2025-03-26 04:59:13,934 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,937 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,937 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,937 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,937 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,937 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,937 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,937 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742191_1367, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala._COPYING_
2025-03-26 04:59:13,946 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,951 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,951 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,951 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,951 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,951 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,951 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,952 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742192_1368, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala._COPYING_
2025-03-26 04:59:13,958 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,961 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,961 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,961 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,961 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,961 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,961 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,962 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742193_1369, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala._COPYING_
2025-03-26 04:59:13,977 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:13,986 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,986 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,986 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:13,986 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:13,986 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:13,986 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:13,986 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742194_1370, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala._COPYING_
2025-03-26 04:59:14,002 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,005 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,005 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,005 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,005 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,005 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,005 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,005 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742195_1371, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala._COPYING_
2025-03-26 04:59:14,027 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,031 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,031 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,031 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,031 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,031 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,031 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,031 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742196_1372, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala._COPYING_
2025-03-26 04:59:14,041 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,045 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,045 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,045 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,045 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,045 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,045 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,045 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742197_1373, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala._COPYING_
2025-03-26 04:59:14,055 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,058 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,058 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,058 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,058 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,058 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,058 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,058 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742198_1374, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala._COPYING_
2025-03-26 04:59:14,071 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,074 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,074 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,074 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,074 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,074 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,074 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,074 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742199_1375, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala._COPYING_
2025-03-26 04:59:14,083 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,086 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,086 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,086 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,086 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,086 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,086 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,087 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742200_1376, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala._COPYING_
2025-03-26 04:59:14,097 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,101 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,101 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,101 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,101 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,101 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,101 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,101 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742201_1377, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala._COPYING_
2025-03-26 04:59:14,106 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,109 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,109 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,109 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,109 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,109 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,109 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,109 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742202_1378, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala._COPYING_
2025-03-26 04:59:14,115 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,118 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,118 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,118 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,118 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,118 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,118 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,118 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742203_1379, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala._COPYING_
2025-03-26 04:59:14,135 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,138 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,138 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,138 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,139 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,139 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,139 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,139 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742204_1380, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala._COPYING_
2025-03-26 04:59:14,146 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,158 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,158 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,158 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,158 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,158 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,158 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,158 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742205_1381, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 04:59:14,166 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,172 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,172 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,172 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,172 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,172 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,172 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,172 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742206_1382, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala._COPYING_
2025-03-26 04:59:14,180 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,187 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,187 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,187 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,187 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,187 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,187 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,187 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742207_1383, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala._COPYING_
2025-03-26 04:59:14,195 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,198 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,198 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,198 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,198 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,198 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,198 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,199 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742208_1384, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 04:59:14,208 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,213 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,213 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,213 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,213 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,213 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,213 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,213 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742209_1385, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala._COPYING_
2025-03-26 04:59:14,220 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,223 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,223 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,223 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,223 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,223 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,223 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,223 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742210_1386, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala._COPYING_
2025-03-26 04:59:14,234 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,237 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,237 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,237 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,237 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,237 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,237 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,237 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742211_1387, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala._COPYING_
2025-03-26 04:59:14,246 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,249 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,249 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,249 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,249 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,249 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,249 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,249 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742212_1388, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala._COPYING_
2025-03-26 04:59:14,253 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,256 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,256 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,256 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,256 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,256 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,256 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,256 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742213_1389, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala._COPYING_
2025-03-26 04:59:14,261 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,264 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,264 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,264 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,264 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,264 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,264 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,264 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742214_1390, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala._COPYING_
2025-03-26 04:59:14,268 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,271 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,271 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,271 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,271 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,271 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,271 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,271 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742215_1391, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala._COPYING_
2025-03-26 04:59:14,275 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,278 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,278 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,278 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,278 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,278 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,278 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,278 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742216_1392, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala._COPYING_
2025-03-26 04:59:14,282 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,284 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,284 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,284 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,284 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,284 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,284 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,284 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742217_1393, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala._COPYING_
2025-03-26 04:59:14,288 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,293 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,293 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,293 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,293 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,293 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,293 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,293 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742218_1394, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala._COPYING_
2025-03-26 04:59:14,296 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,299 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,299 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,299 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,299 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,299 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,299 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,299 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742219_1395, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala._COPYING_
2025-03-26 04:59:14,303 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,306 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,306 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,306 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,306 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,306 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,306 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,306 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742220_1396, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala._COPYING_
2025-03-26 04:59:14,310 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,315 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,315 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,315 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,315 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,315 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,315 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,315 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742221_1397, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala._COPYING_
2025-03-26 04:59:14,318 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,326 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,326 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,326 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,326 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,326 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,326 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,326 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742222_1398, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala._COPYING_
2025-03-26 04:59:14,331 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,333 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,333 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,333 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,333 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,333 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,333 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,333 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742223_1399, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala._COPYING_
2025-03-26 04:59:14,342 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,347 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,347 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,347 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,347 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,347 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,347 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,347 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742224_1400, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala._COPYING_
2025-03-26 04:59:14,351 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,354 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,354 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,354 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,354 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,354 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,354 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,354 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742225_1401, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_
2025-03-26 04:59:14,358 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,361 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,361 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,361 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,361 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,361 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,361 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,361 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742226_1402, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala._COPYING_
2025-03-26 04:59:14,364 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,368 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,368 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,368 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,368 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,368 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,368 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,368 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742227_1403, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala._COPYING_
2025-03-26 04:59:14,373 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,375 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,375 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,375 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,375 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,375 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,375 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,375 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742228_1404, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala._COPYING_
2025-03-26 04:59:14,379 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,387 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,387 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,387 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,387 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,387 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,387 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,387 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742229_1405, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala._COPYING_
2025-03-26 04:59:14,391 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,395 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,395 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,395 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,395 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,395 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,395 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,395 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742230_1406, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala._COPYING_
2025-03-26 04:59:14,399 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,406 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,406 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,406 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,406 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,406 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,406 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,406 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742231_1407, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_
2025-03-26 04:59:14,410 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742231_1407 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_
2025-03-26 04:59:14,812 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,821 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,821 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,821 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,821 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,821 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,821 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,821 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742232_1408, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala._COPYING_
2025-03-26 04:59:14,835 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,848 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,849 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,849 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,849 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,849 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,849 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,849 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742233_1409, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_
2025-03-26 04:59:14,857 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,865 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,865 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,865 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,865 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,865 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,865 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,865 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742234_1410, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala._COPYING_
2025-03-26 04:59:14,870 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,873 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,873 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,873 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,873 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,873 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,873 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,873 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742235_1411, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala._COPYING_
2025-03-26 04:59:14,877 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,886 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,886 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,886 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,886 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,886 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,886 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,886 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742236_1412, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala._COPYING_
2025-03-26 04:59:14,890 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,894 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,894 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,894 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,894 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,894 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,894 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,894 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742237_1413, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala._COPYING_
2025-03-26 04:59:14,898 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,907 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,907 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,907 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,907 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,907 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,907 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,907 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742238_1414, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala._COPYING_
2025-03-26 04:59:14,911 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,914 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,914 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,914 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,914 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,914 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,914 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,914 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742239_1415, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala._COPYING_
2025-03-26 04:59:14,919 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,921 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,921 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,921 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,921 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,921 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,921 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,921 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742240_1416, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala._COPYING_
2025-03-26 04:59:14,926 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,929 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,929 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,929 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,929 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,929 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,929 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,929 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742241_1417, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_
2025-03-26 04:59:14,933 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,935 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,935 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,935 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,935 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,935 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,935 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,935 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742242_1418, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala._COPYING_
2025-03-26 04:59:14,939 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,942 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,942 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,942 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,942 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,942 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,942 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,942 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742243_1419, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala._COPYING_
2025-03-26 04:59:14,946 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,950 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,950 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,950 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,950 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,950 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,951 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,951 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742244_1420, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_
2025-03-26 04:59:14,955 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,957 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,957 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,957 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,958 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,958 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,958 WARN [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,958 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742245_1421, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala._COPYING_
2025-03-26 04:59:14,962 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,966 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,966 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,966 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,966 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,966 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,966 WARN [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,966 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742246_1422, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala._COPYING_
2025-03-26 04:59:14,971 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,972 WARN [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,979 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,979 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,979 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,979 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,979 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,979 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,979 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742247_1423, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala._COPYING_
2025-03-26 04:59:14,987 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,990 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,990 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,990 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,990 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,990 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,990 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,990 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742248_1424, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala._COPYING_
2025-03-26 04:59:14,993 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:14,997 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,997 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,997 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:14,997 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:14,997 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:14,997 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:14,997 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742249_1425, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala._COPYING_
2025-03-26 04:59:15,001 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,004 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,004 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,004 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,004 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,004 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,004 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,004 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742250_1426, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala._COPYING_
2025-03-26 04:59:15,008 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,011 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,011 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,011 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,011 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,011 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,011 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,011 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742251_1427, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala._COPYING_
2025-03-26 04:59:15,018 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,024 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,024 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,024 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,024 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,024 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,024 WARN [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,024 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742252_1428, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_
2025-03-26 04:59:15,028 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,033 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,033 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,033 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,033 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,033 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,033 WARN [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,033 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742253_1429, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala._COPYING_
2025-03-26 04:59:15,037 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,040 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,040 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,040 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,040 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,040 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,040 WARN [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,040 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742254_1430, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala._COPYING_
2025-03-26 04:59:15,043 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,046 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,046 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,046 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,046 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,046 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,046 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,046 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742255_1431, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_
2025-03-26 04:59:15,050 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,052 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,052 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,052 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,052 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,052 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,052 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,053 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742256_1432, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala._COPYING_
2025-03-26 04:59:15,056 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,066 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,066 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,066 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,066 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,066 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,066 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,066 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742257_1433, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_
2025-03-26 04:59:15,074 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,079 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,079 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,079 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,079 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,079 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,079 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,079 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742258_1434, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java._COPYING_
2025-03-26 04:59:15,084 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,087 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,087 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,087 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,087 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,087 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,087 WARN [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,087 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742259_1435, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java._COPYING_
2025-03-26 04:59:15,091 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,094 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,095 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,095 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,095 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,095 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,095 WARN [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,095 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742260_1436, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java._COPYING_
2025-03-26 04:59:15,098 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,101 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,101 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,101 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,101 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:15,101 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:15,101 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:15,101 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742261_1437, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_
2025-03-26 04:59:15,105 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742261_1437 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_
2025-03-26 04:59:15,506 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,515 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,515 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,515 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742262_1438, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java._COPYING_
2025-03-26 04:59:15,533 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,542 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,542 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,542 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742263_1439, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_
2025-03-26 04:59:15,549 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,553 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,553 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,553 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742264_1440, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_
2025-03-26 04:59:15,559 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,562 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,562 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,562 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742265_1441, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java._COPYING_
2025-03-26 04:59:15,567 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,570 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,571 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,571 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742266_1442, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java._COPYING_
2025-03-26 04:59:15,576 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,580 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,580 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,580 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742267_1443, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java._COPYING_
2025-03-26 04:59:15,585 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,588 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,588 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,588 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742268_1444, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java._COPYING_
2025-03-26 04:59:15,593 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,595 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,596 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,596 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742269_1445, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_
2025-03-26 04:59:15,600 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,603 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,603 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,603 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742270_1446, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 04:59:15,614 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,616 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,616 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,616 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742271_1447, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java._COPYING_
2025-03-26 04:59:15,623 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,626 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,626 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,626 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742272_1448, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java._COPYING_
2025-03-26 04:59:15,632 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,635 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,635 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,635 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742273_1449, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java._COPYING_
2025-03-26 04:59:15,640 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,643 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,643 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,643 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742274_1450, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java._COPYING_
2025-03-26 04:59:15,649 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,656 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,656 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,656 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742275_1451, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java._COPYING_
2025-03-26 04:59:15,662 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,665 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,665 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,665 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742276_1452, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java._COPYING_
2025-03-26 04:59:15,670 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,674 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,674 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,674 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742277_1453, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java._COPYING_
2025-03-26 04:59:15,680 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,683 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,683 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,683 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742278_1454, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java._COPYING_
2025-03-26 04:59:15,689 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,692 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,692 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,692 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742279_1455, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java._COPYING_
2025-03-26 04:59:15,698 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,701 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,701 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,701 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742280_1456, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java._COPYING_
2025-03-26 04:59:15,707 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,709 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,709 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,710 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742281_1457, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_
2025-03-26 04:59:15,715 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,719 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,719 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,719 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742282_1458, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java._COPYING_
2025-03-26 04:59:15,724 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,727 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,727 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,727 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742283_1459, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java._COPYING_
2025-03-26 04:59:15,733 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,736 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,736 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,736 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742284_1460, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java._COPYING_
2025-03-26 04:59:15,741 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,744 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,744 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,744 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742285_1461, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java._COPYING_
2025-03-26 04:59:15,751 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,758 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,758 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,758 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742286_1462, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java._COPYING_
2025-03-26 04:59:15,767 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,771 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,771 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,771 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742287_1463, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java._COPYING_
2025-03-26 04:59:15,777 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,780 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,780 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,780 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742288_1464, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java._COPYING_
2025-03-26 04:59:15,786 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,789 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,789 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,789 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742289_1465, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_
2025-03-26 04:59:15,797 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,801 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,801 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,801 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742290_1466, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java._COPYING_
2025-03-26 04:59:15,809 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,812 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,812 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,812 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742291_1467, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java._COPYING_
2025-03-26 04:59:15,817 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,820 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,820 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,820 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742292_1468, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java._COPYING_
2025-03-26 04:59:15,826 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,829 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,829 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,829 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742293_1469, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java._COPYING_
2025-03-26 04:59:15,835 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,841 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,841 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,841 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742294_1470, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java._COPYING_
2025-03-26 04:59:15,846 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,849 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,849 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,849 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742295_1471, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java._COPYING_
2025-03-26 04:59:15,856 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,859 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,859 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,859 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742296_1472, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_
2025-03-26 04:59:15,865 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,868 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,868 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,868 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742297_1473, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java._COPYING_
2025-03-26 04:59:15,875 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,878 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,878 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,878 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742298_1474, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java._COPYING_
2025-03-26 04:59:15,884 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,888 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,888 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,888 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742299_1475, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java._COPYING_
2025-03-26 04:59:15,894 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,897 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,897 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,897 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742300_1476, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_
2025-03-26 04:59:15,903 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,906 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,906 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,906 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742301_1477, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java._COPYING_
2025-03-26 04:59:15,912 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,915 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,915 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,915 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742302_1478, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java._COPYING_
2025-03-26 04:59:15,921 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,924 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,924 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,924 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742303_1479, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java._COPYING_
2025-03-26 04:59:15,929 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,933 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,933 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,933 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742304_1480, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java._COPYING_
2025-03-26 04:59:15,938 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,941 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,941 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,941 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742305_1481, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java._COPYING_
2025-03-26 04:59:15,947 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,949 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,949 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,949 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742306_1482, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java._COPYING_
2025-03-26 04:59:15,954 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,956 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,956 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,957 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742307_1483, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java._COPYING_
2025-03-26 04:59:15,961 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,964 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,964 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,964 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742308_1484, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java._COPYING_
2025-03-26 04:59:15,968 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,971 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,971 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,971 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742309_1485, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java._COPYING_
2025-03-26 04:59:15,976 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,978 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,978 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,979 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742310_1486, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java._COPYING_
2025-03-26 04:59:15,983 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,987 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,987 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,987 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742311_1487, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java._COPYING_
2025-03-26 04:59:15,993 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:15,995 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,996 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:15,996 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742312_1488, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_
2025-03-26 04:59:16,002 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,005 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,005 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,005 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742313_1489, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java._COPYING_
2025-03-26 04:59:16,009 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,012 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,012 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,012 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742314_1490, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java._COPYING_
2025-03-26 04:59:16,017 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,019 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,019 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,019 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742315_1491, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java._COPYING_
2025-03-26 04:59:16,024 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,027 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,027 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,027 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742316_1492, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_
2025-03-26 04:59:16,031 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,034 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,034 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,034 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742317_1493, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java._COPYING_
2025-03-26 04:59:16,039 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,042 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,042 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,042 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742318_1494, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java._COPYING_
2025-03-26 04:59:16,047 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,049 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,049 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,049 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742319_1495, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java._COPYING_
2025-03-26 04:59:16,054 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,062 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,062 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,062 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742320_1496, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java._COPYING_
2025-03-26 04:59:16,067 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,070 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,070 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,070 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742321_1497, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java._COPYING_
2025-03-26 04:59:16,075 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,077 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,077 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,077 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742322_1498, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java._COPYING_
2025-03-26 04:59:16,083 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,086 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,086 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,086 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742323_1499, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java._COPYING_
2025-03-26 04:59:16,093 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,096 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,096 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,096 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742324_1500, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java._COPYING_
2025-03-26 04:59:16,105 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,108 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,108 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,108 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742325_1501, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 04:59:16,117 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,120 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,120 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,120 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742326_1502, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java._COPYING_
2025-03-26 04:59:16,129 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,142 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,142 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,142 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742327_1503, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java._COPYING_
2025-03-26 04:59:16,149 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,152 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,152 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,152 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742328_1504, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java._COPYING_
2025-03-26 04:59:16,159 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,161 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,161 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,161 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742329_1505, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java._COPYING_
2025-03-26 04:59:16,167 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,171 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,171 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,171 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742330_1506, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java._COPYING_
2025-03-26 04:59:16,177 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,180 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,180 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,180 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742331_1507, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java._COPYING_
2025-03-26 04:59:16,188 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,191 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,191 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,191 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742332_1508, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_
2025-03-26 04:59:16,200 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,211 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,211 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,211 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742333_1509, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java._COPYING_
2025-03-26 04:59:16,221 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,224 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,224 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,224 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742334_1510, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_
2025-03-26 04:59:16,229 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,231 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,231 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,231 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742335_1511, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java._COPYING_
2025-03-26 04:59:16,236 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,243 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,243 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,243 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742336_1512, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java._COPYING_
2025-03-26 04:59:16,250 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,254 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,254 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,254 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742337_1513, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java._COPYING_
2025-03-26 04:59:16,259 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,267 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,267 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,267 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742338_1514, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java._COPYING_
2025-03-26 04:59:16,273 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,275 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,275 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,275 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742339_1515, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java._COPYING_
2025-03-26 04:59:16,285 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,289 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,289 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,289 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742340_1516, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_
2025-03-26 04:59:16,294 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,296 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,296 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,296 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742341_1517, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java._COPYING_
2025-03-26 04:59:16,303 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,306 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,306 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,306 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742342_1518, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java._COPYING_
2025-03-26 04:59:16,311 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,314 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,314 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,314 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742343_1519, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java._COPYING_
2025-03-26 04:59:16,319 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,323 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,323 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,323 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742344_1520, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java._COPYING_
2025-03-26 04:59:16,327 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,330 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,330 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,330 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742345_1521, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java._COPYING_
2025-03-26 04:59:16,337 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,339 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,339 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,339 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742346_1522, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java._COPYING_
2025-03-26 04:59:16,344 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,347 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,347 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,347 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742347_1523, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java._COPYING_
2025-03-26 04:59:16,351 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,354 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,354 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,354 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742348_1524, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java._COPYING_
2025-03-26 04:59:16,362 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,365 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,365 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,365 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742349_1525, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java._COPYING_
2025-03-26 04:59:16,370 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,374 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,374 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,374 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742350_1526, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java._COPYING_
2025-03-26 04:59:16,378 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,382 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,382 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,382 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742351_1527, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java._COPYING_
2025-03-26 04:59:16,386 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,389 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,389 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,389 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742352_1528, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java._COPYING_
2025-03-26 04:59:16,398 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,402 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,402 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,402 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742353_1529, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java._COPYING_
2025-03-26 04:59:16,406 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,412 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,412 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,412 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742354_1530, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java._COPYING_
2025-03-26 04:59:16,418 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,431 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,431 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,431 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742355_1531, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java._COPYING_
2025-03-26 04:59:16,437 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,442 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,442 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,442 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742356_1532, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java._COPYING_
2025-03-26 04:59:16,447 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,451 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,451 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,451 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742357_1533, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java._COPYING_
2025-03-26 04:59:16,456 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,460 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,460 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,460 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742358_1534, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java._COPYING_
2025-03-26 04:59:16,465 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,468 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,468 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,468 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742359_1535, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java._COPYING_
2025-03-26 04:59:16,473 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,477 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,477 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,477 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742360_1536, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java._COPYING_
2025-03-26 04:59:16,482 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,485 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,485 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,485 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742361_1537, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java._COPYING_
2025-03-26 04:59:16,489 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,493 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,493 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,493 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742362_1538, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java._COPYING_
2025-03-26 04:59:16,500 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,510 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,510 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,510 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742363_1539, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_
2025-03-26 04:59:16,516 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,519 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,520 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,520 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742364_1540, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java._COPYING_
2025-03-26 04:59:16,526 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,530 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,530 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,530 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742365_1541, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java._COPYING_
2025-03-26 04:59:16,536 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,538 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,538 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,539 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742366_1542, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java._COPYING_
2025-03-26 04:59:16,544 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,547 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,547 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,547 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742367_1543, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_
2025-03-26 04:59:16,556 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,559 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,559 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,559 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742368_1544, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java._COPYING_
2025-03-26 04:59:16,565 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,573 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,573 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,573 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742369_1545, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java._COPYING_
2025-03-26 04:59:16,588 INFO [IPC Server handler 4 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,592 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,592 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,592 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742370_1546, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaTC.java._COPYING_
2025-03-26 04:59:16,597 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaTC.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,604 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,605 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,605 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742371_1547, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java._COPYING_
2025-03-26 04:59:16,611 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,614 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,614 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,614 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742372_1548, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java._COPYING_
2025-03-26 04:59:16,619 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,626 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,626 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,626 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742373_1549, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java._COPYING_
2025-03-26 04:59:16,633 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,640 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,640 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,640 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742374_1550, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java._COPYING_
2025-03-26 04:59:16,646 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,655 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,655 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,655 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742375_1551, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java._COPYING_
2025-03-26 04:59:16,661 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,666 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,666 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,666 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742376_1552, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java._COPYING_
2025-03-26 04:59:16,675 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,679 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,679 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,679 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742377_1553, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java._COPYING_
2025-03-26 04:59:16,685 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,688 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,688 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,688 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742378_1554, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_
2025-03-26 04:59:16,693 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,696 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,696 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,696 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742379_1555, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java._COPYING_
2025-03-26 04:59:16,705 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,710 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,710 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,710 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742380_1556, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_
2025-03-26 04:59:16,722 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,726 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,726 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,726 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742381_1557, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_
2025-03-26 04:59:16,733 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,736 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,736 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,736 INFO [IPC Server handler 1 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742382_1558, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java._COPYING_
2025-03-26 04:59:16,741 INFO [IPC Server handler 3 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,746 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,746 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,746 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742383_1559, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java._COPYING_
2025-03-26 04:59:16,751 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,754 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,754 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,754 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742384_1560, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_
2025-03-26 04:59:16,761 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,764 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,764 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,764 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742385_1561, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java._COPYING_
2025-03-26 04:59:16,768 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,771 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,771 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,771 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742386_1562, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java._COPYING_
2025-03-26 04:59:16,775 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,777 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,777 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,777 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742387_1563, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java._COPYING_
2025-03-26 04:59:16,782 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,784 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,784 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,784 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742388_1564, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java._COPYING_
2025-03-26 04:59:16,789 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,791 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,791 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,791 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742389_1565, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java._COPYING_
2025-03-26 04:59:16,797 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,799 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,799 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,799 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742390_1566, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java._COPYING_
2025-03-26 04:59:16,805 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,808 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,808 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,808 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742391_1567, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_
2025-03-26 04:59:16,818 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:16,821 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,821 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:16,821 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742392_1568, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scripts/getGpusResources.sh._COPYING_
2025-03-26 04:59:16,827 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scripts/getGpusResources.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1196562029_1
2025-03-26 04:59:17,973 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:17,973 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:17,973 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:17,973 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:20,973 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:20,973 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:20,973 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:20,973 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:23,974 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:23,974 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:23,974 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:23,974 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:26,974 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:26,974 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:26,974 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:26,974 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:29,974 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:29,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:29,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:29,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:32,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:32,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:32,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:32,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:35,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:35,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:35,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:35,975 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:38,069 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:38,069 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:38,069 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742393_1569, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/.sparkStaging/application_1742965134050_0001/__spark_libs__5073611204567325152.zip
2025-03-26 04:59:38,798 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:38,798 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:38,799 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742394_1570, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/.sparkStaging/application_1742965134050_0001/__spark_libs__5073611204567325152.zip
2025-03-26 04:59:38,976 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:38,976 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:38,976 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:38,976 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,233 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,233 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,234 INFO [IPC Server handler 7 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742395_1571, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/.sparkStaging/application_1742965134050_0001/__spark_libs__5073611204567325152.zip
2025-03-26 04:59:39,368 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/.sparkStaging/application_1742965134050_0001/__spark_libs__5073611204567325152.zip is closed by DFSClient_NONMAPREDUCE_-964299567_1
2025-03-26 04:59:39,429 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,429 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,429 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,429 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:39,429 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:39,429 WARN [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:39,429 INFO [IPC Server handler 6 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742396_1572, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/.sparkStaging/application_1742965134050_0001/scopt_2.12-3.7.1.jar
2025-03-26 04:59:39,451 INFO [IPC Server handler 9 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/.sparkStaging/application_1742965134050_0001/scopt_2.12-3.7.1.jar is closed by DFSClient_NONMAPREDUCE_-964299567_1
2025-03-26 04:59:39,517 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,517 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,517 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,517 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:39,517 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:39,517 WARN [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:39,517 INFO [IPC Server handler 2 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742397_1573, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/.sparkStaging/application_1742965134050_0001/spark-examples_2.12-3.3.2.jar
2025-03-26 04:59:39,557 INFO [IPC Server handler 5 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/.sparkStaging/application_1742965134050_0001/spark-examples_2.12-3.3.2.jar is closed by DFSClient_NONMAPREDUCE_-964299567_1
2025-03-26 04:59:39,658 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,658 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,658 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:39,658 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 04:59:39,658 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 04:59:39,658 WARN [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 04:59:39,659 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742398_1574, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/.sparkStaging/application_1742965134050_0001/__spark_conf__.zip
2025-03-26 04:59:39,672 INFO [IPC Server handler 8 on default port 9000] org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/.sparkStaging/application_1742965134050_0001/__spark_conf__.zip is closed by DFSClient_NONMAPREDUCE_-964299567_1
2025-03-26 04:59:41,977 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:41,977 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:41,977 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:41,977 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:44,977 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:44,977 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:44,977 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:44,977 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:47,978 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:47,978 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:47,978 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:47,978 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:49,338 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.20.1.14
2025-03-26 04:59:49,338 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2025-03-26 04:59:49,338 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 3496
2025-03-26 04:59:49,339 INFO [FSEditLogAsync] org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3497 Total time for transactions(ms): 69 Number of transactions batched in Syncs: 782 Number of syncs: 2715 SyncTimes(ms): 1451 
2025-03-26 04:59:49,339 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3497 Total time for transactions(ms): 69 Number of transactions batched in Syncs: 782 Number of syncs: 2716 SyncTimes(ms): 1452 
2025-03-26 04:59:49,340 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000003497
2025-03-26 04:59:49,356 INFO [IPC Server handler 0 on default port 9000] org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3498
2025-03-26 04:59:49,446 INFO [qtp1825738663-20] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/name/current/fsimage_0000000000000000000, fileSize: 399. Sent total: 399 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 04:59:49,458 INFO [qtp1825738663-16] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000003497, fileSize: 482942. Sent total: 482942 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 04:59:49,899 INFO [qtp1825738663-17] org.apache.hadoop.hdfs.server.namenode.ImageServlet: Rejecting a fsimage due to small time delta and txnid delta. Time since previous checkpoint is 68 expecting at least 2700 txnid delta since previous checkpoint is 3497 expecting at least 1000000
2025-03-26 04:59:50,978 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:50,978 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:50,978 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:50,978 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:53,979 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:53,979 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:53,979 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:53,979 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:56,979 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:56,979 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:56,979 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:56,979 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:59,980 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:59,980 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:59,980 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 04:59:59,980 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:02,981 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:02,982 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:02,982 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:02,982 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:05,983 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:05,983 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:05,983 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:05,983 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:08,984 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:08,984 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:08,984 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:08,984 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:11,985 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:11,986 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:11,986 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:11,986 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:14,987 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:14,987 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:14,987 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 05:00:14,987 INFO [RedundancyMonitor] org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
