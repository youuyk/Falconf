2025-03-26 02:24:06,381 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NameNode STARTUP_MSG:   host = master/172.20.1.14 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:24:06,385 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:24:06,442 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2025-03-26 02:24:06,519 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:24:06,581 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2025-03-26 02:24:06,581 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:24:06,590 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use master:9000 to access this namenode/service.
2025-03-26 02:24:06,590 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://master:9000
2025-03-26 02:24:06,706 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:24:06,716 INFO org.apache.hadoop.hdfs.DFSUtil: Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-03-26 02:24:06,719 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2025-03-26 02:24:06,726 INFO org.eclipse.jetty.util.log: Logging initialized @606ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:24:06,778 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:06,785 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2025-03-26 02:24:06,790 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:24:06,792 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2025-03-26 02:24:06,792 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:24:06,792 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:24:06,794 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2025-03-26 02:24:06,794 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-03-26 02:24:06,794 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-03-26 02:24:06,812 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2025-03-26 02:24:06,817 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2025-03-26 02:24:06,818 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:24:06,836 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:24:06,836 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:24:06,837 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:24:06,850 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:06,851 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b4c50bc{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:24:06,852 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@79207381{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:24:06,888 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@c7045b9{hdfs,/,file:///hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/hdfs}
2025-03-26 02:24:06,893 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@17503f6b{HTTP/1.1, (http/1.1)}{0.0.0.0:9870}
2025-03-26 02:24:06,893 INFO org.eclipse.jetty.server.Server: Started @774ms
2025-03-26 02:24:07,036 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-03-26 02:24:07,036 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-03-26 02:24:07,060 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2025-03-26 02:24:07,082 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2025-03-26 02:24:07,083 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2025-03-26 02:24:07,083 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2025-03-26 02:24:07,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2025-03-26 02:24:07,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)
2025-03-26 02:24:07,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled    = true
2025-03-26 02:24:07,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isStoragePolicyEnabled = true
2025-03-26 02:24:07,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup             = supergroup
2025-03-26 02:24:07,102 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:24:07,105 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.15" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:24:07,105 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.16" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:24:07,105 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.17" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:24:07,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-26 02:24:07,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-26 02:24:07,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2025 Mar 26 02:24:07
2025-03-26 02:24:07,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-26 02:24:07,109 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2025-03-26 02:24:07,109 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:24:07,110 INFO org.apache.hadoop.util.GSet: 2.0% max memory 910.5 MB = 18.2 MB
2025-03-26 02:24:07,110 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2025-03-26 02:24:07,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Storage policy satisfier is disabled
2025-03-26 02:24:07,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2025-03-26 02:24:07,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2025-03-26 02:24:07,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2025-03-26 02:24:07,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2025-03-26 02:24:07,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2025-03-26 02:24:07,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2025-03-26 02:24:07,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2025-03-26 02:24:07,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
2025-03-26 02:24:07,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2025-03-26 02:24:07,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2025-03-26 02:24:07,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2025-03-26 02:24:07,130 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2025-03-26 02:24:07,130 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2025-03-26 02:24:07,130 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2025-03-26 02:24:07,130 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2025-03-26 02:24:07,138 INFO org.apache.hadoop.util.GSet: 1.0% max memory 910.5 MB = 9.1 MB
2025-03-26 02:24:07,138 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2025-03-26 02:24:07,138 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:24:07,138 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2025-03-26 02:24:07,139 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? true
2025-03-26 02:24:07,139 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2025-03-26 02:24:07,139 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2025-03-26 02:24:07,139 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2025-03-26 02:24:07,143 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-03-26 02:24:07,144 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2025-03-26 02:24:07,147 INFO org.apache.hadoop.util.GSet: 0.25% max memory 910.5 MB = 2.3 MB
2025-03-26 02:24:07,147 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2025-03-26 02:24:07,147 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:24:07,147 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2025-03-26 02:24:07,159 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2025-03-26 02:24:07,159 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-26 02:24:07,159 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-26 02:24:07,161 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2025-03-26 02:24:07,161 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2025-03-26 02:24:07,162 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 910.5 MB = 279.7 KB
2025-03-26 02:24:07,162 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2025-03-26 02:24:07,162 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:24:07,162 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2025-03-26 02:24:07,473 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/name/in_use.lock acquired by nodename 264@master
2025-03-26 02:24:07,489 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2025-03-26 02:24:07,489 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2025-03-26 02:24:07,489 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/tmp/dfs/name/current
2025-03-26 02:24:07,521 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2025-03-26 02:24:07,524 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
2025-03-26 02:24:07,527 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-26 02:24:07,530 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/tmp/dfs/name/current/fsimage_0000000000000000000
2025-03-26 02:24:07,530 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2025-03-26 02:24:07,532 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2025-03-26 02:24:07,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2025-03-26 02:24:07,580 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 417 msecs
2025-03-26 02:24:07,580 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2025-03-26 02:24:07,668 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Enable NameNode state context:false
2025-03-26 02:24:07,668 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master:9000
2025-03-26 02:24:07,676 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:07,684 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2025-03-26 02:24:07,825 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2025-03-26 02:24:07,831 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2025-03-26 02:24:07,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor: Initialized the Default Decommission and Maintenance monitor
2025-03-26 02:24:07,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Start MarkedDeleteBlockScrubber thread
2025-03-26 02:24:07,838 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2025-03-26 02:24:07,838 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2025-03-26 02:24:07,838 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2025-03-26 02:24:07,838 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2025-03-26 02:24:07,863 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2025-03-26 02:24:07,864 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2025-03-26 02:24:07,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2025-03-26 02:24:07,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2025-03-26 02:24:07,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2025-03-26 02:24:07,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2025-03-26 02:24:07,865 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:07,866 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2025-03-26 02:24:07,867 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master/172.20.1.14:9000
2025-03-26 02:24:07,869 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 12 thread(s)
2025-03-26 02:24:07,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2025-03-26 02:24:07,875 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 6 milliseconds name space=1 storage space=0 storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2025-03-26 02:24:07,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2025-03-26 02:24:08,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave0/172.20.1.15 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:24:08,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:24:08,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave1/172.20.1.16 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:24:08,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:24:08,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave2/172.20.1.17 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:24:08,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:24:08,956 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:24:09,025 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:24:09,070 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:24:09,070 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:24:09,130 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:24:09,155 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:24:09,213 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:24:09,223 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:24:09,227 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:24:09,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave0
2025-03-26 02:24:09,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:24:09,234 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:24:09,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:24:09,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:24:09,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:24:09,244 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:24:09,269 INFO org.eclipse.jetty.util.log: Logging initialized @906ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:24:09,296 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:24:09,296 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:24:09,305 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:24:09,305 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:24:09,341 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:09,346 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:24:09,351 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:24:09,352 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:24:09,352 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:24:09,352 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:24:09,412 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44033
2025-03-26 02:24:09,413 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:24:09,429 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:24:09,429 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:24:09,429 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:24:09,436 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2a3888c1{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:24:09,437 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68f1b17f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:24:09,452 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:24:09,459 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:24:09,463 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:24:09,468 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:24:09,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2025-03-26 02:24:09,472 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:24:09,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:24:09,476 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:24:09,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2025-03-26 02:24:09,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:24:09,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:24:09,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:24:09,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:24:09,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:24:09,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:24:09,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:24:09,498 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@49964d75{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:24:09,504 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@63eef88a{HTTP/1.1, (http/1.1)}{localhost:44033}
2025-03-26 02:24:09,504 INFO org.eclipse.jetty.server.Server: Started @1141ms
2025-03-26 02:24:09,526 INFO org.eclipse.jetty.util.log: Logging initialized @1124ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:24:09,532 INFO org.eclipse.jetty.util.log: Logging initialized @1117ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:24:09,547 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:24:09,602 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:24:09,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:24:09,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:24:09,606 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:24:09,609 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:09,615 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:24:09,618 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:09,621 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:24:09,623 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:24:09,623 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:24:09,623 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:24:09,624 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:24:09,629 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:09,631 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:24:09,633 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:24:09,633 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:24:09,633 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:24:09,642 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:24:09,685 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42021
2025-03-26 02:24:09,686 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:24:09,697 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36807
2025-03-26 02:24:09,698 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:24:09,709 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:24:09,709 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:24:09,710 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:24:09,727 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6c372fe6{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:24:09,728 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@14fa86ae{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:24:09,736 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:24:09,736 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:24:09,737 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:24:09,756 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2a3888c1{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:24:09,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:24:09,757 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68f1b17f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:24:09,780 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@42b02722{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:24:09,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:24:09,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:24:09,788 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@3370f42{HTTP/1.1, (http/1.1)}{localhost:42021}
2025-03-26 02:24:09,790 INFO org.eclipse.jetty.server.Server: Started @1375ms
2025-03-26 02:24:09,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000 starting to offer service
2025-03-26 02:24:09,806 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@49964d75{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:24:09,809 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:09,810 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:24:09,813 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@63eef88a{HTTP/1.1, (http/1.1)}{localhost:36807}
2025-03-26 02:24:09,813 INFO org.eclipse.jetty.server.Server: Started @1410ms
2025-03-26 02:24:09,848 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:24:09,871 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:24:09,914 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:24:09,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:24:09,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:24:09,921 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:24:09,934 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:24:09,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:24:09,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:24:09,942 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:24:09,954 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:09,969 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:24:09,973 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:09,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000
2025-03-26 02:24:09,988 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:24:09,989 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:24:10,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:24:10,150 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 92@slave0
2025-03-26 02:24:10,151 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 1756216927. Formatting...
2025-03-26 02:24:10,152 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-90db0e37-4b8f-48e3-b97b-93d475ea7f25 for directory /data/tmp/dfs/data
2025-03-26 02:24:10,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:24:10,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:24:10,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:24:10,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000 starting to offer service
2025-03-26 02:24:10,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:24:10,190 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:10,190 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:24:10,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:24:10,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000 starting to offer service
2025-03-26 02:24:10,223 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:10,225 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:24:10,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000
2025-03-26 02:24:10,275 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:24:10,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.14:9000
2025-03-26 02:24:10,309 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:24:10,519 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 96@slave2
2025-03-26 02:24:10,520 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 1756216927. Formatting...
2025-03-26 02:24:10,521 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-499d1dc3-f8d3-4ca7-ad32-eaa89c220a3b for directory /data/tmp/dfs/data
2025-03-26 02:24:10,670 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 92@slave1
2025-03-26 02:24:10,671 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 1756216927. Formatting...
2025-03-26 02:24:10,672 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-ba1153b5-2294-4c37-8e52-97710252c642 for directory /data/tmp/dfs/data
2025-03-26 02:24:10,686 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:10,686 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1984027250-172.20.1.14-1742955844230 is not formatted. Formatting ...
2025-03-26 02:24:10,686 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1984027250-172.20.1.14-1742955844230 directory /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230/current
2025-03-26 02:24:10,686 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:11,140 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:11,140 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1984027250-172.20.1.14-1742955844230 is not formatted. Formatting ...
2025-03-26 02:24:11,140 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1984027250-172.20.1.14-1742955844230 directory /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230/current
2025-03-26 02:24:11,140 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:11,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1756216927;bpid=BP-1984027250-172.20.1.14-1742955844230;lv=-57;nsInfo=lv=-66;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230;bpid=BP-1984027250-172.20.1.14-1742955844230;dnuuid=null
2025-03-26 02:24:11,311 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:11,311 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:11,312 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1984027250-172.20.1.14-1742955844230 is not formatted. Formatting ...
2025-03-26 02:24:11,312 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1984027250-172.20.1.14-1742955844230 directory /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230/current
2025-03-26 02:24:11,465 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting SecondaryNameNode STARTUP_MSG:   host = master/172.20.1.14 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:24:11,470 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:24:11,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 6d56b89c-125c-462b-baba-7781dfcf9a36
2025-03-26 02:24:11,609 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:24:11,655 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-90db0e37-4b8f-48e3-b97b-93d475ea7f25
2025-03-26 02:24:11,655 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:24:11,657 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:24:11,658 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:24:11,662 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:11,663 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data...
2025-03-26 02:24:11,667 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230/current, will proceed with Du for space computation calculation,
2025-03-26 02:24:11,681 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1984027250-172.20.1.14-1742955844230 on /data/tmp/dfs/data: 19ms
2025-03-26 02:24:11,681 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1984027250-172.20.1.14-1742955844230: 19ms
2025-03-26 02:24:11,682 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230/current/replicas doesn't exist
2025-03-26 02:24:11,682 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data...
2025-03-26 02:24:11,688 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data: 1ms
2025-03-26 02:24:11,688 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1984027250-172.20.1.14-1742955844230: 7ms
2025-03-26 02:24:11,689 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:24:11,694 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:24:11,696 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data
2025-03-26 02:24:11,697 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-90db0e37-4b8f-48e3-b97b-93d475ea7f25): finished scanning block pool BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:11,698 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 17989247ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:24:11,698 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:24:11,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1984027250-172.20.1.14-1742955844230 (Datanode Uuid 6d56b89c-125c-462b-baba-7781dfcf9a36) service to master/172.20.1.14:9000 beginning handshake with NN
2025-03-26 02:24:11,702 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-90db0e37-4b8f-48e3-b97b-93d475ea7f25): no suitable block pools found to scan.  Waiting 1814399994 ms.
2025-03-26 02:24:11,720 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:24:11,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1756216927;bpid=BP-1984027250-172.20.1.14-1742955844230;lv=-57;nsInfo=lv=-66;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230;bpid=BP-1984027250-172.20.1.14-1742955844230;dnuuid=null
2025-03-26 02:24:11,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.15:9866, datanodeUuid=6d56b89c-125c-462b-baba-7781dfcf9a36, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) storage 6d56b89c-125c-462b-baba-7781dfcf9a36
2025-03-26 02:24:11,768 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 6d56b89c-125c-462b-baba-7781dfcf9a36 (172.20.1.15:9866).
2025-03-26 02:24:11,768 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.15:9866
2025-03-26 02:24:11,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1984027250-172.20.1.14-1742955844230 (Datanode Uuid 6d56b89c-125c-462b-baba-7781dfcf9a36) service to master/172.20.1.14:9000 successfully registered with NN
2025-03-26 02:24:11,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.14:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:24:11,785 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:24:11,785 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2025-03-26 02:24:11,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-90db0e37-4b8f-48e3-b97b-93d475ea7f25 for DN 172.20.1.15:9866
2025-03-26 02:24:11,830 INFO BlockStateChange: BLOCK* processReport 0x3c2d98f6e4c1852a with lease ID 0x4a6e85c637c025cb: Processing first storage report for DS-90db0e37-4b8f-48e3-b97b-93d475ea7f25 from datanode DatanodeRegistration(172.20.1.15:9866, datanodeUuid=6d56b89c-125c-462b-baba-7781dfcf9a36, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230)
2025-03-26 02:24:11,831 INFO BlockStateChange: BLOCK* processReport 0x3c2d98f6e4c1852a with lease ID 0x4a6e85c637c025cb: from storage DS-90db0e37-4b8f-48e3-b97b-93d475ea7f25 node DatanodeRegistration(172.20.1.15:9866, datanodeUuid=6d56b89c-125c-462b-baba-7781dfcf9a36, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2025-03-26 02:24:11,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:11,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3c2d98f6e4c1852a with lease ID 0x4a6e85c637c025cb to namenode: master/172.20.1.14:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msecs to generate and 24 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:24:11,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1756216927;bpid=BP-1984027250-172.20.1.14-1742955844230;lv=-57;nsInfo=lv=-66;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230;bpid=BP-1984027250-172.20.1.14-1742955844230;dnuuid=null
2025-03-26 02:24:12,059 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2025-03-26 02:24:12,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID ad43188f-88d6-4817-9e88-53b2d31ec3cb
2025-03-26 02:24:12,084 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:24:12,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-499d1dc3-f8d3-4ca7-ad32-eaa89c220a3b
2025-03-26 02:24:12,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:24:12,142 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:24:12,143 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:24:12,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:12,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data...
2025-03-26 02:24:12,154 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230/current, will proceed with Du for space computation calculation,
2025-03-26 02:24:12,172 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1984027250-172.20.1.14-1742955844230 on /data/tmp/dfs/data: 24ms
2025-03-26 02:24:12,173 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230/current/replicas doesn't exist
2025-03-26 02:24:12,173 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data...
2025-03-26 02:24:12,173 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1984027250-172.20.1.14-1742955844230: 24ms
2025-03-26 02:24:12,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data: 1ms
2025-03-26 02:24:12,175 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:24:12,175 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1984027250-172.20.1.14-1742955844230: 2ms
2025-03-26 02:24:12,180 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:24:12,190 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data
2025-03-26 02:24:12,191 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-499d1dc3-f8d3-4ca7-ad32-eaa89c220a3b): finished scanning block pool BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:12,195 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 5230011ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:24:12,195 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:24:12,198 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-499d1dc3-f8d3-4ca7-ad32-eaa89c220a3b): no suitable block pools found to scan.  Waiting 1814399992 ms.
2025-03-26 02:24:12,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1984027250-172.20.1.14-1742955844230 (Datanode Uuid ad43188f-88d6-4817-9e88-53b2d31ec3cb) service to master/172.20.1.14:9000 beginning handshake with NN
2025-03-26 02:24:12,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 384fe65f-ef29-4d78-98dd-23ce87539aac
2025-03-26 02:24:12,248 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:24:12,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) storage ad43188f-88d6-4817-9e88-53b2d31ec3cb
2025-03-26 02:24:12,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN ad43188f-88d6-4817-9e88-53b2d31ec3cb (172.20.1.17:9866).
2025-03-26 02:24:12,257 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.17:9866
2025-03-26 02:24:12,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1984027250-172.20.1.14-1742955844230 (Datanode Uuid ad43188f-88d6-4817-9e88-53b2d31ec3cb) service to master/172.20.1.14:9000 successfully registered with NN
2025-03-26 02:24:12,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.14:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:24:12,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-499d1dc3-f8d3-4ca7-ad32-eaa89c220a3b for DN 172.20.1.17:9866
2025-03-26 02:24:12,299 INFO BlockStateChange: BLOCK* processReport 0xd5f1a146ff63645e with lease ID 0x4a6e85c637c025cc: Processing first storage report for DS-499d1dc3-f8d3-4ca7-ad32-eaa89c220a3b from datanode DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230)
2025-03-26 02:24:12,300 INFO BlockStateChange: BLOCK* processReport 0xd5f1a146ff63645e with lease ID 0x4a6e85c637c025cc: from storage DS-499d1dc3-f8d3-4ca7-ad32-eaa89c220a3b node DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-26 02:24:12,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:12,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd5f1a146ff63645e with lease ID 0x4a6e85c637c025cc to namenode: master/172.20.1.14:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msecs to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:24:12,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-ba1153b5-2294-4c37-8e52-97710252c642
2025-03-26 02:24:12,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:24:12,311 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:24:12,313 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:24:12,318 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:12,318 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data...
2025-03-26 02:24:12,324 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230/current, will proceed with Du for space computation calculation,
2025-03-26 02:24:12,342 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1984027250-172.20.1.14-1742955844230 on /data/tmp/dfs/data: 24ms
2025-03-26 02:24:12,342 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1984027250-172.20.1.14-1742955844230: 24ms
2025-03-26 02:24:12,343 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1984027250-172.20.1.14-1742955844230/current/replicas doesn't exist
2025-03-26 02:24:12,343 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data...
2025-03-26 02:24:12,344 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:24:12,344 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data: 1ms
2025-03-26 02:24:12,344 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1984027250-172.20.1.14-1742955844230: 2ms
2025-03-26 02:24:12,352 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:24:12,354 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1984027250-172.20.1.14-1742955844230 on volume /data/tmp/dfs/data
2025-03-26 02:24:12,355 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-ba1153b5-2294-4c37-8e52-97710252c642): finished scanning block pool BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:12,356 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 4254061ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:24:12,356 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:24:12,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1984027250-172.20.1.14-1742955844230 (Datanode Uuid 384fe65f-ef29-4d78-98dd-23ce87539aac) service to master/172.20.1.14:9000 beginning handshake with NN
2025-03-26 02:24:12,377 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-ba1153b5-2294-4c37-8e52-97710252c642): no suitable block pools found to scan.  Waiting 1814399977 ms.
2025-03-26 02:24:12,398 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/namesecondary/in_use.lock acquired by nodename 471@master
2025-03-26 02:24:12,420 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2025-03-26 02:24:12,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2025-03-26 02:24:12,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2025-03-26 02:24:12,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2025-03-26 02:24:12,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)
2025-03-26 02:24:12,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled    = true
2025-03-26 02:24:12,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isStoragePolicyEnabled = true
2025-03-26 02:24:12,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup             = supergroup
2025-03-26 02:24:12,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) storage 384fe65f-ef29-4d78-98dd-23ce87539aac
2025-03-26 02:24:12,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 384fe65f-ef29-4d78-98dd-23ce87539aac (172.20.1.16:9866).
2025-03-26 02:24:12,443 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.16:9866
2025-03-26 02:24:12,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1984027250-172.20.1.14-1742955844230 (Datanode Uuid 384fe65f-ef29-4d78-98dd-23ce87539aac) service to master/172.20.1.14:9000 successfully registered with NN
2025-03-26 02:24:12,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.14:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:24:12,447 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:24:12,451 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.15" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:24:12,452 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.16" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:24:12,452 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.17" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:24:12,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-26 02:24:12,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-26 02:24:12,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2025 Mar 26 02:24:12
2025-03-26 02:24:12,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-26 02:24:12,460 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2025-03-26 02:24:12,460 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:24:12,461 INFO org.apache.hadoop.util.GSet: 2.0% max memory 910.5 MB = 18.2 MB
2025-03-26 02:24:12,461 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2025-03-26 02:24:12,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Storage policy satisfier is disabled
2025-03-26 02:24:12,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2025-03-26 02:24:12,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-ba1153b5-2294-4c37-8e52-97710252c642 for DN 172.20.1.16:9866
2025-03-26 02:24:12,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2025-03-26 02:24:12,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2025-03-26 02:24:12,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
2025-03-26 02:24:12,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2025-03-26 02:24:12,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2025-03-26 02:24:12,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2025-03-26 02:24:12,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2025-03-26 02:24:12,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2025-03-26 02:24:12,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2025-03-26 02:24:12,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2025-03-26 02:24:12,488 INFO BlockStateChange: BLOCK* processReport 0x5dd2162ee97da7c1 with lease ID 0x4a6e85c637c025cd: Processing first storage report for DS-ba1153b5-2294-4c37-8e52-97710252c642 from datanode DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230)
2025-03-26 02:24:12,488 INFO BlockStateChange: BLOCK* processReport 0x5dd2162ee97da7c1 with lease ID 0x4a6e85c637c025cd: from storage DS-ba1153b5-2294-4c37-8e52-97710252c642 node DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2025-03-26 02:24:12,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5dd2162ee97da7c1 with lease ID 0x4a6e85c637c025cd to namenode: master/172.20.1.14:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msecs to generate and 17 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:24:12,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1984027250-172.20.1.14-1742955844230
2025-03-26 02:24:12,520 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2025-03-26 02:24:12,520 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2025-03-26 02:24:12,520 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2025-03-26 02:24:12,520 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2025-03-26 02:24:12,527 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? true
2025-03-26 02:24:12,527 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2025-03-26 02:24:12,527 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2025-03-26 02:24:12,527 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2025-03-26 02:24:12,527 INFO org.apache.hadoop.util.GSet: 1.0% max memory 910.5 MB = 9.1 MB
2025-03-26 02:24:12,527 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2025-03-26 02:24:12,527 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:24:12,527 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2025-03-26 02:24:12,530 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-03-26 02:24:12,532 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2025-03-26 02:24:12,534 INFO org.apache.hadoop.util.GSet: 0.25% max memory 910.5 MB = 2.3 MB
2025-03-26 02:24:12,534 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2025-03-26 02:24:12,534 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:24:12,534 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2025-03-26 02:24:12,538 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2025-03-26 02:24:12,538 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-26 02:24:12,538 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-26 02:24:12,544 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2025-03-26 02:24:12,544 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2025-03-26 02:24:12,545 INFO org.apache.hadoop.hdfs.DFSUtil: Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-03-26 02:24:12,549 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:9868
2025-03-26 02:24:12,560 INFO org.eclipse.jetty.util.log: Logging initialized @1353ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:24:12,607 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:12,609 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2025-03-26 02:24:12,613 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:24:12,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:24:12,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2025-03-26 02:24:12,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:24:12,616 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-03-26 02:24:12,616 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context secondary
2025-03-26 02:24:12,616 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-03-26 02:24:12,633 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9868
2025-03-26 02:24:12,633 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:24:12,647 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:24:12,648 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:24:12,648 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:24:12,657 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:12,659 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b73be9f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:24:12,659 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d9b7a8a{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:24:12,692 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@62e6b5c8{secondary,/,file:///hadoop/share/hadoop/hdfs/webapps/secondary/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/secondary}
2025-03-26 02:24:12,695 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2025-03-26 02:24:12,695 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6622fc65{HTTP/1.1, (http/1.1)}{0.0.0.0:9868}
2025-03-26 02:24:12,695 INFO org.eclipse.jetty.server.Server: Started @1488ms
2025-03-26 02:24:15,067 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting ResourceManager STARTUP_MSG:   host = master/172.20.1.14 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:24:15,072 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:24:15,351 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMInfo MBean
2025-03-26 02:24:15,356 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/hadoop/etc/hadoop/core-site.xml
2025-03-26 02:24:15,391 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:24:15,391 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:24:15,412 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/hadoop/etc/hadoop/yarn-site.xml
2025-03-26 02:24:15,417 INFO org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics: Registering GenericEventTypeMetrics
2025-03-26 02:24:15,418 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2025-03-26 02:24:15,438 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2025-03-26 02:24:15,442 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2025-03-26 02:24:15,451 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2025-03-26 02:24:15,476 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2025-03-26 02:24:15,478 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2025-03-26 02:24:15,478 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2025-03-26 02:24:15,504 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2025-03-26 02:24:15,504 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2025-03-26 02:24:15,504 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2025-03-26 02:24:15,505 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2025-03-26 02:24:15,536 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:24:15,542 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:24:15,543 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2025-03-26 02:24:15,566 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.
2025-03-26 02:24:15,568 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2025-03-26 02:24:15,573 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2025-03-26 02:24:15,837 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2025-03-26 02:24:15,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor: Application lifelime monitor interval set to 3000 ms.
2025-03-26 02:24:15,841 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: Initializing NodeSortingService=MultiNodeSortingManager
2025-03-26 02:24:15,842 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.15" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:24:15,842 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.16" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:24:15,842 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.17" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:24:15,842 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2025-03-26 02:24:15,846 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/hadoop/etc/hadoop/capacity-scheduler.xml
2025-03-26 02:24:15,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Maximum allocation = <memory:8192, vCores:4>
2025-03-26 02:24:15,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Minimum allocation = <memory:1024, vCores:1>
2025-03-26 02:24:15,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2025-03-26 02:24:15,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, absoluteCapacity=1.0, maxCapacity=1.0, absoluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*, , reservationsContinueLooking=true, orderingPolicy=utilization, priority=0
2025-03-26 02:24:15,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing root.default capacity = 1.0 [= (float) configuredCapacity / 100 ] absoluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ] maxCapacity = 1.0 [= configuredMaxCapacity ] absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ] effectiveMinResource=<memory:0, vCores:0> , effectiveMaxResource=<memory:0, vCores:0> userLimit = 100 [= configuredUserLimit ] userLimitFactor = 1.0 [= configuredUserLimitFactor ] maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)] maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ] maxParallelApps = 2147483647 usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)] absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory] maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ] minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ] maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ] numContainers = 0 [= currentNumContainers ] state = RUNNING [= configuredState ] acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ] nodeLocalityDelay = 40 rackLocalityAdditionalDelay = -1 labels=*, reservationsContinueLooking = true preemptionDisabled = true defaultAppPriorityPerQueue = 0 priority = 0 maxLifetime = -1 seconds defaultLifetime = -1 seconds
2025-03-26 02:24:15,906 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized queue: root
2025-03-26 02:24:15,906 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized queue: root.default
2025-03-26 02:24:15,908 INFO org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule: Initialized queue mappings, override: false
2025-03-26 02:24:15,908 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2025-03-26 02:24:15,908 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.WorkflowPriorityMappingsManager: Initialized workflow priority mappings, override: false
2025-03-26 02:24:15,909 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms,multiNodePlacementEnabled=false, assignMultipleEnabled=true, maxAssignPerHeartbeat=100, offswitchPerHeartbeatLimit=1
2025-03-26 02:24:15,909 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: MultiNode scheduling is 'false', and configured policies are
2025-03-26 02:24:15,917 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2025-03-26 02:24:15,921 INFO org.apache.hadoop.yarn.server.resourcemanager.AMSProcessingChain: Initializing AMS Processing chain. Root Processor=[org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor].
2025-03-26 02:24:15,922 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: disabled placement handler will be used, all scheduling requests will be rejected.
2025-03-26 02:24:15,922 INFO tp top of AMS Processing chain.
2025-03-26 02:24:15,928 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: TimelineServicePublisher is not configured
2025-03-26 02:24:15,947 INFO org.eclipse.jetty.util.log: Logging initialized @1146ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:24:16,031 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:16,034 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2025-03-26 02:24:16,038 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:24:16,040 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2025-03-26 02:24:16,040 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2025-03-26 02:24:16,040 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2025-03-26 02:24:16,040 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2025-03-26 02:24:16,040 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:24:16,040 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:24:16,280 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:24:16,284 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2025-03-26 02:24:16,285 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:24:16,309 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:24:16,310 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:24:16,311 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:24:16,319 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:16,327 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:24:16,335 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2025-03-26 02:24:16,335 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:24:16,342 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@232a7d73{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:24:16,342 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@305a0c5f{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:24:17,138 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@7add323c{cluster,/,file:///tmp/jetty-master-8088-hadoop-yarn-common-3_3_4_jar-_-any-5096510505381223555/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/cluster}
2025-03-26 02:24:17,142 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2025-03-26 02:24:17,142 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@5b068087{HTTP/1.1, (http/1.1)}{master:8088}
2025-03-26 02:24:17,142 INFO org.eclipse.jetty.server.Server: Started @2340ms
2025-03-26 02:24:17,234 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:17,241 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2025-03-26 02:24:17,363 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2025-03-26 02:24:17,364 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:17,365 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2025-03-26 02:24:17,365 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2025-03-26 02:24:17,378 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2025-03-26 02:24:17,378 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2025-03-26 02:24:17,379 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:24:17,379 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2025-03-26 02:24:17,379 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2025-03-26 02:24:17,379 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2025-03-26 02:24:17,381 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2025-03-26 02:24:17,381 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:24:17,381 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2025-03-26 02:24:17,381 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2025-03-26 02:24:17,382 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave0/172.20.1.15 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:24:17,383 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2025-03-26 02:24:17,389 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:24:17,511 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Created store directory :file:/tmp/hadoop-yarn-root/node-attribute
2025-03-26 02:24:17,542 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Finished create editlog file at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.editlog
2025-03-26 02:24:17,542 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Finished write mirror at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.mirror
2025-03-26 02:24:17,566 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave2/172.20.1.17 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:24:17,567 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$ForwardingEventHandler
2025-03-26 02:24:17,568 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: Starting NodeSortingService=MultiNodeSortingManager
2025-03-26 02:24:17,574 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:24:17,582 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:17,583 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2025-03-26 02:24:17,589 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2025-03-26 02:24:17,590 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:17,590 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2025-03-26 02:24:17,610 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:17,616 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:24:17,618 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2025-03-26 02:24:17,619 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave1/172.20.1.16 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:24:17,623 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2025-03-26 02:24:17,624 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:17,624 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2025-03-26 02:24:17,626 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:24:17,692 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:17,693 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2025-03-26 02:24:17,697 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:17,697 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2025-03-26 02:24:17,698 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2025-03-26 02:24:17,747 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:24:17,747 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:24:17,747 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:24:17,923 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:24:17,924 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:24:17,925 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:24:17,925 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:24:17,925 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:24:17,925 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:24:17,925 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:24:17,927 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:24:17,938 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:24:17,939 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:24:17,976 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:24:17,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:24:17,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:24:17,999 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:24:18,034 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:24:18,034 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:24:18,042 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:24:18,045 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:24:18,045 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:24:18,046 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:24:18,054 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:24:18,065 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:24:18,091 INFO org.apache.hadoop.yarn.server.webproxy.ProxyCA: Created Certificate for OU=YARN-7d5e6234-2fcf-452b-a654-c4c3f24d7fc6
2025-03-26 02:24:18,103 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:24:18,105 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:24:18,107 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:24:18,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:24:18,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:24:18,126 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:24:18,138 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:24:18,140 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:24:18,140 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:24:18,157 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:24:18,157 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:24:18,158 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:24:18,158 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:24:18,158 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:24:18,158 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:24:18,158 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:24:18,158 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:24:18,158 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:24:18,161 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:24:18,162 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:24:18,162 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:24:18,163 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:24:18,170 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2025-03-26 02:24:18,170 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing CA Certificate and Private Key
2025-03-26 02:24:18,188 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:24:18,221 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:18,231 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:24:18,232 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:24:18,233 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:24:18,233 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:24:18,233 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:24:18,234 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:24:18,234 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:24:18,236 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:24:18,252 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:24:18,252 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:24:18,269 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:24:18,280 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:24:18,281 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:24:18,281 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:24:18,282 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:24:18,282 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:24:18,282 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:24:18,283 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:24:18,284 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:24:18,298 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:24:18,300 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:24:18,301 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:24:18,306 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:24:18,307 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:18,307 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:24:18,310 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave0:35667
2025-03-26 02:24:18,315 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:18,315 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:24:18,317 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:24:18,318 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:18,318 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:24:18,319 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:24:18,320 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:24:18,320 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave0/172.20.1.15:35667
2025-03-26 02:24:18,320 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:24:18,324 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:24:18,345 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:24:18,348 INFO org.eclipse.jetty.util.log: Logging initialized @1244ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:24:18,359 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:24:18,359 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:24:18,368 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:24:18,385 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:24:18,396 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:24:18,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:24:18,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:24:18,419 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:24:18,434 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:24:18,434 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:18,437 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:24:18,439 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:24:18,441 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:24:18,442 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:24:18,442 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:24:18,442 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:24:18,443 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:24:18,445 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:24:18,445 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:24:18,445 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:24:18,445 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:24:18,445 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:24:18,445 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:24:18,446 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:24:18,463 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:24:18,476 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:24:18,478 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:24:18,479 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:24:18,482 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:24:18,484 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:24:18,485 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:24:18,486 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:24:18,486 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:24:18,500 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:24:18,500 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:24:18,502 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:24:18,502 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:24:18,502 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:24:18,502 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:24:18,502 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:24:18,502 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:24:18,502 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:24:18,504 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:24:18,505 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:24:18,505 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:24:18,506 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:24:18,507 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:24:18,518 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:24:18,520 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:24:18,521 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:24:18,529 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:24:18,542 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:24:18,542 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:24:18,544 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:24:18,544 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:24:18,544 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:24:18,544 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:24:18,544 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:24:18,544 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:24:18,544 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:24:18,546 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:24:18,547 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:24:18,547 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:24:18,549 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:24:18,553 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:24:18,565 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:18,602 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:18,626 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:24:18,663 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:24:18,670 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:24:18,671 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:18,672 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:24:18,676 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave2:43823
2025-03-26 02:24:18,682 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:18,683 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:24:18,685 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:24:18,686 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:18,686 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:24:18,686 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:24:18,691 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:24:18,691 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave2/172.20.1.17:43823
2025-03-26 02:24:18,691 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:24:18,696 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:24:18,710 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:24:18,711 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:18,712 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:24:18,717 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave1:41163
2025-03-26 02:24:18,724 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:24:18,724 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:24:18,724 INFO org.eclipse.jetty.util.log: Logging initialized @1586ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:24:18,728 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:24:18,728 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:24:18,728 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:24:18,729 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:24:18,734 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:24:18,734 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave1/172.20.1.16:41163
2025-03-26 02:24:18,734 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:24:18,739 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:24:18,739 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:24:18,739 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:24:18,740 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:24:18,761 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:24:18,761 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:24:18,763 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:24:18,766 INFO org.eclipse.jetty.util.log: Logging initialized @1554ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:24:18,784 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:18,786 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:24:18,787 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:24:18,803 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:18,816 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:24:18,823 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:24:18,824 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:24:18,825 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:24:18,825 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:24:18,825 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:24:18,825 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:24:18,825 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:24:18,847 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:18,853 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:24:18,859 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:24:18,861 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:24:18,861 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:24:18,861 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:24:18,861 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:24:18,861 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:24:18,862 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:24:19,185 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:24:19,186 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:24:19,187 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:24:19,210 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:24:19,210 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:24:19,212 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:24:19,217 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:24:19,217 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:24:19,218 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:24:19,255 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:19,256 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:24:19,256 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:24:19,257 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:24:19,258 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:24:19,259 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:24:19,269 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:24:19,271 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:24:19,272 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:24:19,418 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-4261818007832378022/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:24:19,426 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:24:19,426 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:24:19,426 INFO org.eclipse.jetty.server.Server: Started @2322ms
2025-03-26 02:24:19,431 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave0:35667
2025-03-26 02:24:19,440 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.14:8031
2025-03-26 02:24:19,451 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:24:19,993 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-8605011880288031697/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:24:19,998 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave0(cmPort: 35667 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave0:35667
2025-03-26 02:24:20,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave0:35667 Node Transitioned from NEW to RUNNING
2025-03-26 02:24:20,003 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:24:20,003 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:24:20,003 INFO org.eclipse.jetty.server.Server: Started @2865ms
2025-03-26 02:24:20,018 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-8710450419779083013/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:24:20,025 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:24:20,025 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:24:20,025 INFO org.eclipse.jetty.server.Server: Started @2813ms
2025-03-26 02:24:20,026 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave2:43823
2025-03-26 02:24:20,032 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave0:35667 clusterResource: <memory:8192, vCores:8>
2025-03-26 02:24:20,034 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.14:8031
2025-03-26 02:24:20,035 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave1:41163
2025-03-26 02:24:20,035 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1368192302
2025-03-26 02:24:20,036 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave0:35667 with total resource of <memory:8192, vCores:8>
2025-03-26 02:24:20,036 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 2069074645
2025-03-26 02:24:20,043 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.14:8031
2025-03-26 02:24:20,051 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:24:20,055 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:24:20,228 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave2(cmPort: 43823 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave2:43823
2025-03-26 02:24:20,229 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave2:43823 Node Transitioned from NEW to RUNNING
2025-03-26 02:24:20,234 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave2:43823 clusterResource: <memory:16384, vCores:16>
2025-03-26 02:24:20,235 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave1(cmPort: 41163 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave1:41163
2025-03-26 02:24:20,235 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave1:41163 Node Transitioned from NEW to RUNNING
2025-03-26 02:24:20,237 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave1:41163 clusterResource: <memory:24576, vCores:24>
2025-03-26 02:24:20,238 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1368192302
2025-03-26 02:24:20,239 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave2:43823 with total resource of <memory:8192, vCores:8>
2025-03-26 02:24:20,239 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 2069074645
2025-03-26 02:24:20,244 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1368192302
2025-03-26 02:24:20,245 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave1:41163 with total resource of <memory:8192, vCores:8>
2025-03-26 02:24:20,245 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 2069074645
2025-03-26 02:24:21,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,375 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /file.txt._COPYING_
2025-03-26 02:24:21,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741825_1001 src: /172.20.1.14:48210 dest: /172.20.1.17:9866
2025-03-26 02:24:21,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741825_1001 src: /172.20.1.17:47526 dest: /172.20.1.15:9866
2025-03-26 02:24:21,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741825_1001 src: /172.20.1.15:43328 dest: /172.20.1.16:9866
2025-03-26 02:24:21,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:43328, dest: /172.20.1.16:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1864661320_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741825_1001, duration(ns): 34757836
2025-03-26 02:24:21,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47526, dest: /172.20.1.15:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1864661320_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741825_1001, duration(ns): 37640011
2025-03-26 02:24:21,662 INFO terminating
2025-03-26 02:24:21,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48210, dest: /172.20.1.17:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1864661320_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741825_1001, duration(ns): 40059409
2025-03-26 02:24:21,682 INFO terminating
2025-03-26 02:24:21,687 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /file.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1864661320_1
2025-03-26 02:24:23,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /cluster.txt._COPYING_
2025-03-26 02:24:23,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741826_1002 src: /172.20.1.14:48214 dest: /172.20.1.17:9866
2025-03-26 02:24:23,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741826_1002 src: /172.20.1.17:33708 dest: /172.20.1.16:9866
2025-03-26 02:24:23,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741826_1002 src: /172.20.1.16:46152 dest: /172.20.1.15:9866
2025-03-26 02:24:23,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:46152, dest: /172.20.1.15:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_686435916_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741826_1002, duration(ns): 8014989
2025-03-26 02:24:23,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:33708, dest: /172.20.1.16:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_686435916_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741826_1002, duration(ns): 8262163
2025-03-26 02:24:23,154 INFO terminating
2025-03-26 02:24:23,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48214, dest: /172.20.1.17:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_686435916_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741826_1002, duration(ns): 9523207
2025-03-26 02:24:23,155 INFO terminating
2025-03-26 02:24:23,158 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /cluster.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_686435916_1
2025-03-26 02:24:24,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /page.txt._COPYING_
2025-03-26 02:24:24,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741827_1003 src: /172.20.1.14:48228 dest: /172.20.1.17:9866
2025-03-26 02:24:24,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741827_1003 src: /172.20.1.17:47536 dest: /172.20.1.15:9866
2025-03-26 02:24:24,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741827_1003 src: /172.20.1.15:43342 dest: /172.20.1.16:9866
2025-03-26 02:24:24,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:43342, dest: /172.20.1.16:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1373331693_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741827_1003, duration(ns): 6884109
2025-03-26 02:24:24,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:47536, dest: /172.20.1.15:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1373331693_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741827_1003, duration(ns): 7838721
2025-03-26 02:24:24,556 INFO terminating
2025-03-26 02:24:24,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:48228, dest: /172.20.1.17:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1373331693_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741827_1003, duration(ns): 8445725
2025-03-26 02:24:24,557 INFO terminating
2025-03-26 02:24:24,559 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /page.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1373331693_1
2025-03-26 02:24:25,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /lr_test.txt._COPYING_
2025-03-26 02:24:25,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741828_1004 src: /172.20.1.14:49994 dest: /172.20.1.16:9866
2025-03-26 02:24:26,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741828_1004 src: /172.20.1.16:46166 dest: /172.20.1.15:9866
2025-03-26 02:24:26,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741828_1004 src: /172.20.1.15:54448 dest: /172.20.1.17:9866
2025-03-26 02:24:26,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:54448, dest: /172.20.1.17:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-127739293_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741828_1004, duration(ns): 8642200
2025-03-26 02:24:26,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:46166, dest: /172.20.1.15:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-127739293_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741828_1004, duration(ns): 9393468
2025-03-26 02:24:26,017 INFO terminating
2025-03-26 02:24:26,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:49994, dest: /172.20.1.16:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-127739293_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741828_1004, duration(ns): 10041306
2025-03-26 02:24:26,018 INFO terminating
2025-03-26 02:24:26,020 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /lr_test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-127739293_1
2025-03-26 02:24:28,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/graphx/users.txt._COPYING_
2025-03-26 02:24:28,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741829_1005 src: /172.20.1.14:41870 dest: /172.20.1.15:9866
2025-03-26 02:24:28,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741829_1005 src: /172.20.1.15:35932 dest: /172.20.1.17:9866
2025-03-26 02:24:28,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741829_1005 src: /172.20.1.17:59536 dest: /172.20.1.16:9866
2025-03-26 02:24:28,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59536, dest: /172.20.1.16:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741829_1005, duration(ns): 6739451
2025-03-26 02:24:28,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35932, dest: /172.20.1.17:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741829_1005, duration(ns): 8254083
2025-03-26 02:24:28,796 INFO terminating
2025-03-26 02:24:28,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41870, dest: /172.20.1.15:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741829_1005, duration(ns): 9227407
2025-03-26 02:24:28,798 INFO terminating
2025-03-26 02:24:28,800 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/graphx/users.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:28,811 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,811 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/graphx/followers.txt._COPYING_
2025-03-26 02:24:28,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741830_1006 src: /172.20.1.14:46596 dest: /172.20.1.16:9866
2025-03-26 02:24:28,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741830_1006 src: /172.20.1.16:44444 dest: /172.20.1.15:9866
2025-03-26 02:24:28,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741830_1006 src: /172.20.1.15:35946 dest: /172.20.1.17:9866
2025-03-26 02:24:28,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35946, dest: /172.20.1.17:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741830_1006, duration(ns): 10689168
2025-03-26 02:24:28,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44444, dest: /172.20.1.15:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741830_1006, duration(ns): 12002406
2025-03-26 02:24:28,830 INFO terminating
2025-03-26 02:24:28,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46596, dest: /172.20.1.16:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741830_1006, duration(ns): 13162177
2025-03-26 02:24:28,831 INFO terminating
2025-03-26 02:24:28,832 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/graphx/followers.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:28,859 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/mllib/sample_fpgrowth.txt._COPYING_
2025-03-26 02:24:28,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741831_1007 src: /172.20.1.14:41878 dest: /172.20.1.15:9866
2025-03-26 02:24:28,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741831_1007 src: /172.20.1.15:35954 dest: /172.20.1.17:9866
2025-03-26 02:24:28,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741831_1007 src: /172.20.1.17:59546 dest: /172.20.1.16:9866
2025-03-26 02:24:28,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59546, dest: /172.20.1.16:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741831_1007, duration(ns): 2625183
2025-03-26 02:24:28,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35954, dest: /172.20.1.17:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741831_1007, duration(ns): 3945762
2025-03-26 02:24:28,873 INFO terminating
2025-03-26 02:24:28,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41878, dest: /172.20.1.15:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741831_1007, duration(ns): 9131760
2025-03-26 02:24:28,875 INFO terminating
2025-03-26 02:24:28,876 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_fpgrowth.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:28,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/pagerank_data.txt._COPYING_
2025-03-26 02:24:28,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741832_1008 src: /172.20.1.14:41880 dest: /172.20.1.15:9866
2025-03-26 02:24:28,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741832_1008 src: /172.20.1.15:38104 dest: /172.20.1.16:9866
2025-03-26 02:24:28,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741832_1008 src: /172.20.1.16:53828 dest: /172.20.1.17:9866
2025-03-26 02:24:28,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53828, dest: /172.20.1.17:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741832_1008, duration(ns): 2759015
2025-03-26 02:24:28,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38104, dest: /172.20.1.16:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741832_1008, duration(ns): 4321158
2025-03-26 02:24:28,897 INFO terminating
2025-03-26 02:24:28,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41880, dest: /172.20.1.15:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741832_1008, duration(ns): 4964328
2025-03-26 02:24:28,898 INFO terminating
2025-03-26 02:24:28,899 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/pagerank_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:28,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/mllib/streaming_kmeans_data_test.txt._COPYING_
2025-03-26 02:24:28,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741833_1009 src: /172.20.1.14:41886 dest: /172.20.1.15:9866
2025-03-26 02:24:28,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741833_1009 src: /172.20.1.15:35960 dest: /172.20.1.17:9866
2025-03-26 02:24:28,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741833_1009 src: /172.20.1.17:59562 dest: /172.20.1.16:9866
2025-03-26 02:24:28,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59562, dest: /172.20.1.16:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741833_1009, duration(ns): 5353968
2025-03-26 02:24:28,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41886, dest: /172.20.1.15:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741833_1009, duration(ns): 7179436
2025-03-26 02:24:28,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35960, dest: /172.20.1.17:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741833_1009, duration(ns): 6547895
2025-03-26 02:24:28,927 INFO terminating
2025-03-26 02:24:28,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/streaming_kmeans_data_test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:28,928 INFO terminating
2025-03-26 02:24:28,936 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_lda_data.txt._COPYING_
2025-03-26 02:24:28,936 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,936 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741834_1010 src: /172.20.1.14:46600 dest: /172.20.1.16:9866
2025-03-26 02:24:28,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741834_1010 src: /172.20.1.16:53840 dest: /172.20.1.17:9866
2025-03-26 02:24:28,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741834_1010 src: /172.20.1.17:37856 dest: /172.20.1.15:9866
2025-03-26 02:24:28,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37856, dest: /172.20.1.15:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741834_1010, duration(ns): 2490328
2025-03-26 02:24:28,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53840, dest: /172.20.1.17:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741834_1010, duration(ns): 2962399
2025-03-26 02:24:28,947 INFO terminating
2025-03-26 02:24:28,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46600, dest: /172.20.1.16:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741834_1010, duration(ns): 4864410
2025-03-26 02:24:28,949 INFO terminating
2025-03-26 02:24:28,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_lda_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:28,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/als/test.data._COPYING_
2025-03-26 02:24:28,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741835_1011 src: /172.20.1.14:41900 dest: /172.20.1.15:9866
2025-03-26 02:24:28,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741835_1011 src: /172.20.1.15:38106 dest: /172.20.1.16:9866
2025-03-26 02:24:28,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741835_1011 src: /172.20.1.16:53848 dest: /172.20.1.17:9866
2025-03-26 02:24:28,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53848, dest: /172.20.1.17:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741835_1011, duration(ns): 2741051
2025-03-26 02:24:28,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38106, dest: /172.20.1.16:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741835_1011, duration(ns): 4506146
2025-03-26 02:24:28,973 INFO terminating
2025-03-26 02:24:28,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41900, dest: /172.20.1.15:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741835_1011, duration(ns): 5483497
2025-03-26 02:24:28,974 INFO terminating
2025-03-26 02:24:28,975 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/als/test.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:28,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/als/sample_movielens_ratings.txt._COPYING_
2025-03-26 02:24:28,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741836_1012 src: /172.20.1.14:46608 dest: /172.20.1.16:9866
2025-03-26 02:24:28,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741836_1012 src: /172.20.1.16:53864 dest: /172.20.1.17:9866
2025-03-26 02:24:28,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741836_1012 src: /172.20.1.17:37870 dest: /172.20.1.15:9866
2025-03-26 02:24:28,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37870, dest: /172.20.1.15:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741836_1012, duration(ns): 2743997
2025-03-26 02:24:28,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53864, dest: /172.20.1.17:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741836_1012, duration(ns): 3797959
2025-03-26 02:24:29,000 INFO terminating
2025-03-26 02:24:29,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46608, dest: /172.20.1.16:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741836_1012, duration(ns): 4941974
2025-03-26 02:24:29,001 INFO terminating
2025-03-26 02:24:29,002 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/als/sample_movielens_ratings.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_kmeans_data.txt._COPYING_
2025-03-26 02:24:29,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741837_1013 src: /172.20.1.14:36234 dest: /172.20.1.17:9866
2025-03-26 02:24:29,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741837_1013 src: /172.20.1.17:59578 dest: /172.20.1.16:9866
2025-03-26 02:24:29,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741837_1013 src: /172.20.1.16:44460 dest: /172.20.1.15:9866
2025-03-26 02:24:29,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44460, dest: /172.20.1.15:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741837_1013, duration(ns): 2441840
2025-03-26 02:24:29,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59578, dest: /172.20.1.16:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741837_1013, duration(ns): 2977779
2025-03-26 02:24:29,020 INFO terminating
2025-03-26 02:24:29,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36234, dest: /172.20.1.17:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741837_1013, duration(ns): 3621860
2025-03-26 02:24:29,021 INFO terminating
2025-03-26 02:24:29,023 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_kmeans_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,035 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,036 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/mllib/ridge-data/lpsa.data._COPYING_
2025-03-26 02:24:29,036 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741838_1014 src: /172.20.1.14:41916 dest: /172.20.1.15:9866
2025-03-26 02:24:29,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741838_1014 src: /172.20.1.15:35966 dest: /172.20.1.17:9866
2025-03-26 02:24:29,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741838_1014 src: /172.20.1.17:59588 dest: /172.20.1.16:9866
2025-03-26 02:24:29,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59588, dest: /172.20.1.16:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741838_1014, duration(ns): 3168102
2025-03-26 02:24:29,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35966, dest: /172.20.1.17:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741838_1014, duration(ns): 4548969
2025-03-26 02:24:29,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41916, dest: /172.20.1.15:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741838_1014, duration(ns): 5284125
2025-03-26 02:24:29,048 INFO terminating
2025-03-26 02:24:29,049 INFO terminating
2025-03-26 02:24:29,050 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/ridge-data/lpsa.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/gmm_data.txt._COPYING_
2025-03-26 02:24:29,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741839_1015 src: /172.20.1.14:41918 dest: /172.20.1.15:9866
2025-03-26 02:24:29,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741839_1015 src: /172.20.1.15:38122 dest: /172.20.1.16:9866
2025-03-26 02:24:29,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741839_1015 src: /172.20.1.16:53872 dest: /172.20.1.17:9866
2025-03-26 02:24:29,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53872, dest: /172.20.1.17:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741839_1015, duration(ns): 2479422
2025-03-26 02:24:29,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38122, dest: /172.20.1.16:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741839_1015, duration(ns): 3119273
2025-03-26 02:24:29,067 INFO terminating
2025-03-26 02:24:29,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41918, dest: /172.20.1.15:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741839_1015, duration(ns): 4571397
2025-03-26 02:24:29,068 INFO terminating
2025-03-26 02:24:29,069 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/gmm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,077 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_lda_libsvm_data.txt._COPYING_
2025-03-26 02:24:29,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741840_1016 src: /172.20.1.14:46610 dest: /172.20.1.16:9866
2025-03-26 02:24:29,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741840_1016 src: /172.20.1.16:53888 dest: /172.20.1.17:9866
2025-03-26 02:24:29,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741840_1016 src: /172.20.1.17:37882 dest: /172.20.1.15:9866
2025-03-26 02:24:29,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37882, dest: /172.20.1.15:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741840_1016, duration(ns): 3765223
2025-03-26 02:24:29,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53888, dest: /172.20.1.17:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741840_1016, duration(ns): 6840432
2025-03-26 02:24:29,092 INFO terminating
2025-03-26 02:24:29,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46610, dest: /172.20.1.16:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741840_1016, duration(ns): 8656662
2025-03-26 02:24:29,093 INFO terminating
2025-03-26 02:24:29,094 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_lda_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/sample_libsvm_data.txt._COPYING_
2025-03-26 02:24:29,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741841_1017 src: /172.20.1.14:41920 dest: /172.20.1.15:9866
2025-03-26 02:24:29,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741841_1017 src: /172.20.1.15:38132 dest: /172.20.1.16:9866
2025-03-26 02:24:29,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741841_1017 src: /172.20.1.16:53898 dest: /172.20.1.17:9866
2025-03-26 02:24:29,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53898, dest: /172.20.1.17:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741841_1017, duration(ns): 2566472
2025-03-26 02:24:29,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38132, dest: /172.20.1.16:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741841_1017, duration(ns): 4676915
2025-03-26 02:24:29,114 INFO terminating
2025-03-26 02:24:29,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41920, dest: /172.20.1.15:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741841_1017, duration(ns): 5766028
2025-03-26 02:24:29,115 INFO terminating
2025-03-26 02:24:29,116 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/mllib/sample_movielens_data.txt._COPYING_
2025-03-26 02:24:29,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741842_1018 src: /172.20.1.14:46622 dest: /172.20.1.16:9866
2025-03-26 02:24:29,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741842_1018 src: /172.20.1.16:44468 dest: /172.20.1.15:9866
2025-03-26 02:24:29,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741842_1018 src: /172.20.1.15:35974 dest: /172.20.1.17:9866
2025-03-26 02:24:29,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35974, dest: /172.20.1.17:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741842_1018, duration(ns): 2754514
2025-03-26 02:24:29,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44468, dest: /172.20.1.15:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741842_1018, duration(ns): 4626310
2025-03-26 02:24:29,132 INFO terminating
2025-03-26 02:24:29,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46622, dest: /172.20.1.16:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741842_1018, duration(ns): 5100305
2025-03-26 02:24:29,133 INFO terminating
2025-03-26 02:24:29,134 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_movielens_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,143 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,144 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_svm_data.txt._COPYING_
2025-03-26 02:24:29,144 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741843_1019 src: /172.20.1.14:36242 dest: /172.20.1.17:9866
2025-03-26 02:24:29,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741843_1019 src: /172.20.1.17:59596 dest: /172.20.1.16:9866
2025-03-26 02:24:29,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741843_1019 src: /172.20.1.16:44474 dest: /172.20.1.15:9866
2025-03-26 02:24:29,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44474, dest: /172.20.1.15:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741843_1019, duration(ns): 2644239
2025-03-26 02:24:29,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59596, dest: /172.20.1.16:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741843_1019, duration(ns): 3160637
2025-03-26 02:24:29,152 INFO terminating
2025-03-26 02:24:29,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36242, dest: /172.20.1.17:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741843_1019, duration(ns): 3921721
2025-03-26 02:24:29,153 INFO terminating
2025-03-26 02:24:29,155 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_svm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,169 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/images/license.txt._COPYING_
2025-03-26 02:24:29,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741844_1020 src: /172.20.1.14:36258 dest: /172.20.1.17:9866
2025-03-26 02:24:29,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741844_1020 src: /172.20.1.17:37884 dest: /172.20.1.15:9866
2025-03-26 02:24:29,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741844_1020 src: /172.20.1.15:38138 dest: /172.20.1.16:9866
2025-03-26 02:24:29,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38138, dest: /172.20.1.16:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741844_1020, duration(ns): 3409256
2025-03-26 02:24:29,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37884, dest: /172.20.1.15:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741844_1020, duration(ns): 4131937
2025-03-26 02:24:29,179 INFO terminating
2025-03-26 02:24:29,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36258, dest: /172.20.1.17:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741844_1020, duration(ns): 5045861
2025-03-26 02:24:29,180 INFO terminating
2025-03-26 02:24:29,181 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/license.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/multi-channel/grayscale.jpg._COPYING_
2025-03-26 02:24:29,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741845_1021 src: /172.20.1.14:41926 dest: /172.20.1.15:9866
2025-03-26 02:24:29,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741845_1021 src: /172.20.1.15:38150 dest: /172.20.1.16:9866
2025-03-26 02:24:29,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741845_1021 src: /172.20.1.16:53906 dest: /172.20.1.17:9866
2025-03-26 02:24:29,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53906, dest: /172.20.1.17:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741845_1021, duration(ns): 2188143
2025-03-26 02:24:29,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41926, dest: /172.20.1.15:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741845_1021, duration(ns): 3484330
2025-03-26 02:24:29,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38150, dest: /172.20.1.16:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741845_1021, duration(ns): 2525606
2025-03-26 02:24:29,203 INFO terminating
2025-03-26 02:24:29,204 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/grayscale.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,204 INFO terminating
2025-03-26 02:24:29,210 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png._COPYING_
2025-03-26 02:24:29,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741846_1022 src: /172.20.1.14:46638 dest: /172.20.1.16:9866
2025-03-26 02:24:29,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741846_1022 src: /172.20.1.16:53908 dest: /172.20.1.17:9866
2025-03-26 02:24:29,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741846_1022 src: /172.20.1.17:37892 dest: /172.20.1.15:9866
2025-03-26 02:24:29,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53908, dest: /172.20.1.17:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741846_1022, duration(ns): 2701823
2025-03-26 02:24:29,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37892, dest: /172.20.1.15:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741846_1022, duration(ns): 2086813
2025-03-26 02:24:29,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,221 INFO terminating
2025-03-26 02:24:29,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46638, dest: /172.20.1.16:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741846_1022, duration(ns): 3168525
2025-03-26 02:24:29,223 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,223 INFO terminating
2025-03-26 02:24:29,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/images/origin/multi-channel/BGRA.png._COPYING_
2025-03-26 02:24:29,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741847_1023 src: /172.20.1.14:36268 dest: /172.20.1.17:9866
2025-03-26 02:24:29,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741847_1023 src: /172.20.1.17:37906 dest: /172.20.1.15:9866
2025-03-26 02:24:29,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741847_1023 src: /172.20.1.15:38166 dest: /172.20.1.16:9866
2025-03-26 02:24:29,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38166, dest: /172.20.1.16:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741847_1023, duration(ns): 1898601
2025-03-26 02:24:29,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37906, dest: /172.20.1.15:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741847_1023, duration(ns): 2326852
2025-03-26 02:24:29,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36268, dest: /172.20.1.17:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741847_1023, duration(ns): 2608692
2025-03-26 02:24:29,243 INFO terminating
2025-03-26 02:24:29,244 INFO terminating
2025-03-26 02:24:29,245 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/BGRA.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,252 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/multi-channel/chr30.4.184.jpg._COPYING_
2025-03-26 02:24:29,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741848_1024 src: /172.20.1.14:36276 dest: /172.20.1.17:9866
2025-03-26 02:24:29,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741848_1024 src: /172.20.1.17:59604 dest: /172.20.1.16:9866
2025-03-26 02:24:29,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741848_1024 src: /172.20.1.16:44480 dest: /172.20.1.15:9866
2025-03-26 02:24:29,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44480, dest: /172.20.1.15:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741848_1024, duration(ns): 2506270
2025-03-26 02:24:29,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59604, dest: /172.20.1.16:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741848_1024, duration(ns): 3025560
2025-03-26 02:24:29,268 INFO terminating
2025-03-26 02:24:29,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36276, dest: /172.20.1.17:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741848_1024, duration(ns): 11915469
2025-03-26 02:24:29,269 INFO terminating
2025-03-26 02:24:29,270 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/chr30.4.184.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/license.txt._COPYING_
2025-03-26 02:24:29,276 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,276 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741849_1025 src: /172.20.1.14:46652 dest: /172.20.1.16:9866
2025-03-26 02:24:29,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741849_1025 src: /172.20.1.16:53924 dest: /172.20.1.17:9866
2025-03-26 02:24:29,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741849_1025 src: /172.20.1.17:37920 dest: /172.20.1.15:9866
2025-03-26 02:24:29,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37920, dest: /172.20.1.15:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741849_1025, duration(ns): 4016881
2025-03-26 02:24:29,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53924, dest: /172.20.1.17:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741849_1025, duration(ns): 5464794
2025-03-26 02:24:29,289 INFO terminating
2025-03-26 02:24:29,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46652, dest: /172.20.1.16:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741849_1025, duration(ns): 7030382
2025-03-26 02:24:29,290 INFO terminating
2025-03-26 02:24:29,291 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/license.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,306 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg._COPYING_
2025-03-26 02:24:29,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741850_1026 src: /172.20.1.14:41940 dest: /172.20.1.15:9866
2025-03-26 02:24:29,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741850_1026 src: /172.20.1.15:38170 dest: /172.20.1.16:9866
2025-03-26 02:24:29,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741850_1026 src: /172.20.1.16:53936 dest: /172.20.1.17:9866
2025-03-26 02:24:29,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53936, dest: /172.20.1.17:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741850_1026, duration(ns): 2452951
2025-03-26 02:24:29,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38170, dest: /172.20.1.16:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741850_1026, duration(ns): 3255451
2025-03-26 02:24:29,315 INFO terminating
2025-03-26 02:24:29,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41940, dest: /172.20.1.15:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741850_1026, duration(ns): 3845560
2025-03-26 02:24:29,317 INFO terminating
2025-03-26 02:24:29,318 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/kittens/DP802813.jpg._COPYING_
2025-03-26 02:24:29,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741851_1027 src: /172.20.1.14:41954 dest: /172.20.1.15:9866
2025-03-26 02:24:29,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741851_1027 src: /172.20.1.15:38174 dest: /172.20.1.16:9866
2025-03-26 02:24:29,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741851_1027 src: /172.20.1.16:53952 dest: /172.20.1.17:9866
2025-03-26 02:24:29,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53952, dest: /172.20.1.17:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741851_1027, duration(ns): 2448083
2025-03-26 02:24:29,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38174, dest: /172.20.1.16:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741851_1027, duration(ns): 2962244
2025-03-26 02:24:29,339 INFO terminating
2025-03-26 02:24:29,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41954, dest: /172.20.1.15:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741851_1027, duration(ns): 5067270
2025-03-26 02:24:29,340 INFO terminating
2025-03-26 02:24:29,341 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/DP802813.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/mllib/images/origin/kittens/DP153539.jpg._COPYING_
2025-03-26 02:24:29,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741852_1028 src: /172.20.1.14:41962 dest: /172.20.1.15:9866
2025-03-26 02:24:29,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741852_1028 src: /172.20.1.15:35982 dest: /172.20.1.17:9866
2025-03-26 02:24:29,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741852_1028 src: /172.20.1.17:59612 dest: /172.20.1.16:9866
2025-03-26 02:24:29,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59612, dest: /172.20.1.16:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741852_1028, duration(ns): 2520095
2025-03-26 02:24:29,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35982, dest: /172.20.1.17:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741852_1028, duration(ns): 2947994
2025-03-26 02:24:29,364 INFO terminating
2025-03-26 02:24:29,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41962, dest: /172.20.1.15:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741852_1028, duration(ns): 11980625
2025-03-26 02:24:29,365 INFO terminating
2025-03-26 02:24:29,366 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/DP153539.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,372 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/data/mllib/images/origin/kittens/not-image.txt._COPYING_
2025-03-26 02:24:29,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741853_1029 src: /172.20.1.14:41976 dest: /172.20.1.15:9866
2025-03-26 02:24:29,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741853_1029 src: /172.20.1.15:38178 dest: /172.20.1.16:9866
2025-03-26 02:24:29,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741853_1029 src: /172.20.1.16:53966 dest: /172.20.1.17:9866
2025-03-26 02:24:29,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53966, dest: /172.20.1.17:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741853_1029, duration(ns): 2277807
2025-03-26 02:24:29,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38178, dest: /172.20.1.16:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741853_1029, duration(ns): 2719067
2025-03-26 02:24:29,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,381 INFO terminating
2025-03-26 02:24:29,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41976, dest: /172.20.1.15:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741853_1029, duration(ns): 3296849
2025-03-26 02:24:29,382 INFO terminating
2025-03-26 02:24:29,383 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/not-image.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/data/mllib/images/origin/kittens/54893.jpg._COPYING_
2025-03-26 02:24:29,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741854_1030 src: /172.20.1.14:46668 dest: /172.20.1.16:9866
2025-03-26 02:24:29,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741854_1030 src: /172.20.1.16:53978 dest: /172.20.1.17:9866
2025-03-26 02:24:29,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741854_1030 src: /172.20.1.17:37928 dest: /172.20.1.15:9866
2025-03-26 02:24:29,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53978, dest: /172.20.1.17:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741854_1030, duration(ns): 3186753
2025-03-26 02:24:29,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37928, dest: /172.20.1.15:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741854_1030, duration(ns): 2766458
2025-03-26 02:24:29,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,397 INFO terminating
2025-03-26 02:24:29,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46668, dest: /172.20.1.16:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741854_1030, duration(ns): 3622376
2025-03-26 02:24:29,398 INFO terminating
2025-03-26 02:24:29,399 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/54893.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/sample_linear_regression_data.txt._COPYING_
2025-03-26 02:24:29,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741855_1031 src: /172.20.1.14:36290 dest: /172.20.1.17:9866
2025-03-26 02:24:29,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741855_1031 src: /172.20.1.17:37932 dest: /172.20.1.15:9866
2025-03-26 02:24:29,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741855_1031 src: /172.20.1.15:38188 dest: /172.20.1.16:9866
2025-03-26 02:24:29,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38188, dest: /172.20.1.16:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741855_1031, duration(ns): 3504324
2025-03-26 02:24:29,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37932, dest: /172.20.1.15:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741855_1031, duration(ns): 4107624
2025-03-26 02:24:29,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,417 INFO terminating
2025-03-26 02:24:29,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36290, dest: /172.20.1.17:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741855_1031, duration(ns): 4338995
2025-03-26 02:24:29,418 INFO terminating
2025-03-26 02:24:29,419 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_linear_regression_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,425 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/data/mllib/sample_binary_classification_data.txt._COPYING_
2025-03-26 02:24:29,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741856_1032 src: /172.20.1.14:46670 dest: /172.20.1.16:9866
2025-03-26 02:24:29,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741856_1032 src: /172.20.1.16:44488 dest: /172.20.1.15:9866
2025-03-26 02:24:29,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741856_1032 src: /172.20.1.15:35988 dest: /172.20.1.17:9866
2025-03-26 02:24:29,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35988, dest: /172.20.1.17:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741856_1032, duration(ns): 2547359
2025-03-26 02:24:29,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44488, dest: /172.20.1.15:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741856_1032, duration(ns): 3530241
2025-03-26 02:24:29,434 INFO terminating
2025-03-26 02:24:29,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46670, dest: /172.20.1.16:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741856_1032, duration(ns): 4064040
2025-03-26 02:24:29,436 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_binary_classification_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,436 INFO terminating
2025-03-26 02:24:29,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/data/mllib/sample_multiclass_classification_data.txt._COPYING_
2025-03-26 02:24:29,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741857_1033 src: /172.20.1.14:36306 dest: /172.20.1.17:9866
2025-03-26 02:24:29,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741857_1033 src: /172.20.1.17:59618 dest: /172.20.1.16:9866
2025-03-26 02:24:29,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741857_1033 src: /172.20.1.16:44504 dest: /172.20.1.15:9866
2025-03-26 02:24:29,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44504, dest: /172.20.1.15:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741857_1033, duration(ns): 2067920
2025-03-26 02:24:29,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59618, dest: /172.20.1.16:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741857_1033, duration(ns): 2832132
2025-03-26 02:24:29,452 INFO terminating
2025-03-26 02:24:29,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36306, dest: /172.20.1.17:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741857_1033, duration(ns): 4280394
2025-03-26 02:24:29,453 INFO terminating
2025-03-26 02:24:29,454 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_multiclass_classification_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,459 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/mllib/sample_isotonic_regression_libsvm_data.txt._COPYING_
2025-03-26 02:24:29,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741858_1034 src: /172.20.1.14:41980 dest: /172.20.1.15:9866
2025-03-26 02:24:29,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741858_1034 src: /172.20.1.15:35996 dest: /172.20.1.17:9866
2025-03-26 02:24:29,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741858_1034 src: /172.20.1.17:59634 dest: /172.20.1.16:9866
2025-03-26 02:24:29,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59634, dest: /172.20.1.16:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741858_1034, duration(ns): 2705402
2025-03-26 02:24:29,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35996, dest: /172.20.1.17:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741858_1034, duration(ns): 3433339
2025-03-26 02:24:29,469 INFO terminating
2025-03-26 02:24:29,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41980, dest: /172.20.1.15:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741858_1034, duration(ns): 4357728
2025-03-26 02:24:29,471 INFO terminating
2025-03-26 02:24:29,472 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_isotonic_regression_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/data/mllib/pic_data.txt._COPYING_
2025-03-26 02:24:29,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741859_1035 src: /172.20.1.14:41982 dest: /172.20.1.15:9866
2025-03-26 02:24:29,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741859_1035 src: /172.20.1.15:35998 dest: /172.20.1.17:9866
2025-03-26 02:24:29,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741859_1035 src: /172.20.1.17:59650 dest: /172.20.1.16:9866
2025-03-26 02:24:29,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59650, dest: /172.20.1.16:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741859_1035, duration(ns): 2339869
2025-03-26 02:24:29,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:35998, dest: /172.20.1.17:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741859_1035, duration(ns): 3490632
2025-03-26 02:24:29,487 INFO terminating
2025-03-26 02:24:29,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41982, dest: /172.20.1.15:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741859_1035, duration(ns): 4429340
2025-03-26 02:24:29,488 INFO terminating
2025-03-26 02:24:29,489 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/pic_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,497 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/mllib/kmeans_data.txt._COPYING_
2025-03-26 02:24:29,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741860_1036 src: /172.20.1.14:36316 dest: /172.20.1.17:9866
2025-03-26 02:24:29,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741860_1036 src: /172.20.1.17:37936 dest: /172.20.1.15:9866
2025-03-26 02:24:29,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741860_1036 src: /172.20.1.15:38194 dest: /172.20.1.16:9866
2025-03-26 02:24:29,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38194, dest: /172.20.1.16:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741860_1036, duration(ns): 1632962
2025-03-26 02:24:29,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37936, dest: /172.20.1.15:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741860_1036, duration(ns): 2084805
2025-03-26 02:24:29,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,504 INFO terminating
2025-03-26 02:24:29,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36316, dest: /172.20.1.17:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741860_1036, duration(ns): 2465716
2025-03-26 02:24:29,505 INFO terminating
2025-03-26 02:24:29,506 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/kmeans_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,518 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/data/streaming/AFINN-111.txt._COPYING_
2025-03-26 02:24:29,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741861_1037 src: /172.20.1.14:36326 dest: /172.20.1.17:9866
2025-03-26 02:24:29,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741861_1037 src: /172.20.1.17:37950 dest: /172.20.1.15:9866
2025-03-26 02:24:29,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741861_1037 src: /172.20.1.15:38204 dest: /172.20.1.16:9866
2025-03-26 02:24:29,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38204, dest: /172.20.1.16:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741861_1037, duration(ns): 1991159
2025-03-26 02:24:29,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36326, dest: /172.20.1.17:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741861_1037, duration(ns): 2886337
2025-03-26 02:24:29,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37950, dest: /172.20.1.15:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1617822868_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741861_1037, duration(ns): 2512115
2025-03-26 02:24:29,526 INFO terminating
2025-03-26 02:24:29,527 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/streaming/AFINN-111.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617822868_1
2025-03-26 02:24:29,527 INFO terminating
2025-03-26 02:24:30,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,893 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/jars/scopt_2.12-3.7.1.jar._COPYING_
2025-03-26 02:24:30,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741862_1038 src: /172.20.1.14:36334 dest: /172.20.1.17:9866
2025-03-26 02:24:30,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741862_1038 src: /172.20.1.17:59664 dest: /172.20.1.16:9866
2025-03-26 02:24:30,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741862_1038 src: /172.20.1.16:44512 dest: /172.20.1.15:9866
2025-03-26 02:24:30,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44512, dest: /172.20.1.15:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741862_1038, duration(ns): 7122083
2025-03-26 02:24:30,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59664, dest: /172.20.1.16:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741862_1038, duration(ns): 7480807
2025-03-26 02:24:30,941 INFO terminating
2025-03-26 02:24:30,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36334, dest: /172.20.1.17:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741862_1038, duration(ns): 9149019
2025-03-26 02:24:30,942 INFO terminating
2025-03-26 02:24:30,944 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/jars/scopt_2.12-3.7.1.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:30,956 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/jars/spark-examples_2.12-3.3.2.jar._COPYING_
2025-03-26 02:24:30,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741863_1039 src: /172.20.1.14:41998 dest: /172.20.1.15:9866
2025-03-26 02:24:30,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741863_1039 src: /172.20.1.15:36002 dest: /172.20.1.17:9866
2025-03-26 02:24:30,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741863_1039 src: /172.20.1.17:59676 dest: /172.20.1.16:9866
2025-03-26 02:24:30,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59676, dest: /172.20.1.16:9866, bytes: 1567446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741863_1039, duration(ns): 8046777
2025-03-26 02:24:30,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41998, dest: /172.20.1.15:9866, bytes: 1567446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741863_1039, duration(ns): 9865569
2025-03-26 02:24:30,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36002, dest: /172.20.1.17:9866, bytes: 1567446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741863_1039, duration(ns): 8636385
2025-03-26 02:24:30,974 INFO terminating
2025-03-26 02:24:30,975 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/jars/spark-examples_2.12-3.3.2.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:30,975 INFO terminating
2025-03-26 02:24:30,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,999 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/wordcount.py._COPYING_
2025-03-26 02:24:30,999 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741864_1040 src: /172.20.1.14:36340 dest: /172.20.1.17:9866
2025-03-26 02:24:31,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741864_1040 src: /172.20.1.17:37962 dest: /172.20.1.15:9866
2025-03-26 02:24:31,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741864_1040 src: /172.20.1.15:38210 dest: /172.20.1.16:9866
2025-03-26 02:24:31,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38210, dest: /172.20.1.16:9866, bytes: 1418, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741864_1040, duration(ns): 3054989
2025-03-26 02:24:31,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37962, dest: /172.20.1.15:9866, bytes: 1418, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741864_1040, duration(ns): 3971465
2025-03-26 02:24:31,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,008 INFO terminating
2025-03-26 02:24:31,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36340, dest: /172.20.1.17:9866, bytes: 1418, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741864_1040, duration(ns): 4247231
2025-03-26 02:24:31,009 INFO terminating
2025-03-26 02:24:31,011 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/transitive_closure.py._COPYING_
2025-03-26 02:24:31,026 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,026 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741865_1041 src: /172.20.1.14:36354 dest: /172.20.1.17:9866
2025-03-26 02:24:31,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741865_1041 src: /172.20.1.17:37970 dest: /172.20.1.15:9866
2025-03-26 02:24:31,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741865_1041 src: /172.20.1.15:38218 dest: /172.20.1.16:9866
2025-03-26 02:24:31,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38218, dest: /172.20.1.16:9866, bytes: 2445, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741865_1041, duration(ns): 1940026
2025-03-26 02:24:31,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36354, dest: /172.20.1.17:9866, bytes: 2445, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741865_1041, duration(ns): 3396951
2025-03-26 02:24:31,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37970, dest: /172.20.1.15:9866, bytes: 2445, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741865_1041, duration(ns): 2894831
2025-03-26 02:24:31,035 INFO terminating
2025-03-26 02:24:31,035 INFO terminating
2025-03-26 02:24:31,036 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/transitive_closure.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_
2025-03-26 02:24:31,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741866_1042 src: /172.20.1.14:46674 dest: /172.20.1.16:9866
2025-03-26 02:24:31,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741866_1042 src: /172.20.1.16:53994 dest: /172.20.1.17:9866
2025-03-26 02:24:31,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741866_1042 src: /172.20.1.17:37984 dest: /172.20.1.15:9866
2025-03-26 02:24:31,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:37984, dest: /172.20.1.15:9866, bytes: 2432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741866_1042, duration(ns): 1959749
2025-03-26 02:24:31,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53994, dest: /172.20.1.17:9866, bytes: 2432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741866_1042, duration(ns): 2373948
2025-03-26 02:24:31,053 INFO terminating
2025-03-26 02:24:31,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46674, dest: /172.20.1.16:9866, bytes: 2432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741866_1042, duration(ns): 3016330
2025-03-26 02:24:31,054 INFO terminating
2025-03-26 02:24:31,055 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/pi.py._COPYING_
2025-03-26 02:24:31,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741867_1043 src: /172.20.1.14:46680 dest: /172.20.1.16:9866
2025-03-26 02:24:31,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741867_1043 src: /172.20.1.16:53998 dest: /172.20.1.17:9866
2025-03-26 02:24:31,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741867_1043 src: /172.20.1.17:38000 dest: /172.20.1.15:9866
2025-03-26 02:24:31,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38000, dest: /172.20.1.15:9866, bytes: 1444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741867_1043, duration(ns): 5162684
2025-03-26 02:24:31,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:53998, dest: /172.20.1.17:9866, bytes: 1444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741867_1043, duration(ns): 5595640
2025-03-26 02:24:31,072 INFO terminating
2025-03-26 02:24:31,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46680, dest: /172.20.1.16:9866, bytes: 1444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741867_1043, duration(ns): 6150951
2025-03-26 02:24:31,073 INFO terminating
2025-03-26 02:24:31,074 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/pi.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/sort.py._COPYING_
2025-03-26 02:24:31,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741868_1044 src: /172.20.1.14:46684 dest: /172.20.1.16:9866
2025-03-26 02:24:31,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741868_1044 src: /172.20.1.16:54010 dest: /172.20.1.17:9866
2025-03-26 02:24:31,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741868_1044 src: /172.20.1.17:38012 dest: /172.20.1.15:9866
2025-03-26 02:24:31,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38012, dest: /172.20.1.15:9866, bytes: 1594, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741868_1044, duration(ns): 1685119
2025-03-26 02:24:31,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54010, dest: /172.20.1.17:9866, bytes: 1594, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741868_1044, duration(ns): 1924465
2025-03-26 02:24:31,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741868_1044, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,087 INFO terminating
2025-03-26 02:24:31,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46684, dest: /172.20.1.16:9866, bytes: 1594, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741868_1044, duration(ns): 2347986
2025-03-26 02:24:31,088 INFO terminating
2025-03-26 02:24:31,089 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sort.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,101 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/status_api_demo.py._COPYING_
2025-03-26 02:24:31,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741869_1045 src: /172.20.1.14:42014 dest: /172.20.1.15:9866
2025-03-26 02:24:31,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741869_1045 src: /172.20.1.15:38234 dest: /172.20.1.16:9866
2025-03-26 02:24:31,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741869_1045 src: /172.20.1.16:54014 dest: /172.20.1.17:9866
2025-03-26 02:24:31,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54014, dest: /172.20.1.17:9866, bytes: 2368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741869_1045, duration(ns): 1750399
2025-03-26 02:24:31,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741869_1045, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42014, dest: /172.20.1.15:9866, bytes: 2368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741869_1045, duration(ns): 3588378
2025-03-26 02:24:31,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38234, dest: /172.20.1.16:9866, bytes: 2368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741869_1045, duration(ns): 3103291
2025-03-26 02:24:31,110 INFO terminating
2025-03-26 02:24:31,111 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/status_api_demo.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,111 INFO terminating
2025-03-26 02:24:31,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/avro_inputformat.py._COPYING_
2025-03-26 02:24:31,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741870_1046 src: /172.20.1.14:46694 dest: /172.20.1.16:9866
2025-03-26 02:24:31,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741870_1046 src: /172.20.1.16:54024 dest: /172.20.1.17:9866
2025-03-26 02:24:31,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741870_1046 src: /172.20.1.17:38014 dest: /172.20.1.15:9866
2025-03-26 02:24:31,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54024, dest: /172.20.1.17:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741870_1046, duration(ns): 1881804
2025-03-26 02:24:31,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38014, dest: /172.20.1.15:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741870_1046, duration(ns): 1728235
2025-03-26 02:24:31,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741870_1046, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46694, dest: /172.20.1.16:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741870_1046, duration(ns): 2359667
2025-03-26 02:24:31,127 INFO terminating
2025-03-26 02:24:31,127 INFO terminating
2025-03-26 02:24:31,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/avro_inputformat.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/logistic_regression.py._COPYING_
2025-03-26 02:24:31,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741871_1047 src: /172.20.1.14:46704 dest: /172.20.1.16:9866
2025-03-26 02:24:31,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741871_1047 src: /172.20.1.16:44514 dest: /172.20.1.15:9866
2025-03-26 02:24:31,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741871_1047 src: /172.20.1.15:36006 dest: /172.20.1.17:9866
2025-03-26 02:24:31,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36006, dest: /172.20.1.17:9866, bytes: 3307, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741871_1047, duration(ns): 1953280
2025-03-26 02:24:31,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44514, dest: /172.20.1.15:9866, bytes: 3307, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741871_1047, duration(ns): 2494125
2025-03-26 02:24:31,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741871_1047, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,141 INFO terminating
2025-03-26 02:24:31,142 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/logistic_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46704, dest: /172.20.1.16:9866, bytes: 3307, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741871_1047, duration(ns): 2715522
2025-03-26 02:24:31,142 INFO terminating
2025-03-26 02:24:31,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/kmeans.py._COPYING_
2025-03-26 02:24:31,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741872_1048 src: /172.20.1.14:46716 dest: /172.20.1.16:9866
2025-03-26 02:24:31,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741872_1048 src: /172.20.1.16:44518 dest: /172.20.1.15:9866
2025-03-26 02:24:31,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741872_1048 src: /172.20.1.15:36016 dest: /172.20.1.17:9866
2025-03-26 02:24:31,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36016, dest: /172.20.1.17:9866, bytes: 2818, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741872_1048, duration(ns): 1802732
2025-03-26 02:24:31,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741872_1048, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44518, dest: /172.20.1.15:9866, bytes: 2818, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741872_1048, duration(ns): 2916578
2025-03-26 02:24:31,159 INFO terminating
2025-03-26 02:24:31,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46716, dest: /172.20.1.16:9866, bytes: 2818, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741872_1048, duration(ns): 3272640
2025-03-26 02:24:31,160 INFO terminating
2025-03-26 02:24:31,161 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/kmeans.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/svd_example.py._COPYING_
2025-03-26 02:24:31,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741873_1049 src: /172.20.1.14:36358 dest: /172.20.1.17:9866
2025-03-26 02:24:31,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741873_1049 src: /172.20.1.17:38018 dest: /172.20.1.15:9866
2025-03-26 02:24:31,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741873_1049 src: /172.20.1.15:38238 dest: /172.20.1.16:9866
2025-03-26 02:24:31,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38238, dest: /172.20.1.16:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741873_1049, duration(ns): 3472453
2025-03-26 02:24:31,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741873_1049, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36358, dest: /172.20.1.17:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741873_1049, duration(ns): 4503069
2025-03-26 02:24:31,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38018, dest: /172.20.1.15:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741873_1049, duration(ns): 4055084
2025-03-26 02:24:31,184 INFO terminating
2025-03-26 02:24:31,185 INFO terminating
2025-03-26 02:24:31,186 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/svd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/random_forest_regression_example.py._COPYING_
2025-03-26 02:24:31,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741874_1050 src: /172.20.1.14:42020 dest: /172.20.1.15:9866
2025-03-26 02:24:31,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741874_1050 src: /172.20.1.15:36026 dest: /172.20.1.17:9866
2025-03-26 02:24:31,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741874_1050 src: /172.20.1.17:59688 dest: /172.20.1.16:9866
2025-03-26 02:24:31,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59688, dest: /172.20.1.16:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741874_1050, duration(ns): 1742532
2025-03-26 02:24:31,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741874_1050, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42020, dest: /172.20.1.15:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741874_1050, duration(ns): 2794183
2025-03-26 02:24:31,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36026, dest: /172.20.1.17:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741874_1050, duration(ns): 2170069
2025-03-26 02:24:31,202 INFO terminating
2025-03-26 02:24:31,203 INFO terminating
2025-03-26 02:24:31,206 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_forest_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/streaming_linear_regression_example.py._COPYING_
2025-03-26 02:24:31,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741875_1051 src: /172.20.1.14:36364 dest: /172.20.1.17:9866
2025-03-26 02:24:31,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741875_1051 src: /172.20.1.17:59698 dest: /172.20.1.16:9866
2025-03-26 02:24:31,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741875_1051 src: /172.20.1.16:44530 dest: /172.20.1.15:9866
2025-03-26 02:24:31,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44530, dest: /172.20.1.15:9866, bytes: 2082, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741875_1051, duration(ns): 2180418
2025-03-26 02:24:31,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741875_1051, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59698, dest: /172.20.1.16:9866, bytes: 2082, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741875_1051, duration(ns): 2341485
2025-03-26 02:24:31,222 INFO terminating
2025-03-26 02:24:31,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36364, dest: /172.20.1.17:9866, bytes: 2082, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741875_1051, duration(ns): 2304599
2025-03-26 02:24:31,223 INFO terminating
2025-03-26 02:24:31,225 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/streaming_linear_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,236 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/recommendation_example.py._COPYING_
2025-03-26 02:24:31,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741876_1052 src: /172.20.1.14:46732 dest: /172.20.1.16:9866
2025-03-26 02:24:31,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741876_1052 src: /172.20.1.16:54040 dest: /172.20.1.17:9866
2025-03-26 02:24:31,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741876_1052 src: /172.20.1.17:38034 dest: /172.20.1.15:9866
2025-03-26 02:24:31,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38034, dest: /172.20.1.15:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741876_1052, duration(ns): 1999573
2025-03-26 02:24:31,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54040, dest: /172.20.1.17:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741876_1052, duration(ns): 2344122
2025-03-26 02:24:31,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741876_1052, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,245 INFO terminating
2025-03-26 02:24:31,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46732, dest: /172.20.1.16:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741876_1052, duration(ns): 2858155
2025-03-26 02:24:31,246 INFO terminating
2025-03-26 02:24:31,248 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/recommendation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/random_forest_classification_example.py._COPYING_
2025-03-26 02:24:31,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741877_1053 src: /172.20.1.14:42022 dest: /172.20.1.15:9866
2025-03-26 02:24:31,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741877_1053 src: /172.20.1.15:36030 dest: /172.20.1.17:9866
2025-03-26 02:24:31,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741877_1053 src: /172.20.1.17:59714 dest: /172.20.1.16:9866
2025-03-26 02:24:31,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59714, dest: /172.20.1.16:9866, bytes: 2533, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741877_1053, duration(ns): 2155438
2025-03-26 02:24:31,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741877_1053, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36030, dest: /172.20.1.17:9866, bytes: 2533, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741877_1053, duration(ns): 2451941
2025-03-26 02:24:31,265 INFO terminating
2025-03-26 02:24:31,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42022, dest: /172.20.1.15:9866, bytes: 2533, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741877_1053, duration(ns): 2974912
2025-03-26 02:24:31,266 INFO terminating
2025-03-26 02:24:31,267 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_forest_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/gaussian_mixture_model.py._COPYING_
2025-03-26 02:24:31,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741878_1054 src: /172.20.1.14:36368 dest: /172.20.1.17:9866
2025-03-26 02:24:31,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741878_1054 src: /172.20.1.17:38046 dest: /172.20.1.15:9866
2025-03-26 02:24:31,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741878_1054 src: /172.20.1.15:38250 dest: /172.20.1.16:9866
2025-03-26 02:24:31,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38250, dest: /172.20.1.16:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741878_1054, duration(ns): 1851930
2025-03-26 02:24:31,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38046, dest: /172.20.1.15:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741878_1054, duration(ns): 2235273
2025-03-26 02:24:31,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741878_1054, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,280 INFO terminating
2025-03-26 02:24:31,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36368, dest: /172.20.1.17:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741878_1054, duration(ns): 2679996
2025-03-26 02:24:31,281 INFO terminating
2025-03-26 02:24:31,282 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gaussian_mixture_model.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/stratified_sampling_example.py._COPYING_
2025-03-26 02:24:31,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741879_1055 src: /172.20.1.14:36380 dest: /172.20.1.17:9866
2025-03-26 02:24:31,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741879_1055 src: /172.20.1.17:59718 dest: /172.20.1.16:9866
2025-03-26 02:24:31,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741879_1055 src: /172.20.1.16:44540 dest: /172.20.1.15:9866
2025-03-26 02:24:31,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44540, dest: /172.20.1.15:9866, bytes: 1329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741879_1055, duration(ns): 1708724
2025-03-26 02:24:31,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741879_1055, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59718, dest: /172.20.1.16:9866, bytes: 1329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741879_1055, duration(ns): 2146230
2025-03-26 02:24:31,300 INFO terminating
2025-03-26 02:24:31,301 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/stratified_sampling_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36380, dest: /172.20.1.17:9866, bytes: 1329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741879_1055, duration(ns): 2660118
2025-03-26 02:24:31,301 INFO terminating
2025-03-26 02:24:31,312 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/tf_idf_example.py._COPYING_
2025-03-26 02:24:31,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741880_1056 src: /172.20.1.14:46746 dest: /172.20.1.16:9866
2025-03-26 02:24:31,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741880_1056 src: /172.20.1.16:54056 dest: /172.20.1.17:9866
2025-03-26 02:24:31,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741880_1056 src: /172.20.1.17:38050 dest: /172.20.1.15:9866
2025-03-26 02:24:31,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54056, dest: /172.20.1.17:9866, bytes: 2027, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741880_1056, duration(ns): 2043600
2025-03-26 02:24:31,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38050, dest: /172.20.1.15:9866, bytes: 2027, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741880_1056, duration(ns): 1808789
2025-03-26 02:24:31,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741880_1056, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,319 INFO terminating
2025-03-26 02:24:31,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46746, dest: /172.20.1.16:9866, bytes: 2027, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741880_1056, duration(ns): 2539701
2025-03-26 02:24:31,320 INFO terminating
2025-03-26 02:24:31,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/tf_idf_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,326 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/bisecting_k_means_example.py._COPYING_
2025-03-26 02:24:31,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741881_1057 src: /172.20.1.14:42038 dest: /172.20.1.15:9866
2025-03-26 02:24:31,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741881_1057 src: /172.20.1.15:38256 dest: /172.20.1.16:9866
2025-03-26 02:24:31,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741881_1057 src: /172.20.1.16:54062 dest: /172.20.1.17:9866
2025-03-26 02:24:31,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54062, dest: /172.20.1.17:9866, bytes: 1512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741881_1057, duration(ns): 1800093
2025-03-26 02:24:31,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741881_1057, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38256, dest: /172.20.1.16:9866, bytes: 1512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741881_1057, duration(ns): 2175011
2025-03-26 02:24:31,334 INFO terminating
2025-03-26 02:24:31,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42038, dest: /172.20.1.15:9866, bytes: 1512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741881_1057, duration(ns): 3044365
2025-03-26 02:24:31,335 INFO terminating
2025-03-26 02:24:31,336 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/bisecting_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/logistic_regression.py._COPYING_
2025-03-26 02:24:31,344 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,344 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741882_1058 src: /172.20.1.14:42050 dest: /172.20.1.15:9866
2025-03-26 02:24:31,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741882_1058 src: /172.20.1.15:38264 dest: /172.20.1.16:9866
2025-03-26 02:24:31,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741882_1058 src: /172.20.1.16:54074 dest: /172.20.1.17:9866
2025-03-26 02:24:31,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54074, dest: /172.20.1.17:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741882_1058, duration(ns): 1958281
2025-03-26 02:24:31,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741882_1058, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42050, dest: /172.20.1.15:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741882_1058, duration(ns): 3222595
2025-03-26 02:24:31,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38264, dest: /172.20.1.16:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741882_1058, duration(ns): 2615399
2025-03-26 02:24:31,352 INFO terminating
2025-03-26 02:24:31,353 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/logistic_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,353 INFO terminating
2025-03-26 02:24:31,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/naive_bayes_example.py._COPYING_
2025-03-26 02:24:31,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741883_1059 src: /172.20.1.14:46762 dest: /172.20.1.16:9866
2025-03-26 02:24:31,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741883_1059 src: /172.20.1.16:44546 dest: /172.20.1.15:9866
2025-03-26 02:24:31,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741883_1059 src: /172.20.1.15:36038 dest: /172.20.1.17:9866
2025-03-26 02:24:31,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36038, dest: /172.20.1.17:9866, bytes: 2246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741883_1059, duration(ns): 1776682
2025-03-26 02:24:31,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741883_1059, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46762, dest: /172.20.1.16:9866, bytes: 2246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741883_1059, duration(ns): 2825855
2025-03-26 02:24:31,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44546, dest: /172.20.1.15:9866, bytes: 2246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741883_1059, duration(ns): 2279503
2025-03-26 02:24:31,371 INFO terminating
2025-03-26 02:24:31,372 INFO terminating
2025-03-26 02:24:31,373 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/naive_bayes_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,380 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/streaming_k_means_example.py._COPYING_
2025-03-26 02:24:31,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741884_1060 src: /172.20.1.14:36396 dest: /172.20.1.17:9866
2025-03-26 02:24:31,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741884_1060 src: /172.20.1.17:59724 dest: /172.20.1.16:9866
2025-03-26 02:24:31,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741884_1060 src: /172.20.1.16:44548 dest: /172.20.1.15:9866
2025-03-26 02:24:31,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44548, dest: /172.20.1.15:9866, bytes: 2530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741884_1060, duration(ns): 2121381
2025-03-26 02:24:31,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59724, dest: /172.20.1.16:9866, bytes: 2530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741884_1060, duration(ns): 2459633
2025-03-26 02:24:31,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741884_1060, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,388 INFO terminating
2025-03-26 02:24:31,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36396, dest: /172.20.1.17:9866, bytes: 2530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741884_1060, duration(ns): 2929406
2025-03-26 02:24:31,389 INFO terminating
2025-03-26 02:24:31,391 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/streaming_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,397 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py._COPYING_
2025-03-26 02:24:31,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741885_1061 src: /172.20.1.14:46776 dest: /172.20.1.16:9866
2025-03-26 02:24:31,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741885_1061 src: /172.20.1.16:54088 dest: /172.20.1.17:9866
2025-03-26 02:24:31,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741885_1061 src: /172.20.1.17:38062 dest: /172.20.1.15:9866
2025-03-26 02:24:31,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54088, dest: /172.20.1.17:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741885_1061, duration(ns): 2005652
2025-03-26 02:24:31,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38062, dest: /172.20.1.15:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741885_1061, duration(ns): 1793672
2025-03-26 02:24:31,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741885_1061, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,405 INFO terminating
2025-03-26 02:24:31,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46776, dest: /172.20.1.16:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741885_1061, duration(ns): 2662251
2025-03-26 02:24:31,410 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,410 INFO terminating
2025-03-26 02:24:31,420 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/decision_tree_classification_example.py._COPYING_
2025-03-26 02:24:31,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741886_1062 src: /172.20.1.14:36406 dest: /172.20.1.17:9866
2025-03-26 02:24:31,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741886_1062 src: /172.20.1.17:59728 dest: /172.20.1.16:9866
2025-03-26 02:24:31,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741886_1062 src: /172.20.1.16:44558 dest: /172.20.1.15:9866
2025-03-26 02:24:31,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44558, dest: /172.20.1.15:9866, bytes: 2333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741886_1062, duration(ns): 1846453
2025-03-26 02:24:31,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741886_1062, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59728, dest: /172.20.1.16:9866, bytes: 2333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741886_1062, duration(ns): 2151546
2025-03-26 02:24:31,428 INFO terminating
2025-03-26 02:24:31,429 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/decision_tree_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36406, dest: /172.20.1.17:9866, bytes: 2333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741886_1062, duration(ns): 2333663
2025-03-26 02:24:31,429 INFO terminating
2025-03-26 02:24:31,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/word2vec.py._COPYING_
2025-03-26 02:24:31,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741887_1063 src: /172.20.1.14:46792 dest: /172.20.1.16:9866
2025-03-26 02:24:31,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741887_1063 src: /172.20.1.16:54096 dest: /172.20.1.17:9866
2025-03-26 02:24:31,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741887_1063 src: /172.20.1.17:38070 dest: /172.20.1.15:9866
2025-03-26 02:24:31,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38070, dest: /172.20.1.15:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741887_1063, duration(ns): 1462877
2025-03-26 02:24:31,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741887_1063, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54096, dest: /172.20.1.17:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741887_1063, duration(ns): 2022187
2025-03-26 02:24:31,444 INFO terminating
2025-03-26 02:24:31,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46792, dest: /172.20.1.16:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741887_1063, duration(ns): 2999756
2025-03-26 02:24:31,445 INFO terminating
2025-03-26 02:24:31,446 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/word2vec.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/isotonic_regression_example.py._COPYING_
2025-03-26 02:24:31,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741888_1064 src: /172.20.1.14:42058 dest: /172.20.1.15:9866
2025-03-26 02:24:31,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741888_1064 src: /172.20.1.15:38274 dest: /172.20.1.16:9866
2025-03-26 02:24:31,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741888_1064 src: /172.20.1.16:54098 dest: /172.20.1.17:9866
2025-03-26 02:24:31,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54098, dest: /172.20.1.17:9866, bytes: 2341, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741888_1064, duration(ns): 1437078
2025-03-26 02:24:31,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741888_1064, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38274, dest: /172.20.1.16:9866, bytes: 2341, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741888_1064, duration(ns): 2284040
2025-03-26 02:24:31,459 INFO terminating
2025-03-26 02:24:31,460 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/isotonic_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42058, dest: /172.20.1.15:9866, bytes: 2341, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741888_1064, duration(ns): 3432160
2025-03-26 02:24:31,460 INFO terminating
2025-03-26 02:24:31,468 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/pca_rowmatrix_example.py._COPYING_
2025-03-26 02:24:31,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741889_1065 src: /172.20.1.14:36420 dest: /172.20.1.17:9866
2025-03-26 02:24:31,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741889_1065 src: /172.20.1.17:38084 dest: /172.20.1.15:9866
2025-03-26 02:24:31,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741889_1065 src: /172.20.1.15:38278 dest: /172.20.1.16:9866
2025-03-26 02:24:31,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38278, dest: /172.20.1.16:9866, bytes: 1712, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741889_1065, duration(ns): 1355487
2025-03-26 02:24:31,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38084, dest: /172.20.1.15:9866, bytes: 1712, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741889_1065, duration(ns): 1809799
2025-03-26 02:24:31,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741889_1065, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,474 INFO terminating
2025-03-26 02:24:31,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36420, dest: /172.20.1.17:9866, bytes: 1712, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741889_1065, duration(ns): 1966384
2025-03-26 02:24:31,475 INFO terminating
2025-03-26 02:24:31,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/pca_rowmatrix_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/kmeans.py._COPYING_
2025-03-26 02:24:31,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741890_1066 src: /172.20.1.14:46802 dest: /172.20.1.16:9866
2025-03-26 02:24:31,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741890_1066 src: /172.20.1.16:44568 dest: /172.20.1.15:9866
2025-03-26 02:24:31,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741890_1066 src: /172.20.1.15:36050 dest: /172.20.1.17:9866
2025-03-26 02:24:31,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36050, dest: /172.20.1.17:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741890_1066, duration(ns): 1327917
2025-03-26 02:24:31,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44568, dest: /172.20.1.15:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741890_1066, duration(ns): 1792476
2025-03-26 02:24:31,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741890_1066, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,487 INFO terminating
2025-03-26 02:24:31,488 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/kmeans.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46802, dest: /172.20.1.16:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741890_1066, duration(ns): 1935201
2025-03-26 02:24:31,488 INFO terminating
2025-03-26 02:24:31,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/power_iteration_clustering_example.py._COPYING_
2025-03-26 02:24:31,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741891_1067 src: /172.20.1.14:36422 dest: /172.20.1.17:9866
2025-03-26 02:24:31,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741891_1067 src: /172.20.1.17:38088 dest: /172.20.1.15:9866
2025-03-26 02:24:31,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741891_1067 src: /172.20.1.15:38292 dest: /172.20.1.16:9866
2025-03-26 02:24:31,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38292, dest: /172.20.1.16:9866, bytes: 1753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741891_1067, duration(ns): 2120869
2025-03-26 02:24:31,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741891_1067, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38088, dest: /172.20.1.15:9866, bytes: 1753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741891_1067, duration(ns): 3029499
2025-03-26 02:24:31,506 INFO terminating
2025-03-26 02:24:31,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36422, dest: /172.20.1.17:9866, bytes: 1753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741891_1067, duration(ns): 4264323
2025-03-26 02:24:31,508 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/power_iteration_clustering_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,508 INFO terminating
2025-03-26 02:24:31,515 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/gradient_boosting_regression_example.py._COPYING_
2025-03-26 02:24:31,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741892_1068 src: /172.20.1.14:42074 dest: /172.20.1.15:9866
2025-03-26 02:24:31,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741892_1068 src: /172.20.1.15:38296 dest: /172.20.1.16:9866
2025-03-26 02:24:31,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741892_1068 src: /172.20.1.16:54114 dest: /172.20.1.17:9866
2025-03-26 02:24:31,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54114, dest: /172.20.1.17:9866, bytes: 2404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741892_1068, duration(ns): 1440919
2025-03-26 02:24:31,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741892_1068, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38296, dest: /172.20.1.16:9866, bytes: 2404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741892_1068, duration(ns): 1864423
2025-03-26 02:24:31,522 INFO terminating
2025-03-26 02:24:31,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42074, dest: /172.20.1.15:9866, bytes: 2404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741892_1068, duration(ns): 2588949
2025-03-26 02:24:31,523 INFO terminating
2025-03-26 02:24:31,524 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gradient_boosting_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/hypothesis_testing_example.py._COPYING_
2025-03-26 02:24:31,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741893_1069 src: /172.20.1.14:46810 dest: /172.20.1.16:9866
2025-03-26 02:24:31,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741893_1069 src: /172.20.1.16:54116 dest: /172.20.1.17:9866
2025-03-26 02:24:31,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741893_1069 src: /172.20.1.17:38094 dest: /172.20.1.15:9866
2025-03-26 02:24:31,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38094, dest: /172.20.1.15:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741893_1069, duration(ns): 1217285
2025-03-26 02:24:31,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741893_1069, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54116, dest: /172.20.1.17:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741893_1069, duration(ns): 1793042
2025-03-26 02:24:31,536 INFO terminating
2025-03-26 02:24:31,537 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/hypothesis_testing_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46810, dest: /172.20.1.16:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741893_1069, duration(ns): 2450062
2025-03-26 02:24:31,537 INFO terminating
2025-03-26 02:24:31,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,544 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/__init__.py._COPYING_
2025-03-26 02:24:31,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741894_1070 src: /172.20.1.14:46816 dest: /172.20.1.16:9866
2025-03-26 02:24:31,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741894_1070 src: /172.20.1.16:44574 dest: /172.20.1.15:9866
2025-03-26 02:24:31,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741894_1070 src: /172.20.1.15:36056 dest: /172.20.1.17:9866
2025-03-26 02:24:31,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36056, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741894_1070, duration(ns): 1160857
2025-03-26 02:24:31,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46816, dest: /172.20.1.16:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741894_1070, duration(ns): 1834203
2025-03-26 02:24:31,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44574, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741894_1070, duration(ns): 1556018
2025-03-26 02:24:31,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741894_1070, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,550 INFO terminating
2025-03-26 02:24:31,550 INFO terminating
2025-03-26 02:24:31,551 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py._COPYING_
2025-03-26 02:24:31,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741895_1071 src: /172.20.1.14:46822 dest: /172.20.1.16:9866
2025-03-26 02:24:31,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741895_1071 src: /172.20.1.16:54128 dest: /172.20.1.17:9866
2025-03-26 02:24:31,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741895_1071 src: /172.20.1.17:38102 dest: /172.20.1.15:9866
2025-03-26 02:24:31,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38102, dest: /172.20.1.15:9866, bytes: 2150, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741895_1071, duration(ns): 1226611
2025-03-26 02:24:31,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741895_1071, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54128, dest: /172.20.1.17:9866, bytes: 2150, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741895_1071, duration(ns): 1482841
2025-03-26 02:24:31,566 INFO terminating
2025-03-26 02:24:31,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46822, dest: /172.20.1.16:9866, bytes: 2150, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741895_1071, duration(ns): 2212989
2025-03-26 02:24:31,567 INFO terminating
2025-03-26 02:24:31,568 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/summary_statistics_example.py._COPYING_
2025-03-26 02:24:31,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741896_1072 src: /172.20.1.14:46832 dest: /172.20.1.16:9866
2025-03-26 02:24:31,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741896_1072 src: /172.20.1.16:54142 dest: /172.20.1.17:9866
2025-03-26 02:24:31,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741896_1072 src: /172.20.1.17:38104 dest: /172.20.1.15:9866
2025-03-26 02:24:31,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38104, dest: /172.20.1.15:9866, bytes: 1511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741896_1072, duration(ns): 1287130
2025-03-26 02:24:31,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54142, dest: /172.20.1.17:9866, bytes: 1511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741896_1072, duration(ns): 1599635
2025-03-26 02:24:31,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741896_1072, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,579 INFO terminating
2025-03-26 02:24:31,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46832, dest: /172.20.1.16:9866, bytes: 1511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741896_1072, duration(ns): 2082687
2025-03-26 02:24:31,580 INFO terminating
2025-03-26 02:24:31,581 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/summary_statistics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/decision_tree_regression_example.py._COPYING_
2025-03-26 02:24:31,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741897_1073 src: /172.20.1.14:36424 dest: /172.20.1.17:9866
2025-03-26 02:24:31,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741897_1073 src: /172.20.1.17:38114 dest: /172.20.1.15:9866
2025-03-26 02:24:31,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741897_1073 src: /172.20.1.15:38300 dest: /172.20.1.16:9866
2025-03-26 02:24:31,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38300, dest: /172.20.1.16:9866, bytes: 2328, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741897_1073, duration(ns): 1324566
2025-03-26 02:24:31,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741897_1073, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36424, dest: /172.20.1.17:9866, bytes: 2328, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741897_1073, duration(ns): 3078399
2025-03-26 02:24:31,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38114, dest: /172.20.1.15:9866, bytes: 2328, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741897_1073, duration(ns): 2240533
2025-03-26 02:24:31,592 INFO terminating
2025-03-26 02:24:31,593 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/decision_tree_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,593 INFO terminating
2025-03-26 02:24:31,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/word2vec_example.py._COPYING_
2025-03-26 02:24:31,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741898_1074 src: /172.20.1.14:42080 dest: /172.20.1.15:9866
2025-03-26 02:24:31,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741898_1074 src: /172.20.1.15:38302 dest: /172.20.1.16:9866
2025-03-26 02:24:31,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741898_1074 src: /172.20.1.16:54152 dest: /172.20.1.17:9866
2025-03-26 02:24:31,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38302, dest: /172.20.1.16:9866, bytes: 1326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741898_1074, duration(ns): 1486639
2025-03-26 02:24:31,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54152, dest: /172.20.1.17:9866, bytes: 1326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741898_1074, duration(ns): 1094293
2025-03-26 02:24:31,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741898_1074, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,604 INFO terminating
2025-03-26 02:24:31,605 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/word2vec_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42080, dest: /172.20.1.15:9866, bytes: 1326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741898_1074, duration(ns): 1968037
2025-03-26 02:24:31,605 INFO terminating
2025-03-26 02:24:31,611 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,611 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/fpgrowth_example.py._COPYING_
2025-03-26 02:24:31,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741899_1075 src: /172.20.1.14:36428 dest: /172.20.1.17:9866
2025-03-26 02:24:31,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741899_1075 src: /172.20.1.17:59738 dest: /172.20.1.16:9866
2025-03-26 02:24:31,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741899_1075 src: /172.20.1.16:44584 dest: /172.20.1.15:9866
2025-03-26 02:24:31,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44584, dest: /172.20.1.15:9866, bytes: 1280, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741899_1075, duration(ns): 1371245
2025-03-26 02:24:31,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741899_1075, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36428, dest: /172.20.1.17:9866, bytes: 1280, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741899_1075, duration(ns): 2161918
2025-03-26 02:24:31,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59738, dest: /172.20.1.16:9866, bytes: 1280, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741899_1075, duration(ns): 1685706
2025-03-26 02:24:31,618 INFO terminating
2025-03-26 02:24:31,619 INFO terminating
2025-03-26 02:24:31,620 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/fpgrowth_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/correlations_example.py._COPYING_
2025-03-26 02:24:31,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741900_1076 src: /172.20.1.14:46848 dest: /172.20.1.16:9866
2025-03-26 02:24:31,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741900_1076 src: /172.20.1.16:44600 dest: /172.20.1.15:9866
2025-03-26 02:24:31,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741900_1076 src: /172.20.1.15:36060 dest: /172.20.1.17:9866
2025-03-26 02:24:31,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36060, dest: /172.20.1.17:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741900_1076, duration(ns): 1627562
2025-03-26 02:24:31,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741900_1076, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46848, dest: /172.20.1.16:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741900_1076, duration(ns): 3092616
2025-03-26 02:24:31,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44600, dest: /172.20.1.15:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741900_1076, duration(ns): 2434462
2025-03-26 02:24:31,633 INFO terminating
2025-03-26 02:24:31,634 INFO terminating
2025-03-26 02:24:31,635 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/correlations_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/binary_classification_metrics_example.py._COPYING_
2025-03-26 02:24:31,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741901_1077 src: /172.20.1.14:46862 dest: /172.20.1.16:9866
2025-03-26 02:24:31,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741901_1077 src: /172.20.1.15:36070 dest: /172.20.1.17:9866
2025-03-26 02:24:31,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741901_1077 src: /172.20.1.16:44604 dest: /172.20.1.15:9866
2025-03-26 02:24:31,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36070, dest: /172.20.1.17:9866, bytes: 2083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741901_1077, duration(ns): 1519107
2025-03-26 02:24:31,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44604, dest: /172.20.1.15:9866, bytes: 2083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741901_1077, duration(ns): 1977732
2025-03-26 02:24:31,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741901_1077, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,646 INFO terminating
2025-03-26 02:24:31,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46862, dest: /172.20.1.16:9866, bytes: 2083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741901_1077, duration(ns): 2303128
2025-03-26 02:24:31,647 INFO terminating
2025-03-26 02:24:31,648 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/binary_classification_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,656 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/multi_label_metrics_example.py._COPYING_
2025-03-26 02:24:31,656 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,656 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741902_1078 src: /172.20.1.14:36430 dest: /172.20.1.17:9866
2025-03-26 02:24:31,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741902_1078 src: /172.20.1.17:59742 dest: /172.20.1.16:9866
2025-03-26 02:24:31,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741902_1078 src: /172.20.1.16:44608 dest: /172.20.1.15:9866
2025-03-26 02:24:31,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44608, dest: /172.20.1.15:9866, bytes: 2277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741902_1078, duration(ns): 1766437
2025-03-26 02:24:31,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59742, dest: /172.20.1.16:9866, bytes: 2277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741902_1078, duration(ns): 2198434
2025-03-26 02:24:31,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741902_1078, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,663 INFO terminating
2025-03-26 02:24:31,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36430, dest: /172.20.1.17:9866, bytes: 2277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741902_1078, duration(ns): 2776746
2025-03-26 02:24:31,664 INFO terminating
2025-03-26 02:24:31,665 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/multi_label_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py._COPYING_
2025-03-26 02:24:31,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741903_1079 src: /172.20.1.14:46874 dest: /172.20.1.16:9866
2025-03-26 02:24:31,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741903_1079 src: /172.20.1.16:44620 dest: /172.20.1.15:9866
2025-03-26 02:24:31,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741903_1079 src: /172.20.1.15:36076 dest: /172.20.1.17:9866
2025-03-26 02:24:31,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36076, dest: /172.20.1.17:9866, bytes: 1619, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741903_1079, duration(ns): 1373503
2025-03-26 02:24:31,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741903_1079, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44620, dest: /172.20.1.15:9866, bytes: 1619, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741903_1079, duration(ns): 1795954
2025-03-26 02:24:31,682 INFO terminating
2025-03-26 02:24:31,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46874, dest: /172.20.1.16:9866, bytes: 1619, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741903_1079, duration(ns): 2391869
2025-03-26 02:24:31,683 INFO terminating
2025-03-26 02:24:31,684 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,695 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/gradient_boosting_classification_example.py._COPYING_
2025-03-26 02:24:31,695 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,695 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741904_1080 src: /172.20.1.14:42096 dest: /172.20.1.15:9866
2025-03-26 02:24:31,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741904_1080 src: /172.20.1.15:36082 dest: /172.20.1.17:9866
2025-03-26 02:24:31,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741904_1080 src: /172.20.1.17:59758 dest: /172.20.1.16:9866
2025-03-26 02:24:31,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59758, dest: /172.20.1.16:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741904_1080, duration(ns): 1443438
2025-03-26 02:24:31,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36082, dest: /172.20.1.17:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741904_1080, duration(ns): 2277206
2025-03-26 02:24:31,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741904_1080, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,703 INFO terminating
2025-03-26 02:24:31,704 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gradient_boosting_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42096, dest: /172.20.1.15:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741904_1080, duration(ns): 2763128
2025-03-26 02:24:31,704 INFO terminating
2025-03-26 02:24:31,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/correlations.py._COPYING_
2025-03-26 02:24:31,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741905_1081 src: /172.20.1.14:46888 dest: /172.20.1.16:9866
2025-03-26 02:24:31,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741905_1081 src: /172.20.1.16:54158 dest: /172.20.1.17:9866
2025-03-26 02:24:31,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741905_1081 src: /172.20.1.17:38118 dest: /172.20.1.15:9866
2025-03-26 02:24:31,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38118, dest: /172.20.1.15:9866, bytes: 2049, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741905_1081, duration(ns): 1476440
2025-03-26 02:24:31,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741905_1081, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54158, dest: /172.20.1.17:9866, bytes: 2049, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741905_1081, duration(ns): 1720005
2025-03-26 02:24:31,716 INFO terminating
2025-03-26 02:24:31,717 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/correlations.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46888, dest: /172.20.1.16:9866, bytes: 2049, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741905_1081, duration(ns): 2339376
2025-03-26 02:24:31,717 INFO terminating
2025-03-26 02:24:31,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/gaussian_mixture_example.py._COPYING_
2025-03-26 02:24:31,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741906_1082 src: /172.20.1.14:42102 dest: /172.20.1.15:9866
2025-03-26 02:24:31,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741906_1082 src: /172.20.1.15:36086 dest: /172.20.1.17:9866
2025-03-26 02:24:31,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741906_1082 src: /172.20.1.17:59772 dest: /172.20.1.16:9866
2025-03-26 02:24:31,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36086, dest: /172.20.1.17:9866, bytes: 1839, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741906_1082, duration(ns): 2677360
2025-03-26 02:24:31,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59772, dest: /172.20.1.16:9866, bytes: 1839, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741906_1082, duration(ns): 1998454
2025-03-26 02:24:31,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741906_1082, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42102, dest: /172.20.1.15:9866, bytes: 1839, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741906_1082, duration(ns): 3531359
2025-03-26 02:24:31,730 INFO terminating
2025-03-26 02:24:31,730 INFO terminating
2025-03-26 02:24:31,731 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gaussian_mixture_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/k_means_example.py._COPYING_
2025-03-26 02:24:31,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741907_1083 src: /172.20.1.14:36438 dest: /172.20.1.17:9866
2025-03-26 02:24:31,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741907_1083 src: /172.20.1.17:38126 dest: /172.20.1.15:9866
2025-03-26 02:24:31,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741907_1083 src: /172.20.1.15:38314 dest: /172.20.1.16:9866
2025-03-26 02:24:31,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38314, dest: /172.20.1.16:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741907_1083, duration(ns): 1476371
2025-03-26 02:24:31,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38126, dest: /172.20.1.15:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741907_1083, duration(ns): 1887821
2025-03-26 02:24:31,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741907_1083, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,744 INFO terminating
2025-03-26 02:24:31,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36438, dest: /172.20.1.17:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741907_1083, duration(ns): 2364548
2025-03-26 02:24:31,745 INFO terminating
2025-03-26 02:24:31,746 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,752 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/ranking_metrics_example.py._COPYING_
2025-03-26 02:24:31,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741908_1084 src: /172.20.1.14:46898 dest: /172.20.1.16:9866
2025-03-26 02:24:31,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741908_1084 src: /172.20.1.16:54162 dest: /172.20.1.17:9866
2025-03-26 02:24:31,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741908_1084 src: /172.20.1.17:38130 dest: /172.20.1.15:9866
2025-03-26 02:24:31,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38130, dest: /172.20.1.15:9866, bytes: 2181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741908_1084, duration(ns): 1476601
2025-03-26 02:24:31,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741908_1084, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46898, dest: /172.20.1.16:9866, bytes: 2181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741908_1084, duration(ns): 2161426
2025-03-26 02:24:31,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54162, dest: /172.20.1.17:9866, bytes: 2181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741908_1084, duration(ns): 1797794
2025-03-26 02:24:31,759 INFO terminating
2025-03-26 02:24:31,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/ranking_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,760 INFO terminating
2025-03-26 02:24:31,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/multi_class_metrics_example.py._COPYING_
2025-03-26 02:24:31,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741909_1085 src: /172.20.1.14:36452 dest: /172.20.1.17:9866
2025-03-26 02:24:31,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741909_1085 src: /172.20.1.17:38134 dest: /172.20.1.15:9866
2025-03-26 02:24:31,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741909_1085 src: /172.20.1.15:38316 dest: /172.20.1.16:9866
2025-03-26 02:24:31,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38316, dest: /172.20.1.16:9866, bytes: 2836, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741909_1085, duration(ns): 1176569
2025-03-26 02:24:31,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38134, dest: /172.20.1.15:9866, bytes: 2836, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741909_1085, duration(ns): 2001959
2025-03-26 02:24:31,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741909_1085, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,771 INFO terminating
2025-03-26 02:24:31,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36452, dest: /172.20.1.17:9866, bytes: 2836, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741909_1085, duration(ns): 2636836
2025-03-26 02:24:31,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/multi_class_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,773 INFO terminating
2025-03-26 02:24:31,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/linear_regression_with_sgd_example.py._COPYING_
2025-03-26 02:24:31,780 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,780 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741910_1086 src: /172.20.1.14:36466 dest: /172.20.1.17:9866
2025-03-26 02:24:31,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741910_1086 src: /172.20.1.17:38136 dest: /172.20.1.15:9866
2025-03-26 02:24:31,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741910_1086 src: /172.20.1.15:38324 dest: /172.20.1.16:9866
2025-03-26 02:24:31,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38324, dest: /172.20.1.16:9866, bytes: 2013, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741910_1086, duration(ns): 1497768
2025-03-26 02:24:31,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38136, dest: /172.20.1.15:9866, bytes: 2013, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741910_1086, duration(ns): 1980048
2025-03-26 02:24:31,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741910_1086, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,787 INFO terminating
2025-03-26 02:24:31,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36466, dest: /172.20.1.17:9866, bytes: 2013, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741910_1086, duration(ns): 2415212
2025-03-26 02:24:31,788 INFO terminating
2025-03-26 02:24:31,789 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/linear_regression_with_sgd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/standard_scaler_example.py._COPYING_
2025-03-26 02:24:31,794 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,794 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741911_1087 src: /172.20.1.14:36480 dest: /172.20.1.17:9866
2025-03-26 02:24:31,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741911_1087 src: /172.20.1.16:44634 dest: /172.20.1.15:9866
2025-03-26 02:24:31,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741911_1087 src: /172.20.1.17:59788 dest: /172.20.1.16:9866
2025-03-26 02:24:31,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44634, dest: /172.20.1.15:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741911_1087, duration(ns): 1675284
2025-03-26 02:24:31,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59788, dest: /172.20.1.16:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741911_1087, duration(ns): 1922593
2025-03-26 02:24:31,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741911_1087, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,800 INFO terminating
2025-03-26 02:24:31,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36480, dest: /172.20.1.17:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741911_1087, duration(ns): 2362065
2025-03-26 02:24:31,801 INFO terminating
2025-03-26 02:24:31,802 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/standard_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/kernel_density_estimation_example.py._COPYING_
2025-03-26 02:24:31,807 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741912_1088 src: /172.20.1.14:46902 dest: /172.20.1.16:9866
2025-03-26 02:24:31,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741912_1088 src: /172.20.1.16:54178 dest: /172.20.1.17:9866
2025-03-26 02:24:31,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741912_1088 src: /172.20.1.17:38138 dest: /172.20.1.15:9866
2025-03-26 02:24:31,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38138, dest: /172.20.1.15:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741912_1088, duration(ns): 1284614
2025-03-26 02:24:31,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741912_1088, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54178, dest: /172.20.1.17:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741912_1088, duration(ns): 1607351
2025-03-26 02:24:31,815 INFO terminating
2025-03-26 02:24:31,816 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/kernel_density_estimation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46902, dest: /172.20.1.16:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741912_1088, duration(ns): 4204123
2025-03-26 02:24:31,816 INFO terminating
2025-03-26 02:24:31,823 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,823 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/mllib/regression_metrics_example.py._COPYING_
2025-03-26 02:24:31,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741913_1089 src: /172.20.1.14:42118 dest: /172.20.1.15:9866
2025-03-26 02:24:31,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741913_1089 src: /172.20.1.15:38328 dest: /172.20.1.16:9866
2025-03-26 02:24:31,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741913_1089 src: /172.20.1.16:54186 dest: /172.20.1.17:9866
2025-03-26 02:24:31,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42118, dest: /172.20.1.15:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741913_1089, duration(ns): 3209210
2025-03-26 02:24:31,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38328, dest: /172.20.1.16:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741913_1089, duration(ns): 2638818
2025-03-26 02:24:31,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54186, dest: /172.20.1.17:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741913_1089, duration(ns): 2384867
2025-03-26 02:24:31,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741913_1089, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,831 INFO terminating
2025-03-26 02:24:31,832 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/regression_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,832 INFO terminating
2025-03-26 02:24:31,837 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/svm_with_sgd_example.py._COPYING_
2025-03-26 02:24:31,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741914_1090 src: /172.20.1.14:36496 dest: /172.20.1.17:9866
2025-03-26 02:24:31,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741914_1090 src: /172.20.1.17:59804 dest: /172.20.1.16:9866
2025-03-26 02:24:31,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741914_1090 src: /172.20.1.16:44638 dest: /172.20.1.15:9866
2025-03-26 02:24:31,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44638, dest: /172.20.1.15:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741914_1090, duration(ns): 1036840
2025-03-26 02:24:31,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59804, dest: /172.20.1.16:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741914_1090, duration(ns): 1288904
2025-03-26 02:24:31,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741914_1090, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,842 INFO terminating
2025-03-26 02:24:31,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36496, dest: /172.20.1.17:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741914_1090, duration(ns): 1507603
2025-03-26 02:24:31,843 INFO terminating
2025-03-26 02:24:31,846 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/svm_with_sgd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,851 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/normalizer_example.py._COPYING_
2025-03-26 02:24:31,851 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,851 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741915_1091 src: /172.20.1.14:42126 dest: /172.20.1.15:9866
2025-03-26 02:24:31,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741915_1091 src: /172.20.1.15:36098 dest: /172.20.1.17:9866
2025-03-26 02:24:31,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741915_1091 src: /172.20.1.17:59820 dest: /172.20.1.16:9866
2025-03-26 02:24:31,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59820, dest: /172.20.1.16:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741915_1091, duration(ns): 1964748
2025-03-26 02:24:31,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741915_1091, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42126, dest: /172.20.1.15:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741915_1091, duration(ns): 3662909
2025-03-26 02:24:31,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36098, dest: /172.20.1.17:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741915_1091, duration(ns): 2652678
2025-03-26 02:24:31,860 INFO terminating
2025-03-26 02:24:31,860 INFO terminating
2025-03-26 02:24:31,861 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/normalizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/random_rdd_generation.py._COPYING_
2025-03-26 02:24:31,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741916_1092 src: /172.20.1.14:36500 dest: /172.20.1.17:9866
2025-03-26 02:24:31,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741916_1092 src: /172.20.1.17:59836 dest: /172.20.1.16:9866
2025-03-26 02:24:31,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741916_1092 src: /172.20.1.16:44644 dest: /172.20.1.15:9866
2025-03-26 02:24:31,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44644, dest: /172.20.1.15:9866, bytes: 1905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741916_1092, duration(ns): 1071432
2025-03-26 02:24:31,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59836, dest: /172.20.1.16:9866, bytes: 1905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741916_1092, duration(ns): 1332240
2025-03-26 02:24:31,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741916_1092, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36500, dest: /172.20.1.17:9866, bytes: 1905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741916_1092, duration(ns): 1713956
2025-03-26 02:24:31,874 INFO terminating
2025-03-26 02:24:31,874 INFO terminating
2025-03-26 02:24:31,875 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_rdd_generation.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/mllib/sampled_rdds.py._COPYING_
2025-03-26 02:24:31,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741917_1093 src: /172.20.1.14:42130 dest: /172.20.1.15:9866
2025-03-26 02:24:31,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741917_1093 src: /172.20.1.15:36100 dest: /172.20.1.17:9866
2025-03-26 02:24:31,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741917_1093 src: /172.20.1.17:59844 dest: /172.20.1.16:9866
2025-03-26 02:24:31,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59844, dest: /172.20.1.16:9866, bytes: 3185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741917_1093, duration(ns): 1038804
2025-03-26 02:24:31,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741917_1093, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42130, dest: /172.20.1.15:9866, bytes: 3185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741917_1093, duration(ns): 1854781
2025-03-26 02:24:31,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36100, dest: /172.20.1.17:9866, bytes: 3185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741917_1093, duration(ns): 1422748
2025-03-26 02:24:31,888 INFO terminating
2025-03-26 02:24:31,888 INFO terminating
2025-03-26 02:24:31,889 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/sampled_rdds.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,893 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/mllib/elementwise_product_example.py._COPYING_
2025-03-26 02:24:31,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741918_1094 src: /172.20.1.14:36516 dest: /172.20.1.17:9866
2025-03-26 02:24:31,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741918_1094 src: /172.20.1.17:59848 dest: /172.20.1.16:9866
2025-03-26 02:24:31,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741918_1094 src: /172.20.1.16:44654 dest: /172.20.1.15:9866
2025-03-26 02:24:31,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44654, dest: /172.20.1.15:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741918_1094, duration(ns): 1131754
2025-03-26 02:24:31,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741918_1094, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59848, dest: /172.20.1.16:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741918_1094, duration(ns): 1743143
2025-03-26 02:24:31,902 INFO terminating
2025-03-26 02:24:31,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36516, dest: /172.20.1.17:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741918_1094, duration(ns): 4850365
2025-03-26 02:24:31,903 INFO terminating
2025-03-26 02:24:31,904 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/elementwise_product_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,909 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/__init__.py._COPYING_
2025-03-26 02:24:31,909 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,909 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741919_1095 src: /172.20.1.14:36532 dest: /172.20.1.17:9866
2025-03-26 02:24:31,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741919_1095 src: /172.20.1.17:38148 dest: /172.20.1.15:9866
2025-03-26 02:24:31,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741919_1095 src: /172.20.1.15:38342 dest: /172.20.1.16:9866
2025-03-26 02:24:31,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38342, dest: /172.20.1.16:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741919_1095, duration(ns): 1179285
2025-03-26 02:24:31,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38148, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741919_1095, duration(ns): 1599882
2025-03-26 02:24:31,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741919_1095, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,915 INFO terminating
2025-03-26 02:24:31,916 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36532, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741919_1095, duration(ns): 1889286
2025-03-26 02:24:31,916 INFO terminating
2025-03-26 02:24:31,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/pagerank.py._COPYING_
2025-03-26 02:24:31,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741920_1096 src: /172.20.1.14:46918 dest: /172.20.1.16:9866
2025-03-26 02:24:31,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741920_1096 src: /172.20.1.16:44664 dest: /172.20.1.15:9866
2025-03-26 02:24:31,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741920_1096 src: /172.20.1.15:36112 dest: /172.20.1.17:9866
2025-03-26 02:24:31,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36112, dest: /172.20.1.17:9866, bytes: 3339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741920_1096, duration(ns): 1208397
2025-03-26 02:24:31,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44664, dest: /172.20.1.15:9866, bytes: 3339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741920_1096, duration(ns): 1987675
2025-03-26 02:24:31,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741920_1096, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,929 INFO terminating
2025-03-26 02:24:31,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46918, dest: /172.20.1.16:9866, bytes: 3339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741920_1096, duration(ns): 2312363
2025-03-26 02:24:31,930 INFO terminating
2025-03-26 02:24:31,931 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/pagerank.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,945 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/fm_regressor_example.py._COPYING_
2025-03-26 02:24:31,945 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,945 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741921_1097 src: /172.20.1.14:42146 dest: /172.20.1.15:9866
2025-03-26 02:24:31,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741921_1097 src: /172.20.1.15:36118 dest: /172.20.1.17:9866
2025-03-26 02:24:31,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741921_1097 src: /172.20.1.17:59856 dest: /172.20.1.16:9866
2025-03-26 02:24:31,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36118, dest: /172.20.1.17:9866, bytes: 2559, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741921_1097, duration(ns): 1835881
2025-03-26 02:24:31,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59856, dest: /172.20.1.16:9866, bytes: 2559, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741921_1097, duration(ns): 1594664
2025-03-26 02:24:31,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741921_1097, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,952 INFO terminating
2025-03-26 02:24:31,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42146, dest: /172.20.1.15:9866, bytes: 2559, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741921_1097, duration(ns): 2350134
2025-03-26 02:24:31,953 INFO terminating
2025-03-26 02:24:31,954 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fm_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/string_indexer_example.py._COPYING_
2025-03-26 02:24:31,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741922_1098 src: /172.20.1.14:36534 dest: /172.20.1.17:9866
2025-03-26 02:24:31,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741922_1098 src: /172.20.1.17:59860 dest: /172.20.1.16:9866
2025-03-26 02:24:31,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741922_1098 src: /172.20.1.16:44676 dest: /172.20.1.15:9866
2025-03-26 02:24:31,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44676, dest: /172.20.1.15:9866, bytes: 1363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741922_1098, duration(ns): 1214929
2025-03-26 02:24:31,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59860, dest: /172.20.1.16:9866, bytes: 1363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741922_1098, duration(ns): 1515620
2025-03-26 02:24:31,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741922_1098, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,966 INFO terminating
2025-03-26 02:24:31,967 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/string_indexer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36534, dest: /172.20.1.17:9866, bytes: 1363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741922_1098, duration(ns): 1942616
2025-03-26 02:24:31,967 INFO terminating
2025-03-26 02:24:31,976 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/vector_assembler_example.py._COPYING_
2025-03-26 02:24:31,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741923_1099 src: /172.20.1.14:42158 dest: /172.20.1.15:9866
2025-03-26 02:24:31,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741923_1099 src: /172.20.1.15:38354 dest: /172.20.1.16:9866
2025-03-26 02:24:31,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741923_1099 src: /172.20.1.16:54196 dest: /172.20.1.17:9866
2025-03-26 02:24:31,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54196, dest: /172.20.1.17:9866, bytes: 1610, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741923_1099, duration(ns): 1095001
2025-03-26 02:24:31,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741923_1099, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42158, dest: /172.20.1.15:9866, bytes: 1610, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741923_1099, duration(ns): 1974977
2025-03-26 02:24:31,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38354, dest: /172.20.1.16:9866, bytes: 1610, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741923_1099, duration(ns): 1429639
2025-03-26 02:24:31,983 INFO terminating
2025-03-26 02:24:31,983 INFO terminating
2025-03-26 02:24:31,984 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_assembler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:31,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/robust_scaler_example.py._COPYING_
2025-03-26 02:24:31,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741924_1100 src: /172.20.1.14:46932 dest: /172.20.1.16:9866
2025-03-26 02:24:31,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741924_1100 src: /172.20.1.16:54210 dest: /172.20.1.17:9866
2025-03-26 02:24:31,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741924_1100 src: /172.20.1.17:38162 dest: /172.20.1.15:9866
2025-03-26 02:24:31,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38162, dest: /172.20.1.15:9866, bytes: 1600, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741924_1100, duration(ns): 1888549
2025-03-26 02:24:31,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741924_1100, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54210, dest: /172.20.1.17:9866, bytes: 1600, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741924_1100, duration(ns): 2123764
2025-03-26 02:24:31,996 INFO terminating
2025-03-26 02:24:31,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46932, dest: /172.20.1.16:9866, bytes: 1600, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741924_1100, duration(ns): 3415603
2025-03-26 02:24:31,997 INFO terminating
2025-03-26 02:24:31,998 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/robust_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,002 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_
2025-03-26 02:24:32,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741925_1101 src: /172.20.1.14:46940 dest: /172.20.1.16:9866
2025-03-26 02:24:32,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741925_1101 src: /172.20.1.16:54220 dest: /172.20.1.17:9866
2025-03-26 02:24:32,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741925_1101 src: /172.20.1.17:38178 dest: /172.20.1.15:9866
2025-03-26 02:24:32,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38178, dest: /172.20.1.15:9866, bytes: 2653, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741925_1101, duration(ns): 1202128
2025-03-26 02:24:32,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741925_1101, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54220, dest: /172.20.1.17:9866, bytes: 2653, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741925_1101, duration(ns): 1745403
2025-03-26 02:24:32,009 INFO terminating
2025-03-26 02:24:32,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46940, dest: /172.20.1.16:9866, bytes: 2653, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741925_1101, duration(ns): 2520272
2025-03-26 02:24:32,010 INFO terminating
2025-03-26 02:24:32,011 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,015 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/vector_indexer_example.py._COPYING_
2025-03-26 02:24:32,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741926_1102 src: /172.20.1.14:36542 dest: /172.20.1.17:9866
2025-03-26 02:24:32,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741926_1102 src: /172.20.1.17:59866 dest: /172.20.1.16:9866
2025-03-26 02:24:32,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741926_1102 src: /172.20.1.16:44690 dest: /172.20.1.15:9866
2025-03-26 02:24:32,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44690, dest: /172.20.1.15:9866, bytes: 1646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741926_1102, duration(ns): 1153813
2025-03-26 02:24:32,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741926_1102, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59866, dest: /172.20.1.16:9866, bytes: 1646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741926_1102, duration(ns): 1646745
2025-03-26 02:24:32,022 INFO terminating
2025-03-26 02:24:32,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36542, dest: /172.20.1.17:9866, bytes: 1646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741926_1102, duration(ns): 1814386
2025-03-26 02:24:32,023 INFO terminating
2025-03-26 02:24:32,024 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_indexer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,028 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/variance_threshold_selector_example.py._COPYING_
2025-03-26 02:24:32,028 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,028 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741927_1103 src: /172.20.1.14:42174 dest: /172.20.1.15:9866
2025-03-26 02:24:32,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741927_1103 src: /172.20.1.15:36120 dest: /172.20.1.17:9866
2025-03-26 02:24:32,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741927_1103 src: /172.20.1.17:59878 dest: /172.20.1.16:9866
2025-03-26 02:24:32,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59878, dest: /172.20.1.16:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741927_1103, duration(ns): 2027099
2025-03-26 02:24:32,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36120, dest: /172.20.1.17:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741927_1103, duration(ns): 2606460
2025-03-26 02:24:32,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741927_1103, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,035 INFO terminating
2025-03-26 02:24:32,036 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/variance_threshold_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42174, dest: /172.20.1.15:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741927_1103, duration(ns): 3435449
2025-03-26 02:24:32,036 INFO terminating
2025-03-26 02:24:32,040 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/feature_hasher_example.py._COPYING_
2025-03-26 02:24:32,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741928_1104 src: /172.20.1.14:42188 dest: /172.20.1.15:9866
2025-03-26 02:24:32,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741928_1104 src: /172.20.1.15:36124 dest: /172.20.1.17:9866
2025-03-26 02:24:32,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741928_1104 src: /172.20.1.17:59888 dest: /172.20.1.16:9866
2025-03-26 02:24:32,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59888, dest: /172.20.1.16:9866, bytes: 1521, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741928_1104, duration(ns): 1993103
2025-03-26 02:24:32,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741928_1104, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42188, dest: /172.20.1.15:9866, bytes: 1521, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741928_1104, duration(ns): 2243475
2025-03-26 02:24:32,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36124, dest: /172.20.1.17:9866, bytes: 1521, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741928_1104, duration(ns): 2430316
2025-03-26 02:24:32,049 INFO terminating
2025-03-26 02:24:32,049 INFO terminating
2025-03-26 02:24:32,051 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/feature_hasher_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,055 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_
2025-03-26 02:24:32,055 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,055 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741929_1105 src: /172.20.1.14:36556 dest: /172.20.1.17:9866
2025-03-26 02:24:32,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741929_1105 src: /172.20.1.17:59902 dest: /172.20.1.16:9866
2025-03-26 02:24:32,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741929_1105 src: /172.20.1.16:44698 dest: /172.20.1.15:9866
2025-03-26 02:24:32,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44698, dest: /172.20.1.15:9866, bytes: 1934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741929_1105, duration(ns): 1213137
2025-03-26 02:24:32,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59902, dest: /172.20.1.16:9866, bytes: 1934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741929_1105, duration(ns): 1424659
2025-03-26 02:24:32,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741929_1105, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,061 INFO terminating
2025-03-26 02:24:32,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36556, dest: /172.20.1.17:9866, bytes: 1934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741929_1105, duration(ns): 1933175
2025-03-26 02:24:32,062 INFO terminating
2025-03-26 02:24:32,063 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/tf_idf_example.py._COPYING_
2025-03-26 02:24:32,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741930_1106 src: /172.20.1.14:42190 dest: /172.20.1.15:9866
2025-03-26 02:24:32,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741930_1106 src: /172.20.1.15:36132 dest: /172.20.1.17:9866
2025-03-26 02:24:32,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741930_1106 src: /172.20.1.17:59910 dest: /172.20.1.16:9866
2025-03-26 02:24:32,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59910, dest: /172.20.1.16:9866, bytes: 1863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741930_1106, duration(ns): 1204735
2025-03-26 02:24:32,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741930_1106, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42190, dest: /172.20.1.15:9866, bytes: 1863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741930_1106, duration(ns): 2414243
2025-03-26 02:24:32,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36132, dest: /172.20.1.17:9866, bytes: 1863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741930_1106, duration(ns): 1894897
2025-03-26 02:24:32,074 INFO terminating
2025-03-26 02:24:32,074 INFO terminating
2025-03-26 02:24:32,075 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/tf_idf_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/stopwords_remover_example.py._COPYING_
2025-03-26 02:24:32,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741931_1107 src: /172.20.1.14:46944 dest: /172.20.1.16:9866
2025-03-26 02:24:32,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741931_1107 src: /172.20.1.16:54224 dest: /172.20.1.17:9866
2025-03-26 02:24:32,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741931_1107 src: /172.20.1.17:38188 dest: /172.20.1.15:9866
2025-03-26 02:24:32,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38188, dest: /172.20.1.15:9866, bytes: 1395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741931_1107, duration(ns): 1265400
2025-03-26 02:24:32,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741931_1107, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54224, dest: /172.20.1.17:9866, bytes: 1395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741931_1107, duration(ns): 3151315
2025-03-26 02:24:32,088 INFO terminating
2025-03-26 02:24:32,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46944, dest: /172.20.1.16:9866, bytes: 1395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741931_1107, duration(ns): 4028741
2025-03-26 02:24:32,089 INFO terminating
2025-03-26 02:24:32,090 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/stopwords_remover_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,095 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/cross_validator.py._COPYING_
2025-03-26 02:24:32,095 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,095 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741932_1108 src: /172.20.1.14:42194 dest: /172.20.1.15:9866
2025-03-26 02:24:32,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741932_1108 src: /172.20.1.15:38366 dest: /172.20.1.16:9866
2025-03-26 02:24:32,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741932_1108 src: /172.20.1.16:54240 dest: /172.20.1.17:9866
2025-03-26 02:24:32,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54240, dest: /172.20.1.17:9866, bytes: 3904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741932_1108, duration(ns): 1385173
2025-03-26 02:24:32,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741932_1108, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42194, dest: /172.20.1.15:9866, bytes: 3904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741932_1108, duration(ns): 2196662
2025-03-26 02:24:32,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38366, dest: /172.20.1.16:9866, bytes: 3904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741932_1108, duration(ns): 1708326
2025-03-26 02:24:32,102 INFO terminating
2025-03-26 02:24:32,102 INFO terminating
2025-03-26 02:24:32,103 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/cross_validator.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py._COPYING_
2025-03-26 02:24:32,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741933_1109 src: /172.20.1.14:36570 dest: /172.20.1.17:9866
2025-03-26 02:24:32,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741933_1109 src: /172.20.1.17:59926 dest: /172.20.1.16:9866
2025-03-26 02:24:32,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741933_1109 src: /172.20.1.16:44710 dest: /172.20.1.15:9866
2025-03-26 02:24:32,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44710, dest: /172.20.1.15:9866, bytes: 2950, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741933_1109, duration(ns): 1391892
2025-03-26 02:24:32,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741933_1109, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36570, dest: /172.20.1.17:9866, bytes: 2950, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741933_1109, duration(ns): 2234595
2025-03-26 02:24:32,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59926, dest: /172.20.1.16:9866, bytes: 2950, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741933_1109, duration(ns): 1794466
2025-03-26 02:24:32,116 INFO terminating
2025-03-26 02:24:32,117 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,117 INFO terminating
2025-03-26 02:24:32,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/bisecting_k_means_example.py._COPYING_
2025-03-26 02:24:32,121 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,121 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741934_1110 src: /172.20.1.14:42210 dest: /172.20.1.15:9866
2025-03-26 02:24:32,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741934_1110 src: /172.20.1.15:38382 dest: /172.20.1.16:9866
2025-03-26 02:24:32,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741934_1110 src: /172.20.1.16:54254 dest: /172.20.1.17:9866
2025-03-26 02:24:32,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38382, dest: /172.20.1.16:9866, bytes: 1953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741934_1110, duration(ns): 1597567
2025-03-26 02:24:32,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54254, dest: /172.20.1.17:9866, bytes: 1953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741934_1110, duration(ns): 1214893
2025-03-26 02:24:32,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741934_1110, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42210, dest: /172.20.1.15:9866, bytes: 1953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741934_1110, duration(ns): 2185071
2025-03-26 02:24:32,129 INFO terminating
2025-03-26 02:24:32,129 INFO terminating
2025-03-26 02:24:32,130 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bisecting_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/correlation_example.py._COPYING_
2025-03-26 02:24:32,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741935_1111 src: /172.20.1.14:46948 dest: /172.20.1.16:9866
2025-03-26 02:24:32,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741935_1111 src: /172.20.1.16:44714 dest: /172.20.1.15:9866
2025-03-26 02:24:32,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741935_1111 src: /172.20.1.15:36144 dest: /172.20.1.17:9866
2025-03-26 02:24:32,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36144, dest: /172.20.1.17:9866, bytes: 1885, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741935_1111, duration(ns): 1247491
2025-03-26 02:24:32,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46948, dest: /172.20.1.16:9866, bytes: 1885, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741935_1111, duration(ns): 2547430
2025-03-26 02:24:32,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44714, dest: /172.20.1.15:9866, bytes: 1885, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741935_1111, duration(ns): 2175441
2025-03-26 02:24:32,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741935_1111, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,146 INFO terminating
2025-03-26 02:24:32,147 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/correlation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,147 INFO terminating
2025-03-26 02:24:32,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/kmeans_example.py._COPYING_
2025-03-26 02:24:32,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741936_1112 src: /172.20.1.14:42222 dest: /172.20.1.15:9866
2025-03-26 02:24:32,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741936_1112 src: /172.20.1.15:38390 dest: /172.20.1.16:9866
2025-03-26 02:24:32,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741936_1112 src: /172.20.1.16:54264 dest: /172.20.1.17:9866
2025-03-26 02:24:32,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38390, dest: /172.20.1.16:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741936_1112, duration(ns): 1537713
2025-03-26 02:24:32,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54264, dest: /172.20.1.17:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741936_1112, duration(ns): 1195341
2025-03-26 02:24:32,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741936_1112, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42222, dest: /172.20.1.15:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741936_1112, duration(ns): 1988023
2025-03-26 02:24:32,160 INFO terminating
2025-03-26 02:24:32,160 INFO terminating
2025-03-26 02:24:32,161 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/kmeans_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,165 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py._COPYING_
2025-03-26 02:24:32,165 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,165 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741937_1113 src: /172.20.1.14:36584 dest: /172.20.1.17:9866
2025-03-26 02:24:32,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741937_1113 src: /172.20.1.17:38194 dest: /172.20.1.15:9866
2025-03-26 02:24:32,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741937_1113 src: /172.20.1.15:38406 dest: /172.20.1.16:9866
2025-03-26 02:24:32,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38406, dest: /172.20.1.16:9866, bytes: 2654, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741937_1113, duration(ns): 1526429
2025-03-26 02:24:32,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741937_1113, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36584, dest: /172.20.1.17:9866, bytes: 2654, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741937_1113, duration(ns): 2308685
2025-03-26 02:24:32,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38194, dest: /172.20.1.15:9866, bytes: 2654, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741937_1113, duration(ns): 1940906
2025-03-26 02:24:32,171 INFO terminating
2025-03-26 02:24:32,171 INFO terminating
2025-03-26 02:24:32,172 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/naive_bayes_example.py._COPYING_
2025-03-26 02:24:32,176 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,176 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741938_1114 src: /172.20.1.14:46960 dest: /172.20.1.16:9866
2025-03-26 02:24:32,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741938_1114 src: /172.20.1.16:54272 dest: /172.20.1.17:9866
2025-03-26 02:24:32,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741938_1114 src: /172.20.1.17:38200 dest: /172.20.1.15:9866
2025-03-26 02:24:32,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54272, dest: /172.20.1.17:9866, bytes: 1978, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741938_1114, duration(ns): 2244837
2025-03-26 02:24:32,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38200, dest: /172.20.1.15:9866, bytes: 1978, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741938_1114, duration(ns): 1659169
2025-03-26 02:24:32,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741938_1114, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,184 INFO terminating
2025-03-26 02:24:32,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46960, dest: /172.20.1.16:9866, bytes: 1978, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741938_1114, duration(ns): 2596034
2025-03-26 02:24:32,185 INFO terminating
2025-03-26 02:24:32,186 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/naive_bayes_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,192 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/count_vectorizer_example.py._COPYING_
2025-03-26 02:24:32,192 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,192 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741939_1115 src: /172.20.1.14:42224 dest: /172.20.1.15:9866
2025-03-26 02:24:32,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741939_1115 src: /172.20.1.15:36158 dest: /172.20.1.17:9866
2025-03-26 02:24:32,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741939_1115 src: /172.20.1.17:59934 dest: /172.20.1.16:9866
2025-03-26 02:24:32,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59934, dest: /172.20.1.16:9866, bytes: 1509, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741939_1115, duration(ns): 6733147
2025-03-26 02:24:32,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741939_1115, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42224, dest: /172.20.1.15:9866, bytes: 1509, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741939_1115, duration(ns): 7800415
2025-03-26 02:24:32,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36158, dest: /172.20.1.17:9866, bytes: 1509, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741939_1115, duration(ns): 7179766
2025-03-26 02:24:32,204 INFO terminating
2025-03-26 02:24:32,205 INFO terminating
2025-03-26 02:24:32,208 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/count_vectorizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/decision_tree_classification_example.py._COPYING_
2025-03-26 02:24:32,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741940_1116 src: /172.20.1.14:36596 dest: /172.20.1.17:9866
2025-03-26 02:24:32,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741940_1116 src: /172.20.1.17:38202 dest: /172.20.1.15:9866
2025-03-26 02:24:32,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741940_1116 src: /172.20.1.15:38416 dest: /172.20.1.16:9866
2025-03-26 02:24:32,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38416, dest: /172.20.1.16:9866, bytes: 2964, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741940_1116, duration(ns): 18740741
2025-03-26 02:24:32,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741940_1116, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38202, dest: /172.20.1.15:9866, bytes: 2964, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741940_1116, duration(ns): 20769244
2025-03-26 02:24:32,293 INFO terminating
2025-03-26 02:24:32,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36596, dest: /172.20.1.17:9866, bytes: 2964, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741940_1116, duration(ns): 21586453
2025-03-26 02:24:32,297 INFO terminating
2025-03-26 02:24:32,298 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/decision_tree_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/isotonic_regression_example.py._COPYING_
2025-03-26 02:24:32,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741941_1117 src: /172.20.1.14:42226 dest: /172.20.1.15:9866
2025-03-26 02:24:32,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741941_1117 src: /172.20.1.15:38420 dest: /172.20.1.16:9866
2025-03-26 02:24:32,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741941_1117 src: /172.20.1.16:54278 dest: /172.20.1.17:9866
2025-03-26 02:24:32,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54278, dest: /172.20.1.17:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741941_1117, duration(ns): 1369333
2025-03-26 02:24:32,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741941_1117, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38420, dest: /172.20.1.16:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741941_1117, duration(ns): 1817762
2025-03-26 02:24:32,311 INFO terminating
2025-03-26 02:24:32,312 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/isotonic_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42226, dest: /172.20.1.15:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741941_1117, duration(ns): 2996268
2025-03-26 02:24:32,312 INFO terminating
2025-03-26 02:24:32,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/sql_transformer.py._COPYING_
2025-03-26 02:24:32,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741942_1118 src: /172.20.1.14:46974 dest: /172.20.1.16:9866
2025-03-26 02:24:32,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741942_1118 src: /172.20.1.16:54280 dest: /172.20.1.17:9866
2025-03-26 02:24:32,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741942_1118 src: /172.20.1.17:38206 dest: /172.20.1.15:9866
2025-03-26 02:24:32,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38206, dest: /172.20.1.15:9866, bytes: 1343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741942_1118, duration(ns): 1310012
2025-03-26 02:24:32,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741942_1118, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46974, dest: /172.20.1.16:9866, bytes: 1343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741942_1118, duration(ns): 2035518
2025-03-26 02:24:32,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54280, dest: /172.20.1.17:9866, bytes: 1343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741942_1118, duration(ns): 1507572
2025-03-26 02:24:32,327 INFO terminating
2025-03-26 02:24:32,328 INFO terminating
2025-03-26 02:24:32,329 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/sql_transformer.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,334 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/polynomial_expansion_example.py._COPYING_
2025-03-26 02:24:32,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741943_1119 src: /172.20.1.14:42228 dest: /172.20.1.15:9866
2025-03-26 02:24:32,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741943_1119 src: /172.20.1.15:36172 dest: /172.20.1.17:9866
2025-03-26 02:24:32,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741943_1119 src: /172.20.1.17:59940 dest: /172.20.1.16:9866
2025-03-26 02:24:32,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59940, dest: /172.20.1.16:9866, bytes: 1483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741943_1119, duration(ns): 1438406
2025-03-26 02:24:32,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741943_1119, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36172, dest: /172.20.1.17:9866, bytes: 1483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741943_1119, duration(ns): 2116935
2025-03-26 02:24:32,341 INFO terminating
2025-03-26 02:24:32,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42228, dest: /172.20.1.15:9866, bytes: 1483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741943_1119, duration(ns): 3087358
2025-03-26 02:24:32,342 INFO terminating
2025-03-26 02:24:32,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/polynomial_expansion_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/bucketizer_example.py._COPYING_
2025-03-26 02:24:32,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741944_1120 src: /172.20.1.14:42232 dest: /172.20.1.15:9866
2025-03-26 02:24:32,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741944_1120 src: /172.20.1.15:36184 dest: /172.20.1.17:9866
2025-03-26 02:24:32,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741944_1120 src: /172.20.1.17:59946 dest: /172.20.1.16:9866
2025-03-26 02:24:32,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36184, dest: /172.20.1.17:9866, bytes: 1580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741944_1120, duration(ns): 1852787
2025-03-26 02:24:32,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59946, dest: /172.20.1.16:9866, bytes: 1580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741944_1120, duration(ns): 1478583
2025-03-26 02:24:32,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741944_1120, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,357 INFO terminating
2025-03-26 02:24:32,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42232, dest: /172.20.1.15:9866, bytes: 1580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741944_1120, duration(ns): 2419351
2025-03-26 02:24:32,358 INFO terminating
2025-03-26 02:24:32,360 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bucketizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,364 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/univariate_feature_selector_example.py._COPYING_
2025-03-26 02:24:32,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741945_1121 src: /172.20.1.14:42246 dest: /172.20.1.15:9866
2025-03-26 02:24:32,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741945_1121 src: /172.20.1.15:38436 dest: /172.20.1.16:9866
2025-03-26 02:24:32,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741945_1121 src: /172.20.1.16:54296 dest: /172.20.1.17:9866
2025-03-26 02:24:32,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54296, dest: /172.20.1.17:9866, bytes: 2243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741945_1121, duration(ns): 1565763
2025-03-26 02:24:32,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741945_1121, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42246, dest: /172.20.1.15:9866, bytes: 2243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741945_1121, duration(ns): 2947102
2025-03-26 02:24:32,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38436, dest: /172.20.1.16:9866, bytes: 2243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741945_1121, duration(ns): 2419840
2025-03-26 02:24:32,371 INFO terminating
2025-03-26 02:24:32,371 INFO terminating
2025-03-26 02:24:32,372 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/univariate_feature_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/power_iteration_clustering_example.py._COPYING_
2025-03-26 02:24:32,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741946_1122 src: /172.20.1.14:46976 dest: /172.20.1.16:9866
2025-03-26 02:24:32,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741946_1122 src: /172.20.1.16:44720 dest: /172.20.1.15:9866
2025-03-26 02:24:32,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741946_1122 src: /172.20.1.15:36198 dest: /172.20.1.17:9866
2025-03-26 02:24:32,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36198, dest: /172.20.1.17:9866, bytes: 1604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741946_1122, duration(ns): 1288265
2025-03-26 02:24:32,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44720, dest: /172.20.1.15:9866, bytes: 1604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741946_1122, duration(ns): 1695311
2025-03-26 02:24:32,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741946_1122, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,389 INFO terminating
2025-03-26 02:24:32,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46976, dest: /172.20.1.16:9866, bytes: 1604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741946_1122, duration(ns): 1998215
2025-03-26 02:24:32,390 INFO terminating
2025-03-26 02:24:32,391 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/power_iteration_clustering_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,395 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/als_example.py._COPYING_
2025-03-26 02:24:32,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741947_1123 src: /172.20.1.14:36600 dest: /172.20.1.17:9866
2025-03-26 02:24:32,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741947_1123 src: /172.20.1.17:59958 dest: /172.20.1.16:9866
2025-03-26 02:24:32,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741947_1123 src: /172.20.1.16:44732 dest: /172.20.1.15:9866
2025-03-26 02:24:32,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44732, dest: /172.20.1.15:9866, bytes: 2936, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741947_1123, duration(ns): 1133986
2025-03-26 02:24:32,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741947_1123, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36600, dest: /172.20.1.17:9866, bytes: 2936, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741947_1123, duration(ns): 1688657
2025-03-26 02:24:32,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59958, dest: /172.20.1.16:9866, bytes: 2936, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741947_1123, duration(ns): 1323045
2025-03-26 02:24:32,401 INFO terminating
2025-03-26 02:24:32,401 INFO terminating
2025-03-26 02:24:32,403 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/als_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/logistic_regression_summary_example.py._COPYING_
2025-03-26 02:24:32,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741948_1124 src: /172.20.1.14:46986 dest: /172.20.1.16:9866
2025-03-26 02:24:32,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741948_1124 src: /172.20.1.16:44740 dest: /172.20.1.15:9866
2025-03-26 02:24:32,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741948_1124 src: /172.20.1.15:36200 dest: /172.20.1.17:9866
2025-03-26 02:24:32,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36200, dest: /172.20.1.17:9866, bytes: 2402, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741948_1124, duration(ns): 1131694
2025-03-26 02:24:32,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741948_1124, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44740, dest: /172.20.1.15:9866, bytes: 2402, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741948_1124, duration(ns): 1572223
2025-03-26 02:24:32,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46986, dest: /172.20.1.16:9866, bytes: 2402, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741948_1124, duration(ns): 3140713
2025-03-26 02:24:32,414 INFO terminating
2025-03-26 02:24:32,415 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/logistic_regression_summary_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,415 INFO terminating
2025-03-26 02:24:32,425 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/summarizer_example.py._COPYING_
2025-03-26 02:24:32,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741949_1125 src: /172.20.1.14:46992 dest: /172.20.1.16:9866
2025-03-26 02:24:32,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741949_1125 src: /172.20.1.16:54308 dest: /172.20.1.17:9866
2025-03-26 02:24:32,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741949_1125 src: /172.20.1.17:38220 dest: /172.20.1.15:9866
2025-03-26 02:24:32,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38220, dest: /172.20.1.15:9866, bytes: 2121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741949_1125, duration(ns): 1533710
2025-03-26 02:24:32,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741949_1125, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54308, dest: /172.20.1.17:9866, bytes: 2121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741949_1125, duration(ns): 2580098
2025-03-26 02:24:32,432 INFO terminating
2025-03-26 02:24:32,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46992, dest: /172.20.1.16:9866, bytes: 2121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741949_1125, duration(ns): 3503931
2025-03-26 02:24:32,434 INFO terminating
2025-03-26 02:24:32,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/summarizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,440 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/vector_slicer_example.py._COPYING_
2025-03-26 02:24:32,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741950_1126 src: /172.20.1.14:46994 dest: /172.20.1.16:9866
2025-03-26 02:24:32,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741950_1126 src: /172.20.1.16:54314 dest: /172.20.1.17:9866
2025-03-26 02:24:32,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741950_1126 src: /172.20.1.17:38222 dest: /172.20.1.15:9866
2025-03-26 02:24:32,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38222, dest: /172.20.1.15:9866, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741950_1126, duration(ns): 1297063
2025-03-26 02:24:32,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741950_1126, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46994, dest: /172.20.1.16:9866, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741950_1126, duration(ns): 1893185
2025-03-26 02:24:32,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54314, dest: /172.20.1.17:9866, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741950_1126, duration(ns): 1461387
2025-03-26 02:24:32,446 INFO terminating
2025-03-26 02:24:32,446 INFO terminating
2025-03-26 02:24:32,447 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_slicer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,452 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/imputer_example.py._COPYING_
2025-03-26 02:24:32,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741951_1127 src: /172.20.1.14:46998 dest: /172.20.1.16:9866
2025-03-26 02:24:32,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741951_1127 src: /172.20.1.16:44746 dest: /172.20.1.15:9866
2025-03-26 02:24:32,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741951_1127 src: /172.20.1.15:36204 dest: /172.20.1.17:9866
2025-03-26 02:24:32,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36204, dest: /172.20.1.17:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741951_1127, duration(ns): 1704116
2025-03-26 02:24:32,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741951_1127, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44746, dest: /172.20.1.15:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741951_1127, duration(ns): 2108424
2025-03-26 02:24:32,459 INFO terminating
2025-03-26 02:24:32,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:46998, dest: /172.20.1.16:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741951_1127, duration(ns): 2729884
2025-03-26 02:24:32,460 INFO terminating
2025-03-26 02:24:32,462 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/imputer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/onehot_encoder_example.py._COPYING_
2025-03-26 02:24:32,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741952_1128 src: /172.20.1.14:42260 dest: /172.20.1.15:9866
2025-03-26 02:24:32,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741952_1128 src: /172.20.1.15:38440 dest: /172.20.1.16:9866
2025-03-26 02:24:32,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741952_1128 src: /172.20.1.16:54318 dest: /172.20.1.17:9866
2025-03-26 02:24:32,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54318, dest: /172.20.1.17:9866, bytes: 1599, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741952_1128, duration(ns): 1271469
2025-03-26 02:24:32,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741952_1128, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42260, dest: /172.20.1.15:9866, bytes: 1599, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741952_1128, duration(ns): 3269759
2025-03-26 02:24:32,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38440, dest: /172.20.1.16:9866, bytes: 1599, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741952_1128, duration(ns): 2436928
2025-03-26 02:24:32,475 INFO terminating
2025-03-26 02:24:32,475 INFO terminating
2025-03-26 02:24:32,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/onehot_encoder_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,483 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/linearsvc.py._COPYING_
2025-03-26 02:24:32,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741953_1129 src: /172.20.1.14:42268 dest: /172.20.1.15:9866
2025-03-26 02:24:32,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741953_1129 src: /172.20.1.15:36216 dest: /172.20.1.17:9866
2025-03-26 02:24:32,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741953_1129 src: /172.20.1.17:59964 dest: /172.20.1.16:9866
2025-03-26 02:24:32,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59964, dest: /172.20.1.16:9866, bytes: 1477, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741953_1129, duration(ns): 885509
2025-03-26 02:24:32,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741953_1129, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36216, dest: /172.20.1.17:9866, bytes: 1477, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741953_1129, duration(ns): 1330708
2025-03-26 02:24:32,489 INFO terminating
2025-03-26 02:24:32,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42268, dest: /172.20.1.15:9866, bytes: 1477, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741953_1129, duration(ns): 1994160
2025-03-26 02:24:32,490 INFO terminating
2025-03-26 02:24:32,491 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/linearsvc.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_
2025-03-26 02:24:32,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741954_1130 src: /172.20.1.14:47004 dest: /172.20.1.16:9866
2025-03-26 02:24:32,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741954_1130 src: /172.20.1.16:54334 dest: /172.20.1.17:9866
2025-03-26 02:24:32,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741954_1130 src: /172.20.1.17:38234 dest: /172.20.1.15:9866
2025-03-26 02:24:32,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54334, dest: /172.20.1.17:9866, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741954_1130, duration(ns): 1713143
2025-03-26 02:24:32,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38234, dest: /172.20.1.15:9866, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741954_1130, duration(ns): 1397289
2025-03-26 02:24:32,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741954_1130, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,505 INFO terminating
2025-03-26 02:24:32,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47004, dest: /172.20.1.16:9866, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741954_1130, duration(ns): 2204244
2025-03-26 02:24:32,506 INFO terminating
2025-03-26 02:24:32,507 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,511 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/fm_classifier_example.py._COPYING_
2025-03-26 02:24:32,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741955_1131 src: /172.20.1.14:36608 dest: /172.20.1.17:9866
2025-03-26 02:24:32,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741955_1131 src: /172.20.1.16:44752 dest: /172.20.1.15:9866
2025-03-26 02:24:32,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741955_1131 src: /172.20.1.17:59966 dest: /172.20.1.16:9866
2025-03-26 02:24:32,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44752, dest: /172.20.1.15:9866, bytes: 2855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741955_1131, duration(ns): 1260810
2025-03-26 02:24:32,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59966, dest: /172.20.1.16:9866, bytes: 2855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741955_1131, duration(ns): 1565607
2025-03-26 02:24:32,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741955_1131, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,517 INFO terminating
2025-03-26 02:24:32,518 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fm_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36608, dest: /172.20.1.17:9866, bytes: 2855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741955_1131, duration(ns): 2040579
2025-03-26 02:24:32,518 INFO terminating
2025-03-26 02:24:32,522 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/decision_tree_regression_example.py._COPYING_
2025-03-26 02:24:32,522 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,522 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741956_1132 src: /172.20.1.14:42272 dest: /172.20.1.15:9866
2025-03-26 02:24:32,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741956_1132 src: /172.20.1.15:36230 dest: /172.20.1.17:9866
2025-03-26 02:24:32,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741956_1132 src: /172.20.1.17:59972 dest: /172.20.1.16:9866
2025-03-26 02:24:32,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36230, dest: /172.20.1.17:9866, bytes: 2661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741956_1132, duration(ns): 1934720
2025-03-26 02:24:32,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59972, dest: /172.20.1.16:9866, bytes: 2661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741956_1132, duration(ns): 1572999
2025-03-26 02:24:32,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741956_1132, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42272, dest: /172.20.1.15:9866, bytes: 2661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741956_1132, duration(ns): 2426382
2025-03-26 02:24:32,529 INFO terminating
2025-03-26 02:24:32,529 INFO terminating
2025-03-26 02:24:32,530 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/decision_tree_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,536 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/word2vec_example.py._COPYING_
2025-03-26 02:24:32,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741957_1133 src: /172.20.1.14:47012 dest: /172.20.1.16:9866
2025-03-26 02:24:32,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741957_1133 src: /172.20.1.16:44756 dest: /172.20.1.15:9866
2025-03-26 02:24:32,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741957_1133 src: /172.20.1.15:36234 dest: /172.20.1.17:9866
2025-03-26 02:24:32,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36234, dest: /172.20.1.17:9866, bytes: 1737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741957_1133, duration(ns): 984773
2025-03-26 02:24:32,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741957_1133, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47012, dest: /172.20.1.16:9866, bytes: 1737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741957_1133, duration(ns): 1569605
2025-03-26 02:24:32,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44756, dest: /172.20.1.15:9866, bytes: 1737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741957_1133, duration(ns): 1345705
2025-03-26 02:24:32,542 INFO terminating
2025-03-26 02:24:32,542 INFO terminating
2025-03-26 02:24:32,543 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/word2vec_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,547 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,547 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/fpgrowth_example.py._COPYING_
2025-03-26 02:24:32,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741958_1134 src: /172.20.1.14:36622 dest: /172.20.1.17:9866
2025-03-26 02:24:32,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741958_1134 src: /172.20.1.17:59976 dest: /172.20.1.16:9866
2025-03-26 02:24:32,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741958_1134 src: /172.20.1.16:44762 dest: /172.20.1.15:9866
2025-03-26 02:24:32,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44762, dest: /172.20.1.15:9866, bytes: 1733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741958_1134, duration(ns): 1039056
2025-03-26 02:24:32,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59976, dest: /172.20.1.16:9866, bytes: 1733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741958_1134, duration(ns): 1297406
2025-03-26 02:24:32,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741958_1134, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,553 INFO terminating
2025-03-26 02:24:32,554 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fpgrowth_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36622, dest: /172.20.1.17:9866, bytes: 1733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741958_1134, duration(ns): 1698477
2025-03-26 02:24:32,554 INFO terminating
2025-03-26 02:24:32,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/pipeline_example.py._COPYING_
2025-03-26 02:24:32,558 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,558 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741959_1135 src: /172.20.1.14:47024 dest: /172.20.1.16:9866
2025-03-26 02:24:32,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741959_1135 src: /172.20.1.16:54350 dest: /172.20.1.17:9866
2025-03-26 02:24:32,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741959_1135 src: /172.20.1.17:38238 dest: /172.20.1.15:9866
2025-03-26 02:24:32,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38238, dest: /172.20.1.15:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741959_1135, duration(ns): 1092478
2025-03-26 02:24:32,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741959_1135, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47024, dest: /172.20.1.16:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741959_1135, duration(ns): 1570173
2025-03-26 02:24:32,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54350, dest: /172.20.1.17:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741959_1135, duration(ns): 1336305
2025-03-26 02:24:32,564 INFO terminating
2025-03-26 02:24:32,564 INFO terminating
2025-03-26 02:24:32,565 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/pipeline_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,569 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/logistic_regression_with_elastic_net.py._COPYING_
2025-03-26 02:24:32,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741960_1136 src: /172.20.1.14:47032 dest: /172.20.1.16:9866
2025-03-26 02:24:32,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741960_1136 src: /172.20.1.16:44768 dest: /172.20.1.15:9866
2025-03-26 02:24:32,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741960_1136 src: /172.20.1.15:36246 dest: /172.20.1.17:9866
2025-03-26 02:24:32,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36246, dest: /172.20.1.17:9866, bytes: 1990, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741960_1136, duration(ns): 956592
2025-03-26 02:24:32,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44768, dest: /172.20.1.15:9866, bytes: 1990, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741960_1136, duration(ns): 1411778
2025-03-26 02:24:32,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741960_1136, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,574 INFO terminating
2025-03-26 02:24:32,575 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/logistic_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47032, dest: /172.20.1.16:9866, bytes: 1990, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741960_1136, duration(ns): 1674837
2025-03-26 02:24:32,575 INFO terminating
2025-03-26 02:24:32,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/train_validation_split.py._COPYING_
2025-03-26 02:24:32,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741961_1137 src: /172.20.1.14:42274 dest: /172.20.1.15:9866
2025-03-26 02:24:32,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741961_1137 src: /172.20.1.15:36248 dest: /172.20.1.17:9866
2025-03-26 02:24:32,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741961_1137 src: /172.20.1.17:59984 dest: /172.20.1.16:9866
2025-03-26 02:24:32,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42274, dest: /172.20.1.15:9866, bytes: 2841, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741961_1137, duration(ns): 1611736
2025-03-26 02:24:32,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36248, dest: /172.20.1.17:9866, bytes: 2841, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741961_1137, duration(ns): 1189585
2025-03-26 02:24:32,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59984, dest: /172.20.1.16:9866, bytes: 2841, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741961_1137, duration(ns): 910355
2025-03-26 02:24:32,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741961_1137, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,584 INFO terminating
2025-03-26 02:24:32,584 INFO terminating
2025-03-26 02:24:32,586 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/train_validation_split.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,591 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/interaction_example.py._COPYING_
2025-03-26 02:24:32,591 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,591 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741962_1138 src: /172.20.1.14:36636 dest: /172.20.1.17:9866
2025-03-26 02:24:32,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741962_1138 src: /172.20.1.15:38456 dest: /172.20.1.16:9866
2025-03-26 02:24:32,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741962_1138 src: /172.20.1.17:38240 dest: /172.20.1.15:9866
2025-03-26 02:24:32,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38456, dest: /172.20.1.16:9866, bytes: 1868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741962_1138, duration(ns): 949085
2025-03-26 02:24:32,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38240, dest: /172.20.1.15:9866, bytes: 1868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741962_1138, duration(ns): 1308723
2025-03-26 02:24:32,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741962_1138, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36636, dest: /172.20.1.17:9866, bytes: 1868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741962_1138, duration(ns): 1527470
2025-03-26 02:24:32,597 INFO terminating
2025-03-26 02:24:32,597 INFO terminating
2025-03-26 02:24:32,600 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/interaction_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,603 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/random_forest_classifier_example.py._COPYING_
2025-03-26 02:24:32,603 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,603 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741963_1139 src: /172.20.1.14:36652 dest: /172.20.1.17:9866
2025-03-26 02:24:32,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741963_1139 src: /172.20.1.17:38256 dest: /172.20.1.15:9866
2025-03-26 02:24:32,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741963_1139 src: /172.20.1.15:38458 dest: /172.20.1.16:9866
2025-03-26 02:24:32,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38458, dest: /172.20.1.16:9866, bytes: 3195, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741963_1139, duration(ns): 870549
2025-03-26 02:24:32,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38256, dest: /172.20.1.15:9866, bytes: 3195, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741963_1139, duration(ns): 1214055
2025-03-26 02:24:32,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741963_1139, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,608 INFO terminating
2025-03-26 02:24:32,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36652, dest: /172.20.1.17:9866, bytes: 3195, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741963_1139, duration(ns): 1484127
2025-03-26 02:24:32,609 INFO terminating
2025-03-26 02:24:32,610 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/random_forest_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,614 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/quantile_discretizer_example.py._COPYING_
2025-03-26 02:24:32,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741964_1140 src: /172.20.1.14:42288 dest: /172.20.1.15:9866
2025-03-26 02:24:32,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741964_1140 src: /172.20.1.15:38474 dest: /172.20.1.16:9866
2025-03-26 02:24:32,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741964_1140 src: /172.20.1.16:54354 dest: /172.20.1.17:9866
2025-03-26 02:24:32,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38474, dest: /172.20.1.16:9866, bytes: 1668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741964_1140, duration(ns): 1280165
2025-03-26 02:24:32,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54354, dest: /172.20.1.17:9866, bytes: 1668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741964_1140, duration(ns): 956440
2025-03-26 02:24:32,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741964_1140, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,620 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/quantile_discretizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42288, dest: /172.20.1.15:9866, bytes: 1668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741964_1140, duration(ns): 1683497
2025-03-26 02:24:32,620 INFO terminating
2025-03-26 02:24:32,620 INFO terminating
2025-03-26 02:24:32,625 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/aft_survival_regression.py._COPYING_
2025-03-26 02:24:32,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741965_1141 src: /172.20.1.14:42300 dest: /172.20.1.15:9866
2025-03-26 02:24:32,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741965_1141 src: /172.20.1.15:36250 dest: /172.20.1.17:9866
2025-03-26 02:24:32,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741965_1141 src: /172.20.1.17:59986 dest: /172.20.1.16:9866
2025-03-26 02:24:32,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59986, dest: /172.20.1.16:9866, bytes: 2112, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741965_1141, duration(ns): 573423
2025-03-26 02:24:32,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741965_1141, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42300, dest: /172.20.1.15:9866, bytes: 2112, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741965_1141, duration(ns): 2984799
2025-03-26 02:24:32,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36250, dest: /172.20.1.17:9866, bytes: 2112, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741965_1141, duration(ns): 2115469
2025-03-26 02:24:32,632 INFO terminating
2025-03-26 02:24:32,632 INFO terminating
2025-03-26 02:24:32,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/aft_survival_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,637 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/estimator_transformer_param_example.py._COPYING_
2025-03-26 02:24:32,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,637 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741966_1142 src: /172.20.1.14:47036 dest: /172.20.1.16:9866
2025-03-26 02:24:32,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741966_1142 src: /172.20.1.16:54356 dest: /172.20.1.17:9866
2025-03-26 02:24:32,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741966_1142 src: /172.20.1.17:38272 dest: /172.20.1.15:9866
2025-03-26 02:24:32,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54356, dest: /172.20.1.17:9866, bytes: 3951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741966_1142, duration(ns): 3508113
2025-03-26 02:24:32,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38272, dest: /172.20.1.15:9866, bytes: 3951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741966_1142, duration(ns): 3028047
2025-03-26 02:24:32,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741966_1142, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,645 INFO terminating
2025-03-26 02:24:32,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47036, dest: /172.20.1.16:9866, bytes: 3951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741966_1142, duration(ns): 3955542
2025-03-26 02:24:32,646 INFO terminating
2025-03-26 02:24:32,647 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/estimator_transformer_param_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/__init__,py._COPYING_
2025-03-26 02:24:32,654 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,654 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741967_1143 src: /172.20.1.14:47046 dest: /172.20.1.16:9866
2025-03-26 02:24:32,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741967_1143 src: /172.20.1.16:54362 dest: /172.20.1.17:9866
2025-03-26 02:24:32,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741967_1143 src: /172.20.1.17:38284 dest: /172.20.1.15:9866
2025-03-26 02:24:32,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38284, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741967_1143, duration(ns): 997671
2025-03-26 02:24:32,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741967_1143, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54362, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741967_1143, duration(ns): 1170872
2025-03-26 02:24:32,659 INFO terminating
2025-03-26 02:24:32,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47046, dest: /172.20.1.16:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741967_1143, duration(ns): 1546352
2025-03-26 02:24:32,660 INFO terminating
2025-03-26 02:24:32,661 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/__init__,py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,664 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/chi_square_test_example.py._COPYING_
2025-03-26 02:24:32,664 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,664 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741968_1144 src: /172.20.1.14:36658 dest: /172.20.1.17:9866
2025-03-26 02:24:32,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741968_1144 src: /172.20.1.16:44770 dest: /172.20.1.15:9866
2025-03-26 02:24:32,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741968_1144 src: /172.20.1.17:59998 dest: /172.20.1.16:9866
2025-03-26 02:24:32,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44770, dest: /172.20.1.15:9866, bytes: 1869, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741968_1144, duration(ns): 1007272
2025-03-26 02:24:32,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741968_1144, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:59998, dest: /172.20.1.16:9866, bytes: 1869, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741968_1144, duration(ns): 1538883
2025-03-26 02:24:32,674 INFO terminating
2025-03-26 02:24:32,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36658, dest: /172.20.1.17:9866, bytes: 1869, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741968_1144, duration(ns): 5850425
2025-03-26 02:24:32,675 INFO terminating
2025-03-26 02:24:32,676 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/chi_square_test_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,682 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/multilayer_perceptron_classification.py._COPYING_
2025-03-26 02:24:32,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741969_1145 src: /172.20.1.14:42316 dest: /172.20.1.15:9866
2025-03-26 02:24:32,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741969_1145 src: /172.20.1.15:38484 dest: /172.20.1.16:9866
2025-03-26 02:24:32,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741969_1145 src: /172.20.1.16:54376 dest: /172.20.1.17:9866
2025-03-26 02:24:32,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54376, dest: /172.20.1.17:9866, bytes: 2133, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741969_1145, duration(ns): 1242769
2025-03-26 02:24:32,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741969_1145, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42316, dest: /172.20.1.15:9866, bytes: 2133, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741969_1145, duration(ns): 1991008
2025-03-26 02:24:32,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38484, dest: /172.20.1.16:9866, bytes: 2133, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741969_1145, duration(ns): 1542180
2025-03-26 02:24:32,688 INFO terminating
2025-03-26 02:24:32,688 INFO terminating
2025-03-26 02:24:32,689 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/multilayer_perceptron_classification.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,696 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/dataframe_example.py._COPYING_
2025-03-26 02:24:32,696 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,696 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741970_1146 src: /172.20.1.14:36662 dest: /172.20.1.17:9866
2025-03-26 02:24:32,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741970_1146 src: /172.20.1.17:38298 dest: /172.20.1.15:9866
2025-03-26 02:24:32,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741970_1146 src: /172.20.1.15:38494 dest: /172.20.1.16:9866
2025-03-26 02:24:32,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38494, dest: /172.20.1.16:9866, bytes: 2663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741970_1146, duration(ns): 999456
2025-03-26 02:24:32,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38298, dest: /172.20.1.15:9866, bytes: 2663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741970_1146, duration(ns): 1680331
2025-03-26 02:24:32,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741970_1146, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,702 INFO terminating
2025-03-26 02:24:32,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36662, dest: /172.20.1.17:9866, bytes: 2663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741970_1146, duration(ns): 1900728
2025-03-26 02:24:32,705 INFO terminating
2025-03-26 02:24:32,706 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/dataframe_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,712 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,712 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,713 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/prefixspan_example.py._COPYING_
2025-03-26 02:24:32,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741971_1147 src: /172.20.1.14:36670 dest: /172.20.1.17:9866
2025-03-26 02:24:32,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741971_1147 src: /172.20.1.17:60000 dest: /172.20.1.16:9866
2025-03-26 02:24:32,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741971_1147 src: /172.20.1.16:44784 dest: /172.20.1.15:9866
2025-03-26 02:24:32,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44784, dest: /172.20.1.15:9866, bytes: 1685, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741971_1147, duration(ns): 1257059
2025-03-26 02:24:32,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60000, dest: /172.20.1.16:9866, bytes: 1685, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741971_1147, duration(ns): 1434041
2025-03-26 02:24:32,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741971_1147, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,718 INFO terminating
2025-03-26 02:24:32,719 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/prefixspan_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36670, dest: /172.20.1.17:9866, bytes: 1685, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741971_1147, duration(ns): 1750881
2025-03-26 02:24:32,719 INFO terminating
2025-03-26 02:24:32,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/index_to_string_example.py._COPYING_
2025-03-26 02:24:32,724 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,724 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741972_1148 src: /172.20.1.14:47060 dest: /172.20.1.16:9866
2025-03-26 02:24:32,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741972_1148 src: /172.20.1.16:54386 dest: /172.20.1.17:9866
2025-03-26 02:24:32,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741972_1148 src: /172.20.1.17:38300 dest: /172.20.1.15:9866
2025-03-26 02:24:32,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47060, dest: /172.20.1.16:9866, bytes: 1975, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741972_1148, duration(ns): 1541264
2025-03-26 02:24:32,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54386, dest: /172.20.1.17:9866, bytes: 1975, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741972_1148, duration(ns): 1188918
2025-03-26 02:24:32,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38300, dest: /172.20.1.15:9866, bytes: 1975, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741972_1148, duration(ns): 1024990
2025-03-26 02:24:32,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741972_1148, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,730 INFO terminating
2025-03-26 02:24:32,731 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/index_to_string_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,731 INFO terminating
2025-03-26 02:24:32,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/one_vs_rest_example.py._COPYING_
2025-03-26 02:24:32,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741973_1149 src: /172.20.1.14:47064 dest: /172.20.1.16:9866
2025-03-26 02:24:32,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741973_1149 src: /172.20.1.16:44800 dest: /172.20.1.15:9866
2025-03-26 02:24:32,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741973_1149 src: /172.20.1.15:36266 dest: /172.20.1.17:9866
2025-03-26 02:24:32,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36266, dest: /172.20.1.17:9866, bytes: 2197, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741973_1149, duration(ns): 1042899
2025-03-26 02:24:32,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741973_1149, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47064, dest: /172.20.1.16:9866, bytes: 2197, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741973_1149, duration(ns): 1622525
2025-03-26 02:24:32,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44800, dest: /172.20.1.15:9866, bytes: 2197, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741973_1149, duration(ns): 1394583
2025-03-26 02:24:32,740 INFO terminating
2025-03-26 02:24:32,740 INFO terminating
2025-03-26 02:24:32,741 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/one_vs_rest_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,745 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/chisq_selector_example.py._COPYING_
2025-03-26 02:24:32,745 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,745 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741974_1150 src: /172.20.1.14:42320 dest: /172.20.1.15:9866
2025-03-26 02:24:32,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741974_1150 src: /172.20.1.15:36276 dest: /172.20.1.17:9866
2025-03-26 02:24:32,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741974_1150 src: /172.20.1.17:60010 dest: /172.20.1.16:9866
2025-03-26 02:24:32,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36276, dest: /172.20.1.17:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741974_1150, duration(ns): 1173099
2025-03-26 02:24:32,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60010, dest: /172.20.1.16:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741974_1150, duration(ns): 891495
2025-03-26 02:24:32,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741974_1150, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,751 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/chisq_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42320, dest: /172.20.1.15:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741974_1150, duration(ns): 1580417
2025-03-26 02:24:32,751 INFO terminating
2025-03-26 02:24:32,751 INFO terminating
2025-03-26 02:24:32,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/gaussian_mixture_example.py._COPYING_
2025-03-26 02:24:32,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741975_1151 src: /172.20.1.14:36680 dest: /172.20.1.17:9866
2025-03-26 02:24:32,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741975_1151 src: /172.20.1.17:60022 dest: /172.20.1.16:9866
2025-03-26 02:24:32,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741975_1151 src: /172.20.1.16:44804 dest: /172.20.1.15:9866
2025-03-26 02:24:32,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44804, dest: /172.20.1.15:9866, bytes: 1530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741975_1151, duration(ns): 996954
2025-03-26 02:24:32,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60022, dest: /172.20.1.16:9866, bytes: 1530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741975_1151, duration(ns): 1169125
2025-03-26 02:24:32,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741975_1151, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,761 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gaussian_mixture_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36680, dest: /172.20.1.17:9866, bytes: 1530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741975_1151, duration(ns): 1512212
2025-03-26 02:24:32,761 INFO terminating
2025-03-26 02:24:32,761 INFO terminating
2025-03-26 02:24:32,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/pca_example.py._COPYING_
2025-03-26 02:24:32,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741976_1152 src: /172.20.1.14:47066 dest: /172.20.1.16:9866
2025-03-26 02:24:32,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741976_1152 src: /172.20.1.16:54396 dest: /172.20.1.17:9866
2025-03-26 02:24:32,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741976_1152 src: /172.20.1.17:38308 dest: /172.20.1.15:9866
2025-03-26 02:24:32,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54396, dest: /172.20.1.17:9866, bytes: 1510, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741976_1152, duration(ns): 1176132
2025-03-26 02:24:32,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38308, dest: /172.20.1.15:9866, bytes: 1510, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741976_1152, duration(ns): 956307
2025-03-26 02:24:32,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741976_1152, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,772 INFO terminating
2025-03-26 02:24:32,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/pca_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47066, dest: /172.20.1.16:9866, bytes: 1510, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741976_1152, duration(ns): 1525215
2025-03-26 02:24:32,773 INFO terminating
2025-03-26 02:24:32,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,778 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1153, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/generalized_linear_regression_example.py._COPYING_
2025-03-26 02:24:32,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741977_1153 src: /172.20.1.14:47072 dest: /172.20.1.16:9866
2025-03-26 02:24:32,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741977_1153 src: /172.20.1.16:54402 dest: /172.20.1.17:9866
2025-03-26 02:24:32,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741977_1153 src: /172.20.1.17:38318 dest: /172.20.1.15:9866
2025-03-26 02:24:32,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38318, dest: /172.20.1.15:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741977_1153, duration(ns): 1217121
2025-03-26 02:24:32,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741977_1153, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54402, dest: /172.20.1.17:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741977_1153, duration(ns): 1416948
2025-03-26 02:24:32,783 INFO terminating
2025-03-26 02:24:32,784 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/generalized_linear_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47072, dest: /172.20.1.16:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741977_1153, duration(ns): 2189055
2025-03-26 02:24:32,784 INFO terminating
2025-03-26 02:24:32,792 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1154, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/lda_example.py._COPYING_
2025-03-26 02:24:32,792 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,792 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741978_1154 src: /172.20.1.14:47088 dest: /172.20.1.16:9866
2025-03-26 02:24:32,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741978_1154 src: /172.20.1.16:44812 dest: /172.20.1.15:9866
2025-03-26 02:24:32,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741978_1154 src: /172.20.1.15:36286 dest: /172.20.1.17:9866
2025-03-26 02:24:32,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36286, dest: /172.20.1.17:9866, bytes: 1859, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741978_1154, duration(ns): 1071999
2025-03-26 02:24:32,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44812, dest: /172.20.1.15:9866, bytes: 1859, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741978_1154, duration(ns): 1476401
2025-03-26 02:24:32,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741978_1154, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,797 INFO terminating
2025-03-26 02:24:32,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47088, dest: /172.20.1.16:9866, bytes: 1859, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741978_1154, duration(ns): 1734945
2025-03-26 02:24:32,798 INFO terminating
2025-03-26 02:24:32,799 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/lda_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,806 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1155, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/min_max_scaler_example.py._COPYING_
2025-03-26 02:24:32,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741979_1155 src: /172.20.1.14:47104 dest: /172.20.1.16:9866
2025-03-26 02:24:32,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741979_1155 src: /172.20.1.16:54406 dest: /172.20.1.17:9866
2025-03-26 02:24:32,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741979_1155 src: /172.20.1.17:38322 dest: /172.20.1.15:9866
2025-03-26 02:24:32,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38322, dest: /172.20.1.15:9866, bytes: 1759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741979_1155, duration(ns): 1133404
2025-03-26 02:24:32,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741979_1155, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54406, dest: /172.20.1.17:9866, bytes: 1759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741979_1155, duration(ns): 1514998
2025-03-26 02:24:32,813 INFO terminating
2025-03-26 02:24:32,814 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/min_max_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47104, dest: /172.20.1.16:9866, bytes: 1759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741979_1155, duration(ns): 2238109
2025-03-26 02:24:32,814 INFO terminating
2025-03-26 02:24:32,819 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1156, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_
2025-03-26 02:24:32,819 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,819 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741980_1156 src: /172.20.1.14:36696 dest: /172.20.1.17:9866
2025-03-26 02:24:32,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741980_1156 src: /172.20.1.17:38324 dest: /172.20.1.15:9866
2025-03-26 02:24:32,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741980_1156 src: /172.20.1.15:38496 dest: /172.20.1.16:9866
2025-03-26 02:24:32,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38496, dest: /172.20.1.16:9866, bytes: 3199, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741980_1156, duration(ns): 969012
2025-03-26 02:24:32,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36696, dest: /172.20.1.17:9866, bytes: 3199, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741980_1156, duration(ns): 1575946
2025-03-26 02:24:32,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38324, dest: /172.20.1.15:9866, bytes: 3199, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741980_1156, duration(ns): 1315064
2025-03-26 02:24:32,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741980_1156, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,824 INFO terminating
2025-03-26 02:24:32,824 INFO terminating
2025-03-26 02:24:32,825 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1157, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/standard_scaler_example.py._COPYING_
2025-03-26 02:24:32,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741981_1157 src: /172.20.1.14:36710 dest: /172.20.1.17:9866
2025-03-26 02:24:32,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741981_1157 src: /172.20.1.15:38502 dest: /172.20.1.16:9866
2025-03-26 02:24:32,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741981_1157 src: /172.20.1.17:38336 dest: /172.20.1.15:9866
2025-03-26 02:24:32,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38502, dest: /172.20.1.16:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741981_1157, duration(ns): 1348864
2025-03-26 02:24:32,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38336, dest: /172.20.1.15:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741981_1157, duration(ns): 1739719
2025-03-26 02:24:32,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741981_1157, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,836 INFO terminating
2025-03-26 02:24:32,837 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/standard_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36710, dest: /172.20.1.17:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741981_1157, duration(ns): 2409262
2025-03-26 02:24:32,837 INFO terminating
2025-03-26 02:24:32,841 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1158, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/tokenizer_example.py._COPYING_
2025-03-26 02:24:32,841 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,841 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741982_1158 src: /172.20.1.14:47114 dest: /172.20.1.16:9866
2025-03-26 02:24:32,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741982_1158 src: /172.20.1.16:54414 dest: /172.20.1.17:9866
2025-03-26 02:24:32,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741982_1158 src: /172.20.1.17:38342 dest: /172.20.1.15:9866
2025-03-26 02:24:32,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54414, dest: /172.20.1.17:9866, bytes: 2044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741982_1158, duration(ns): 1306687
2025-03-26 02:24:32,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38342, dest: /172.20.1.15:9866, bytes: 2044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741982_1158, duration(ns): 1124623
2025-03-26 02:24:32,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741982_1158, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47114, dest: /172.20.1.16:9866, bytes: 2044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741982_1158, duration(ns): 2158408
2025-03-26 02:24:32,851 INFO terminating
2025-03-26 02:24:32,851 INFO terminating
2025-03-26 02:24:32,852 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/tokenizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1159, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/rformula_example.py._COPYING_
2025-03-26 02:24:32,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741983_1159 src: /172.20.1.14:36712 dest: /172.20.1.17:9866
2025-03-26 02:24:32,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741983_1159 src: /172.20.1.16:44828 dest: /172.20.1.15:9866
2025-03-26 02:24:32,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741983_1159 src: /172.20.1.17:60028 dest: /172.20.1.16:9866
2025-03-26 02:24:32,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44828, dest: /172.20.1.15:9866, bytes: 1481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741983_1159, duration(ns): 912753
2025-03-26 02:24:32,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60028, dest: /172.20.1.16:9866, bytes: 1481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741983_1159, duration(ns): 1114318
2025-03-26 02:24:32,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741983_1159, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,860 INFO terminating
2025-03-26 02:24:32,861 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/rformula_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36712, dest: /172.20.1.17:9866, bytes: 1481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741983_1159, duration(ns): 1463260
2025-03-26 02:24:32,861 INFO terminating
2025-03-26 02:24:32,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1160, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/normalizer_example.py._COPYING_
2025-03-26 02:24:32,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741984_1160 src: /172.20.1.14:36720 dest: /172.20.1.17:9866
2025-03-26 02:24:32,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741984_1160 src: /172.20.1.17:38348 dest: /172.20.1.15:9866
2025-03-26 02:24:32,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741984_1160 src: /172.20.1.15:38504 dest: /172.20.1.16:9866
2025-03-26 02:24:32,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38504, dest: /172.20.1.16:9866, bytes: 1768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741984_1160, duration(ns): 880121
2025-03-26 02:24:32,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38348, dest: /172.20.1.15:9866, bytes: 1768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741984_1160, duration(ns): 1265601
2025-03-26 02:24:32,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741984_1160, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,870 INFO terminating
2025-03-26 02:24:32,871 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/normalizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36720, dest: /172.20.1.17:9866, bytes: 1768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741984_1160, duration(ns): 1836124
2025-03-26 02:24:32,871 INFO terminating
2025-03-26 02:24:32,898 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1161, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/n_gram_example.py._COPYING_
2025-03-26 02:24:32,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741985_1161 src: /172.20.1.14:36724 dest: /172.20.1.17:9866
2025-03-26 02:24:32,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741985_1161 src: /172.20.1.17:60042 dest: /172.20.1.16:9866
2025-03-26 02:24:32,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741985_1161 src: /172.20.1.16:44836 dest: /172.20.1.15:9866
2025-03-26 02:24:32,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44836, dest: /172.20.1.15:9866, bytes: 1506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741985_1161, duration(ns): 3333122
2025-03-26 02:24:32,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741985_1161, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60042, dest: /172.20.1.16:9866, bytes: 1506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741985_1161, duration(ns): 3664241
2025-03-26 02:24:32,910 INFO terminating
2025-03-26 02:24:32,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36724, dest: /172.20.1.17:9866, bytes: 1506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741985_1161, duration(ns): 4813694
2025-03-26 02:24:32,911 INFO terminating
2025-03-26 02:24:32,913 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/n_gram_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,923 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1162, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/dct_example.py._COPYING_
2025-03-26 02:24:32,923 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,923 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741986_1162 src: /172.20.1.14:47124 dest: /172.20.1.16:9866
2025-03-26 02:24:32,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741986_1162 src: /172.20.1.15:36296 dest: /172.20.1.17:9866
2025-03-26 02:24:32,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741986_1162 src: /172.20.1.16:44848 dest: /172.20.1.15:9866
2025-03-26 02:24:32,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36296, dest: /172.20.1.17:9866, bytes: 1470, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741986_1162, duration(ns): 1173639
2025-03-26 02:24:32,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741986_1162, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47124, dest: /172.20.1.16:9866, bytes: 1470, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741986_1162, duration(ns): 1770261
2025-03-26 02:24:32,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44848, dest: /172.20.1.15:9866, bytes: 1470, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741986_1162, duration(ns): 1567796
2025-03-26 02:24:32,929 INFO terminating
2025-03-26 02:24:32,929 INFO terminating
2025-03-26 02:24:32,930 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/dct_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,934 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1163, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/min_hash_lsh_example.py._COPYING_
2025-03-26 02:24:32,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741987_1163 src: /172.20.1.14:42328 dest: /172.20.1.15:9866
2025-03-26 02:24:32,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741987_1163 src: /172.20.1.15:36312 dest: /172.20.1.17:9866
2025-03-26 02:24:32,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741987_1163 src: /172.20.1.17:60050 dest: /172.20.1.16:9866
2025-03-26 02:24:32,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60050, dest: /172.20.1.16:9866, bytes: 3183, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741987_1163, duration(ns): 1397691
2025-03-26 02:24:32,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741987_1163, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42328, dest: /172.20.1.15:9866, bytes: 3183, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741987_1163, duration(ns): 2183504
2025-03-26 02:24:32,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36312, dest: /172.20.1.17:9866, bytes: 3183, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741987_1163, duration(ns): 1723183
2025-03-26 02:24:32,940 INFO terminating
2025-03-26 02:24:32,940 INFO terminating
2025-03-26 02:24:32,942 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/min_hash_lsh_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1164, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py._COPYING_
2025-03-26 02:24:32,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741988_1164 src: /172.20.1.14:42336 dest: /172.20.1.15:9866
2025-03-26 02:24:32,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741988_1164 src: /172.20.1.15:36314 dest: /172.20.1.17:9866
2025-03-26 02:24:32,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741988_1164 src: /172.20.1.17:60062 dest: /172.20.1.16:9866
2025-03-26 02:24:32,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42336, dest: /172.20.1.15:9866, bytes: 3128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741988_1164, duration(ns): 2224683
2025-03-26 02:24:32,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36314, dest: /172.20.1.17:9866, bytes: 3128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741988_1164, duration(ns): 1700137
2025-03-26 02:24:32,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60062, dest: /172.20.1.16:9866, bytes: 3128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741988_1164, duration(ns): 1408926
2025-03-26 02:24:32,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741988_1164, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,953 INFO terminating
2025-03-26 02:24:32,954 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,954 INFO terminating
2025-03-26 02:24:32,958 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1165, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/ml/binarizer_example.py._COPYING_
2025-03-26 02:24:32,958 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,958 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741989_1165 src: /172.20.1.14:47134 dest: /172.20.1.16:9866
2025-03-26 02:24:32,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741989_1165 src: /172.20.1.16:44860 dest: /172.20.1.15:9866
2025-03-26 02:24:32,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741989_1165 src: /172.20.1.15:36330 dest: /172.20.1.17:9866
2025-03-26 02:24:32,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36330, dest: /172.20.1.17:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741989_1165, duration(ns): 1101795
2025-03-26 02:24:32,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44860, dest: /172.20.1.15:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741989_1165, duration(ns): 1538298
2025-03-26 02:24:32,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741989_1165, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,965 INFO terminating
2025-03-26 02:24:32,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/binarizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47134, dest: /172.20.1.16:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741989_1165, duration(ns): 1645415
2025-03-26 02:24:32,966 INFO terminating
2025-03-26 02:24:32,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1166, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/ml/elementwise_product_example.py._COPYING_
2025-03-26 02:24:32,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741990_1166 src: /172.20.1.14:47146 dest: /172.20.1.16:9866
2025-03-26 02:24:32,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741990_1166 src: /172.20.1.16:54430 dest: /172.20.1.17:9866
2025-03-26 02:24:32,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741990_1166 src: /172.20.1.17:38352 dest: /172.20.1.15:9866
2025-03-26 02:24:32,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54430, dest: /172.20.1.17:9866, bytes: 1593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741990_1166, duration(ns): 3032455
2025-03-26 02:24:32,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38352, dest: /172.20.1.15:9866, bytes: 1593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741990_1166, duration(ns): 1122957
2025-03-26 02:24:32,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741990_1166, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,977 INFO terminating
2025-03-26 02:24:32,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47146, dest: /172.20.1.16:9866, bytes: 1593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741990_1166, duration(ns): 3380705
2025-03-26 02:24:32,978 INFO terminating
2025-03-26 02:24:32,979 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/elementwise_product_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1167, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/ml/max_abs_scaler_example.py._COPYING_
2025-03-26 02:24:32,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741991_1167 src: /172.20.1.14:36738 dest: /172.20.1.17:9866
2025-03-26 02:24:32,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741991_1167 src: /172.20.1.15:38516 dest: /172.20.1.16:9866
2025-03-26 02:24:32,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741991_1167 src: /172.20.1.17:38368 dest: /172.20.1.15:9866
2025-03-26 02:24:32,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38516, dest: /172.20.1.16:9866, bytes: 1673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741991_1167, duration(ns): 905162
2025-03-26 02:24:32,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38368, dest: /172.20.1.15:9866, bytes: 1673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741991_1167, duration(ns): 1379587
2025-03-26 02:24:32,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741991_1167, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:32,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36738, dest: /172.20.1.17:9866, bytes: 1673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741991_1167, duration(ns): 1606371
2025-03-26 02:24:32,991 INFO terminating
2025-03-26 02:24:32,991 INFO terminating
2025-03-26 02:24:32,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/max_abs_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:32,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:32,999 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1168, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/als.py._COPYING_
2025-03-26 02:24:33,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741992_1168 src: /172.20.1.14:47154 dest: /172.20.1.16:9866
2025-03-26 02:24:33,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741992_1168 src: /172.20.1.16:54440 dest: /172.20.1.17:9866
2025-03-26 02:24:33,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741992_1168 src: /172.20.1.17:38378 dest: /172.20.1.15:9866
2025-03-26 02:24:33,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54440, dest: /172.20.1.17:9866, bytes: 3329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741992_1168, duration(ns): 1618542
2025-03-26 02:24:33,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38378, dest: /172.20.1.15:9866, bytes: 3329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741992_1168, duration(ns): 1104446
2025-03-26 02:24:33,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741992_1168, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,004 INFO terminating
2025-03-26 02:24:33,005 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/als.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47154, dest: /172.20.1.16:9866, bytes: 3329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741992_1168, duration(ns): 1914490
2025-03-26 02:24:33,005 INFO terminating
2025-03-26 02:24:33,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1169, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/sql/hive.py._COPYING_
2025-03-26 02:24:33,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741993_1169 src: /172.20.1.14:47160 dest: /172.20.1.16:9866
2025-03-26 02:24:33,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741993_1169 src: /172.20.1.16:54442 dest: /172.20.1.17:9866
2025-03-26 02:24:33,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741993_1169 src: /172.20.1.17:38384 dest: /172.20.1.15:9866
2025-03-26 02:24:33,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38384, dest: /172.20.1.15:9866, bytes: 3260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741993_1169, duration(ns): 1000053
2025-03-26 02:24:33,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741993_1169, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47160, dest: /172.20.1.16:9866, bytes: 3260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741993_1169, duration(ns): 1541528
2025-03-26 02:24:33,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54442, dest: /172.20.1.17:9866, bytes: 3260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741993_1169, duration(ns): 1206988
2025-03-26 02:24:33,017 INFO terminating
2025-03-26 02:24:33,017 INFO terminating
2025-03-26 02:24:33,018 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/hive.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,022 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1170, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/__init__.py._COPYING_
2025-03-26 02:24:33,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741994_1170 src: /172.20.1.14:47170 dest: /172.20.1.16:9866
2025-03-26 02:24:33,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741994_1170 src: /172.20.1.15:36340 dest: /172.20.1.17:9866
2025-03-26 02:24:33,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741994_1170 src: /172.20.1.16:44862 dest: /172.20.1.15:9866
2025-03-26 02:24:33,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36340, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741994_1170, duration(ns): 820072
2025-03-26 02:24:33,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47170, dest: /172.20.1.16:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741994_1170, duration(ns): 1967971
2025-03-26 02:24:33,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44862, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741994_1170, duration(ns): 1760304
2025-03-26 02:24:33,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741994_1170, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,027 INFO terminating
2025-03-26 02:24:33,027 INFO terminating
2025-03-26 02:24:33,028 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1171, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/sql/datasource.py._COPYING_
2025-03-26 02:24:33,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741995_1171 src: /172.20.1.14:36744 dest: /172.20.1.17:9866
2025-03-26 02:24:33,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741995_1171 src: /172.20.1.17:38398 dest: /172.20.1.15:9866
2025-03-26 02:24:33,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741995_1171 src: /172.20.1.15:38522 dest: /172.20.1.16:9866
2025-03-26 02:24:33,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38522, dest: /172.20.1.16:9866, bytes: 15038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741995_1171, duration(ns): 965258
2025-03-26 02:24:33,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38398, dest: /172.20.1.15:9866, bytes: 15038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741995_1171, duration(ns): 1377025
2025-03-26 02:24:33,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741995_1171, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,038 INFO terminating
2025-03-26 02:24:33,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36744, dest: /172.20.1.17:9866, bytes: 15038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741995_1171, duration(ns): 1695067
2025-03-26 02:24:33,039 INFO terminating
2025-03-26 02:24:33,041 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/datasource.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,046 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1172, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/basic.py._COPYING_
2025-03-26 02:24:33,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741996_1172 src: /172.20.1.14:47186 dest: /172.20.1.16:9866
2025-03-26 02:24:33,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741996_1172 src: /172.20.1.16:44872 dest: /172.20.1.15:9866
2025-03-26 02:24:33,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741996_1172 src: /172.20.1.15:36344 dest: /172.20.1.17:9866
2025-03-26 02:24:33,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36344, dest: /172.20.1.17:9866, bytes: 6331, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741996_1172, duration(ns): 987684
2025-03-26 02:24:33,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44872, dest: /172.20.1.15:9866, bytes: 6331, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741996_1172, duration(ns): 1299731
2025-03-26 02:24:33,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741996_1172, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,051 INFO terminating
2025-03-26 02:24:33,052 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/basic.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47186, dest: /172.20.1.16:9866, bytes: 6331, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741996_1172, duration(ns): 1644248
2025-03-26 02:24:33,052 INFO terminating
2025-03-26 02:24:33,056 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1173, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/sql/arrow.py._COPYING_
2025-03-26 02:24:33,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741997_1173 src: /172.20.1.14:36750 dest: /172.20.1.17:9866
2025-03-26 02:24:33,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741997_1173 src: /172.20.1.17:60066 dest: /172.20.1.16:9866
2025-03-26 02:24:33,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741997_1173 src: /172.20.1.16:44878 dest: /172.20.1.15:9866
2025-03-26 02:24:33,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44878, dest: /172.20.1.15:9866, bytes: 9733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741997_1173, duration(ns): 937179
2025-03-26 02:24:33,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741997_1173, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36750, dest: /172.20.1.17:9866, bytes: 9733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741997_1173, duration(ns): 1493952
2025-03-26 02:24:33,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60066, dest: /172.20.1.16:9866, bytes: 9733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741997_1173, duration(ns): 1138597
2025-03-26 02:24:33,061 INFO terminating
2025-03-26 02:24:33,061 INFO terminating
2025-03-26 02:24:33,062 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/arrow.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,067 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1174, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/sql/streaming/structured_sessionization.py._COPYING_
2025-03-26 02:24:33,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741998_1174 src: /172.20.1.14:36758 dest: /172.20.1.17:9866
2025-03-26 02:24:33,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741998_1174 src: /172.20.1.15:38530 dest: /172.20.1.16:9866
2025-03-26 02:24:33,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741998_1174 src: /172.20.1.17:38414 dest: /172.20.1.15:9866
2025-03-26 02:24:33,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38530, dest: /172.20.1.16:9866, bytes: 3213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741998_1174, duration(ns): 934998
2025-03-26 02:24:33,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38414, dest: /172.20.1.15:9866, bytes: 3213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741998_1174, duration(ns): 1311667
2025-03-26 02:24:33,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741998_1174, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,071 INFO terminating
2025-03-26 02:24:33,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36758, dest: /172.20.1.17:9866, bytes: 3213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741998_1174, duration(ns): 1581751
2025-03-26 02:24:33,072 INFO terminating
2025-03-26 02:24:33,073 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_sessionization.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,077 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1175, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py._COPYING_
2025-03-26 02:24:33,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741999_1175 src: /172.20.1.14:42338 dest: /172.20.1.15:9866
2025-03-26 02:24:33,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741999_1175 src: /172.20.1.15:38546 dest: /172.20.1.16:9866
2025-03-26 02:24:33,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073741999_1175 src: /172.20.1.16:54456 dest: /172.20.1.17:9866
2025-03-26 02:24:33,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54456, dest: /172.20.1.17:9866, bytes: 3172, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741999_1175, duration(ns): 867708
2025-03-26 02:24:33,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073741999_1175, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42338, dest: /172.20.1.15:9866, bytes: 3172, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741999_1175, duration(ns): 1568741
2025-03-26 02:24:33,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38546, dest: /172.20.1.16:9866, bytes: 3172, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073741999_1175, duration(ns): 1191339
2025-03-26 02:24:33,082 INFO terminating
2025-03-26 02:24:33,082 INFO terminating
2025-03-26 02:24:33,083 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1176, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/sql/streaming/__init__,py._COPYING_
2025-03-26 02:24:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742000_1176 src: /172.20.1.14:47200 dest: /172.20.1.16:9866
2025-03-26 02:24:33,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742000_1176 src: /172.20.1.16:54472 dest: /172.20.1.17:9866
2025-03-26 02:24:33,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742000_1176 src: /172.20.1.17:38424 dest: /172.20.1.15:9866
2025-03-26 02:24:33,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38424, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742000_1176, duration(ns): 1026151
2025-03-26 02:24:33,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742000_1176, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47200, dest: /172.20.1.16:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742000_1176, duration(ns): 1552808
2025-03-26 02:24:33,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54472, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742000_1176, duration(ns): 1147858
2025-03-26 02:24:33,098 INFO terminating
2025-03-26 02:24:33,098 INFO terminating
2025-03-26 02:24:33,099 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/__init__,py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1177, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount.py._COPYING_
2025-03-26 02:24:33,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742001_1177 src: /172.20.1.14:36774 dest: /172.20.1.17:9866
2025-03-26 02:24:33,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742001_1177 src: /172.20.1.17:60082 dest: /172.20.1.16:9866
2025-03-26 02:24:33,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742001_1177 src: /172.20.1.16:44884 dest: /172.20.1.15:9866
2025-03-26 02:24:33,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36774, dest: /172.20.1.17:9866, bytes: 2500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742001_1177, duration(ns): 1487865
2025-03-26 02:24:33,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44884, dest: /172.20.1.15:9866, bytes: 2500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742001_1177, duration(ns): 966969
2025-03-26 02:24:33,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60082, dest: /172.20.1.16:9866, bytes: 2500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742001_1177, duration(ns): 1157778
2025-03-26 02:24:33,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742001_1177, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,107 INFO terminating
2025-03-26 02:24:33,108 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,108 INFO terminating
2025-03-26 02:24:33,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1178, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py._COPYING_
2025-03-26 02:24:33,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742002_1178 src: /172.20.1.14:36790 dest: /172.20.1.17:9866
2025-03-26 02:24:33,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742002_1178 src: /172.20.1.17:38426 dest: /172.20.1.15:9866
2025-03-26 02:24:33,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742002_1178 src: /172.20.1.15:38562 dest: /172.20.1.16:9866
2025-03-26 02:24:33,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38562, dest: /172.20.1.16:9866, bytes: 4047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742002_1178, duration(ns): 1573366
2025-03-26 02:24:33,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742002_1178, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38426, dest: /172.20.1.15:9866, bytes: 4047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742002_1178, duration(ns): 2337023
2025-03-26 02:24:33,118 INFO terminating
2025-03-26 02:24:33,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36790, dest: /172.20.1.17:9866, bytes: 4047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742002_1178, duration(ns): 1929247
2025-03-26 02:24:33,127 INFO terminating
2025-03-26 02:24:33,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,138 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1179, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/queue_stream.py._COPYING_
2025-03-26 02:24:33,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742003_1179 src: /172.20.1.14:36806 dest: /172.20.1.17:9866
2025-03-26 02:24:33,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742003_1179 src: /172.20.1.17:60094 dest: /172.20.1.16:9866
2025-03-26 02:24:33,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742003_1179 src: /172.20.1.16:44888 dest: /172.20.1.15:9866
2025-03-26 02:24:33,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44888, dest: /172.20.1.15:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742003_1179, duration(ns): 1761640
2025-03-26 02:24:33,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742003_1179, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36806, dest: /172.20.1.17:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742003_1179, duration(ns): 2248661
2025-03-26 02:24:33,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60094, dest: /172.20.1.16:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742003_1179, duration(ns): 1898724
2025-03-26 02:24:33,144 INFO terminating
2025-03-26 02:24:33,144 INFO terminating
2025-03-26 02:24:33,145 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/queue_stream.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1180, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/network_wordcount.py._COPYING_
2025-03-26 02:24:33,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742004_1180 src: /172.20.1.14:36812 dest: /172.20.1.17:9866
2025-03-26 02:24:33,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742004_1180 src: /172.20.1.17:60108 dest: /172.20.1.16:9866
2025-03-26 02:24:33,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742004_1180 src: /172.20.1.16:44896 dest: /172.20.1.15:9866
2025-03-26 02:24:33,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44896, dest: /172.20.1.15:9866, bytes: 1883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742004_1180, duration(ns): 894063
2025-03-26 02:24:33,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60108, dest: /172.20.1.16:9866, bytes: 1883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742004_1180, duration(ns): 1056359
2025-03-26 02:24:33,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742004_1180, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,155 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36812, dest: /172.20.1.17:9866, bytes: 1883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742004_1180, duration(ns): 1314438
2025-03-26 02:24:33,155 INFO terminating
2025-03-26 02:24:33,155 INFO terminating
2025-03-26 02:24:33,159 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1181, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/streaming/__init__.py._COPYING_
2025-03-26 02:24:33,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,159 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742005_1181 src: /172.20.1.14:42354 dest: /172.20.1.15:9866
2025-03-26 02:24:33,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742005_1181 src: /172.20.1.15:38578 dest: /172.20.1.16:9866
2025-03-26 02:24:33,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742005_1181 src: /172.20.1.16:54484 dest: /172.20.1.17:9866
2025-03-26 02:24:33,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54484, dest: /172.20.1.17:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742005_1181, duration(ns): 941870
2025-03-26 02:24:33,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742005_1181, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42354, dest: /172.20.1.15:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742005_1181, duration(ns): 5173195
2025-03-26 02:24:33,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38578, dest: /172.20.1.16:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742005_1181, duration(ns): 4367547
2025-03-26 02:24:33,168 INFO terminating
2025-03-26 02:24:33,168 INFO terminating
2025-03-26 02:24:33,169 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1182, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/sql_network_wordcount.py._COPYING_
2025-03-26 02:24:33,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742006_1182 src: /172.20.1.14:47208 dest: /172.20.1.16:9866
2025-03-26 02:24:33,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742006_1182 src: /172.20.1.16:54490 dest: /172.20.1.17:9866
2025-03-26 02:24:33,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742006_1182 src: /172.20.1.17:38436 dest: /172.20.1.15:9866
2025-03-26 02:24:33,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38436, dest: /172.20.1.15:9866, bytes: 3297, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742006_1182, duration(ns): 1062403
2025-03-26 02:24:33,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742006_1182, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47208, dest: /172.20.1.16:9866, bytes: 3297, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742006_1182, duration(ns): 1603248
2025-03-26 02:24:33,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54490, dest: /172.20.1.17:9866, bytes: 3297, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742006_1182, duration(ns): 1190492
2025-03-26 02:24:33,180 INFO terminating
2025-03-26 02:24:33,180 INFO terminating
2025-03-26 02:24:33,181 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/sql_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,185 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1183, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/streaming/hdfs_wordcount.py._COPYING_
2025-03-26 02:24:33,185 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,185 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742007_1183 src: /172.20.1.14:47214 dest: /172.20.1.16:9866
2025-03-26 02:24:33,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742007_1183 src: /172.20.1.16:44912 dest: /172.20.1.15:9866
2025-03-26 02:24:33,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742007_1183 src: /172.20.1.15:36352 dest: /172.20.1.17:9866
2025-03-26 02:24:33,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36352, dest: /172.20.1.17:9866, bytes: 1832, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742007_1183, duration(ns): 705357
2025-03-26 02:24:33,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44912, dest: /172.20.1.15:9866, bytes: 1832, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742007_1183, duration(ns): 4262248
2025-03-26 02:24:33,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742007_1183, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,193 INFO terminating
2025-03-26 02:24:33,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/hdfs_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47214, dest: /172.20.1.16:9866, bytes: 1832, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742007_1183, duration(ns): 4355483
2025-03-26 02:24:33,194 INFO terminating
2025-03-26 02:24:33,198 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1184, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/python/streaming/network_wordjoinsentiments.py._COPYING_
2025-03-26 02:24:33,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742008_1184 src: /172.20.1.14:47222 dest: /172.20.1.16:9866
2025-03-26 02:24:33,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742008_1184 src: /172.20.1.16:54496 dest: /172.20.1.17:9866
2025-03-26 02:24:33,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742008_1184 src: /172.20.1.17:38450 dest: /172.20.1.15:9866
2025-03-26 02:24:33,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38450, dest: /172.20.1.15:9866, bytes: 3393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742008_1184, duration(ns): 929571
2025-03-26 02:24:33,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742008_1184, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47222, dest: /172.20.1.16:9866, bytes: 3393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742008_1184, duration(ns): 1487125
2025-03-26 02:24:33,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54496, dest: /172.20.1.17:9866, bytes: 3393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742008_1184, duration(ns): 1129783
2025-03-26 02:24:33,203 INFO terminating
2025-03-26 02:24:33,203 INFO terminating
2025-03-26 02:24:33,204 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/network_wordjoinsentiments.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,207 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1185, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_
2025-03-26 02:24:33,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742009_1185 src: /172.20.1.14:42356 dest: /172.20.1.15:9866
2025-03-26 02:24:33,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742009_1185 src: /172.20.1.15:36368 dest: /172.20.1.17:9866
2025-03-26 02:24:33,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742009_1185 src: /172.20.1.17:60124 dest: /172.20.1.16:9866
2025-03-26 02:24:33,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60124, dest: /172.20.1.16:9866, bytes: 2310, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742009_1185, duration(ns): 939370
2025-03-26 02:24:33,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742009_1185, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42356, dest: /172.20.1.15:9866, bytes: 2310, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742009_1185, duration(ns): 2056200
2025-03-26 02:24:33,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36368, dest: /172.20.1.17:9866, bytes: 2310, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742009_1185, duration(ns): 1645841
2025-03-26 02:24:33,213 INFO terminating
2025-03-26 02:24:33,213 INFO terminating
2025-03-26 02:24:33,216 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1186, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/python/streaming/recoverable_network_wordcount.py._COPYING_
2025-03-26 02:24:33,220 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742010_1186 src: /172.20.1.14:47224 dest: /172.20.1.16:9866
2025-03-26 02:24:33,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742010_1186 src: /172.20.1.16:44924 dest: /172.20.1.15:9866
2025-03-26 02:24:33,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742010_1186 src: /172.20.1.15:36384 dest: /172.20.1.17:9866
2025-03-26 02:24:33,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36384, dest: /172.20.1.17:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742010_1186, duration(ns): 937885
2025-03-26 02:24:33,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742010_1186, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47224, dest: /172.20.1.16:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742010_1186, duration(ns): 1548188
2025-03-26 02:24:33,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44924, dest: /172.20.1.15:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742010_1186, duration(ns): 1285958
2025-03-26 02:24:33,225 INFO terminating
2025-03-26 02:24:33,225 INFO terminating
2025-03-26 02:24:33,226 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/recoverable_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,236 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1187, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/data-manipulation.R._COPYING_
2025-03-26 02:24:33,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742011_1187 src: /172.20.1.14:47226 dest: /172.20.1.16:9866
2025-03-26 02:24:33,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742011_1187 src: /172.20.1.16:54506 dest: /172.20.1.17:9866
2025-03-26 02:24:33,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742011_1187 src: /172.20.1.17:38462 dest: /172.20.1.15:9866
2025-03-26 02:24:33,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47226, dest: /172.20.1.16:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742011_1187, duration(ns): 1500834
2025-03-26 02:24:33,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54506, dest: /172.20.1.17:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742011_1187, duration(ns): 1188829
2025-03-26 02:24:33,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38462, dest: /172.20.1.15:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742011_1187, duration(ns): 950038
2025-03-26 02:24:33,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742011_1187, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,243 INFO terminating
2025-03-26 02:24:33,244 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/data-manipulation.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,244 INFO terminating
2025-03-26 02:24:33,248 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1188, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/RSparkSQLExample.R._COPYING_
2025-03-26 02:24:33,248 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,248 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742012_1188 src: /172.20.1.14:42364 dest: /172.20.1.15:9866
2025-03-26 02:24:33,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742012_1188 src: /172.20.1.15:38580 dest: /172.20.1.16:9866
2025-03-26 02:24:33,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742012_1188 src: /172.20.1.16:54514 dest: /172.20.1.17:9866
2025-03-26 02:24:33,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54514, dest: /172.20.1.17:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742012_1188, duration(ns): 873245
2025-03-26 02:24:33,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742012_1188, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42364, dest: /172.20.1.15:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742012_1188, duration(ns): 1889977
2025-03-26 02:24:33,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38580, dest: /172.20.1.16:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742012_1188, duration(ns): 1483723
2025-03-26 02:24:33,254 INFO terminating
2025-03-26 02:24:33,254 INFO terminating
2025-03-26 02:24:33,255 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/RSparkSQLExample.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,263 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1189, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/als.R._COPYING_
2025-03-26 02:24:33,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742013_1189 src: /172.20.1.14:42372 dest: /172.20.1.15:9866
2025-03-26 02:24:33,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742013_1189 src: /172.20.1.15:36390 dest: /172.20.1.17:9866
2025-03-26 02:24:33,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742013_1189 src: /172.20.1.17:60136 dest: /172.20.1.16:9866
2025-03-26 02:24:33,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36390, dest: /172.20.1.17:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742013_1189, duration(ns): 2034357
2025-03-26 02:24:33,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60136, dest: /172.20.1.16:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742013_1189, duration(ns): 1348253
2025-03-26 02:24:33,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742013_1189, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,269 INFO terminating
2025-03-26 02:24:33,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42372, dest: /172.20.1.15:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742013_1189, duration(ns): 2753563
2025-03-26 02:24:33,270 INFO terminating
2025-03-26 02:24:33,271 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/als.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1190, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/ml.R._COPYING_
2025-03-26 02:24:33,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742014_1190 src: /172.20.1.14:47236 dest: /172.20.1.16:9866
2025-03-26 02:24:33,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742014_1190 src: /172.20.1.16:44926 dest: /172.20.1.15:9866
2025-03-26 02:24:33,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742014_1190 src: /172.20.1.15:36406 dest: /172.20.1.17:9866
2025-03-26 02:24:33,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36406, dest: /172.20.1.17:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742014_1190, duration(ns): 871595
2025-03-26 02:24:33,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44926, dest: /172.20.1.15:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742014_1190, duration(ns): 1360569
2025-03-26 02:24:33,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742014_1190, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,282 INFO terminating
2025-03-26 02:24:33,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47236, dest: /172.20.1.16:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742014_1190, duration(ns): 1619120
2025-03-26 02:24:33,283 INFO terminating
2025-03-26 02:24:33,289 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/ml.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,294 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1191, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/prefixSpan.R._COPYING_
2025-03-26 02:24:33,294 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,294 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742015_1191 src: /172.20.1.14:47250 dest: /172.20.1.16:9866
2025-03-26 02:24:33,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742015_1191 src: /172.20.1.16:54522 dest: /172.20.1.17:9866
2025-03-26 02:24:33,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742015_1191 src: /172.20.1.17:38464 dest: /172.20.1.15:9866
2025-03-26 02:24:33,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47250, dest: /172.20.1.16:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742015_1191, duration(ns): 2038896
2025-03-26 02:24:33,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54522, dest: /172.20.1.17:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742015_1191, duration(ns): 1727114
2025-03-26 02:24:33,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38464, dest: /172.20.1.15:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742015_1191, duration(ns): 1536234
2025-03-26 02:24:33,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742015_1191, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,300 INFO terminating
2025-03-26 02:24:33,301 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/prefixSpan.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,301 INFO terminating
2025-03-26 02:24:33,305 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1192, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_
2025-03-26 02:24:33,305 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,305 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742016_1192 src: /172.20.1.14:47256 dest: /172.20.1.16:9866
2025-03-26 02:24:33,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742016_1192 src: /172.20.1.16:44932 dest: /172.20.1.15:9866
2025-03-26 02:24:33,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742016_1192 src: /172.20.1.15:36422 dest: /172.20.1.17:9866
2025-03-26 02:24:33,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36422, dest: /172.20.1.17:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742016_1192, duration(ns): 967760
2025-03-26 02:24:33,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742016_1192, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47256, dest: /172.20.1.16:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742016_1192, duration(ns): 1885760
2025-03-26 02:24:33,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44932, dest: /172.20.1.15:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742016_1192, duration(ns): 1351907
2025-03-26 02:24:33,312 INFO terminating
2025-03-26 02:24:33,313 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,313 INFO terminating
2025-03-26 02:24:33,318 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1193, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/lm_with_elastic_net.R._COPYING_
2025-03-26 02:24:33,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742017_1193 src: /172.20.1.14:47266 dest: /172.20.1.16:9866
2025-03-26 02:24:33,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742017_1193 src: /172.20.1.16:54532 dest: /172.20.1.17:9866
2025-03-26 02:24:33,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742017_1193 src: /172.20.1.17:38470 dest: /172.20.1.15:9866
2025-03-26 02:24:33,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54532, dest: /172.20.1.17:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742017_1193, duration(ns): 1293655
2025-03-26 02:24:33,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38470, dest: /172.20.1.15:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742017_1193, duration(ns): 1094563
2025-03-26 02:24:33,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742017_1193, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,323 INFO terminating
2025-03-26 02:24:33,324 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/lm_with_elastic_net.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47266, dest: /172.20.1.16:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742017_1193, duration(ns): 1623874
2025-03-26 02:24:33,324 INFO terminating
2025-03-26 02:24:33,328 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1194, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/naiveBayes.R._COPYING_
2025-03-26 02:24:33,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742018_1194 src: /172.20.1.14:42376 dest: /172.20.1.15:9866
2025-03-26 02:24:33,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742018_1194 src: /172.20.1.15:36432 dest: /172.20.1.17:9866
2025-03-26 02:24:33,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742018_1194 src: /172.20.1.17:60138 dest: /172.20.1.16:9866
2025-03-26 02:24:33,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42376, dest: /172.20.1.15:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742018_1194, duration(ns): 1426352
2025-03-26 02:24:33,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36432, dest: /172.20.1.17:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742018_1194, duration(ns): 1046839
2025-03-26 02:24:33,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60138, dest: /172.20.1.16:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742018_1194, duration(ns): 751592
2025-03-26 02:24:33,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742018_1194, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,332 INFO terminating
2025-03-26 02:24:33,332 INFO terminating
2025-03-26 02:24:33,333 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/naiveBayes.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,338 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,338 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,339 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1195, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/decisionTree.R._COPYING_
2025-03-26 02:24:33,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742019_1195 src: /172.20.1.14:42388 dest: /172.20.1.15:9866
2025-03-26 02:24:33,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742019_1195 src: /172.20.1.15:36446 dest: /172.20.1.17:9866
2025-03-26 02:24:33,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742019_1195 src: /172.20.1.17:60152 dest: /172.20.1.16:9866
2025-03-26 02:24:33,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36446, dest: /172.20.1.17:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742019_1195, duration(ns): 1047539
2025-03-26 02:24:33,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60152, dest: /172.20.1.16:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742019_1195, duration(ns): 769777
2025-03-26 02:24:33,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742019_1195, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,343 INFO terminating
2025-03-26 02:24:33,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/decisionTree.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42388, dest: /172.20.1.15:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742019_1195, duration(ns): 1733433
2025-03-26 02:24:33,344 INFO terminating
2025-03-26 02:24:33,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1196, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/lda.R._COPYING_
2025-03-26 02:24:33,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742020_1196 src: /172.20.1.14:47278 dest: /172.20.1.16:9866
2025-03-26 02:24:33,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742020_1196 src: /172.20.1.16:44938 dest: /172.20.1.15:9866
2025-03-26 02:24:33,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742020_1196 src: /172.20.1.15:36456 dest: /172.20.1.17:9866
2025-03-26 02:24:33,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36456, dest: /172.20.1.17:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742020_1196, duration(ns): 786474
2025-03-26 02:24:33,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44938, dest: /172.20.1.15:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742020_1196, duration(ns): 1157576
2025-03-26 02:24:33,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742020_1196, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,354 INFO terminating
2025-03-26 02:24:33,355 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/lda.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47278, dest: /172.20.1.16:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742020_1196, duration(ns): 1837577
2025-03-26 02:24:33,355 INFO terminating
2025-03-26 02:24:33,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1197, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/survreg.R._COPYING_
2025-03-26 02:24:33,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742021_1197 src: /172.20.1.14:42398 dest: /172.20.1.15:9866
2025-03-26 02:24:33,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742021_1197 src: /172.20.1.15:36464 dest: /172.20.1.17:9866
2025-03-26 02:24:33,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742021_1197 src: /172.20.1.17:60168 dest: /172.20.1.16:9866
2025-03-26 02:24:33,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42398, dest: /172.20.1.15:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742021_1197, duration(ns): 1419278
2025-03-26 02:24:33,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36464, dest: /172.20.1.17:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742021_1197, duration(ns): 1066596
2025-03-26 02:24:33,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60168, dest: /172.20.1.16:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742021_1197, duration(ns): 788015
2025-03-26 02:24:33,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742021_1197, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,364 INFO terminating
2025-03-26 02:24:33,364 INFO terminating
2025-03-26 02:24:33,365 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/survreg.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1198, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/svmLinear.R._COPYING_
2025-03-26 02:24:33,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742022_1198 src: /172.20.1.14:36828 dest: /172.20.1.17:9866
2025-03-26 02:24:33,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742022_1198 src: /172.20.1.17:38480 dest: /172.20.1.15:9866
2025-03-26 02:24:33,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742022_1198 src: /172.20.1.15:38582 dest: /172.20.1.16:9866
2025-03-26 02:24:33,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38582, dest: /172.20.1.16:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742022_1198, duration(ns): 2063164
2025-03-26 02:24:33,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38480, dest: /172.20.1.15:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742022_1198, duration(ns): 2392705
2025-03-26 02:24:33,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742022_1198, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,374 INFO terminating
2025-03-26 02:24:33,375 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/svmLinear.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36828, dest: /172.20.1.17:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742022_1198, duration(ns): 2632191
2025-03-26 02:24:33,375 INFO terminating
2025-03-26 02:24:33,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1199, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/isoreg.R._COPYING_
2025-03-26 02:24:33,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742023_1199 src: /172.20.1.14:36842 dest: /172.20.1.17:9866
2025-03-26 02:24:33,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742023_1199 src: /172.20.1.16:44946 dest: /172.20.1.15:9866
2025-03-26 02:24:33,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742023_1199 src: /172.20.1.17:60174 dest: /172.20.1.16:9866
2025-03-26 02:24:33,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44946, dest: /172.20.1.15:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742023_1199, duration(ns): 828919
2025-03-26 02:24:33,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60174, dest: /172.20.1.16:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742023_1199, duration(ns): 1001752
2025-03-26 02:24:33,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742023_1199, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,383 INFO terminating
2025-03-26 02:24:33,384 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/isoreg.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36842, dest: /172.20.1.17:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742023_1199, duration(ns): 1328016
2025-03-26 02:24:33,384 INFO terminating
2025-03-26 02:24:33,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742024_1200, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/bisectingKmeans.R._COPYING_
2025-03-26 02:24:33,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742024_1200 src: /172.20.1.14:47284 dest: /172.20.1.16:9866
2025-03-26 02:24:33,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742024_1200 src: /172.20.1.16:44952 dest: /172.20.1.15:9866
2025-03-26 02:24:33,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742024_1200 src: /172.20.1.15:36470 dest: /172.20.1.17:9866
2025-03-26 02:24:33,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36470, dest: /172.20.1.17:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742024_1200, duration(ns): 789982
2025-03-26 02:24:33,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44952, dest: /172.20.1.15:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742024_1200, duration(ns): 1130628
2025-03-26 02:24:33,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742024_1200, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,393 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/bisectingKmeans.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47284, dest: /172.20.1.16:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742024_1200, duration(ns): 1181434
2025-03-26 02:24:33,393 INFO terminating
2025-03-26 02:24:33,393 INFO terminating
2025-03-26 02:24:33,397 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742025_1201, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/mlp.R._COPYING_
2025-03-26 02:24:33,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742025_1201 src: /172.20.1.14:42406 dest: /172.20.1.15:9866
2025-03-26 02:24:33,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742025_1201 src: /172.20.1.15:38592 dest: /172.20.1.16:9866
2025-03-26 02:24:33,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742025_1201 src: /172.20.1.16:54534 dest: /172.20.1.17:9866
2025-03-26 02:24:33,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38592, dest: /172.20.1.16:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742025_1201, duration(ns): 1097155
2025-03-26 02:24:33,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54534, dest: /172.20.1.17:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742025_1201, duration(ns): 763100
2025-03-26 02:24:33,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742025_1201, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,401 INFO terminating
2025-03-26 02:24:33,402 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/mlp.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42406, dest: /172.20.1.15:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742025_1201, duration(ns): 1455135
2025-03-26 02:24:33,402 INFO terminating
2025-03-26 02:24:33,405 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742026_1202, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/fpm.R._COPYING_
2025-03-26 02:24:33,405 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,405 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742026_1202 src: /172.20.1.14:42410 dest: /172.20.1.15:9866
2025-03-26 02:24:33,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742026_1202 src: /172.20.1.15:38602 dest: /172.20.1.16:9866
2025-03-26 02:24:33,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742026_1202 src: /172.20.1.16:54536 dest: /172.20.1.17:9866
2025-03-26 02:24:33,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42410, dest: /172.20.1.15:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742026_1202, duration(ns): 1756610
2025-03-26 02:24:33,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38602, dest: /172.20.1.16:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742026_1202, duration(ns): 1362716
2025-03-26 02:24:33,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54536, dest: /172.20.1.17:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742026_1202, duration(ns): 773481
2025-03-26 02:24:33,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742026_1202, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,410 INFO terminating
2025-03-26 02:24:33,411 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fpm.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,411 INFO terminating
2025-03-26 02:24:33,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742027_1203, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/glm.R._COPYING_
2025-03-26 02:24:33,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742027_1203 src: /172.20.1.14:42422 dest: /172.20.1.15:9866
2025-03-26 02:24:33,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742027_1203 src: /172.20.1.15:38610 dest: /172.20.1.16:9866
2025-03-26 02:24:33,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742027_1203 src: /172.20.1.16:54548 dest: /172.20.1.17:9866
2025-03-26 02:24:33,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38610, dest: /172.20.1.16:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742027_1203, duration(ns): 1071754
2025-03-26 02:24:33,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54548, dest: /172.20.1.17:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742027_1203, duration(ns): 761376
2025-03-26 02:24:33,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742027_1203, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42422, dest: /172.20.1.15:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742027_1203, duration(ns): 1424158
2025-03-26 02:24:33,419 INFO terminating
2025-03-26 02:24:33,419 INFO terminating
2025-03-26 02:24:33,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/glm.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742028_1204, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/randomForest.R._COPYING_
2025-03-26 02:24:33,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742028_1204 src: /172.20.1.14:42432 dest: /172.20.1.15:9866
2025-03-26 02:24:33,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742028_1204 src: /172.20.1.15:38620 dest: /172.20.1.16:9866
2025-03-26 02:24:33,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742028_1204 src: /172.20.1.16:54552 dest: /172.20.1.17:9866
2025-03-26 02:24:33,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38620, dest: /172.20.1.16:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742028_1204, duration(ns): 1042562
2025-03-26 02:24:33,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54552, dest: /172.20.1.17:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742028_1204, duration(ns): 747900
2025-03-26 02:24:33,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742028_1204, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42432, dest: /172.20.1.15:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742028_1204, duration(ns): 1413219
2025-03-26 02:24:33,429 INFO terminating
2025-03-26 02:24:33,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/randomForest.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,430 INFO terminating
2025-03-26 02:24:33,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742029_1205, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/ml/gaussianMixture.R._COPYING_
2025-03-26 02:24:33,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742029_1205 src: /172.20.1.14:42448 dest: /172.20.1.15:9866
2025-03-26 02:24:33,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742029_1205 src: /172.20.1.15:36482 dest: /172.20.1.17:9866
2025-03-26 02:24:33,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742029_1205 src: /172.20.1.17:60184 dest: /172.20.1.16:9866
2025-03-26 02:24:33,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36482, dest: /172.20.1.17:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742029_1205, duration(ns): 1215698
2025-03-26 02:24:33,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60184, dest: /172.20.1.16:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742029_1205, duration(ns): 886530
2025-03-26 02:24:33,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742029_1205, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,444 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/gaussianMixture.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42448, dest: /172.20.1.15:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742029_1205, duration(ns): 1905183
2025-03-26 02:24:33,444 INFO terminating
2025-03-26 02:24:33,444 INFO terminating
2025-03-26 02:24:33,450 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742030_1206, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/fmClassifier.R._COPYING_
2025-03-26 02:24:33,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742030_1206 src: /172.20.1.14:47298 dest: /172.20.1.16:9866
2025-03-26 02:24:33,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742030_1206 src: /172.20.1.16:44962 dest: /172.20.1.15:9866
2025-03-26 02:24:33,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742030_1206 src: /172.20.1.15:36488 dest: /172.20.1.17:9866
2025-03-26 02:24:33,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36488, dest: /172.20.1.17:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742030_1206, duration(ns): 758654
2025-03-26 02:24:33,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742030_1206, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47298, dest: /172.20.1.16:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742030_1206, duration(ns): 1614542
2025-03-26 02:24:33,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44962, dest: /172.20.1.15:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742030_1206, duration(ns): 1395225
2025-03-26 02:24:33,456 INFO terminating
2025-03-26 02:24:33,456 INFO terminating
2025-03-26 02:24:33,457 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fmClassifier.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,460 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742031_1207, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/gbt.R._COPYING_
2025-03-26 02:24:33,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742031_1207 src: /172.20.1.14:47308 dest: /172.20.1.16:9866
2025-03-26 02:24:33,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742031_1207 src: /172.20.1.16:54554 dest: /172.20.1.17:9866
2025-03-26 02:24:33,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742031_1207 src: /172.20.1.17:38494 dest: /172.20.1.15:9866
2025-03-26 02:24:33,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38494, dest: /172.20.1.15:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742031_1207, duration(ns): 887418
2025-03-26 02:24:33,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742031_1207, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47308, dest: /172.20.1.16:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742031_1207, duration(ns): 1463528
2025-03-26 02:24:33,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54554, dest: /172.20.1.17:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742031_1207, duration(ns): 1080939
2025-03-26 02:24:33,465 INFO terminating
2025-03-26 02:24:33,465 INFO terminating
2025-03-26 02:24:33,466 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/gbt.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742032_1208, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/fmRegressor.R._COPYING_
2025-03-26 02:24:33,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742032_1208 src: /172.20.1.14:47318 dest: /172.20.1.16:9866
2025-03-26 02:24:33,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742032_1208 src: /172.20.1.16:54564 dest: /172.20.1.17:9866
2025-03-26 02:24:33,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742032_1208 src: /172.20.1.17:38504 dest: /172.20.1.15:9866
2025-03-26 02:24:33,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54564, dest: /172.20.1.17:9866, bytes: 1458, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742032_1208, duration(ns): 1525363
2025-03-26 02:24:33,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38504, dest: /172.20.1.15:9866, bytes: 1458, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742032_1208, duration(ns): 1298513
2025-03-26 02:24:33,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742032_1208, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,475 INFO terminating
2025-03-26 02:24:33,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fmRegressor.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47318, dest: /172.20.1.16:9866, bytes: 1458, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742032_1208, duration(ns): 1906030
2025-03-26 02:24:33,476 INFO terminating
2025-03-26 02:24:33,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742033_1209, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/kmeans.R._COPYING_
2025-03-26 02:24:33,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742033_1209 src: /172.20.1.14:42462 dest: /172.20.1.15:9866
2025-03-26 02:24:33,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742033_1209 src: /172.20.1.15:38634 dest: /172.20.1.16:9866
2025-03-26 02:24:33,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742033_1209 src: /172.20.1.16:54570 dest: /172.20.1.17:9866
2025-03-26 02:24:33,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54570, dest: /172.20.1.17:9866, bytes: 1558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742033_1209, duration(ns): 830007
2025-03-26 02:24:33,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742033_1209, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42462, dest: /172.20.1.15:9866, bytes: 1558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742033_1209, duration(ns): 1602333
2025-03-26 02:24:33,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38634, dest: /172.20.1.16:9866, bytes: 1558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742033_1209, duration(ns): 1206199
2025-03-26 02:24:33,485 INFO terminating
2025-03-26 02:24:33,485 INFO terminating
2025-03-26 02:24:33,486 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/kmeans.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,489 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742034_1210, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/ml/kstest.R._COPYING_
2025-03-26 02:24:33,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742034_1210 src: /172.20.1.14:47328 dest: /172.20.1.16:9866
2025-03-26 02:24:33,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742034_1210 src: /172.20.1.16:44968 dest: /172.20.1.15:9866
2025-03-26 02:24:33,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742034_1210 src: /172.20.1.15:36498 dest: /172.20.1.17:9866
2025-03-26 02:24:33,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36498, dest: /172.20.1.17:9866, bytes: 1345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742034_1210, duration(ns): 1747608
2025-03-26 02:24:33,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742034_1210, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47328, dest: /172.20.1.16:9866, bytes: 1345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742034_1210, duration(ns): 2780031
2025-03-26 02:24:33,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44968, dest: /172.20.1.15:9866, bytes: 1345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742034_1210, duration(ns): 2116316
2025-03-26 02:24:33,495 INFO terminating
2025-03-26 02:24:33,495 INFO terminating
2025-03-26 02:24:33,496 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/kstest.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742035_1211, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/r/ml/logit.R._COPYING_
2025-03-26 02:24:33,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742035_1211 src: /172.20.1.14:36856 dest: /172.20.1.17:9866
2025-03-26 02:24:33,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742035_1211 src: /172.20.1.17:60196 dest: /172.20.1.16:9866
2025-03-26 02:24:33,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742035_1211 src: /172.20.1.16:44970 dest: /172.20.1.15:9866
2025-03-26 02:24:33,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44970, dest: /172.20.1.15:9866, bytes: 1980, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742035_1211, duration(ns): 890082
2025-03-26 02:24:33,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60196, dest: /172.20.1.16:9866, bytes: 1980, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742035_1211, duration(ns): 1099460
2025-03-26 02:24:33,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742035_1211, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,504 INFO terminating
2025-03-26 02:24:33,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/logit.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36856, dest: /172.20.1.17:9866, bytes: 1980, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742035_1211, duration(ns): 1656271
2025-03-26 02:24:33,505 INFO terminating
2025-03-26 02:24:33,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742036_1212, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/r/dataframe.R._COPYING_
2025-03-26 02:24:33,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742036_1212 src: /172.20.1.14:42478 dest: /172.20.1.15:9866
2025-03-26 02:24:33,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742036_1212 src: /172.20.1.15:38638 dest: /172.20.1.16:9866
2025-03-26 02:24:33,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742036_1212 src: /172.20.1.16:54578 dest: /172.20.1.17:9866
2025-03-26 02:24:33,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54578, dest: /172.20.1.17:9866, bytes: 1930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742036_1212, duration(ns): 732592
2025-03-26 02:24:33,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742036_1212, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38638, dest: /172.20.1.16:9866, bytes: 1930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742036_1212, duration(ns): 1365627
2025-03-26 02:24:33,515 INFO terminating
2025-03-26 02:24:33,516 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/dataframe.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42478, dest: /172.20.1.15:9866, bytes: 1930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742036_1212, duration(ns): 2199474
2025-03-26 02:24:33,516 INFO terminating
2025-03-26 02:24:33,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742037_1213, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/r/streaming/structured_network_wordcount.R._COPYING_
2025-03-26 02:24:33,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742037_1213 src: /172.20.1.14:36868 dest: /172.20.1.17:9866
2025-03-26 02:24:33,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742037_1213 src: /172.20.1.17:38506 dest: /172.20.1.15:9866
2025-03-26 02:24:33,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742037_1213 src: /172.20.1.15:38640 dest: /172.20.1.16:9866
2025-03-26 02:24:33,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38640, dest: /172.20.1.16:9866, bytes: 2084, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742037_1213, duration(ns): 795453
2025-03-26 02:24:33,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742037_1213, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36868, dest: /172.20.1.17:9866, bytes: 2084, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742037_1213, duration(ns): 1572018
2025-03-26 02:24:33,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38506, dest: /172.20.1.15:9866, bytes: 2084, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742037_1213, duration(ns): 1380287
2025-03-26 02:24:33,526 INFO terminating
2025-03-26 02:24:33,526 INFO terminating
2025-03-26 02:24:33,527 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/streaming/structured_network_wordcount.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,531 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742038_1214, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/kv1.txt._COPYING_
2025-03-26 02:24:33,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742038_1214 src: /172.20.1.14:47336 dest: /172.20.1.16:9866
2025-03-26 02:24:33,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742038_1214 src: /172.20.1.16:44984 dest: /172.20.1.15:9866
2025-03-26 02:24:33,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742038_1214 src: /172.20.1.15:36514 dest: /172.20.1.17:9866
2025-03-26 02:24:33,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36514, dest: /172.20.1.17:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742038_1214, duration(ns): 839780
2025-03-26 02:24:33,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44984, dest: /172.20.1.15:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742038_1214, duration(ns): 1114428
2025-03-26 02:24:33,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742038_1214, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47336, dest: /172.20.1.16:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742038_1214, duration(ns): 1879914
2025-03-26 02:24:33,539 INFO terminating
2025-03-26 02:24:33,539 INFO terminating
2025-03-26 02:24:33,543 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/kv1.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742039_1215, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/dir1/file1.parquet._COPYING_
2025-03-26 02:24:33,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742039_1215 src: /172.20.1.14:47348 dest: /172.20.1.16:9866
2025-03-26 02:24:33,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742039_1215 src: /172.20.1.15:36516 dest: /172.20.1.17:9866
2025-03-26 02:24:33,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742039_1215 src: /172.20.1.16:44986 dest: /172.20.1.15:9866
2025-03-26 02:24:33,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36516, dest: /172.20.1.17:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742039_1215, duration(ns): 883830
2025-03-26 02:24:33,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44986, dest: /172.20.1.15:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742039_1215, duration(ns): 1276488
2025-03-26 02:24:33,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742039_1215, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,555 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/file1.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47348, dest: /172.20.1.16:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742039_1215, duration(ns): 1504056
2025-03-26 02:24:33,555 INFO terminating
2025-03-26 02:24:33,555 INFO terminating
2025-03-26 02:24:33,559 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742040_1216, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/dir1/file3.json._COPYING_
2025-03-26 02:24:33,559 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,559 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742040_1216 src: /172.20.1.14:36882 dest: /172.20.1.17:9866
2025-03-26 02:24:33,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742040_1216 src: /172.20.1.16:44992 dest: /172.20.1.15:9866
2025-03-26 02:24:33,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742040_1216 src: /172.20.1.17:60212 dest: /172.20.1.16:9866
2025-03-26 02:24:33,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:44992, dest: /172.20.1.15:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742040_1216, duration(ns): 990868
2025-03-26 02:24:33,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60212, dest: /172.20.1.16:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742040_1216, duration(ns): 1169410
2025-03-26 02:24:33,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742040_1216, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,564 INFO terminating
2025-03-26 02:24:33,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36882, dest: /172.20.1.17:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742040_1216, duration(ns): 1365261
2025-03-26 02:24:33,565 INFO terminating
2025-03-26 02:24:33,566 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/file3.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,572 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742041_1217, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/dir1/dir2/file2.parquet._COPYING_
2025-03-26 02:24:33,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742041_1217 src: /172.20.1.14:36886 dest: /172.20.1.17:9866
2025-03-26 02:24:33,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742041_1217 src: /172.20.1.17:38522 dest: /172.20.1.15:9866
2025-03-26 02:24:33,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742041_1217 src: /172.20.1.15:38654 dest: /172.20.1.16:9866
2025-03-26 02:24:33,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38654, dest: /172.20.1.16:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742041_1217, duration(ns): 21713529
2025-03-26 02:24:33,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742041_1217, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36886, dest: /172.20.1.17:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742041_1217, duration(ns): 22440031
2025-03-26 02:24:33,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38522, dest: /172.20.1.15:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742041_1217, duration(ns): 22188561
2025-03-26 02:24:33,598 INFO terminating
2025-03-26 02:24:33,598 INFO terminating
2025-03-26 02:24:33,599 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/dir2/file2.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,602 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742042_1218, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/user.avsc._COPYING_
2025-03-26 02:24:33,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742042_1218 src: /172.20.1.14:47362 dest: /172.20.1.16:9866
2025-03-26 02:24:33,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742042_1218 src: /172.20.1.16:54594 dest: /172.20.1.17:9866
2025-03-26 02:24:33,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742042_1218 src: /172.20.1.17:38528 dest: /172.20.1.15:9866
2025-03-26 02:24:33,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38528, dest: /172.20.1.15:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742042_1218, duration(ns): 1465431
2025-03-26 02:24:33,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742042_1218, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47362, dest: /172.20.1.16:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742042_1218, duration(ns): 1883285
2025-03-26 02:24:33,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54594, dest: /172.20.1.17:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742042_1218, duration(ns): 1566968
2025-03-26 02:24:33,608 INFO terminating
2025-03-26 02:24:33,608 INFO terminating
2025-03-26 02:24:33,609 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/user.avsc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742043_1219, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/people.csv._COPYING_
2025-03-26 02:24:33,612 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,612 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742043_1219 src: /172.20.1.14:42494 dest: /172.20.1.15:9866
2025-03-26 02:24:33,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742043_1219 src: /172.20.1.15:36526 dest: /172.20.1.17:9866
2025-03-26 02:24:33,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742043_1219 src: /172.20.1.17:60214 dest: /172.20.1.16:9866
2025-03-26 02:24:33,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60214, dest: /172.20.1.16:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742043_1219, duration(ns): 982301
2025-03-26 02:24:33,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42494, dest: /172.20.1.15:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742043_1219, duration(ns): 1866635
2025-03-26 02:24:33,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36526, dest: /172.20.1.17:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742043_1219, duration(ns): 1302757
2025-03-26 02:24:33,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742043_1219, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,618 INFO terminating
2025-03-26 02:24:33,618 INFO terminating
2025-03-26 02:24:33,619 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742044_1220, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/full_user.avsc._COPYING_
2025-03-26 02:24:33,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742044_1220 src: /172.20.1.14:47366 dest: /172.20.1.16:9866
2025-03-26 02:24:33,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742044_1220 src: /172.20.1.16:54596 dest: /172.20.1.17:9866
2025-03-26 02:24:33,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742044_1220 src: /172.20.1.17:38534 dest: /172.20.1.15:9866
2025-03-26 02:24:33,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54596, dest: /172.20.1.17:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742044_1220, duration(ns): 1218355
2025-03-26 02:24:33,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38534, dest: /172.20.1.15:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742044_1220, duration(ns): 1093142
2025-03-26 02:24:33,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742044_1220, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,634 INFO terminating
2025-03-26 02:24:33,635 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/full_user.avsc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47366, dest: /172.20.1.16:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742044_1220, duration(ns): 1663323
2025-03-26 02:24:33,635 INFO terminating
2025-03-26 02:24:33,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742045_1221, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/users.avro._COPYING_
2025-03-26 02:24:33,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742045_1221 src: /172.20.1.14:42500 dest: /172.20.1.15:9866
2025-03-26 02:24:33,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742045_1221 src: /172.20.1.15:38656 dest: /172.20.1.16:9866
2025-03-26 02:24:33,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742045_1221 src: /172.20.1.16:54602 dest: /172.20.1.17:9866
2025-03-26 02:24:33,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54602, dest: /172.20.1.17:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742045_1221, duration(ns): 815324
2025-03-26 02:24:33,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742045_1221, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42500, dest: /172.20.1.15:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742045_1221, duration(ns): 1935026
2025-03-26 02:24:33,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38656, dest: /172.20.1.16:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742045_1221, duration(ns): 1187889
2025-03-26 02:24:33,646 INFO terminating
2025-03-26 02:24:33,646 INFO terminating
2025-03-26 02:24:33,647 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.avro._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742046_1222, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider._COPYING_
2025-03-26 02:24:33,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742046_1222 src: /172.20.1.14:36898 dest: /172.20.1.17:9866
2025-03-26 02:24:33,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742046_1222 src: /172.20.1.17:60216 dest: /172.20.1.16:9866
2025-03-26 02:24:33,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742046_1222 src: /172.20.1.16:45004 dest: /172.20.1.15:9866
2025-03-26 02:24:33,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45004, dest: /172.20.1.15:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742046_1222, duration(ns): 2673626
2025-03-26 02:24:33,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60216, dest: /172.20.1.16:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742046_1222, duration(ns): 1704485
2025-03-26 02:24:33,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742046_1222, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,661 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36898, dest: /172.20.1.17:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742046_1222, duration(ns): 2314751
2025-03-26 02:24:33,661 INFO terminating
2025-03-26 02:24:33,661 INFO terminating
2025-03-26 02:24:33,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742047_1223, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider._COPYING_
2025-03-26 02:24:33,665 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,665 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742047_1223 src: /172.20.1.14:36906 dest: /172.20.1.17:9866
2025-03-26 02:24:33,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742047_1223 src: /172.20.1.17:38550 dest: /172.20.1.15:9866
2025-03-26 02:24:33,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742047_1223 src: /172.20.1.15:38662 dest: /172.20.1.16:9866
2025-03-26 02:24:33,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38662, dest: /172.20.1.16:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742047_1223, duration(ns): 825271
2025-03-26 02:24:33,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36906, dest: /172.20.1.17:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742047_1223, duration(ns): 1331013
2025-03-26 02:24:33,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38550, dest: /172.20.1.15:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742047_1223, duration(ns): 1282657
2025-03-26 02:24:33,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742047_1223, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,670 INFO terminating
2025-03-26 02:24:33,670 INFO terminating
2025-03-26 02:24:33,671 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742048_1224, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/users.parquet._COPYING_
2025-03-26 02:24:33,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742048_1224 src: /172.20.1.14:36918 dest: /172.20.1.17:9866
2025-03-26 02:24:33,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742048_1224 src: /172.20.1.16:45014 dest: /172.20.1.15:9866
2025-03-26 02:24:33,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742048_1224 src: /172.20.1.17:60224 dest: /172.20.1.16:9866
2025-03-26 02:24:33,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45014, dest: /172.20.1.15:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742048_1224, duration(ns): 1017566
2025-03-26 02:24:33,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742048_1224, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60224, dest: /172.20.1.16:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742048_1224, duration(ns): 1065832
2025-03-26 02:24:33,683 INFO terminating
2025-03-26 02:24:33,684 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36918, dest: /172.20.1.17:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742048_1224, duration(ns): 4169720
2025-03-26 02:24:33,684 INFO terminating
2025-03-26 02:24:33,688 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742049_1225, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/users.orc._COPYING_
2025-03-26 02:24:33,688 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,688 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742049_1225 src: /172.20.1.14:47378 dest: /172.20.1.16:9866
2025-03-26 02:24:33,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742049_1225 src: /172.20.1.16:45028 dest: /172.20.1.15:9866
2025-03-26 02:24:33,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742049_1225 src: /172.20.1.15:36542 dest: /172.20.1.17:9866
2025-03-26 02:24:33,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36542, dest: /172.20.1.17:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742049_1225, duration(ns): 885947
2025-03-26 02:24:33,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45028, dest: /172.20.1.15:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742049_1225, duration(ns): 1592049
2025-03-26 02:24:33,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742049_1225, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,693 INFO terminating
2025-03-26 02:24:33,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47378, dest: /172.20.1.16:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742049_1225, duration(ns): 1645785
2025-03-26 02:24:33,694 INFO terminating
2025-03-26 02:24:33,695 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.orc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,698 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742050_1226, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/people.txt._COPYING_
2025-03-26 02:24:33,698 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,698 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742050_1226 src: /172.20.1.14:47386 dest: /172.20.1.16:9866
2025-03-26 02:24:33,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742050_1226 src: /172.20.1.16:54606 dest: /172.20.1.17:9866
2025-03-26 02:24:33,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742050_1226 src: /172.20.1.17:38552 dest: /172.20.1.15:9866
2025-03-26 02:24:33,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54606, dest: /172.20.1.17:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742050_1226, duration(ns): 1510037
2025-03-26 02:24:33,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38552, dest: /172.20.1.15:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742050_1226, duration(ns): 984936
2025-03-26 02:24:33,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742050_1226, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,704 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47386, dest: /172.20.1.16:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742050_1226, duration(ns): 1772401
2025-03-26 02:24:33,704 INFO terminating
2025-03-26 02:24:33,704 INFO terminating
2025-03-26 02:24:33,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742051_1227, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/resources/people.json._COPYING_
2025-03-26 02:24:33,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742051_1227 src: /172.20.1.14:36932 dest: /172.20.1.17:9866
2025-03-26 02:24:33,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742051_1227 src: /172.20.1.17:60240 dest: /172.20.1.16:9866
2025-03-26 02:24:33,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742051_1227 src: /172.20.1.16:45042 dest: /172.20.1.15:9866
2025-03-26 02:24:33,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45042, dest: /172.20.1.15:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742051_1227, duration(ns): 995535
2025-03-26 02:24:33,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60240, dest: /172.20.1.16:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742051_1227, duration(ns): 2315905
2025-03-26 02:24:33,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742051_1227, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,714 INFO terminating
2025-03-26 02:24:33,715 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36932, dest: /172.20.1.17:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742051_1227, duration(ns): 2667036
2025-03-26 02:24:33,715 INFO terminating
2025-03-26 02:24:33,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742052_1228, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/resources/employees.json._COPYING_
2025-03-26 02:24:33,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742052_1228 src: /172.20.1.14:47390 dest: /172.20.1.16:9866
2025-03-26 02:24:33,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742052_1228 src: /172.20.1.16:45054 dest: /172.20.1.15:9866
2025-03-26 02:24:33,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742052_1228 src: /172.20.1.15:36550 dest: /172.20.1.17:9866
2025-03-26 02:24:33,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36550, dest: /172.20.1.17:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742052_1228, duration(ns): 977188
2025-03-26 02:24:33,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45054, dest: /172.20.1.15:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742052_1228, duration(ns): 1805163
2025-03-26 02:24:33,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742052_1228, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,725 INFO terminating
2025-03-26 02:24:33,726 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/employees.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47390, dest: /172.20.1.16:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742052_1228, duration(ns): 2167641
2025-03-26 02:24:33,726 INFO terminating
2025-03-26 02:24:33,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742053_1229, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala._COPYING_
2025-03-26 02:24:33,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742053_1229 src: /172.20.1.14:42514 dest: /172.20.1.15:9866
2025-03-26 02:24:33,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742053_1229 src: /172.20.1.15:38668 dest: /172.20.1.16:9866
2025-03-26 02:24:33,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742053_1229 src: /172.20.1.16:54610 dest: /172.20.1.17:9866
2025-03-26 02:24:33,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38668, dest: /172.20.1.16:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742053_1229, duration(ns): 1264233
2025-03-26 02:24:33,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54610, dest: /172.20.1.17:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742053_1229, duration(ns): 973064
2025-03-26 02:24:33,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742053_1229, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42514, dest: /172.20.1.15:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742053_1229, duration(ns): 2008566
2025-03-26 02:24:33,744 INFO terminating
2025-03-26 02:24:33,744 INFO terminating
2025-03-26 02:24:33,752 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742054_1230, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala._COPYING_
2025-03-26 02:24:33,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742054_1230 src: /172.20.1.14:36934 dest: /172.20.1.17:9866
2025-03-26 02:24:33,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742054_1230 src: /172.20.1.17:60254 dest: /172.20.1.16:9866
2025-03-26 02:24:33,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742054_1230 src: /172.20.1.16:45070 dest: /172.20.1.15:9866
2025-03-26 02:24:33,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45070, dest: /172.20.1.15:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742054_1230, duration(ns): 998919
2025-03-26 02:24:33,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742054_1230, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36934, dest: /172.20.1.17:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742054_1230, duration(ns): 1543044
2025-03-26 02:24:33,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60254, dest: /172.20.1.16:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742054_1230, duration(ns): 1222080
2025-03-26 02:24:33,757 INFO terminating
2025-03-26 02:24:33,757 INFO terminating
2025-03-26 02:24:33,758 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,761 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742055_1231, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_
2025-03-26 02:24:33,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742055_1231 src: /172.20.1.14:42522 dest: /172.20.1.15:9866
2025-03-26 02:24:33,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742055_1231 src: /172.20.1.15:36566 dest: /172.20.1.17:9866
2025-03-26 02:24:33,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742055_1231 src: /172.20.1.17:60270 dest: /172.20.1.16:9866
2025-03-26 02:24:33,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60270, dest: /172.20.1.16:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742055_1231, duration(ns): 712285
2025-03-26 02:24:33,766 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42522, dest: /172.20.1.15:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742055_1231, duration(ns): 1562258
2025-03-26 02:24:33,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36566, dest: /172.20.1.17:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742055_1231, duration(ns): 1215971
2025-03-26 02:24:33,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742055_1231, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,766 INFO terminating
2025-03-26 02:24:33,766 INFO terminating
2025-03-26 02:24:33,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742056_1232, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala._COPYING_
2025-03-26 02:24:33,771 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,771 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742056_1232 src: /172.20.1.14:47404 dest: /172.20.1.16:9866
2025-03-26 02:24:33,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742056_1232 src: /172.20.1.16:45076 dest: /172.20.1.15:9866
2025-03-26 02:24:33,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742056_1232 src: /172.20.1.15:36574 dest: /172.20.1.17:9866
2025-03-26 02:24:33,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36574, dest: /172.20.1.17:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742056_1232, duration(ns): 923719
2025-03-26 02:24:33,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742056_1232, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47404, dest: /172.20.1.16:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742056_1232, duration(ns): 2139078
2025-03-26 02:24:33,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45076, dest: /172.20.1.15:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742056_1232, duration(ns): 1555450
2025-03-26 02:24:33,779 INFO terminating
2025-03-26 02:24:33,779 INFO terminating
2025-03-26 02:24:33,780 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,783 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742057_1233, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala._COPYING_
2025-03-26 02:24:33,783 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,783 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742057_1233 src: /172.20.1.14:36942 dest: /172.20.1.17:9866
2025-03-26 02:24:33,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742057_1233 src: /172.20.1.17:38554 dest: /172.20.1.15:9866
2025-03-26 02:24:33,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742057_1233 src: /172.20.1.15:38682 dest: /172.20.1.16:9866
2025-03-26 02:24:33,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38682, dest: /172.20.1.16:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742057_1233, duration(ns): 778589
2025-03-26 02:24:33,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38554, dest: /172.20.1.15:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742057_1233, duration(ns): 1129122
2025-03-26 02:24:33,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742057_1233, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,787 INFO terminating
2025-03-26 02:24:33,788 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36942, dest: /172.20.1.17:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742057_1233, duration(ns): 1293066
2025-03-26 02:24:33,788 INFO terminating
2025-03-26 02:24:33,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742058_1234, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala._COPYING_
2025-03-26 02:24:33,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742058_1234 src: /172.20.1.14:42538 dest: /172.20.1.15:9866
2025-03-26 02:24:33,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742058_1234 src: /172.20.1.15:38688 dest: /172.20.1.16:9866
2025-03-26 02:24:33,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742058_1234 src: /172.20.1.16:54626 dest: /172.20.1.17:9866
2025-03-26 02:24:33,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38688, dest: /172.20.1.16:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742058_1234, duration(ns): 1195732
2025-03-26 02:24:33,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54626, dest: /172.20.1.17:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742058_1234, duration(ns): 777077
2025-03-26 02:24:33,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742058_1234, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,796 INFO terminating
2025-03-26 02:24:33,797 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42538, dest: /172.20.1.15:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742058_1234, duration(ns): 1605025
2025-03-26 02:24:33,797 INFO terminating
2025-03-26 02:24:33,800 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742059_1235, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala._COPYING_
2025-03-26 02:24:33,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742059_1235 src: /172.20.1.14:47408 dest: /172.20.1.16:9866
2025-03-26 02:24:33,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742059_1235 src: /172.20.1.16:45086 dest: /172.20.1.15:9866
2025-03-26 02:24:33,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742059_1235 src: /172.20.1.15:36582 dest: /172.20.1.17:9866
2025-03-26 02:24:33,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36582, dest: /172.20.1.17:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742059_1235, duration(ns): 734425
2025-03-26 02:24:33,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742059_1235, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47408, dest: /172.20.1.16:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742059_1235, duration(ns): 1296557
2025-03-26 02:24:33,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45086, dest: /172.20.1.15:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742059_1235, duration(ns): 1061755
2025-03-26 02:24:33,805 INFO terminating
2025-03-26 02:24:33,805 INFO terminating
2025-03-26 02:24:33,806 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742060_1236, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala._COPYING_
2025-03-26 02:24:33,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742060_1236 src: /172.20.1.14:36950 dest: /172.20.1.17:9866
2025-03-26 02:24:33,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742060_1236 src: /172.20.1.17:60284 dest: /172.20.1.16:9866
2025-03-26 02:24:33,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742060_1236 src: /172.20.1.16:45090 dest: /172.20.1.15:9866
2025-03-26 02:24:33,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45090, dest: /172.20.1.15:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742060_1236, duration(ns): 6027578
2025-03-26 02:24:33,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742060_1236, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36950, dest: /172.20.1.17:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742060_1236, duration(ns): 6889016
2025-03-26 02:24:33,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60284, dest: /172.20.1.16:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742060_1236, duration(ns): 6350358
2025-03-26 02:24:33,819 INFO terminating
2025-03-26 02:24:33,820 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,820 INFO terminating
2025-03-26 02:24:33,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742061_1237, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala._COPYING_
2025-03-26 02:24:33,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742061_1237 src: /172.20.1.14:47422 dest: /172.20.1.16:9866
2025-03-26 02:24:33,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742061_1237 src: /172.20.1.16:45102 dest: /172.20.1.15:9866
2025-03-26 02:24:33,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742061_1237 src: /172.20.1.15:36592 dest: /172.20.1.17:9866
2025-03-26 02:24:33,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36592, dest: /172.20.1.17:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742061_1237, duration(ns): 1004648
2025-03-26 02:24:33,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45102, dest: /172.20.1.15:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742061_1237, duration(ns): 1377168
2025-03-26 02:24:33,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742061_1237, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47422, dest: /172.20.1.16:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742061_1237, duration(ns): 2261996
2025-03-26 02:24:33,830 INFO terminating
2025-03-26 02:24:33,831 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,831 INFO terminating
2025-03-26 02:24:33,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,838 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742062_1238, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala._COPYING_
2025-03-26 02:24:33,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742062_1238 src: /172.20.1.14:42542 dest: /172.20.1.15:9866
2025-03-26 02:24:33,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742062_1238 src: /172.20.1.15:36600 dest: /172.20.1.17:9866
2025-03-26 02:24:33,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742062_1238 src: /172.20.1.17:60290 dest: /172.20.1.16:9866
2025-03-26 02:24:33,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36600, dest: /172.20.1.17:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742062_1238, duration(ns): 1105074
2025-03-26 02:24:33,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60290, dest: /172.20.1.16:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742062_1238, duration(ns): 751177
2025-03-26 02:24:33,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742062_1238, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,842 INFO terminating
2025-03-26 02:24:33,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42542, dest: /172.20.1.15:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742062_1238, duration(ns): 1539259
2025-03-26 02:24:33,843 INFO terminating
2025-03-26 02:24:33,844 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,848 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742063_1239, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala._COPYING_
2025-03-26 02:24:33,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742063_1239 src: /172.20.1.14:36954 dest: /172.20.1.17:9866
2025-03-26 02:24:33,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742063_1239 src: /172.20.1.16:45110 dest: /172.20.1.15:9866
2025-03-26 02:24:33,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742063_1239 src: /172.20.1.17:60304 dest: /172.20.1.16:9866
2025-03-26 02:24:33,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45110, dest: /172.20.1.15:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742063_1239, duration(ns): 868742
2025-03-26 02:24:33,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742063_1239, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60304, dest: /172.20.1.16:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742063_1239, duration(ns): 1332534
2025-03-26 02:24:33,854 INFO terminating
2025-03-26 02:24:33,855 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36954, dest: /172.20.1.17:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742063_1239, duration(ns): 2092603
2025-03-26 02:24:33,855 INFO terminating
2025-03-26 02:24:33,859 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742064_1240, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala._COPYING_
2025-03-26 02:24:33,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742064_1240 src: /172.20.1.14:36964 dest: /172.20.1.17:9866
2025-03-26 02:24:33,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742064_1240 src: /172.20.1.17:38568 dest: /172.20.1.15:9866
2025-03-26 02:24:33,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742064_1240 src: /172.20.1.15:38690 dest: /172.20.1.16:9866
2025-03-26 02:24:33,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38690, dest: /172.20.1.16:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742064_1240, duration(ns): 1341319
2025-03-26 02:24:33,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38568, dest: /172.20.1.15:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742064_1240, duration(ns): 1870464
2025-03-26 02:24:33,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742064_1240, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36964, dest: /172.20.1.17:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742064_1240, duration(ns): 2158409
2025-03-26 02:24:33,871 INFO terminating
2025-03-26 02:24:33,871 INFO terminating
2025-03-26 02:24:33,872 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,876 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742065_1241, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala._COPYING_
2025-03-26 02:24:33,876 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,876 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742065_1241 src: /172.20.1.14:36974 dest: /172.20.1.17:9866
2025-03-26 02:24:33,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742065_1241 src: /172.20.1.17:60312 dest: /172.20.1.16:9866
2025-03-26 02:24:33,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742065_1241 src: /172.20.1.16:45122 dest: /172.20.1.15:9866
2025-03-26 02:24:33,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45122, dest: /172.20.1.15:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742065_1241, duration(ns): 1061702
2025-03-26 02:24:33,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60312, dest: /172.20.1.16:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742065_1241, duration(ns): 1254855
2025-03-26 02:24:33,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742065_1241, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,881 INFO terminating
2025-03-26 02:24:33,882 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36974, dest: /172.20.1.17:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742065_1241, duration(ns): 1611764
2025-03-26 02:24:33,882 INFO terminating
2025-03-26 02:24:33,887 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742066_1242, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala._COPYING_
2025-03-26 02:24:33,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742066_1242 src: /172.20.1.14:36984 dest: /172.20.1.17:9866
2025-03-26 02:24:33,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742066_1242 src: /172.20.1.17:60316 dest: /172.20.1.16:9866
2025-03-26 02:24:33,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742066_1242 src: /172.20.1.16:45124 dest: /172.20.1.15:9866
2025-03-26 02:24:33,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45124, dest: /172.20.1.15:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742066_1242, duration(ns): 1662350
2025-03-26 02:24:33,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742066_1242, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60316, dest: /172.20.1.16:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742066_1242, duration(ns): 2437075
2025-03-26 02:24:33,894 INFO terminating
2025-03-26 02:24:33,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:36984, dest: /172.20.1.17:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742066_1242, duration(ns): 4699933
2025-03-26 02:24:33,897 INFO terminating
2025-03-26 02:24:33,898 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742067_1243, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala._COPYING_
2025-03-26 02:24:33,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742067_1243 src: /172.20.1.14:47432 dest: /172.20.1.16:9866
2025-03-26 02:24:33,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742067_1243 src: /172.20.1.15:36612 dest: /172.20.1.17:9866
2025-03-26 02:24:33,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742067_1243 src: /172.20.1.16:45130 dest: /172.20.1.15:9866
2025-03-26 02:24:33,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36612, dest: /172.20.1.17:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742067_1243, duration(ns): 1476021
2025-03-26 02:24:33,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45130, dest: /172.20.1.15:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742067_1243, duration(ns): 1886354
2025-03-26 02:24:33,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742067_1243, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47432, dest: /172.20.1.16:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742067_1243, duration(ns): 3638230
2025-03-26 02:24:33,916 INFO terminating
2025-03-26 02:24:33,916 INFO terminating
2025-03-26 02:24:33,917 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742068_1244, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala._COPYING_
2025-03-26 02:24:33,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742068_1244 src: /172.20.1.14:37000 dest: /172.20.1.17:9866
2025-03-26 02:24:33,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742068_1244 src: /172.20.1.16:45136 dest: /172.20.1.15:9866
2025-03-26 02:24:33,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742068_1244 src: /172.20.1.17:60322 dest: /172.20.1.16:9866
2025-03-26 02:24:33,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45136, dest: /172.20.1.15:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742068_1244, duration(ns): 1064557
2025-03-26 02:24:33,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60322, dest: /172.20.1.16:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742068_1244, duration(ns): 1231390
2025-03-26 02:24:33,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742068_1244, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37000, dest: /172.20.1.17:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742068_1244, duration(ns): 1634020
2025-03-26 02:24:33,927 INFO terminating
2025-03-26 02:24:33,927 INFO terminating
2025-03-26 02:24:33,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742069_1245, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala._COPYING_
2025-03-26 02:24:33,932 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,932 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742069_1245 src: /172.20.1.14:47446 dest: /172.20.1.16:9866
2025-03-26 02:24:33,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742069_1245 src: /172.20.1.16:45142 dest: /172.20.1.15:9866
2025-03-26 02:24:33,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742069_1245 src: /172.20.1.15:36616 dest: /172.20.1.17:9866
2025-03-26 02:24:33,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36616, dest: /172.20.1.17:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742069_1245, duration(ns): 911918
2025-03-26 02:24:33,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45142, dest: /172.20.1.15:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742069_1245, duration(ns): 1281977
2025-03-26 02:24:33,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742069_1245, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,938 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47446, dest: /172.20.1.16:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742069_1245, duration(ns): 1444321
2025-03-26 02:24:33,938 INFO terminating
2025-03-26 02:24:33,938 INFO terminating
2025-03-26 02:24:33,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742070_1246, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala._COPYING_
2025-03-26 02:24:33,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742070_1246 src: /172.20.1.14:37004 dest: /172.20.1.17:9866
2025-03-26 02:24:33,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742070_1246 src: /172.20.1.15:38704 dest: /172.20.1.16:9866
2025-03-26 02:24:33,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742070_1246 src: /172.20.1.17:38578 dest: /172.20.1.15:9866
2025-03-26 02:24:33,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38704, dest: /172.20.1.16:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742070_1246, duration(ns): 3213796
2025-03-26 02:24:33,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742070_1246, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38578, dest: /172.20.1.15:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742070_1246, duration(ns): 5947501
2025-03-26 02:24:33,955 INFO terminating
2025-03-26 02:24:33,956 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37004, dest: /172.20.1.17:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742070_1246, duration(ns): 8227859
2025-03-26 02:24:33,956 INFO terminating
2025-03-26 02:24:33,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742071_1247, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala._COPYING_
2025-03-26 02:24:33,962 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,962 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742071_1247 src: /172.20.1.14:47462 dest: /172.20.1.16:9866
2025-03-26 02:24:33,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742071_1247 src: /172.20.1.16:45152 dest: /172.20.1.15:9866
2025-03-26 02:24:33,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742071_1247 src: /172.20.1.15:36628 dest: /172.20.1.17:9866
2025-03-26 02:24:33,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36628, dest: /172.20.1.17:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742071_1247, duration(ns): 1328457
2025-03-26 02:24:33,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742071_1247, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47462, dest: /172.20.1.16:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742071_1247, duration(ns): 2004337
2025-03-26 02:24:33,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45152, dest: /172.20.1.15:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742071_1247, duration(ns): 1698246
2025-03-26 02:24:33,980 INFO terminating
2025-03-26 02:24:33,980 INFO terminating
2025-03-26 02:24:33,981 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742072_1248, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala._COPYING_
2025-03-26 02:24:33,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742072_1248 src: /172.20.1.14:47476 dest: /172.20.1.16:9866
2025-03-26 02:24:33,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742072_1248 src: /172.20.1.16:54632 dest: /172.20.1.17:9866
2025-03-26 02:24:33,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742072_1248 src: /172.20.1.17:38592 dest: /172.20.1.15:9866
2025-03-26 02:24:33,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54632, dest: /172.20.1.17:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742072_1248, duration(ns): 1155961
2025-03-26 02:24:33,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38592, dest: /172.20.1.15:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742072_1248, duration(ns): 1059958
2025-03-26 02:24:33,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742072_1248, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:33,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47476, dest: /172.20.1.16:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742072_1248, duration(ns): 1456467
2025-03-26 02:24:33,991 INFO terminating
2025-03-26 02:24:33,991 INFO terminating
2025-03-26 02:24:33,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:33,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742073_1249, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala._COPYING_
2025-03-26 02:24:33,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:33,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742073_1249 src: /172.20.1.14:42550 dest: /172.20.1.15:9866
2025-03-26 02:24:34,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742073_1249 src: /172.20.1.15:38720 dest: /172.20.1.16:9866
2025-03-26 02:24:34,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742073_1249 src: /172.20.1.16:54648 dest: /172.20.1.17:9866
2025-03-26 02:24:34,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54648, dest: /172.20.1.17:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742073_1249, duration(ns): 918183
2025-03-26 02:24:34,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742073_1249, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42550, dest: /172.20.1.15:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742073_1249, duration(ns): 1677629
2025-03-26 02:24:34,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38720, dest: /172.20.1.16:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742073_1249, duration(ns): 1246132
2025-03-26 02:24:34,003 INFO terminating
2025-03-26 02:24:34,003 INFO terminating
2025-03-26 02:24:34,004 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742074_1250, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala._COPYING_
2025-03-26 02:24:34,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742074_1250 src: /172.20.1.14:47490 dest: /172.20.1.16:9866
2025-03-26 02:24:34,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742074_1250 src: /172.20.1.16:54664 dest: /172.20.1.17:9866
2025-03-26 02:24:34,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742074_1250 src: /172.20.1.17:38606 dest: /172.20.1.15:9866
2025-03-26 02:24:34,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54664, dest: /172.20.1.17:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742074_1250, duration(ns): 1375770
2025-03-26 02:24:34,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38606, dest: /172.20.1.15:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742074_1250, duration(ns): 1272562
2025-03-26 02:24:34,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742074_1250, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,014 INFO terminating
2025-03-26 02:24:34,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47490, dest: /172.20.1.16:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742074_1250, duration(ns): 1702373
2025-03-26 02:24:34,015 INFO terminating
2025-03-26 02:24:34,016 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,022 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742075_1251, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala._COPYING_
2025-03-26 02:24:34,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742075_1251 src: /172.20.1.14:37012 dest: /172.20.1.17:9866
2025-03-26 02:24:34,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742075_1251 src: /172.20.1.17:60324 dest: /172.20.1.16:9866
2025-03-26 02:24:34,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742075_1251 src: /172.20.1.16:45168 dest: /172.20.1.15:9866
2025-03-26 02:24:34,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45168, dest: /172.20.1.15:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742075_1251, duration(ns): 4603648
2025-03-26 02:24:34,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742075_1251, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60324, dest: /172.20.1.16:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742075_1251, duration(ns): 4789029
2025-03-26 02:24:34,040 INFO terminating
2025-03-26 02:24:34,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37012, dest: /172.20.1.17:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742075_1251, duration(ns): 5200694
2025-03-26 02:24:34,041 INFO terminating
2025-03-26 02:24:34,046 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742076_1252, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala._COPYING_
2025-03-26 02:24:34,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742076_1252 src: /172.20.1.14:37022 dest: /172.20.1.17:9866
2025-03-26 02:24:34,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742076_1252 src: /172.20.1.17:38622 dest: /172.20.1.15:9866
2025-03-26 02:24:34,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742076_1252 src: /172.20.1.15:38736 dest: /172.20.1.16:9866
2025-03-26 02:24:34,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38736, dest: /172.20.1.16:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742076_1252, duration(ns): 9730824
2025-03-26 02:24:34,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38622, dest: /172.20.1.15:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742076_1252, duration(ns): 10914163
2025-03-26 02:24:34,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742076_1252, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37022, dest: /172.20.1.17:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742076_1252, duration(ns): 11108670
2025-03-26 02:24:34,070 INFO terminating
2025-03-26 02:24:34,070 INFO terminating
2025-03-26 02:24:34,071 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742077_1253, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala._COPYING_
2025-03-26 02:24:34,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742077_1253 src: /172.20.1.14:47500 dest: /172.20.1.16:9866
2025-03-26 02:24:34,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742077_1253 src: /172.20.1.16:54668 dest: /172.20.1.17:9866
2025-03-26 02:24:34,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742077_1253 src: /172.20.1.17:38630 dest: /172.20.1.15:9866
2025-03-26 02:24:34,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54668, dest: /172.20.1.17:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742077_1253, duration(ns): 12048381
2025-03-26 02:24:34,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38630, dest: /172.20.1.15:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742077_1253, duration(ns): 10989239
2025-03-26 02:24:34,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742077_1253, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,095 INFO terminating
2025-03-26 02:24:34,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47500, dest: /172.20.1.16:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742077_1253, duration(ns): 12424926
2025-03-26 02:24:34,096 INFO terminating
2025-03-26 02:24:34,097 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742078_1254, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala._COPYING_
2025-03-26 02:24:34,104 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,104 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742078_1254 src: /172.20.1.14:42560 dest: /172.20.1.15:9866
2025-03-26 02:24:34,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742078_1254 src: /172.20.1.15:38748 dest: /172.20.1.16:9866
2025-03-26 02:24:34,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742078_1254 src: /172.20.1.16:54672 dest: /172.20.1.17:9866
2025-03-26 02:24:34,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54672, dest: /172.20.1.17:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742078_1254, duration(ns): 9379663
2025-03-26 02:24:34,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742078_1254, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38748, dest: /172.20.1.16:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742078_1254, duration(ns): 9691232
2025-03-26 02:24:34,119 INFO terminating
2025-03-26 02:24:34,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42560, dest: /172.20.1.15:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742078_1254, duration(ns): 10608142
2025-03-26 02:24:34,120 INFO terminating
2025-03-26 02:24:34,130 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,143 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742079_1255, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala._COPYING_
2025-03-26 02:24:34,143 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,143 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742079_1255 src: /172.20.1.14:37024 dest: /172.20.1.17:9866
2025-03-26 02:24:34,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742079_1255 src: /172.20.1.17:38636 dest: /172.20.1.15:9866
2025-03-26 02:24:34,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742079_1255 src: /172.20.1.15:38752 dest: /172.20.1.16:9866
2025-03-26 02:24:34,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38752, dest: /172.20.1.16:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742079_1255, duration(ns): 9797164
2025-03-26 02:24:34,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38636, dest: /172.20.1.15:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742079_1255, duration(ns): 10182375
2025-03-26 02:24:34,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742079_1255, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,160 INFO terminating
2025-03-26 02:24:34,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37024, dest: /172.20.1.17:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742079_1255, duration(ns): 10467415
2025-03-26 02:24:34,161 INFO terminating
2025-03-26 02:24:34,162 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,167 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,167 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742080_1256, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala._COPYING_
2025-03-26 02:24:34,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742080_1256 src: /172.20.1.14:47514 dest: /172.20.1.16:9866
2025-03-26 02:24:34,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742080_1256 src: /172.20.1.16:45184 dest: /172.20.1.15:9866
2025-03-26 02:24:34,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742080_1256 src: /172.20.1.15:36632 dest: /172.20.1.17:9866
2025-03-26 02:24:34,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36632, dest: /172.20.1.17:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742080_1256, duration(ns): 11162615
2025-03-26 02:24:34,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45184, dest: /172.20.1.15:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742080_1256, duration(ns): 11403198
2025-03-26 02:24:34,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742080_1256, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,198 INFO terminating
2025-03-26 02:24:34,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47514, dest: /172.20.1.16:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742080_1256, duration(ns): 12218881
2025-03-26 02:24:34,199 INFO terminating
2025-03-26 02:24:34,200 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742081_1257, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala._COPYING_
2025-03-26 02:24:34,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742081_1257 src: /172.20.1.14:42576 dest: /172.20.1.15:9866
2025-03-26 02:24:34,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742081_1257 src: /172.20.1.15:36648 dest: /172.20.1.17:9866
2025-03-26 02:24:34,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742081_1257 src: /172.20.1.17:60336 dest: /172.20.1.16:9866
2025-03-26 02:24:34,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60336, dest: /172.20.1.16:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742081_1257, duration(ns): 12323896
2025-03-26 02:24:34,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36648, dest: /172.20.1.17:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742081_1257, duration(ns): 12878528
2025-03-26 02:24:34,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742081_1257, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,239 INFO terminating
2025-03-26 02:24:34,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42576, dest: /172.20.1.15:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742081_1257, duration(ns): 13462375
2025-03-26 02:24:34,240 INFO terminating
2025-03-26 02:24:34,242 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,246 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,246 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,247 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742082_1258, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 02:24:34,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742082_1258 src: /172.20.1.14:42592 dest: /172.20.1.15:9866
2025-03-26 02:24:34,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742082_1258 src: /172.20.1.15:36652 dest: /172.20.1.17:9866
2025-03-26 02:24:34,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742082_1258 src: /172.20.1.17:60342 dest: /172.20.1.16:9866
2025-03-26 02:24:34,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60342, dest: /172.20.1.16:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742082_1258, duration(ns): 9856903
2025-03-26 02:24:34,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742082_1258, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42592, dest: /172.20.1.15:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742082_1258, duration(ns): 11254670
2025-03-26 02:24:34,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36652, dest: /172.20.1.17:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742082_1258, duration(ns): 10219929
2025-03-26 02:24:34,262 INFO terminating
2025-03-26 02:24:34,262 INFO terminating
2025-03-26 02:24:34,263 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742083_1259, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala._COPYING_
2025-03-26 02:24:34,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742083_1259 src: /172.20.1.14:47526 dest: /172.20.1.16:9866
2025-03-26 02:24:34,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742083_1259 src: /172.20.1.16:54674 dest: /172.20.1.17:9866
2025-03-26 02:24:34,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742083_1259 src: /172.20.1.17:38648 dest: /172.20.1.15:9866
2025-03-26 02:24:34,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54674, dest: /172.20.1.17:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742083_1259, duration(ns): 7360584
2025-03-26 02:24:34,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38648, dest: /172.20.1.15:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742083_1259, duration(ns): 7166557
2025-03-26 02:24:34,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742083_1259, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,279 INFO terminating
2025-03-26 02:24:34,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47526, dest: /172.20.1.16:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742083_1259, duration(ns): 7808520
2025-03-26 02:24:34,280 INFO terminating
2025-03-26 02:24:34,281 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,285 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742084_1260, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala._COPYING_
2025-03-26 02:24:34,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742084_1260 src: /172.20.1.14:47536 dest: /172.20.1.16:9866
2025-03-26 02:24:34,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742084_1260 src: /172.20.1.16:45186 dest: /172.20.1.15:9866
2025-03-26 02:24:34,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742084_1260 src: /172.20.1.15:36658 dest: /172.20.1.17:9866
2025-03-26 02:24:34,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36658, dest: /172.20.1.17:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742084_1260, duration(ns): 9740658
2025-03-26 02:24:34,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45186, dest: /172.20.1.15:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742084_1260, duration(ns): 10237087
2025-03-26 02:24:34,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742084_1260, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,299 INFO terminating
2025-03-26 02:24:34,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47536, dest: /172.20.1.16:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742084_1260, duration(ns): 10411082
2025-03-26 02:24:34,300 INFO terminating
2025-03-26 02:24:34,306 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,312 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742085_1261, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala._COPYING_
2025-03-26 02:24:34,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742085_1261 src: /172.20.1.14:47548 dest: /172.20.1.16:9866
2025-03-26 02:24:34,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742085_1261 src: /172.20.1.16:54680 dest: /172.20.1.17:9866
2025-03-26 02:24:34,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742085_1261 src: /172.20.1.17:38654 dest: /172.20.1.15:9866
2025-03-26 02:24:34,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54680, dest: /172.20.1.17:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742085_1261, duration(ns): 9942795
2025-03-26 02:24:34,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38654, dest: /172.20.1.15:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742085_1261, duration(ns): 9871946
2025-03-26 02:24:34,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742085_1261, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,326 INFO terminating
2025-03-26 02:24:34,327 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47548, dest: /172.20.1.16:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742085_1261, duration(ns): 10399220
2025-03-26 02:24:34,327 INFO terminating
2025-03-26 02:24:34,332 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,332 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,333 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742086_1262, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala._COPYING_
2025-03-26 02:24:34,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742086_1262 src: /172.20.1.14:47550 dest: /172.20.1.16:9866
2025-03-26 02:24:34,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742086_1262 src: /172.20.1.16:54688 dest: /172.20.1.17:9866
2025-03-26 02:24:34,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742086_1262 src: /172.20.1.17:38662 dest: /172.20.1.15:9866
2025-03-26 02:24:34,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38662, dest: /172.20.1.15:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742086_1262, duration(ns): 9708069
2025-03-26 02:24:34,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742086_1262, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47550, dest: /172.20.1.16:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742086_1262, duration(ns): 10641667
2025-03-26 02:24:34,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54688, dest: /172.20.1.17:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742086_1262, duration(ns): 9797342
2025-03-26 02:24:34,347 INFO terminating
2025-03-26 02:24:34,348 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,348 INFO terminating
2025-03-26 02:24:34,353 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742087_1263, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala._COPYING_
2025-03-26 02:24:34,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742087_1263 src: /172.20.1.14:37032 dest: /172.20.1.17:9866
2025-03-26 02:24:34,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742087_1263 src: /172.20.1.17:38668 dest: /172.20.1.15:9866
2025-03-26 02:24:34,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742087_1263 src: /172.20.1.15:38758 dest: /172.20.1.16:9866
2025-03-26 02:24:34,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38758, dest: /172.20.1.16:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742087_1263, duration(ns): 10105507
2025-03-26 02:24:34,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742087_1263, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37032, dest: /172.20.1.17:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742087_1263, duration(ns): 10985411
2025-03-26 02:24:34,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38668, dest: /172.20.1.15:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742087_1263, duration(ns): 10572184
2025-03-26 02:24:34,368 INFO terminating
2025-03-26 02:24:34,369 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,369 INFO terminating
2025-03-26 02:24:34,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742088_1264, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala._COPYING_
2025-03-26 02:24:34,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742088_1264 src: /172.20.1.14:47562 dest: /172.20.1.16:9866
2025-03-26 02:24:34,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742088_1264 src: /172.20.1.15:36662 dest: /172.20.1.17:9866
2025-03-26 02:24:34,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742088_1264 src: /172.20.1.16:45194 dest: /172.20.1.15:9866
2025-03-26 02:24:34,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36662, dest: /172.20.1.17:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742088_1264, duration(ns): 15293421
2025-03-26 02:24:34,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45194, dest: /172.20.1.15:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742088_1264, duration(ns): 15818119
2025-03-26 02:24:34,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742088_1264, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,396 INFO terminating
2025-03-26 02:24:34,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47562, dest: /172.20.1.16:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742088_1264, duration(ns): 16008128
2025-03-26 02:24:34,397 INFO terminating
2025-03-26 02:24:34,398 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,402 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742089_1265, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala._COPYING_
2025-03-26 02:24:34,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742089_1265 src: /172.20.1.14:37034 dest: /172.20.1.17:9866
2025-03-26 02:24:34,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742089_1265 src: /172.20.1.17:60354 dest: /172.20.1.16:9866
2025-03-26 02:24:34,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742089_1265 src: /172.20.1.16:45202 dest: /172.20.1.15:9866
2025-03-26 02:24:34,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45202, dest: /172.20.1.15:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742089_1265, duration(ns): 9907930
2025-03-26 02:24:34,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60354, dest: /172.20.1.16:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742089_1265, duration(ns): 10137560
2025-03-26 02:24:34,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742089_1265, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,416 INFO terminating
2025-03-26 02:24:34,417 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37034, dest: /172.20.1.17:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742089_1265, duration(ns): 10571397
2025-03-26 02:24:34,417 INFO terminating
2025-03-26 02:24:34,423 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742090_1266, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala._COPYING_
2025-03-26 02:24:34,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742090_1266 src: /172.20.1.14:37042 dest: /172.20.1.17:9866
2025-03-26 02:24:34,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742090_1266 src: /172.20.1.17:60356 dest: /172.20.1.16:9866
2025-03-26 02:24:34,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742090_1266 src: /172.20.1.16:45206 dest: /172.20.1.15:9866
2025-03-26 02:24:34,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45206, dest: /172.20.1.15:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742090_1266, duration(ns): 4660106
2025-03-26 02:24:34,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60356, dest: /172.20.1.16:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742090_1266, duration(ns): 4787945
2025-03-26 02:24:34,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742090_1266, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,432 INFO terminating
2025-03-26 02:24:34,433 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37042, dest: /172.20.1.17:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742090_1266, duration(ns): 5182482
2025-03-26 02:24:34,433 INFO terminating
2025-03-26 02:24:34,438 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,438 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742091_1267, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala._COPYING_
2025-03-26 02:24:34,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742091_1267 src: /172.20.1.14:42594 dest: /172.20.1.15:9866
2025-03-26 02:24:34,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742091_1267 src: /172.20.1.15:38774 dest: /172.20.1.16:9866
2025-03-26 02:24:34,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742091_1267 src: /172.20.1.16:54692 dest: /172.20.1.17:9866
2025-03-26 02:24:34,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54692, dest: /172.20.1.17:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742091_1267, duration(ns): 1322708
2025-03-26 02:24:34,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742091_1267, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42594, dest: /172.20.1.15:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742091_1267, duration(ns): 2002450
2025-03-26 02:24:34,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38774, dest: /172.20.1.16:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742091_1267, duration(ns): 1511129
2025-03-26 02:24:34,444 INFO terminating
2025-03-26 02:24:34,444 INFO terminating
2025-03-26 02:24:34,445 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742092_1268, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala._COPYING_
2025-03-26 02:24:34,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742092_1268 src: /172.20.1.14:47572 dest: /172.20.1.16:9866
2025-03-26 02:24:34,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742092_1268 src: /172.20.1.16:54704 dest: /172.20.1.17:9866
2025-03-26 02:24:34,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742092_1268 src: /172.20.1.17:38680 dest: /172.20.1.15:9866
2025-03-26 02:24:34,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38680, dest: /172.20.1.15:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742092_1268, duration(ns): 13741559
2025-03-26 02:24:34,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54704, dest: /172.20.1.17:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742092_1268, duration(ns): 14347382
2025-03-26 02:24:34,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742092_1268, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,469 INFO terminating
2025-03-26 02:24:34,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47572, dest: /172.20.1.16:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742092_1268, duration(ns): 14802244
2025-03-26 02:24:34,470 INFO terminating
2025-03-26 02:24:34,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742093_1269, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala._COPYING_
2025-03-26 02:24:34,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742093_1269 src: /172.20.1.14:42604 dest: /172.20.1.15:9866
2025-03-26 02:24:34,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742093_1269 src: /172.20.1.15:36664 dest: /172.20.1.17:9866
2025-03-26 02:24:34,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742093_1269 src: /172.20.1.17:60358 dest: /172.20.1.16:9866
2025-03-26 02:24:34,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36664, dest: /172.20.1.17:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742093_1269, duration(ns): 10522676
2025-03-26 02:24:34,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60358, dest: /172.20.1.16:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742093_1269, duration(ns): 10120229
2025-03-26 02:24:34,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742093_1269, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42604, dest: /172.20.1.15:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742093_1269, duration(ns): 11123647
2025-03-26 02:24:34,514 INFO terminating
2025-03-26 02:24:34,514 INFO terminating
2025-03-26 02:24:34,515 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,528 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742094_1270, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala._COPYING_
2025-03-26 02:24:34,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742094_1270 src: /172.20.1.14:37054 dest: /172.20.1.17:9866
2025-03-26 02:24:34,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742094_1270 src: /172.20.1.16:45216 dest: /172.20.1.15:9866
2025-03-26 02:24:34,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742094_1270 src: /172.20.1.17:60362 dest: /172.20.1.16:9866
2025-03-26 02:24:34,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45216, dest: /172.20.1.15:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742094_1270, duration(ns): 10374242
2025-03-26 02:24:34,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60362, dest: /172.20.1.16:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742094_1270, duration(ns): 11014128
2025-03-26 02:24:34,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742094_1270, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37054, dest: /172.20.1.17:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742094_1270, duration(ns): 11487375
2025-03-26 02:24:34,544 INFO terminating
2025-03-26 02:24:34,544 INFO terminating
2025-03-26 02:24:34,545 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,550 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742095_1271, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala._COPYING_
2025-03-26 02:24:34,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742095_1271 src: /172.20.1.14:37058 dest: /172.20.1.17:9866
2025-03-26 02:24:34,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742095_1271 src: /172.20.1.15:38784 dest: /172.20.1.16:9866
2025-03-26 02:24:34,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742095_1271 src: /172.20.1.17:38694 dest: /172.20.1.15:9866
2025-03-26 02:24:34,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38784, dest: /172.20.1.16:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742095_1271, duration(ns): 1643067
2025-03-26 02:24:34,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38694, dest: /172.20.1.15:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742095_1271, duration(ns): 2086114
2025-03-26 02:24:34,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742095_1271, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,556 INFO terminating
2025-03-26 02:24:34,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37058, dest: /172.20.1.17:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742095_1271, duration(ns): 2315962
2025-03-26 02:24:34,557 INFO terminating
2025-03-26 02:24:34,558 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,563 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742096_1272, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala._COPYING_
2025-03-26 02:24:34,563 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742096_1272 src: /172.20.1.14:42610 dest: /172.20.1.15:9866
2025-03-26 02:24:34,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742096_1272 src: /172.20.1.15:38792 dest: /172.20.1.16:9866
2025-03-26 02:24:34,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742096_1272 src: /172.20.1.16:54716 dest: /172.20.1.17:9866
2025-03-26 02:24:34,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54716, dest: /172.20.1.17:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742096_1272, duration(ns): 1241212
2025-03-26 02:24:34,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742096_1272, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38792, dest: /172.20.1.16:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742096_1272, duration(ns): 1638203
2025-03-26 02:24:34,569 INFO terminating
2025-03-26 02:24:34,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42610, dest: /172.20.1.15:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742096_1272, duration(ns): 2514359
2025-03-26 02:24:34,570 INFO terminating
2025-03-26 02:24:34,571 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742097_1273, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala._COPYING_
2025-03-26 02:24:34,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742097_1273 src: /172.20.1.14:42622 dest: /172.20.1.15:9866
2025-03-26 02:24:34,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742097_1273 src: /172.20.1.15:36680 dest: /172.20.1.17:9866
2025-03-26 02:24:34,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742097_1273 src: /172.20.1.17:60366 dest: /172.20.1.16:9866
2025-03-26 02:24:34,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60366, dest: /172.20.1.16:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742097_1273, duration(ns): 1410783
2025-03-26 02:24:34,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42622, dest: /172.20.1.15:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742097_1273, duration(ns): 2255013
2025-03-26 02:24:34,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36680, dest: /172.20.1.17:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742097_1273, duration(ns): 1716645
2025-03-26 02:24:34,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742097_1273, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,582 INFO terminating
2025-03-26 02:24:34,583 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,583 INFO terminating
2025-03-26 02:24:34,587 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742098_1274, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala._COPYING_
2025-03-26 02:24:34,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742098_1274 src: /172.20.1.14:47580 dest: /172.20.1.16:9866
2025-03-26 02:24:34,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742098_1274 src: /172.20.1.16:45218 dest: /172.20.1.15:9866
2025-03-26 02:24:34,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742098_1274 src: /172.20.1.15:36696 dest: /172.20.1.17:9866
2025-03-26 02:24:34,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36696, dest: /172.20.1.17:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742098_1274, duration(ns): 1233321
2025-03-26 02:24:34,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45218, dest: /172.20.1.15:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742098_1274, duration(ns): 1655075
2025-03-26 02:24:34,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742098_1274, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,592 INFO terminating
2025-03-26 02:24:34,593 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47580, dest: /172.20.1.16:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742098_1274, duration(ns): 1912190
2025-03-26 02:24:34,593 INFO terminating
2025-03-26 02:24:34,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742099_1275, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala._COPYING_
2025-03-26 02:24:34,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742099_1275 src: /172.20.1.14:37074 dest: /172.20.1.17:9866
2025-03-26 02:24:34,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742099_1275 src: /172.20.1.17:38706 dest: /172.20.1.15:9866
2025-03-26 02:24:34,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742099_1275 src: /172.20.1.15:38808 dest: /172.20.1.16:9866
2025-03-26 02:24:34,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38808, dest: /172.20.1.16:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742099_1275, duration(ns): 891157
2025-03-26 02:24:34,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38706, dest: /172.20.1.15:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742099_1275, duration(ns): 1269200
2025-03-26 02:24:34,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742099_1275, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,601 INFO terminating
2025-03-26 02:24:34,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37074, dest: /172.20.1.17:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742099_1275, duration(ns): 1364955
2025-03-26 02:24:34,602 INFO terminating
2025-03-26 02:24:34,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742100_1276, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala._COPYING_
2025-03-26 02:24:34,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742100_1276 src: /172.20.1.14:47596 dest: /172.20.1.16:9866
2025-03-26 02:24:34,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742100_1276 src: /172.20.1.16:54730 dest: /172.20.1.17:9866
2025-03-26 02:24:34,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742100_1276 src: /172.20.1.17:38718 dest: /172.20.1.15:9866
2025-03-26 02:24:34,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47596, dest: /172.20.1.16:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742100_1276, duration(ns): 1397309
2025-03-26 02:24:34,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54730, dest: /172.20.1.17:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742100_1276, duration(ns): 1049813
2025-03-26 02:24:34,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38718, dest: /172.20.1.15:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742100_1276, duration(ns): 999603
2025-03-26 02:24:34,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742100_1276, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,612 INFO terminating
2025-03-26 02:24:34,612 INFO terminating
2025-03-26 02:24:34,614 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,617 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742101_1277, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala._COPYING_
2025-03-26 02:24:34,617 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,617 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742101_1277 src: /172.20.1.14:37078 dest: /172.20.1.17:9866
2025-03-26 02:24:34,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742101_1277 src: /172.20.1.17:38734 dest: /172.20.1.15:9866
2025-03-26 02:24:34,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742101_1277 src: /172.20.1.15:38814 dest: /172.20.1.16:9866
2025-03-26 02:24:34,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38814, dest: /172.20.1.16:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742101_1277, duration(ns): 719974
2025-03-26 02:24:34,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742101_1277, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,622 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37078, dest: /172.20.1.17:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742101_1277, duration(ns): 1229732
2025-03-26 02:24:34,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38734, dest: /172.20.1.15:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742101_1277, duration(ns): 1058613
2025-03-26 02:24:34,622 INFO terminating
2025-03-26 02:24:34,622 INFO terminating
2025-03-26 02:24:34,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742102_1278, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala._COPYING_
2025-03-26 02:24:34,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,626 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742102_1278 src: /172.20.1.14:42638 dest: /172.20.1.15:9866
2025-03-26 02:24:34,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742102_1278 src: /172.20.1.15:38826 dest: /172.20.1.16:9866
2025-03-26 02:24:34,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742102_1278 src: /172.20.1.16:54740 dest: /172.20.1.17:9866
2025-03-26 02:24:34,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38826, dest: /172.20.1.16:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742102_1278, duration(ns): 1166887
2025-03-26 02:24:34,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54740, dest: /172.20.1.17:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742102_1278, duration(ns): 924701
2025-03-26 02:24:34,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742102_1278, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,631 INFO terminating
2025-03-26 02:24:34,632 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42638, dest: /172.20.1.15:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742102_1278, duration(ns): 1494086
2025-03-26 02:24:34,632 INFO terminating
2025-03-26 02:24:34,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742103_1279, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala._COPYING_
2025-03-26 02:24:34,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742103_1279 src: /172.20.1.14:42650 dest: /172.20.1.15:9866
2025-03-26 02:24:34,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742103_1279 src: /172.20.1.15:38836 dest: /172.20.1.16:9866
2025-03-26 02:24:34,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742103_1279 src: /172.20.1.16:54744 dest: /172.20.1.17:9866
2025-03-26 02:24:34,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54744, dest: /172.20.1.17:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742103_1279, duration(ns): 910063
2025-03-26 02:24:34,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42650, dest: /172.20.1.15:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742103_1279, duration(ns): 1471543
2025-03-26 02:24:34,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38836, dest: /172.20.1.16:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742103_1279, duration(ns): 1174803
2025-03-26 02:24:34,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742103_1279, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,643 INFO terminating
2025-03-26 02:24:34,643 INFO terminating
2025-03-26 02:24:34,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742104_1280, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala._COPYING_
2025-03-26 02:24:34,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742104_1280 src: /172.20.1.14:37084 dest: /172.20.1.17:9866
2025-03-26 02:24:34,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742104_1280 src: /172.20.1.15:38844 dest: /172.20.1.16:9866
2025-03-26 02:24:34,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742104_1280 src: /172.20.1.17:38738 dest: /172.20.1.15:9866
2025-03-26 02:24:34,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37084, dest: /172.20.1.17:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742104_1280, duration(ns): 1425533
2025-03-26 02:24:34,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38844, dest: /172.20.1.16:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742104_1280, duration(ns): 902020
2025-03-26 02:24:34,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38738, dest: /172.20.1.15:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742104_1280, duration(ns): 1209936
2025-03-26 02:24:34,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742104_1280, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,653 INFO terminating
2025-03-26 02:24:34,653 INFO terminating
2025-03-26 02:24:34,655 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,658 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742105_1281, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala._COPYING_
2025-03-26 02:24:34,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742105_1281 src: /172.20.1.14:42666 dest: /172.20.1.15:9866
2025-03-26 02:24:34,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742105_1281 src: /172.20.1.15:38852 dest: /172.20.1.16:9866
2025-03-26 02:24:34,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742105_1281 src: /172.20.1.16:54752 dest: /172.20.1.17:9866
2025-03-26 02:24:34,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42666, dest: /172.20.1.15:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742105_1281, duration(ns): 2057263
2025-03-26 02:24:34,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38852, dest: /172.20.1.16:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742105_1281, duration(ns): 1701683
2025-03-26 02:24:34,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54752, dest: /172.20.1.17:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742105_1281, duration(ns): 1437541
2025-03-26 02:24:34,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742105_1281, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,663 INFO terminating
2025-03-26 02:24:34,664 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,664 INFO terminating
2025-03-26 02:24:34,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742106_1282, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala._COPYING_
2025-03-26 02:24:34,668 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,668 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742106_1282 src: /172.20.1.14:37098 dest: /172.20.1.17:9866
2025-03-26 02:24:34,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742106_1282 src: /172.20.1.17:38742 dest: /172.20.1.15:9866
2025-03-26 02:24:34,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742106_1282 src: /172.20.1.15:38860 dest: /172.20.1.16:9866
2025-03-26 02:24:34,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38860, dest: /172.20.1.16:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742106_1282, duration(ns): 799224
2025-03-26 02:24:34,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742106_1282, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37098, dest: /172.20.1.17:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742106_1282, duration(ns): 1727997
2025-03-26 02:24:34,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38742, dest: /172.20.1.15:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742106_1282, duration(ns): 1356646
2025-03-26 02:24:34,673 INFO terminating
2025-03-26 02:24:34,673 INFO terminating
2025-03-26 02:24:34,675 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742107_1283, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala._COPYING_
2025-03-26 02:24:34,679 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,679 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742107_1283 src: /172.20.1.14:47606 dest: /172.20.1.16:9866
2025-03-26 02:24:34,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742107_1283 src: /172.20.1.16:45222 dest: /172.20.1.15:9866
2025-03-26 02:24:34,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742107_1283 src: /172.20.1.15:36706 dest: /172.20.1.17:9866
2025-03-26 02:24:34,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36706, dest: /172.20.1.17:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742107_1283, duration(ns): 856612
2025-03-26 02:24:34,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742107_1283, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45222, dest: /172.20.1.15:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742107_1283, duration(ns): 1169906
2025-03-26 02:24:34,684 INFO terminating
2025-03-26 02:24:34,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47606, dest: /172.20.1.16:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742107_1283, duration(ns): 2189502
2025-03-26 02:24:34,685 INFO terminating
2025-03-26 02:24:34,686 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742108_1284, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala._COPYING_
2025-03-26 02:24:34,692 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,692 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742108_1284 src: /172.20.1.14:37112 dest: /172.20.1.17:9866
2025-03-26 02:24:34,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742108_1284 src: /172.20.1.17:38744 dest: /172.20.1.15:9866
2025-03-26 02:24:34,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742108_1284 src: /172.20.1.15:38874 dest: /172.20.1.16:9866
2025-03-26 02:24:34,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38874, dest: /172.20.1.16:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742108_1284, duration(ns): 712892
2025-03-26 02:24:34,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742108_1284, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38744, dest: /172.20.1.15:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742108_1284, duration(ns): 1129180
2025-03-26 02:24:34,697 INFO terminating
2025-03-26 02:24:34,698 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37112, dest: /172.20.1.17:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742108_1284, duration(ns): 1905058
2025-03-26 02:24:34,698 INFO terminating
2025-03-26 02:24:34,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742109_1285, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala._COPYING_
2025-03-26 02:24:34,701 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,701 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742109_1285 src: /172.20.1.14:37128 dest: /172.20.1.17:9866
2025-03-26 02:24:34,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742109_1285 src: /172.20.1.17:38756 dest: /172.20.1.15:9866
2025-03-26 02:24:34,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742109_1285 src: /172.20.1.15:38876 dest: /172.20.1.16:9866
2025-03-26 02:24:34,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38876, dest: /172.20.1.16:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742109_1285, duration(ns): 1193247
2025-03-26 02:24:34,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742109_1285, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37128, dest: /172.20.1.17:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742109_1285, duration(ns): 2514359
2025-03-26 02:24:34,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38756, dest: /172.20.1.15:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742109_1285, duration(ns): 1952235
2025-03-26 02:24:34,707 INFO terminating
2025-03-26 02:24:34,707 INFO terminating
2025-03-26 02:24:34,708 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,712 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742110_1286, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala._COPYING_
2025-03-26 02:24:34,712 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,712 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742110_1286 src: /172.20.1.14:47612 dest: /172.20.1.16:9866
2025-03-26 02:24:34,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742110_1286 src: /172.20.1.16:54758 dest: /172.20.1.17:9866
2025-03-26 02:24:34,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742110_1286 src: /172.20.1.17:38760 dest: /172.20.1.15:9866
2025-03-26 02:24:34,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54758, dest: /172.20.1.17:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742110_1286, duration(ns): 1928987
2025-03-26 02:24:34,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38760, dest: /172.20.1.15:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742110_1286, duration(ns): 806012
2025-03-26 02:24:34,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742110_1286, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,717 INFO terminating
2025-03-26 02:24:34,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47612, dest: /172.20.1.16:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742110_1286, duration(ns): 2246085
2025-03-26 02:24:34,719 INFO terminating
2025-03-26 02:24:34,720 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742111_1287, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala._COPYING_
2025-03-26 02:24:34,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742111_1287 src: /172.20.1.14:47624 dest: /172.20.1.16:9866
2025-03-26 02:24:34,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742111_1287 src: /172.20.1.15:36718 dest: /172.20.1.17:9866
2025-03-26 02:24:34,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742111_1287 src: /172.20.1.16:45228 dest: /172.20.1.15:9866
2025-03-26 02:24:34,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36718, dest: /172.20.1.17:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742111_1287, duration(ns): 809592
2025-03-26 02:24:34,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742111_1287, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45228, dest: /172.20.1.15:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742111_1287, duration(ns): 1282236
2025-03-26 02:24:34,734 INFO terminating
2025-03-26 02:24:34,741 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47624, dest: /172.20.1.16:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742111_1287, duration(ns): 2199375
2025-03-26 02:24:34,741 INFO terminating
2025-03-26 02:24:34,745 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742112_1288, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala._COPYING_
2025-03-26 02:24:34,745 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,745 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742112_1288 src: /172.20.1.14:37140 dest: /172.20.1.17:9866
2025-03-26 02:24:34,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742112_1288 src: /172.20.1.17:60374 dest: /172.20.1.16:9866
2025-03-26 02:24:34,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742112_1288 src: /172.20.1.16:45232 dest: /172.20.1.15:9866
2025-03-26 02:24:34,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45232, dest: /172.20.1.15:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742112_1288, duration(ns): 902695
2025-03-26 02:24:34,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742112_1288, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37140, dest: /172.20.1.17:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742112_1288, duration(ns): 1708475
2025-03-26 02:24:34,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60374, dest: /172.20.1.16:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742112_1288, duration(ns): 1067023
2025-03-26 02:24:34,750 INFO terminating
2025-03-26 02:24:34,750 INFO terminating
2025-03-26 02:24:34,751 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742113_1289, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala._COPYING_
2025-03-26 02:24:34,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742113_1289 src: /172.20.1.14:47628 dest: /172.20.1.16:9866
2025-03-26 02:24:34,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742113_1289 src: /172.20.1.16:45246 dest: /172.20.1.15:9866
2025-03-26 02:24:34,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742113_1289 src: /172.20.1.15:36722 dest: /172.20.1.17:9866
2025-03-26 02:24:34,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36722, dest: /172.20.1.17:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742113_1289, duration(ns): 678104
2025-03-26 02:24:34,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45246, dest: /172.20.1.15:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742113_1289, duration(ns): 1022660
2025-03-26 02:24:34,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742113_1289, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,759 INFO terminating
2025-03-26 02:24:34,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47628, dest: /172.20.1.16:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742113_1289, duration(ns): 1204147
2025-03-26 02:24:34,760 INFO terminating
2025-03-26 02:24:34,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742114_1290, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala._COPYING_
2025-03-26 02:24:34,765 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,765 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742114_1290 src: /172.20.1.14:37156 dest: /172.20.1.17:9866
2025-03-26 02:24:34,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742114_1290 src: /172.20.1.17:38774 dest: /172.20.1.15:9866
2025-03-26 02:24:34,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742114_1290 src: /172.20.1.15:38880 dest: /172.20.1.16:9866
2025-03-26 02:24:34,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38880, dest: /172.20.1.16:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742114_1290, duration(ns): 721432
2025-03-26 02:24:34,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742114_1290, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,770 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37156, dest: /172.20.1.17:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742114_1290, duration(ns): 1273897
2025-03-26 02:24:34,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38774, dest: /172.20.1.15:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742114_1290, duration(ns): 1075003
2025-03-26 02:24:34,770 INFO terminating
2025-03-26 02:24:34,770 INFO terminating
2025-03-26 02:24:34,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742115_1291, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala._COPYING_
2025-03-26 02:24:34,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742115_1291 src: /172.20.1.14:42668 dest: /172.20.1.15:9866
2025-03-26 02:24:34,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742115_1291 src: /172.20.1.15:38882 dest: /172.20.1.16:9866
2025-03-26 02:24:34,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742115_1291 src: /172.20.1.16:54774 dest: /172.20.1.17:9866
2025-03-26 02:24:34,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38882, dest: /172.20.1.16:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742115_1291, duration(ns): 4676119
2025-03-26 02:24:34,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54774, dest: /172.20.1.17:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742115_1291, duration(ns): 694677
2025-03-26 02:24:34,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742115_1291, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,782 INFO terminating
2025-03-26 02:24:34,783 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42668, dest: /172.20.1.15:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742115_1291, duration(ns): 5063734
2025-03-26 02:24:34,783 INFO terminating
2025-03-26 02:24:34,790 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742116_1292, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala._COPYING_
2025-03-26 02:24:34,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742116_1292 src: /172.20.1.14:37158 dest: /172.20.1.17:9866
2025-03-26 02:24:34,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742116_1292 src: /172.20.1.17:60390 dest: /172.20.1.16:9866
2025-03-26 02:24:34,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742116_1292 src: /172.20.1.16:45250 dest: /172.20.1.15:9866
2025-03-26 02:24:34,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45250, dest: /172.20.1.15:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742116_1292, duration(ns): 807956
2025-03-26 02:24:34,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37158, dest: /172.20.1.17:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742116_1292, duration(ns): 1283418
2025-03-26 02:24:34,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60390, dest: /172.20.1.16:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742116_1292, duration(ns): 961958
2025-03-26 02:24:34,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742116_1292, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,795 INFO terminating
2025-03-26 02:24:34,795 INFO terminating
2025-03-26 02:24:34,796 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742117_1293, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala._COPYING_
2025-03-26 02:24:34,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742117_1293 src: /172.20.1.14:42680 dest: /172.20.1.15:9866
2025-03-26 02:24:34,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742117_1293 src: /172.20.1.15:36736 dest: /172.20.1.17:9866
2025-03-26 02:24:34,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742117_1293 src: /172.20.1.17:60396 dest: /172.20.1.16:9866
2025-03-26 02:24:34,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60396, dest: /172.20.1.16:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742117_1293, duration(ns): 13673126
2025-03-26 02:24:34,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36736, dest: /172.20.1.17:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742117_1293, duration(ns): 14041167
2025-03-26 02:24:34,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742117_1293, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,822 INFO terminating
2025-03-26 02:24:34,823 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42680, dest: /172.20.1.15:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742117_1293, duration(ns): 14629983
2025-03-26 02:24:34,823 INFO terminating
2025-03-26 02:24:34,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742118_1294, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala._COPYING_
2025-03-26 02:24:34,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742118_1294 src: /172.20.1.14:42696 dest: /172.20.1.15:9866
2025-03-26 02:24:34,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742118_1294 src: /172.20.1.15:36746 dest: /172.20.1.17:9866
2025-03-26 02:24:34,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742118_1294 src: /172.20.1.17:60402 dest: /172.20.1.16:9866
2025-03-26 02:24:34,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36746, dest: /172.20.1.17:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742118_1294, duration(ns): 1469847
2025-03-26 02:24:34,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60402, dest: /172.20.1.16:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742118_1294, duration(ns): 1053908
2025-03-26 02:24:34,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742118_1294, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,836 INFO terminating
2025-03-26 02:24:34,837 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42696, dest: /172.20.1.15:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742118_1294, duration(ns): 1994117
2025-03-26 02:24:34,837 INFO terminating
2025-03-26 02:24:34,841 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,841 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,842 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742119_1295, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala._COPYING_
2025-03-26 02:24:34,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742119_1295 src: /172.20.1.14:37168 dest: /172.20.1.17:9866
2025-03-26 02:24:34,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742119_1295 src: /172.20.1.17:38786 dest: /172.20.1.15:9866
2025-03-26 02:24:34,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742119_1295 src: /172.20.1.15:38888 dest: /172.20.1.16:9866
2025-03-26 02:24:34,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37168, dest: /172.20.1.17:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742119_1295, duration(ns): 1590776
2025-03-26 02:24:34,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38888, dest: /172.20.1.16:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742119_1295, duration(ns): 1138524
2025-03-26 02:24:34,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38786, dest: /172.20.1.15:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742119_1295, duration(ns): 1477996
2025-03-26 02:24:34,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742119_1295, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,847 INFO terminating
2025-03-26 02:24:34,848 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,848 INFO terminating
2025-03-26 02:24:34,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742120_1296, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala._COPYING_
2025-03-26 02:24:34,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742120_1296 src: /172.20.1.14:47638 dest: /172.20.1.16:9866
2025-03-26 02:24:34,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742120_1296 src: /172.20.1.16:45252 dest: /172.20.1.15:9866
2025-03-26 02:24:34,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742120_1296 src: /172.20.1.15:36754 dest: /172.20.1.17:9866
2025-03-26 02:24:34,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36754, dest: /172.20.1.17:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742120_1296, duration(ns): 1016962
2025-03-26 02:24:34,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45252, dest: /172.20.1.15:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742120_1296, duration(ns): 1382645
2025-03-26 02:24:34,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742120_1296, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,859 INFO terminating
2025-03-26 02:24:34,860 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47638, dest: /172.20.1.16:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742120_1296, duration(ns): 1408384
2025-03-26 02:24:34,860 INFO terminating
2025-03-26 02:24:34,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742121_1297, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala._COPYING_
2025-03-26 02:24:34,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742121_1297 src: /172.20.1.14:37180 dest: /172.20.1.17:9866
2025-03-26 02:24:34,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742121_1297 src: /172.20.1.17:60408 dest: /172.20.1.16:9866
2025-03-26 02:24:34,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742121_1297 src: /172.20.1.16:45264 dest: /172.20.1.15:9866
2025-03-26 02:24:34,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45264, dest: /172.20.1.15:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742121_1297, duration(ns): 963713
2025-03-26 02:24:34,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60408, dest: /172.20.1.16:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742121_1297, duration(ns): 1056449
2025-03-26 02:24:34,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742121_1297, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,869 INFO terminating
2025-03-26 02:24:34,870 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37180, dest: /172.20.1.17:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742121_1297, duration(ns): 1245822
2025-03-26 02:24:34,870 INFO terminating
2025-03-26 02:24:34,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742122_1298, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala._COPYING_
2025-03-26 02:24:34,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742122_1298 src: /172.20.1.14:47652 dest: /172.20.1.16:9866
2025-03-26 02:24:34,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742122_1298 src: /172.20.1.15:36768 dest: /172.20.1.17:9866
2025-03-26 02:24:34,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742122_1298 src: /172.20.1.16:45272 dest: /172.20.1.15:9866
2025-03-26 02:24:34,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36768, dest: /172.20.1.17:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742122_1298, duration(ns): 733105
2025-03-26 02:24:34,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45272, dest: /172.20.1.15:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742122_1298, duration(ns): 1146346
2025-03-26 02:24:34,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742122_1298, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,878 INFO terminating
2025-03-26 02:24:34,879 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47652, dest: /172.20.1.16:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742122_1298, duration(ns): 1205738
2025-03-26 02:24:34,879 INFO terminating
2025-03-26 02:24:34,884 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742123_1299, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala._COPYING_
2025-03-26 02:24:34,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742123_1299 src: /172.20.1.14:47654 dest: /172.20.1.16:9866
2025-03-26 02:24:34,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742123_1299 src: /172.20.1.16:45288 dest: /172.20.1.15:9866
2025-03-26 02:24:34,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742123_1299 src: /172.20.1.15:36782 dest: /172.20.1.17:9866
2025-03-26 02:24:34,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36782, dest: /172.20.1.17:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742123_1299, duration(ns): 2028002
2025-03-26 02:24:34,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45288, dest: /172.20.1.15:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742123_1299, duration(ns): 2363268
2025-03-26 02:24:34,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742123_1299, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,893 INFO terminating
2025-03-26 02:24:34,894 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47654, dest: /172.20.1.16:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742123_1299, duration(ns): 1378522
2025-03-26 02:24:34,894 INFO terminating
2025-03-26 02:24:34,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742124_1300, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala._COPYING_
2025-03-26 02:24:34,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742124_1300 src: /172.20.1.14:37188 dest: /172.20.1.17:9866
2025-03-26 02:24:34,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742124_1300 src: /172.20.1.16:45302 dest: /172.20.1.15:9866
2025-03-26 02:24:34,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742124_1300 src: /172.20.1.17:60414 dest: /172.20.1.16:9866
2025-03-26 02:24:34,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45302, dest: /172.20.1.15:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742124_1300, duration(ns): 902417
2025-03-26 02:24:34,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742124_1300, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,906 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37188, dest: /172.20.1.17:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742124_1300, duration(ns): 4600699
2025-03-26 02:24:34,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60414, dest: /172.20.1.16:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742124_1300, duration(ns): 946059
2025-03-26 02:24:34,906 INFO terminating
2025-03-26 02:24:34,906 INFO terminating
2025-03-26 02:24:34,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742125_1301, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala._COPYING_
2025-03-26 02:24:34,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742125_1301 src: /172.20.1.14:37196 dest: /172.20.1.17:9866
2025-03-26 02:24:34,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742125_1301 src: /172.20.1.17:60428 dest: /172.20.1.16:9866
2025-03-26 02:24:34,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742125_1301 src: /172.20.1.16:45310 dest: /172.20.1.15:9866
2025-03-26 02:24:34,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45310, dest: /172.20.1.15:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742125_1301, duration(ns): 832901
2025-03-26 02:24:34,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742125_1301, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37196, dest: /172.20.1.17:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742125_1301, duration(ns): 1661124
2025-03-26 02:24:34,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60428, dest: /172.20.1.16:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742125_1301, duration(ns): 1096359
2025-03-26 02:24:34,916 INFO terminating
2025-03-26 02:24:34,916 INFO terminating
2025-03-26 02:24:34,917 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742126_1302, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala._COPYING_
2025-03-26 02:24:34,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742126_1302 src: /172.20.1.14:42702 dest: /172.20.1.15:9866
2025-03-26 02:24:34,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742126_1302 src: /172.20.1.15:36786 dest: /172.20.1.17:9866
2025-03-26 02:24:34,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742126_1302 src: /172.20.1.17:60436 dest: /172.20.1.16:9866
2025-03-26 02:24:34,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36786, dest: /172.20.1.17:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742126_1302, duration(ns): 959413
2025-03-26 02:24:34,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60436, dest: /172.20.1.16:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742126_1302, duration(ns): 617032
2025-03-26 02:24:34,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742126_1302, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,924 INFO terminating
2025-03-26 02:24:34,925 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42702, dest: /172.20.1.15:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742126_1302, duration(ns): 1322635
2025-03-26 02:24:34,925 INFO terminating
2025-03-26 02:24:34,928 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742127_1303, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala._COPYING_
2025-03-26 02:24:34,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742127_1303 src: /172.20.1.14:37210 dest: /172.20.1.17:9866
2025-03-26 02:24:34,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742127_1303 src: /172.20.1.17:60440 dest: /172.20.1.16:9866
2025-03-26 02:24:34,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742127_1303 src: /172.20.1.16:45314 dest: /172.20.1.15:9866
2025-03-26 02:24:34,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45314, dest: /172.20.1.15:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742127_1303, duration(ns): 703540
2025-03-26 02:24:34,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742127_1303, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60440, dest: /172.20.1.16:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742127_1303, duration(ns): 873545
2025-03-26 02:24:34,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37210, dest: /172.20.1.17:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742127_1303, duration(ns): 2328782
2025-03-26 02:24:34,934 INFO terminating
2025-03-26 02:24:34,934 INFO terminating
2025-03-26 02:24:34,935 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,938 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742128_1304, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_
2025-03-26 02:24:34,938 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,938 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742128_1304 src: /172.20.1.14:37218 dest: /172.20.1.17:9866
2025-03-26 02:24:34,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742128_1304 src: /172.20.1.16:45328 dest: /172.20.1.15:9866
2025-03-26 02:24:34,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742128_1304 src: /172.20.1.17:60444 dest: /172.20.1.16:9866
2025-03-26 02:24:34,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37218, dest: /172.20.1.17:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742128_1304, duration(ns): 1180054
2025-03-26 02:24:34,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45328, dest: /172.20.1.15:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742128_1304, duration(ns): 711284
2025-03-26 02:24:34,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60444, dest: /172.20.1.16:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742128_1304, duration(ns): 853511
2025-03-26 02:24:34,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742128_1304, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,942 INFO terminating
2025-03-26 02:24:34,942 INFO terminating
2025-03-26 02:24:34,943 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,946 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742129_1305, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala._COPYING_
2025-03-26 02:24:34,946 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,946 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742129_1305 src: /172.20.1.14:37226 dest: /172.20.1.17:9866
2025-03-26 02:24:34,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742129_1305 src: /172.20.1.15:38892 dest: /172.20.1.16:9866
2025-03-26 02:24:34,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742129_1305 src: /172.20.1.17:38802 dest: /172.20.1.15:9866
2025-03-26 02:24:34,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38892, dest: /172.20.1.16:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742129_1305, duration(ns): 1223407
2025-03-26 02:24:34,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742129_1305, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37226, dest: /172.20.1.17:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742129_1305, duration(ns): 1715651
2025-03-26 02:24:34,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38802, dest: /172.20.1.15:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742129_1305, duration(ns): 1521040
2025-03-26 02:24:34,951 INFO terminating
2025-03-26 02:24:34,951 INFO terminating
2025-03-26 02:24:34,953 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,956 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742130_1306, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala._COPYING_
2025-03-26 02:24:34,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742130_1306 src: /172.20.1.14:42714 dest: /172.20.1.15:9866
2025-03-26 02:24:34,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742130_1306 src: /172.20.1.15:36796 dest: /172.20.1.17:9866
2025-03-26 02:24:34,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742130_1306 src: /172.20.1.17:60454 dest: /172.20.1.16:9866
2025-03-26 02:24:34,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60454, dest: /172.20.1.16:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742130_1306, duration(ns): 4356593
2025-03-26 02:24:34,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36796, dest: /172.20.1.17:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742130_1306, duration(ns): 5054644
2025-03-26 02:24:34,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742130_1306, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,965 INFO terminating
2025-03-26 02:24:34,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42714, dest: /172.20.1.15:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742130_1306, duration(ns): 5431125
2025-03-26 02:24:34,966 INFO terminating
2025-03-26 02:24:34,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742131_1307, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala._COPYING_
2025-03-26 02:24:34,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742131_1307 src: /172.20.1.14:37242 dest: /172.20.1.17:9866
2025-03-26 02:24:34,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742131_1307 src: /172.20.1.17:60458 dest: /172.20.1.16:9866
2025-03-26 02:24:34,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742131_1307 src: /172.20.1.16:45330 dest: /172.20.1.15:9866
2025-03-26 02:24:34,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45330, dest: /172.20.1.15:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742131_1307, duration(ns): 3410470
2025-03-26 02:24:34,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742131_1307, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60458, dest: /172.20.1.16:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742131_1307, duration(ns): 3768128
2025-03-26 02:24:34,978 INFO terminating
2025-03-26 02:24:34,979 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37242, dest: /172.20.1.17:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742131_1307, duration(ns): 4267114
2025-03-26 02:24:34,979 INFO terminating
2025-03-26 02:24:34,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742132_1308, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala._COPYING_
2025-03-26 02:24:34,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742132_1308 src: /172.20.1.14:42718 dest: /172.20.1.15:9866
2025-03-26 02:24:34,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742132_1308 src: /172.20.1.15:38900 dest: /172.20.1.16:9866
2025-03-26 02:24:34,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742132_1308 src: /172.20.1.16:54786 dest: /172.20.1.17:9866
2025-03-26 02:24:34,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54786, dest: /172.20.1.17:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742132_1308, duration(ns): 668518
2025-03-26 02:24:34,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742132_1308, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:34,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42718, dest: /172.20.1.15:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742132_1308, duration(ns): 1627058
2025-03-26 02:24:34,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38900, dest: /172.20.1.16:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742132_1308, duration(ns): 950542
2025-03-26 02:24:34,987 INFO terminating
2025-03-26 02:24:34,987 INFO terminating
2025-03-26 02:24:34,988 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:34,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742133_1309, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala._COPYING_
2025-03-26 02:24:34,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742133_1309 src: /172.20.1.14:37256 dest: /172.20.1.17:9866
2025-03-26 02:24:35,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742133_1309 src: /172.20.1.15:38914 dest: /172.20.1.16:9866
2025-03-26 02:24:35,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742133_1309 src: /172.20.1.17:38804 dest: /172.20.1.15:9866
2025-03-26 02:24:35,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38914, dest: /172.20.1.16:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742133_1309, duration(ns): 697752
2025-03-26 02:24:35,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38804, dest: /172.20.1.15:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742133_1309, duration(ns): 1019404
2025-03-26 02:24:35,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742133_1309, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,002 INFO terminating
2025-03-26 02:24:35,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37256, dest: /172.20.1.17:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742133_1309, duration(ns): 1084950
2025-03-26 02:24:35,003 INFO terminating
2025-03-26 02:24:35,004 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742134_1310, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala._COPYING_
2025-03-26 02:24:35,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742134_1310 src: /172.20.1.14:42734 dest: /172.20.1.15:9866
2025-03-26 02:24:35,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742134_1310 src: /172.20.1.15:36810 dest: /172.20.1.17:9866
2025-03-26 02:24:35,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742134_1310 src: /172.20.1.17:60460 dest: /172.20.1.16:9866
2025-03-26 02:24:35,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36810, dest: /172.20.1.17:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742134_1310, duration(ns): 1091995
2025-03-26 02:24:35,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60460, dest: /172.20.1.16:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742134_1310, duration(ns): 801726
2025-03-26 02:24:35,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742134_1310, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,013 INFO terminating
2025-03-26 02:24:35,014 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42734, dest: /172.20.1.15:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742134_1310, duration(ns): 1481233
2025-03-26 02:24:35,014 INFO terminating
2025-03-26 02:24:35,019 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742135_1311, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala._COPYING_
2025-03-26 02:24:35,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742135_1311 src: /172.20.1.14:37268 dest: /172.20.1.17:9866
2025-03-26 02:24:35,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742135_1311 src: /172.20.1.17:60472 dest: /172.20.1.16:9866
2025-03-26 02:24:35,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742135_1311 src: /172.20.1.16:45342 dest: /172.20.1.15:9866
2025-03-26 02:24:35,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45342, dest: /172.20.1.15:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742135_1311, duration(ns): 947701
2025-03-26 02:24:35,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60472, dest: /172.20.1.16:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742135_1311, duration(ns): 1429848
2025-03-26 02:24:35,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742135_1311, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,024 INFO terminating
2025-03-26 02:24:35,025 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37268, dest: /172.20.1.17:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742135_1311, duration(ns): 1774124
2025-03-26 02:24:35,025 INFO terminating
2025-03-26 02:24:35,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742136_1312, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala._COPYING_
2025-03-26 02:24:35,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742136_1312 src: /172.20.1.14:37272 dest: /172.20.1.17:9866
2025-03-26 02:24:35,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742136_1312 src: /172.20.1.17:60482 dest: /172.20.1.16:9866
2025-03-26 02:24:35,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742136_1312 src: /172.20.1.16:45344 dest: /172.20.1.15:9866
2025-03-26 02:24:35,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37272, dest: /172.20.1.17:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742136_1312, duration(ns): 1251792
2025-03-26 02:24:35,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45344, dest: /172.20.1.15:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742136_1312, duration(ns): 932104
2025-03-26 02:24:35,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60482, dest: /172.20.1.16:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742136_1312, duration(ns): 1081652
2025-03-26 02:24:35,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742136_1312, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,036 INFO terminating
2025-03-26 02:24:35,037 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,037 INFO terminating
2025-03-26 02:24:35,040 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742137_1313, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala._COPYING_
2025-03-26 02:24:35,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742137_1313 src: /172.20.1.14:42740 dest: /172.20.1.15:9866
2025-03-26 02:24:35,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742137_1313 src: /172.20.1.15:38926 dest: /172.20.1.16:9866
2025-03-26 02:24:35,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742137_1313 src: /172.20.1.16:54788 dest: /172.20.1.17:9866
2025-03-26 02:24:35,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54788, dest: /172.20.1.17:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742137_1313, duration(ns): 725697
2025-03-26 02:24:35,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742137_1313, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42740, dest: /172.20.1.15:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742137_1313, duration(ns): 2150191
2025-03-26 02:24:35,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38926, dest: /172.20.1.16:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742137_1313, duration(ns): 1287095
2025-03-26 02:24:35,046 INFO terminating
2025-03-26 02:24:35,046 INFO terminating
2025-03-26 02:24:35,047 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,050 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742138_1314, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_
2025-03-26 02:24:35,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742138_1314 src: /172.20.1.14:37286 dest: /172.20.1.17:9866
2025-03-26 02:24:35,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742138_1314 src: /172.20.1.17:60498 dest: /172.20.1.16:9866
2025-03-26 02:24:35,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742138_1314 src: /172.20.1.16:45348 dest: /172.20.1.15:9866
2025-03-26 02:24:35,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45348, dest: /172.20.1.15:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742138_1314, duration(ns): 1005891
2025-03-26 02:24:35,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60498, dest: /172.20.1.16:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742138_1314, duration(ns): 1156759
2025-03-26 02:24:35,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742138_1314, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37286, dest: /172.20.1.17:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742138_1314, duration(ns): 1780546
2025-03-26 02:24:35,057 INFO terminating
2025-03-26 02:24:35,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,058 INFO terminating
2025-03-26 02:24:35,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742139_1315, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala._COPYING_
2025-03-26 02:24:35,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742139_1315 src: /172.20.1.14:47656 dest: /172.20.1.16:9866
2025-03-26 02:24:35,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742139_1315 src: /172.20.1.15:36824 dest: /172.20.1.17:9866
2025-03-26 02:24:35,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742139_1315 src: /172.20.1.16:45358 dest: /172.20.1.15:9866
2025-03-26 02:24:35,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36824, dest: /172.20.1.17:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742139_1315, duration(ns): 939313
2025-03-26 02:24:35,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47656, dest: /172.20.1.16:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742139_1315, duration(ns): 1651800
2025-03-26 02:24:35,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45358, dest: /172.20.1.15:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742139_1315, duration(ns): 1605813
2025-03-26 02:24:35,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742139_1315, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,076 INFO terminating
2025-03-26 02:24:35,076 INFO terminating
2025-03-26 02:24:35,077 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,082 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742140_1316, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala._COPYING_
2025-03-26 02:24:35,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,082 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742140_1316 src: /172.20.1.14:47666 dest: /172.20.1.16:9866
2025-03-26 02:24:35,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742140_1316 src: /172.20.1.16:45360 dest: /172.20.1.15:9866
2025-03-26 02:24:35,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742140_1316 src: /172.20.1.15:36840 dest: /172.20.1.17:9866
2025-03-26 02:24:35,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36840, dest: /172.20.1.17:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742140_1316, duration(ns): 3626141
2025-03-26 02:24:35,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45360, dest: /172.20.1.15:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742140_1316, duration(ns): 4318375
2025-03-26 02:24:35,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742140_1316, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,091 INFO terminating
2025-03-26 02:24:35,092 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47666, dest: /172.20.1.16:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742140_1316, duration(ns): 4427069
2025-03-26 02:24:35,092 INFO terminating
2025-03-26 02:24:35,096 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742141_1317, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala._COPYING_
2025-03-26 02:24:35,096 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,096 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742141_1317 src: /172.20.1.14:47680 dest: /172.20.1.16:9866
2025-03-26 02:24:35,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742141_1317 src: /172.20.1.16:45368 dest: /172.20.1.15:9866
2025-03-26 02:24:35,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742141_1317 src: /172.20.1.15:36846 dest: /172.20.1.17:9866
2025-03-26 02:24:35,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36846, dest: /172.20.1.17:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742141_1317, duration(ns): 929676
2025-03-26 02:24:35,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45368, dest: /172.20.1.15:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742141_1317, duration(ns): 1663329
2025-03-26 02:24:35,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742141_1317, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,101 INFO terminating
2025-03-26 02:24:35,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47680, dest: /172.20.1.16:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742141_1317, duration(ns): 2507878
2025-03-26 02:24:35,102 INFO terminating
2025-03-26 02:24:35,103 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,110 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742142_1318, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala._COPYING_
2025-03-26 02:24:35,110 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,110 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742142_1318 src: /172.20.1.14:47686 dest: /172.20.1.16:9866
2025-03-26 02:24:35,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742142_1318 src: /172.20.1.16:54802 dest: /172.20.1.17:9866
2025-03-26 02:24:35,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742142_1318 src: /172.20.1.17:38810 dest: /172.20.1.15:9866
2025-03-26 02:24:35,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38810, dest: /172.20.1.15:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742142_1318, duration(ns): 1160934
2025-03-26 02:24:35,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742142_1318, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47686, dest: /172.20.1.16:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742142_1318, duration(ns): 2032533
2025-03-26 02:24:35,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54802, dest: /172.20.1.17:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742142_1318, duration(ns): 1275019
2025-03-26 02:24:35,117 INFO terminating
2025-03-26 02:24:35,118 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,118 INFO terminating
2025-03-26 02:24:35,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742143_1319, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala._COPYING_
2025-03-26 02:24:35,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742143_1319 src: /172.20.1.14:42752 dest: /172.20.1.15:9866
2025-03-26 02:24:35,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742143_1319 src: /172.20.1.15:36860 dest: /172.20.1.17:9866
2025-03-26 02:24:35,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742143_1319 src: /172.20.1.17:60510 dest: /172.20.1.16:9866
2025-03-26 02:24:35,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60510, dest: /172.20.1.16:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742143_1319, duration(ns): 1025194
2025-03-26 02:24:35,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742143_1319, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36860, dest: /172.20.1.17:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742143_1319, duration(ns): 1656902
2025-03-26 02:24:35,130 INFO terminating
2025-03-26 02:24:35,131 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42752, dest: /172.20.1.15:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742143_1319, duration(ns): 4778585
2025-03-26 02:24:35,131 INFO terminating
2025-03-26 02:24:35,135 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742144_1320, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_
2025-03-26 02:24:35,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742144_1320 src: /172.20.1.14:47690 dest: /172.20.1.16:9866
2025-03-26 02:24:35,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742144_1320 src: /172.20.1.15:36864 dest: /172.20.1.17:9866
2025-03-26 02:24:35,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742144_1320 src: /172.20.1.16:45376 dest: /172.20.1.15:9866
2025-03-26 02:24:35,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36864, dest: /172.20.1.17:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742144_1320, duration(ns): 895990
2025-03-26 02:24:35,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45376, dest: /172.20.1.15:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742144_1320, duration(ns): 1745529
2025-03-26 02:24:35,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742144_1320, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,142 INFO terminating
2025-03-26 02:24:35,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47690, dest: /172.20.1.16:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742144_1320, duration(ns): 4059001
2025-03-26 02:24:35,151 INFO terminating
2025-03-26 02:24:35,152 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,157 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1321, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala._COPYING_
2025-03-26 02:24:35,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742145_1321 src: /172.20.1.14:47698 dest: /172.20.1.16:9866
2025-03-26 02:24:35,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742145_1321 src: /172.20.1.16:54816 dest: /172.20.1.17:9866
2025-03-26 02:24:35,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742145_1321 src: /172.20.1.17:38826 dest: /172.20.1.15:9866
2025-03-26 02:24:35,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38826, dest: /172.20.1.15:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742145_1321, duration(ns): 983241
2025-03-26 02:24:35,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742145_1321, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54816, dest: /172.20.1.17:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742145_1321, duration(ns): 1155366
2025-03-26 02:24:35,163 INFO terminating
2025-03-26 02:24:35,164 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47698, dest: /172.20.1.16:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742145_1321, duration(ns): 1516592
2025-03-26 02:24:35,164 INFO terminating
2025-03-26 02:24:35,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1322, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala._COPYING_
2025-03-26 02:24:35,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742146_1322 src: /172.20.1.14:42768 dest: /172.20.1.15:9866
2025-03-26 02:24:35,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742146_1322 src: /172.20.1.15:38934 dest: /172.20.1.16:9866
2025-03-26 02:24:35,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742146_1322 src: /172.20.1.16:54820 dest: /172.20.1.17:9866
2025-03-26 02:24:35,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54820, dest: /172.20.1.17:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742146_1322, duration(ns): 919678
2025-03-26 02:24:35,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742146_1322, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42768, dest: /172.20.1.15:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742146_1322, duration(ns): 2374913
2025-03-26 02:24:35,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38934, dest: /172.20.1.16:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742146_1322, duration(ns): 1552478
2025-03-26 02:24:35,174 INFO terminating
2025-03-26 02:24:35,174 INFO terminating
2025-03-26 02:24:35,175 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,178 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1323, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 02:24:35,178 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,178 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742147_1323 src: /172.20.1.14:42772 dest: /172.20.1.15:9866
2025-03-26 02:24:35,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742147_1323 src: /172.20.1.15:36868 dest: /172.20.1.17:9866
2025-03-26 02:24:35,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742147_1323 src: /172.20.1.17:60524 dest: /172.20.1.16:9866
2025-03-26 02:24:35,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60524, dest: /172.20.1.16:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742147_1323, duration(ns): 1027269
2025-03-26 02:24:35,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742147_1323, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36868, dest: /172.20.1.17:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742147_1323, duration(ns): 1685170
2025-03-26 02:24:35,184 INFO terminating
2025-03-26 02:24:35,191 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42772, dest: /172.20.1.15:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742147_1323, duration(ns): 8272603
2025-03-26 02:24:35,191 INFO terminating
2025-03-26 02:24:35,200 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1324, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala._COPYING_
2025-03-26 02:24:35,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742148_1324 src: /172.20.1.14:47708 dest: /172.20.1.16:9866
2025-03-26 02:24:35,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742148_1324 src: /172.20.1.16:45388 dest: /172.20.1.15:9866
2025-03-26 02:24:35,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742148_1324 src: /172.20.1.15:36882 dest: /172.20.1.17:9866
2025-03-26 02:24:35,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36882, dest: /172.20.1.17:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742148_1324, duration(ns): 1990120
2025-03-26 02:24:35,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45388, dest: /172.20.1.15:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742148_1324, duration(ns): 3132830
2025-03-26 02:24:35,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742148_1324, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,210 INFO terminating
2025-03-26 02:24:35,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47708, dest: /172.20.1.16:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742148_1324, duration(ns): 3459742
2025-03-26 02:24:35,211 INFO terminating
2025-03-26 02:24:35,212 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1325, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala._COPYING_
2025-03-26 02:24:35,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742149_1325 src: /172.20.1.14:42786 dest: /172.20.1.15:9866
2025-03-26 02:24:35,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742149_1325 src: /172.20.1.15:38944 dest: /172.20.1.16:9866
2025-03-26 02:24:35,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742149_1325 src: /172.20.1.16:54830 dest: /172.20.1.17:9866
2025-03-26 02:24:35,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54830, dest: /172.20.1.17:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742149_1325, duration(ns): 1239488
2025-03-26 02:24:35,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742149_1325, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38944, dest: /172.20.1.16:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742149_1325, duration(ns): 1953967
2025-03-26 02:24:35,228 INFO terminating
2025-03-26 02:24:35,229 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42786, dest: /172.20.1.15:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742149_1325, duration(ns): 2775895
2025-03-26 02:24:35,229 INFO terminating
2025-03-26 02:24:35,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1326, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala._COPYING_
2025-03-26 02:24:35,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742150_1326 src: /172.20.1.14:37298 dest: /172.20.1.17:9866
2025-03-26 02:24:35,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742150_1326 src: /172.20.1.17:38830 dest: /172.20.1.15:9866
2025-03-26 02:24:35,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742150_1326 src: /172.20.1.15:38946 dest: /172.20.1.16:9866
2025-03-26 02:24:35,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38946, dest: /172.20.1.16:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742150_1326, duration(ns): 1033005
2025-03-26 02:24:35,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742150_1326, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38830, dest: /172.20.1.15:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742150_1326, duration(ns): 1790313
2025-03-26 02:24:35,240 INFO terminating
2025-03-26 02:24:35,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37298, dest: /172.20.1.17:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742150_1326, duration(ns): 2362494
2025-03-26 02:24:35,241 INFO terminating
2025-03-26 02:24:35,247 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,253 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1327, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala._COPYING_
2025-03-26 02:24:35,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742151_1327 src: /172.20.1.14:42790 dest: /172.20.1.15:9866
2025-03-26 02:24:35,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742151_1327 src: /172.20.1.15:36886 dest: /172.20.1.17:9866
2025-03-26 02:24:35,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742151_1327 src: /172.20.1.17:60532 dest: /172.20.1.16:9866
2025-03-26 02:24:35,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60532, dest: /172.20.1.16:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742151_1327, duration(ns): 1366141
2025-03-26 02:24:35,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742151_1327, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36886, dest: /172.20.1.17:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742151_1327, duration(ns): 2420988
2025-03-26 02:24:35,261 INFO terminating
2025-03-26 02:24:35,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42790, dest: /172.20.1.15:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742151_1327, duration(ns): 3477586
2025-03-26 02:24:35,262 INFO terminating
2025-03-26 02:24:35,263 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1328, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala._COPYING_
2025-03-26 02:24:35,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742152_1328 src: /172.20.1.14:47716 dest: /172.20.1.16:9866
2025-03-26 02:24:35,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742152_1328 src: /172.20.1.16:54840 dest: /172.20.1.17:9866
2025-03-26 02:24:35,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742152_1328 src: /172.20.1.17:38834 dest: /172.20.1.15:9866
2025-03-26 02:24:35,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38834, dest: /172.20.1.15:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742152_1328, duration(ns): 1295398
2025-03-26 02:24:35,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742152_1328, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54840, dest: /172.20.1.17:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742152_1328, duration(ns): 2625391
2025-03-26 02:24:35,275 INFO terminating
2025-03-26 02:24:35,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47716, dest: /172.20.1.16:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742152_1328, duration(ns): 3915788
2025-03-26 02:24:35,277 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,277 INFO terminating
2025-03-26 02:24:35,282 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,282 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1329, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala._COPYING_
2025-03-26 02:24:35,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742153_1329 src: /172.20.1.14:47732 dest: /172.20.1.16:9866
2025-03-26 02:24:35,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742153_1329 src: /172.20.1.16:54852 dest: /172.20.1.17:9866
2025-03-26 02:24:35,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742153_1329 src: /172.20.1.17:38844 dest: /172.20.1.15:9866
2025-03-26 02:24:35,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38844, dest: /172.20.1.15:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742153_1329, duration(ns): 1499075
2025-03-26 02:24:35,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742153_1329, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54852, dest: /172.20.1.17:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742153_1329, duration(ns): 2398962
2025-03-26 02:24:35,292 INFO terminating
2025-03-26 02:24:35,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47732, dest: /172.20.1.16:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742153_1329, duration(ns): 3208096
2025-03-26 02:24:35,293 INFO terminating
2025-03-26 02:24:35,294 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,302 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1330, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala._COPYING_
2025-03-26 02:24:35,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742154_1330 src: /172.20.1.14:42806 dest: /172.20.1.15:9866
2025-03-26 02:24:35,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742154_1330 src: /172.20.1.15:36892 dest: /172.20.1.17:9866
2025-03-26 02:24:35,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742154_1330 src: /172.20.1.17:60540 dest: /172.20.1.16:9866
2025-03-26 02:24:35,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60540, dest: /172.20.1.16:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742154_1330, duration(ns): 1502294
2025-03-26 02:24:35,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742154_1330, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36892, dest: /172.20.1.17:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742154_1330, duration(ns): 1981347
2025-03-26 02:24:35,310 INFO terminating
2025-03-26 02:24:35,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42806, dest: /172.20.1.15:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742154_1330, duration(ns): 3559471
2025-03-26 02:24:35,312 INFO terminating
2025-03-26 02:24:35,313 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1331, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:24:35,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742155_1331 src: /172.20.1.14:37304 dest: /172.20.1.17:9866
2025-03-26 02:24:35,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742155_1331 src: /172.20.1.17:60546 dest: /172.20.1.16:9866
2025-03-26 02:24:35,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742155_1331 src: /172.20.1.16:45392 dest: /172.20.1.15:9866
2025-03-26 02:24:35,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45392, dest: /172.20.1.15:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742155_1331, duration(ns): 1397604
2025-03-26 02:24:35,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742155_1331, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60546, dest: /172.20.1.16:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742155_1331, duration(ns): 2003103
2025-03-26 02:24:35,329 INFO terminating
2025-03-26 02:24:35,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37304, dest: /172.20.1.17:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742155_1331, duration(ns): 2956998
2025-03-26 02:24:35,331 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,331 INFO terminating
2025-03-26 02:24:35,335 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,335 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1332, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala._COPYING_
2025-03-26 02:24:35,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742156_1332 src: /172.20.1.14:42816 dest: /172.20.1.15:9866
2025-03-26 02:24:35,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742156_1332 src: /172.20.1.15:36896 dest: /172.20.1.17:9866
2025-03-26 02:24:35,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742156_1332 src: /172.20.1.17:60552 dest: /172.20.1.16:9866
2025-03-26 02:24:35,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60552, dest: /172.20.1.16:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742156_1332, duration(ns): 1204826
2025-03-26 02:24:35,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742156_1332, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36896, dest: /172.20.1.17:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742156_1332, duration(ns): 2022766
2025-03-26 02:24:35,348 INFO terminating
2025-03-26 02:24:35,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42816, dest: /172.20.1.15:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742156_1332, duration(ns): 4026699
2025-03-26 02:24:35,350 INFO terminating
2025-03-26 02:24:35,351 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,357 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1333, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala._COPYING_
2025-03-26 02:24:35,357 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,357 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742157_1333 src: /172.20.1.14:42824 dest: /172.20.1.15:9866
2025-03-26 02:24:35,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742157_1333 src: /172.20.1.15:38958 dest: /172.20.1.16:9866
2025-03-26 02:24:35,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742157_1333 src: /172.20.1.16:54860 dest: /172.20.1.17:9866
2025-03-26 02:24:35,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54860, dest: /172.20.1.17:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742157_1333, duration(ns): 1298765
2025-03-26 02:24:35,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742157_1333, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38958, dest: /172.20.1.16:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742157_1333, duration(ns): 2104500
2025-03-26 02:24:35,367 INFO terminating
2025-03-26 02:24:35,368 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42824, dest: /172.20.1.15:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742157_1333, duration(ns): 3062027
2025-03-26 02:24:35,368 INFO terminating
2025-03-26 02:24:35,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1334, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala._COPYING_
2025-03-26 02:24:35,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742158_1334 src: /172.20.1.14:42830 dest: /172.20.1.15:9866
2025-03-26 02:24:35,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742158_1334 src: /172.20.1.15:36898 dest: /172.20.1.17:9866
2025-03-26 02:24:35,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742158_1334 src: /172.20.1.17:60566 dest: /172.20.1.16:9866
2025-03-26 02:24:35,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60566, dest: /172.20.1.16:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742158_1334, duration(ns): 1151253
2025-03-26 02:24:35,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742158_1334, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36898, dest: /172.20.1.17:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742158_1334, duration(ns): 2013991
2025-03-26 02:24:35,383 INFO terminating
2025-03-26 02:24:35,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42830, dest: /172.20.1.15:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742158_1334, duration(ns): 2984350
2025-03-26 02:24:35,384 INFO terminating
2025-03-26 02:24:35,385 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1335, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala._COPYING_
2025-03-26 02:24:35,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742159_1335 src: /172.20.1.14:47738 dest: /172.20.1.16:9866
2025-03-26 02:24:35,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742159_1335 src: /172.20.1.16:45396 dest: /172.20.1.15:9866
2025-03-26 02:24:35,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742159_1335 src: /172.20.1.15:36906 dest: /172.20.1.17:9866
2025-03-26 02:24:35,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36906, dest: /172.20.1.17:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742159_1335, duration(ns): 1350991
2025-03-26 02:24:35,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742159_1335, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45396, dest: /172.20.1.15:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742159_1335, duration(ns): 1836085
2025-03-26 02:24:35,397 INFO terminating
2025-03-26 02:24:35,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47738, dest: /172.20.1.16:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742159_1335, duration(ns): 2997213
2025-03-26 02:24:35,398 INFO terminating
2025-03-26 02:24:35,399 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1336, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala._COPYING_
2025-03-26 02:24:35,403 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,403 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742160_1336 src: /172.20.1.14:47754 dest: /172.20.1.16:9866
2025-03-26 02:24:35,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742160_1336 src: /172.20.1.16:45402 dest: /172.20.1.15:9866
2025-03-26 02:24:35,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742160_1336 src: /172.20.1.15:36912 dest: /172.20.1.17:9866
2025-03-26 02:24:35,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36912, dest: /172.20.1.17:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742160_1336, duration(ns): 1024503
2025-03-26 02:24:35,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45402, dest: /172.20.1.15:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742160_1336, duration(ns): 1905905
2025-03-26 02:24:35,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742160_1336, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47754, dest: /172.20.1.16:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742160_1336, duration(ns): 2490375
2025-03-26 02:24:35,411 INFO terminating
2025-03-26 02:24:35,412 INFO terminating
2025-03-26 02:24:35,413 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1337, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala._COPYING_
2025-03-26 02:24:35,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742161_1337 src: /172.20.1.14:47758 dest: /172.20.1.16:9866
2025-03-26 02:24:35,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742161_1337 src: /172.20.1.16:45416 dest: /172.20.1.15:9866
2025-03-26 02:24:35,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742161_1337 src: /172.20.1.15:36924 dest: /172.20.1.17:9866
2025-03-26 02:24:35,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36924, dest: /172.20.1.17:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742161_1337, duration(ns): 1216977
2025-03-26 02:24:35,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742161_1337, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45416, dest: /172.20.1.15:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742161_1337, duration(ns): 1679971
2025-03-26 02:24:35,432 INFO terminating
2025-03-26 02:24:35,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47758, dest: /172.20.1.16:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742161_1337, duration(ns): 2612573
2025-03-26 02:24:35,433 INFO terminating
2025-03-26 02:24:35,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1338, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala._COPYING_
2025-03-26 02:24:35,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742162_1338 src: /172.20.1.14:47760 dest: /172.20.1.16:9866
2025-03-26 02:24:35,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742162_1338 src: /172.20.1.15:36928 dest: /172.20.1.17:9866
2025-03-26 02:24:35,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742162_1338 src: /172.20.1.16:45424 dest: /172.20.1.15:9866
2025-03-26 02:24:35,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36928, dest: /172.20.1.17:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742162_1338, duration(ns): 873984
2025-03-26 02:24:35,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742162_1338, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47760, dest: /172.20.1.16:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742162_1338, duration(ns): 1695254
2025-03-26 02:24:35,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45424, dest: /172.20.1.15:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742162_1338, duration(ns): 1421162
2025-03-26 02:24:35,447 INFO terminating
2025-03-26 02:24:35,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,448 INFO terminating
2025-03-26 02:24:35,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1339, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala._COPYING_
2025-03-26 02:24:35,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742163_1339 src: /172.20.1.14:37318 dest: /172.20.1.17:9866
2025-03-26 02:24:35,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742163_1339 src: /172.20.1.17:38850 dest: /172.20.1.15:9866
2025-03-26 02:24:35,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742163_1339 src: /172.20.1.15:38974 dest: /172.20.1.16:9866
2025-03-26 02:24:35,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38974, dest: /172.20.1.16:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742163_1339, duration(ns): 1167923
2025-03-26 02:24:35,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38850, dest: /172.20.1.15:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742163_1339, duration(ns): 1886230
2025-03-26 02:24:35,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742163_1339, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,459 INFO terminating
2025-03-26 02:24:35,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37318, dest: /172.20.1.17:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742163_1339, duration(ns): 1983406
2025-03-26 02:24:35,460 INFO terminating
2025-03-26 02:24:35,461 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,485 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1340, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala._COPYING_
2025-03-26 02:24:35,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742164_1340 src: /172.20.1.14:47766 dest: /172.20.1.16:9866
2025-03-26 02:24:35,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742164_1340 src: /172.20.1.16:54872 dest: /172.20.1.17:9866
2025-03-26 02:24:35,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742164_1340 src: /172.20.1.17:38858 dest: /172.20.1.15:9866
2025-03-26 02:24:35,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38858, dest: /172.20.1.15:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742164_1340, duration(ns): 3417723
2025-03-26 02:24:35,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742164_1340, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47766, dest: /172.20.1.16:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742164_1340, duration(ns): 4126476
2025-03-26 02:24:35,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54872, dest: /172.20.1.17:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742164_1340, duration(ns): 3577116
2025-03-26 02:24:35,496 INFO terminating
2025-03-26 02:24:35,497 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,497 INFO terminating
2025-03-26 02:24:35,501 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1341, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala._COPYING_
2025-03-26 02:24:35,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742165_1341 src: /172.20.1.14:42836 dest: /172.20.1.15:9866
2025-03-26 02:24:35,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742165_1341 src: /172.20.1.15:38976 dest: /172.20.1.16:9866
2025-03-26 02:24:35,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742165_1341 src: /172.20.1.16:54878 dest: /172.20.1.17:9866
2025-03-26 02:24:35,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38976, dest: /172.20.1.16:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742165_1341, duration(ns): 2726724
2025-03-26 02:24:35,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54878, dest: /172.20.1.17:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742165_1341, duration(ns): 2521858
2025-03-26 02:24:35,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742165_1341, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42836, dest: /172.20.1.15:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742165_1341, duration(ns): 3217220
2025-03-26 02:24:35,508 INFO terminating
2025-03-26 02:24:35,508 INFO terminating
2025-03-26 02:24:35,509 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1342, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala._COPYING_
2025-03-26 02:24:35,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742166_1342 src: /172.20.1.14:47778 dest: /172.20.1.16:9866
2025-03-26 02:24:35,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742166_1342 src: /172.20.1.16:45428 dest: /172.20.1.15:9866
2025-03-26 02:24:35,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742166_1342 src: /172.20.1.15:36942 dest: /172.20.1.17:9866
2025-03-26 02:24:35,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36942, dest: /172.20.1.17:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742166_1342, duration(ns): 1000957
2025-03-26 02:24:35,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45428, dest: /172.20.1.15:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742166_1342, duration(ns): 1585984
2025-03-26 02:24:35,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742166_1342, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,524 INFO terminating
2025-03-26 02:24:35,525 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47778, dest: /172.20.1.16:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742166_1342, duration(ns): 1754639
2025-03-26 02:24:35,525 INFO terminating
2025-03-26 02:24:35,530 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1343, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala._COPYING_
2025-03-26 02:24:35,530 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,530 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742167_1343 src: /172.20.1.14:37324 dest: /172.20.1.17:9866
2025-03-26 02:24:35,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742167_1343 src: /172.20.1.17:60568 dest: /172.20.1.16:9866
2025-03-26 02:24:35,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742167_1343 src: /172.20.1.16:45440 dest: /172.20.1.15:9866
2025-03-26 02:24:35,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45440, dest: /172.20.1.15:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742167_1343, duration(ns): 1100343
2025-03-26 02:24:35,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60568, dest: /172.20.1.16:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742167_1343, duration(ns): 1221457
2025-03-26 02:24:35,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742167_1343, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,535 INFO terminating
2025-03-26 02:24:35,536 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37324, dest: /172.20.1.17:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742167_1343, duration(ns): 1522015
2025-03-26 02:24:35,536 INFO terminating
2025-03-26 02:24:35,540 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1344, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala._COPYING_
2025-03-26 02:24:35,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,540 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742168_1344 src: /172.20.1.14:37330 dest: /172.20.1.17:9866
2025-03-26 02:24:35,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742168_1344 src: /172.20.1.15:38986 dest: /172.20.1.16:9866
2025-03-26 02:24:35,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742168_1344 src: /172.20.1.17:38862 dest: /172.20.1.15:9866
2025-03-26 02:24:35,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:38986, dest: /172.20.1.16:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742168_1344, duration(ns): 913179
2025-03-26 02:24:35,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38862, dest: /172.20.1.15:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742168_1344, duration(ns): 1208690
2025-03-26 02:24:35,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742168_1344, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,545 INFO terminating
2025-03-26 02:24:35,546 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37330, dest: /172.20.1.17:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742168_1344, duration(ns): 1433977
2025-03-26 02:24:35,546 INFO terminating
2025-03-26 02:24:35,550 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1345, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala._COPYING_
2025-03-26 02:24:35,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742169_1345 src: /172.20.1.14:47782 dest: /172.20.1.16:9866
2025-03-26 02:24:35,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742169_1345 src: /172.20.1.16:45446 dest: /172.20.1.15:9866
2025-03-26 02:24:35,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742169_1345 src: /172.20.1.15:36948 dest: /172.20.1.17:9866
2025-03-26 02:24:35,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47782, dest: /172.20.1.16:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742169_1345, duration(ns): 1576708
2025-03-26 02:24:35,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36948, dest: /172.20.1.17:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742169_1345, duration(ns): 1122097
2025-03-26 02:24:35,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45446, dest: /172.20.1.15:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742169_1345, duration(ns): 1439248
2025-03-26 02:24:35,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742169_1345, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,555 INFO terminating
2025-03-26 02:24:35,556 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,556 INFO terminating
2025-03-26 02:24:35,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1346, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala._COPYING_
2025-03-26 02:24:35,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,560 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742170_1346 src: /172.20.1.14:37332 dest: /172.20.1.17:9866
2025-03-26 02:24:35,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742170_1346 src: /172.20.1.17:38866 dest: /172.20.1.15:9866
2025-03-26 02:24:35,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742170_1346 src: /172.20.1.15:39002 dest: /172.20.1.16:9866
2025-03-26 02:24:35,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39002, dest: /172.20.1.16:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742170_1346, duration(ns): 778562
2025-03-26 02:24:35,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38866, dest: /172.20.1.15:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742170_1346, duration(ns): 1087672
2025-03-26 02:24:35,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742170_1346, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,565 INFO terminating
2025-03-26 02:24:35,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37332, dest: /172.20.1.17:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742170_1346, duration(ns): 1549421
2025-03-26 02:24:35,566 INFO terminating
2025-03-26 02:24:35,567 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,570 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1347, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala._COPYING_
2025-03-26 02:24:35,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742171_1347 src: /172.20.1.14:47792 dest: /172.20.1.16:9866
2025-03-26 02:24:35,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742171_1347 src: /172.20.1.16:54886 dest: /172.20.1.17:9866
2025-03-26 02:24:35,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742171_1347 src: /172.20.1.17:38870 dest: /172.20.1.15:9866
2025-03-26 02:24:35,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47792, dest: /172.20.1.16:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742171_1347, duration(ns): 1328819
2025-03-26 02:24:35,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54886, dest: /172.20.1.17:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742171_1347, duration(ns): 1020253
2025-03-26 02:24:35,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38870, dest: /172.20.1.15:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742171_1347, duration(ns): 906895
2025-03-26 02:24:35,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742171_1347, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,575 INFO terminating
2025-03-26 02:24:35,575 INFO terminating
2025-03-26 02:24:35,576 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1348, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala._COPYING_
2025-03-26 02:24:35,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,585 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742172_1348 src: /172.20.1.14:37344 dest: /172.20.1.17:9866
2025-03-26 02:24:35,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742172_1348 src: /172.20.1.17:60584 dest: /172.20.1.16:9866
2025-03-26 02:24:35,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742172_1348 src: /172.20.1.16:45460 dest: /172.20.1.15:9866
2025-03-26 02:24:35,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45460, dest: /172.20.1.15:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742172_1348, duration(ns): 783989
2025-03-26 02:24:35,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60584, dest: /172.20.1.16:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742172_1348, duration(ns): 929794
2025-03-26 02:24:35,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742172_1348, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,589 INFO terminating
2025-03-26 02:24:35,590 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37344, dest: /172.20.1.17:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742172_1348, duration(ns): 1068467
2025-03-26 02:24:35,590 INFO terminating
2025-03-26 02:24:35,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742173_1349, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala._COPYING_
2025-03-26 02:24:35,593 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,593 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742173_1349 src: /172.20.1.14:47794 dest: /172.20.1.16:9866
2025-03-26 02:24:35,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742173_1349 src: /172.20.1.16:54890 dest: /172.20.1.17:9866
2025-03-26 02:24:35,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742173_1349 src: /172.20.1.17:38874 dest: /172.20.1.15:9866
2025-03-26 02:24:35,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38874, dest: /172.20.1.15:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742173_1349, duration(ns): 737933
2025-03-26 02:24:35,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742173_1349, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47794, dest: /172.20.1.16:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742173_1349, duration(ns): 1514123
2025-03-26 02:24:35,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54890, dest: /172.20.1.17:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742173_1349, duration(ns): 849273
2025-03-26 02:24:35,598 INFO terminating
2025-03-26 02:24:35,598 INFO terminating
2025-03-26 02:24:35,599 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,604 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742174_1350, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala._COPYING_
2025-03-26 02:24:35,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742174_1350 src: /172.20.1.14:42838 dest: /172.20.1.15:9866
2025-03-26 02:24:35,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742174_1350 src: /172.20.1.15:39008 dest: /172.20.1.16:9866
2025-03-26 02:24:35,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742174_1350 src: /172.20.1.16:54902 dest: /172.20.1.17:9866
2025-03-26 02:24:35,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39008, dest: /172.20.1.16:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742174_1350, duration(ns): 1377263
2025-03-26 02:24:35,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54902, dest: /172.20.1.17:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742174_1350, duration(ns): 718692
2025-03-26 02:24:35,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742174_1350, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,609 INFO terminating
2025-03-26 02:24:35,610 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42838, dest: /172.20.1.15:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742174_1350, duration(ns): 2007544
2025-03-26 02:24:35,610 INFO terminating
2025-03-26 02:24:35,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742175_1351, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala._COPYING_
2025-03-26 02:24:35,615 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,615 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742175_1351 src: /172.20.1.14:37356 dest: /172.20.1.17:9866
2025-03-26 02:24:35,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742175_1351 src: /172.20.1.17:60592 dest: /172.20.1.16:9866
2025-03-26 02:24:35,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742175_1351 src: /172.20.1.16:45462 dest: /172.20.1.15:9866
2025-03-26 02:24:35,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45462, dest: /172.20.1.15:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742175_1351, duration(ns): 937090
2025-03-26 02:24:35,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60592, dest: /172.20.1.16:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742175_1351, duration(ns): 1046435
2025-03-26 02:24:35,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742175_1351, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37356, dest: /172.20.1.17:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742175_1351, duration(ns): 1568966
2025-03-26 02:24:35,620 INFO terminating
2025-03-26 02:24:35,620 INFO terminating
2025-03-26 02:24:35,621 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742176_1352, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala._COPYING_
2025-03-26 02:24:35,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742176_1352 src: /172.20.1.14:37358 dest: /172.20.1.17:9866
2025-03-26 02:24:35,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742176_1352 src: /172.20.1.17:38876 dest: /172.20.1.15:9866
2025-03-26 02:24:35,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742176_1352 src: /172.20.1.15:39012 dest: /172.20.1.16:9866
2025-03-26 02:24:35,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39012, dest: /172.20.1.16:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742176_1352, duration(ns): 823341
2025-03-26 02:24:35,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38876, dest: /172.20.1.15:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742176_1352, duration(ns): 1406426
2025-03-26 02:24:35,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742176_1352, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,630 INFO terminating
2025-03-26 02:24:35,631 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37358, dest: /172.20.1.17:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742176_1352, duration(ns): 2129330
2025-03-26 02:24:35,631 INFO terminating
2025-03-26 02:24:35,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742177_1353, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala._COPYING_
2025-03-26 02:24:35,634 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,634 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742177_1353 src: /172.20.1.14:47800 dest: /172.20.1.16:9866
2025-03-26 02:24:35,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742177_1353 src: /172.20.1.16:54914 dest: /172.20.1.17:9866
2025-03-26 02:24:35,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742177_1353 src: /172.20.1.17:38880 dest: /172.20.1.15:9866
2025-03-26 02:24:35,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38880, dest: /172.20.1.15:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742177_1353, duration(ns): 740106
2025-03-26 02:24:35,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742177_1353, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54914, dest: /172.20.1.17:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742177_1353, duration(ns): 846550
2025-03-26 02:24:35,639 INFO terminating
2025-03-26 02:24:35,640 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47800, dest: /172.20.1.16:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742177_1353, duration(ns): 1533123
2025-03-26 02:24:35,640 INFO terminating
2025-03-26 02:24:35,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742178_1354, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala._COPYING_
2025-03-26 02:24:35,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742178_1354 src: /172.20.1.14:47804 dest: /172.20.1.16:9866
2025-03-26 02:24:35,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742178_1354 src: /172.20.1.16:45464 dest: /172.20.1.15:9866
2025-03-26 02:24:35,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742178_1354 src: /172.20.1.15:36952 dest: /172.20.1.17:9866
2025-03-26 02:24:35,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36952, dest: /172.20.1.17:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742178_1354, duration(ns): 655651
2025-03-26 02:24:35,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742178_1354, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47804, dest: /172.20.1.16:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742178_1354, duration(ns): 2442530
2025-03-26 02:24:35,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45464, dest: /172.20.1.15:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742178_1354, duration(ns): 1310988
2025-03-26 02:24:35,649 INFO terminating
2025-03-26 02:24:35,649 INFO terminating
2025-03-26 02:24:35,650 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,658 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742179_1355, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala._COPYING_
2025-03-26 02:24:35,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742179_1355 src: /172.20.1.14:42844 dest: /172.20.1.15:9866
2025-03-26 02:24:35,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742179_1355 src: /172.20.1.15:39024 dest: /172.20.1.16:9866
2025-03-26 02:24:35,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742179_1355 src: /172.20.1.16:54926 dest: /172.20.1.17:9866
2025-03-26 02:24:35,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54926, dest: /172.20.1.17:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742179_1355, duration(ns): 737027
2025-03-26 02:24:35,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742179_1355, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39024, dest: /172.20.1.16:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742179_1355, duration(ns): 3363118
2025-03-26 02:24:35,666 INFO terminating
2025-03-26 02:24:35,668 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42844, dest: /172.20.1.15:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742179_1355, duration(ns): 5800128
2025-03-26 02:24:35,668 INFO terminating
2025-03-26 02:24:35,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742180_1356, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala._COPYING_
2025-03-26 02:24:35,671 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,671 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742180_1356 src: /172.20.1.14:37374 dest: /172.20.1.17:9866
2025-03-26 02:24:35,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742180_1356 src: /172.20.1.17:60596 dest: /172.20.1.16:9866
2025-03-26 02:24:35,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742180_1356 src: /172.20.1.16:45466 dest: /172.20.1.15:9866
2025-03-26 02:24:35,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45466, dest: /172.20.1.15:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742180_1356, duration(ns): 829860
2025-03-26 02:24:35,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742180_1356, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60596, dest: /172.20.1.16:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742180_1356, duration(ns): 1277120
2025-03-26 02:24:35,677 INFO terminating
2025-03-26 02:24:35,678 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37374, dest: /172.20.1.17:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742180_1356, duration(ns): 2229025
2025-03-26 02:24:35,678 INFO terminating
2025-03-26 02:24:35,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742181_1357, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala._COPYING_
2025-03-26 02:24:35,683 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,683 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742181_1357 src: /172.20.1.14:42848 dest: /172.20.1.15:9866
2025-03-26 02:24:35,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742181_1357 src: /172.20.1.15:36968 dest: /172.20.1.17:9866
2025-03-26 02:24:35,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742181_1357 src: /172.20.1.17:60602 dest: /172.20.1.16:9866
2025-03-26 02:24:35,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60602, dest: /172.20.1.16:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742181_1357, duration(ns): 758037
2025-03-26 02:24:35,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742181_1357, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42848, dest: /172.20.1.15:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742181_1357, duration(ns): 1820871
2025-03-26 02:24:35,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36968, dest: /172.20.1.17:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742181_1357, duration(ns): 1067881
2025-03-26 02:24:35,690 INFO terminating
2025-03-26 02:24:35,690 INFO terminating
2025-03-26 02:24:35,691 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742182_1358, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala._COPYING_
2025-03-26 02:24:35,694 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,694 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742182_1358 src: /172.20.1.14:37384 dest: /172.20.1.17:9866
2025-03-26 02:24:35,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742182_1358 src: /172.20.1.17:60608 dest: /172.20.1.16:9866
2025-03-26 02:24:35,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742182_1358 src: /172.20.1.16:45470 dest: /172.20.1.15:9866
2025-03-26 02:24:35,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45470, dest: /172.20.1.15:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742182_1358, duration(ns): 857649
2025-03-26 02:24:35,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60608, dest: /172.20.1.16:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742182_1358, duration(ns): 1237531
2025-03-26 02:24:35,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742182_1358, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,699 INFO terminating
2025-03-26 02:24:35,700 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37384, dest: /172.20.1.17:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742182_1358, duration(ns): 1387685
2025-03-26 02:24:35,700 INFO terminating
2025-03-26 02:24:35,703 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742183_1359, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala._COPYING_
2025-03-26 02:24:35,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742183_1359 src: /172.20.1.14:47806 dest: /172.20.1.16:9866
2025-03-26 02:24:35,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742183_1359 src: /172.20.1.16:54938 dest: /172.20.1.17:9866
2025-03-26 02:24:35,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742183_1359 src: /172.20.1.17:38882 dest: /172.20.1.15:9866
2025-03-26 02:24:35,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54938, dest: /172.20.1.17:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742183_1359, duration(ns): 1370835
2025-03-26 02:24:35,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38882, dest: /172.20.1.15:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742183_1359, duration(ns): 954560
2025-03-26 02:24:35,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742183_1359, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,708 INFO terminating
2025-03-26 02:24:35,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47806, dest: /172.20.1.16:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742183_1359, duration(ns): 1908442
2025-03-26 02:24:35,709 INFO terminating
2025-03-26 02:24:35,710 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,714 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742184_1360, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala._COPYING_
2025-03-26 02:24:35,714 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,714 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742184_1360 src: /172.20.1.14:37398 dest: /172.20.1.17:9866
2025-03-26 02:24:35,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742184_1360 src: /172.20.1.17:60610 dest: /172.20.1.16:9866
2025-03-26 02:24:35,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742184_1360 src: /172.20.1.16:45478 dest: /172.20.1.15:9866
2025-03-26 02:24:35,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45478, dest: /172.20.1.15:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742184_1360, duration(ns): 872346
2025-03-26 02:24:35,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742184_1360, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60610, dest: /172.20.1.16:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742184_1360, duration(ns): 1257810
2025-03-26 02:24:35,720 INFO terminating
2025-03-26 02:24:35,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37398, dest: /172.20.1.17:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742184_1360, duration(ns): 2090850
2025-03-26 02:24:35,721 INFO terminating
2025-03-26 02:24:35,722 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,725 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742185_1361, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala._COPYING_
2025-03-26 02:24:35,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742185_1361 src: /172.20.1.14:37402 dest: /172.20.1.17:9866
2025-03-26 02:24:35,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742185_1361 src: /172.20.1.17:38888 dest: /172.20.1.15:9866
2025-03-26 02:24:35,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742185_1361 src: /172.20.1.15:39030 dest: /172.20.1.16:9866
2025-03-26 02:24:35,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39030, dest: /172.20.1.16:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742185_1361, duration(ns): 749763
2025-03-26 02:24:35,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742185_1361, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38888, dest: /172.20.1.15:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742185_1361, duration(ns): 1309475
2025-03-26 02:24:35,730 INFO terminating
2025-03-26 02:24:35,731 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37402, dest: /172.20.1.17:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742185_1361, duration(ns): 1595813
2025-03-26 02:24:35,731 INFO terminating
2025-03-26 02:24:35,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742186_1362, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala._COPYING_
2025-03-26 02:24:35,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742186_1362 src: /172.20.1.14:42862 dest: /172.20.1.15:9866
2025-03-26 02:24:35,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742186_1362 src: /172.20.1.15:39038 dest: /172.20.1.16:9866
2025-03-26 02:24:35,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742186_1362 src: /172.20.1.16:54954 dest: /172.20.1.17:9866
2025-03-26 02:24:35,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54954, dest: /172.20.1.17:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742186_1362, duration(ns): 728324
2025-03-26 02:24:35,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742186_1362, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42862, dest: /172.20.1.15:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742186_1362, duration(ns): 3548576
2025-03-26 02:24:35,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39038, dest: /172.20.1.16:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742186_1362, duration(ns): 1313199
2025-03-26 02:24:35,742 INFO terminating
2025-03-26 02:24:35,742 INFO terminating
2025-03-26 02:24:35,743 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742187_1363, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_
2025-03-26 02:24:35,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742187_1363 src: /172.20.1.14:37416 dest: /172.20.1.17:9866
2025-03-26 02:24:35,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742187_1363 src: /172.20.1.17:60612 dest: /172.20.1.16:9866
2025-03-26 02:24:35,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742187_1363 src: /172.20.1.16:45484 dest: /172.20.1.15:9866
2025-03-26 02:24:35,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45484, dest: /172.20.1.15:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742187_1363, duration(ns): 726559
2025-03-26 02:24:35,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742187_1363, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37416, dest: /172.20.1.17:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742187_1363, duration(ns): 1297911
2025-03-26 02:24:35,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60612, dest: /172.20.1.16:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742187_1363, duration(ns): 1172678
2025-03-26 02:24:35,751 INFO terminating
2025-03-26 02:24:35,752 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,752 INFO terminating
2025-03-26 02:24:35,756 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742188_1364, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala._COPYING_
2025-03-26 02:24:35,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742188_1364 src: /172.20.1.14:42864 dest: /172.20.1.15:9866
2025-03-26 02:24:35,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742188_1364 src: /172.20.1.15:36974 dest: /172.20.1.17:9866
2025-03-26 02:24:35,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742188_1364 src: /172.20.1.17:60616 dest: /172.20.1.16:9866
2025-03-26 02:24:35,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60616, dest: /172.20.1.16:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742188_1364, duration(ns): 859411
2025-03-26 02:24:35,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742188_1364, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42864, dest: /172.20.1.15:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742188_1364, duration(ns): 1840964
2025-03-26 02:24:35,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:36974, dest: /172.20.1.17:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742188_1364, duration(ns): 1102638
2025-03-26 02:24:35,762 INFO terminating
2025-03-26 02:24:35,762 INFO terminating
2025-03-26 02:24:35,763 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,766 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742189_1365, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala._COPYING_
2025-03-26 02:24:35,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742189_1365 src: /172.20.1.14:37428 dest: /172.20.1.17:9866
2025-03-26 02:24:35,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742189_1365 src: /172.20.1.17:38904 dest: /172.20.1.15:9866
2025-03-26 02:24:35,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742189_1365 src: /172.20.1.15:39040 dest: /172.20.1.16:9866
2025-03-26 02:24:35,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:39040, dest: /172.20.1.16:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742189_1365, duration(ns): 11651754
2025-03-26 02:24:35,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:38904, dest: /172.20.1.15:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742189_1365, duration(ns): 12054150
2025-03-26 02:24:35,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742189_1365, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37428, dest: /172.20.1.17:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742189_1365, duration(ns): 12752521
2025-03-26 02:24:35,786 INFO terminating
2025-03-26 02:24:35,786 INFO terminating
2025-03-26 02:24:35,787 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,790 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,790 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,790 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742190_1366, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala._COPYING_
2025-03-26 02:24:35,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742190_1366 src: /172.20.1.14:47810 dest: /172.20.1.16:9866
2025-03-26 02:24:35,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742190_1366 src: /172.20.1.16:54958 dest: /172.20.1.17:9866
2025-03-26 02:24:35,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54958, dest: /172.20.1.17:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742190_1366, duration(ns): 544299
2025-03-26 02:24:35,795 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47810, dest: /172.20.1.16:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742190_1366, duration(ns): 1213555
2025-03-26 02:24:35,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742190_1366, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,795 INFO terminating
2025-03-26 02:24:35,798 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742191_1367, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala._COPYING_
2025-03-26 02:24:35,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,798 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,798 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,798 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,798 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742191_1367 src: /172.20.1.14:47822 dest: /172.20.1.16:9866
2025-03-26 02:24:35,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742191_1367 src: /172.20.1.16:54964 dest: /172.20.1.17:9866
2025-03-26 02:24:35,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47822, dest: /172.20.1.16:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742191_1367, duration(ns): 1074585
2025-03-26 02:24:35,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54964, dest: /172.20.1.17:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742191_1367, duration(ns): 588898
2025-03-26 02:24:35,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742191_1367, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,803 INFO terminating
2025-03-26 02:24:35,804 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742192_1368, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala._COPYING_
2025-03-26 02:24:35,807 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,807 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,807 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,807 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,807 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,807 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742192_1368 src: /172.20.1.14:47838 dest: /172.20.1.16:9866
2025-03-26 02:24:35,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742192_1368 src: /172.20.1.16:54972 dest: /172.20.1.17:9866
2025-03-26 02:24:35,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47838, dest: /172.20.1.16:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742192_1368, duration(ns): 3259146
2025-03-26 02:24:35,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54972, dest: /172.20.1.17:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742192_1368, duration(ns): 1124553
2025-03-26 02:24:35,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742192_1368, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,814 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,814 INFO terminating
2025-03-26 02:24:35,817 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742193_1369, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala._COPYING_
2025-03-26 02:24:35,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,817 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,817 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,817 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742193_1369 src: /172.20.1.14:47852 dest: /172.20.1.16:9866
2025-03-26 02:24:35,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742193_1369 src: /172.20.1.16:54974 dest: /172.20.1.17:9866
2025-03-26 02:24:35,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54974, dest: /172.20.1.17:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742193_1369, duration(ns): 529225
2025-03-26 02:24:35,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742193_1369, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,821 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47852, dest: /172.20.1.16:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742193_1369, duration(ns): 1138785
2025-03-26 02:24:35,821 INFO terminating
2025-03-26 02:24:35,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,824 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,824 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,824 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,825 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742194_1370, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala._COPYING_
2025-03-26 02:24:35,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742194_1370 src: /172.20.1.14:47868 dest: /172.20.1.16:9866
2025-03-26 02:24:35,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742194_1370 src: /172.20.1.16:54982 dest: /172.20.1.17:9866
2025-03-26 02:24:35,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54982, dest: /172.20.1.17:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742194_1370, duration(ns): 516114
2025-03-26 02:24:35,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742194_1370, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,831 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47868, dest: /172.20.1.16:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742194_1370, duration(ns): 3596716
2025-03-26 02:24:35,831 INFO terminating
2025-03-26 02:24:35,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742195_1371, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala._COPYING_
2025-03-26 02:24:35,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,834 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,834 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,834 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742195_1371 src: /172.20.1.14:37430 dest: /172.20.1.17:9866
2025-03-26 02:24:35,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742195_1371 src: /172.20.1.17:60620 dest: /172.20.1.16:9866
2025-03-26 02:24:35,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60620, dest: /172.20.1.16:9866, bytes: 1721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742195_1371, duration(ns): 479951
2025-03-26 02:24:35,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742195_1371, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37430, dest: /172.20.1.17:9866, bytes: 1721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742195_1371, duration(ns): 558851
2025-03-26 02:24:35,839 INFO terminating
2025-03-26 02:24:35,840 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,842 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,842 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,843 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742196_1372, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala._COPYING_
2025-03-26 02:24:35,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,843 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742196_1372 src: /172.20.1.14:47874 dest: /172.20.1.16:9866
2025-03-26 02:24:35,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742196_1372 src: /172.20.1.16:54998 dest: /172.20.1.17:9866
2025-03-26 02:24:35,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:54998, dest: /172.20.1.17:9866, bytes: 2906, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742196_1372, duration(ns): 456540
2025-03-26 02:24:35,854 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47874, dest: /172.20.1.16:9866, bytes: 2906, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742196_1372, duration(ns): 8494111
2025-03-26 02:24:35,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742196_1372, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,854 INFO terminating
2025-03-26 02:24:35,858 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742197_1373, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala._COPYING_
2025-03-26 02:24:35,858 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,858 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,858 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,858 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,858 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,858 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742197_1373 src: /172.20.1.14:47890 dest: /172.20.1.16:9866
2025-03-26 02:24:35,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742197_1373 src: /172.20.1.16:55004 dest: /172.20.1.17:9866
2025-03-26 02:24:35,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47890, dest: /172.20.1.16:9866, bytes: 2064, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742197_1373, duration(ns): 3799162
2025-03-26 02:24:35,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55004, dest: /172.20.1.17:9866, bytes: 2064, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742197_1373, duration(ns): 635645
2025-03-26 02:24:35,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742197_1373, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,865 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,865 INFO terminating
2025-03-26 02:24:35,868 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742198_1374, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala._COPYING_
2025-03-26 02:24:35,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,868 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,868 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,868 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742198_1374 src: /172.20.1.14:47902 dest: /172.20.1.16:9866
2025-03-26 02:24:35,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742198_1374 src: /172.20.1.16:55006 dest: /172.20.1.17:9866
2025-03-26 02:24:35,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47902, dest: /172.20.1.16:9866, bytes: 1918, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742198_1374, duration(ns): 4391188
2025-03-26 02:24:35,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55006, dest: /172.20.1.17:9866, bytes: 1918, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742198_1374, duration(ns): 548988
2025-03-26 02:24:35,875 INFO terminating
2025-03-26 02:24:35,876 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742198_1374, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742199_1375, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala._COPYING_
2025-03-26 02:24:35,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,879 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,879 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,879 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742199_1375 src: /172.20.1.14:47916 dest: /172.20.1.16:9866
2025-03-26 02:24:35,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742199_1375 src: /172.20.1.16:55014 dest: /172.20.1.17:9866
2025-03-26 02:24:35,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47916, dest: /172.20.1.16:9866, bytes: 1695, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742199_1375, duration(ns): 1277919
2025-03-26 02:24:35,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55014, dest: /172.20.1.17:9866, bytes: 1695, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742199_1375, duration(ns): 610690
2025-03-26 02:24:35,886 INFO terminating
2025-03-26 02:24:35,887 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742199_1375, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,890 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742200_1376, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala._COPYING_
2025-03-26 02:24:35,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,890 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,890 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,890 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742200_1376 src: /172.20.1.14:47930 dest: /172.20.1.16:9866
2025-03-26 02:24:35,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742200_1376 src: /172.20.1.16:55026 dest: /172.20.1.17:9866
2025-03-26 02:24:35,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55026, dest: /172.20.1.17:9866, bytes: 1851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742200_1376, duration(ns): 512267
2025-03-26 02:24:35,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742200_1376, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,895 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47930, dest: /172.20.1.16:9866, bytes: 1851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742200_1376, duration(ns): 1146785
2025-03-26 02:24:35,895 INFO terminating
2025-03-26 02:24:35,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,898 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,898 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,898 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742201_1377, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala._COPYING_
2025-03-26 02:24:35,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742201_1377 src: /172.20.1.14:37444 dest: /172.20.1.17:9866
2025-03-26 02:24:35,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742201_1377 src: /172.20.1.17:60630 dest: /172.20.1.16:9866
2025-03-26 02:24:35,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37444, dest: /172.20.1.17:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742201_1377, duration(ns): 705236
2025-03-26 02:24:35,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60630, dest: /172.20.1.16:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742201_1377, duration(ns): 629500
2025-03-26 02:24:35,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742201_1377, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,904 INFO terminating
2025-03-26 02:24:35,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742202_1378, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala._COPYING_
2025-03-26 02:24:35,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,908 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,908 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,908 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742202_1378 src: /172.20.1.14:47932 dest: /172.20.1.16:9866
2025-03-26 02:24:35,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742202_1378 src: /172.20.1.16:55040 dest: /172.20.1.17:9866
2025-03-26 02:24:35,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55040, dest: /172.20.1.17:9866, bytes: 1822, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742202_1378, duration(ns): 521744
2025-03-26 02:24:35,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47932, dest: /172.20.1.16:9866, bytes: 1822, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742202_1378, duration(ns): 1006654
2025-03-26 02:24:35,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742202_1378, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,912 INFO terminating
2025-03-26 02:24:35,918 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742203_1379, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala._COPYING_
2025-03-26 02:24:35,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,922 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,922 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,922 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742203_1379 src: /172.20.1.14:37458 dest: /172.20.1.17:9866
2025-03-26 02:24:35,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742203_1379 src: /172.20.1.17:60638 dest: /172.20.1.16:9866
2025-03-26 02:24:35,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60638, dest: /172.20.1.16:9866, bytes: 2248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742203_1379, duration(ns): 715816
2025-03-26 02:24:35,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742203_1379, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,930 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37458, dest: /172.20.1.17:9866, bytes: 2248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742203_1379, duration(ns): 1158828
2025-03-26 02:24:35,930 INFO terminating
2025-03-26 02:24:35,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742204_1380, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala._COPYING_
2025-03-26 02:24:35,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,933 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,933 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,933 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742204_1380 src: /172.20.1.14:47940 dest: /172.20.1.16:9866
2025-03-26 02:24:35,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742204_1380 src: /172.20.1.16:55054 dest: /172.20.1.17:9866
2025-03-26 02:24:35,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55054, dest: /172.20.1.17:9866, bytes: 3245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742204_1380, duration(ns): 591856
2025-03-26 02:24:35,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742204_1380, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,938 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47940, dest: /172.20.1.16:9866, bytes: 3245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742204_1380, duration(ns): 1004176
2025-03-26 02:24:35,938 INFO terminating
2025-03-26 02:24:35,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,947 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,948 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742205_1381, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:24:35,948 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,948 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742205_1381 src: /172.20.1.14:37468 dest: /172.20.1.17:9866
2025-03-26 02:24:35,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742205_1381 src: /172.20.1.17:60650 dest: /172.20.1.16:9866
2025-03-26 02:24:35,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60650, dest: /172.20.1.16:9866, bytes: 3465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742205_1381, duration(ns): 789582
2025-03-26 02:24:35,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37468, dest: /172.20.1.17:9866, bytes: 3465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742205_1381, duration(ns): 1443159
2025-03-26 02:24:35,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742205_1381, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,954 INFO terminating
2025-03-26 02:24:35,958 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,967 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,967 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,967 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742206_1382, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala._COPYING_
2025-03-26 02:24:35,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742206_1382 src: /172.20.1.14:37476 dest: /172.20.1.17:9866
2025-03-26 02:24:35,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742206_1382 src: /172.20.1.17:60654 dest: /172.20.1.16:9866
2025-03-26 02:24:35,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60654, dest: /172.20.1.16:9866, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742206_1382, duration(ns): 2023981
2025-03-26 02:24:35,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742206_1382, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:35,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37476, dest: /172.20.1.17:9866, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742206_1382, duration(ns): 3773890
2025-03-26 02:24:35,977 INFO terminating
2025-03-26 02:24:35,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:35,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742207_1383, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala._COPYING_
2025-03-26 02:24:35,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:35,981 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:35,981 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:35,981 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:35,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742207_1383 src: /172.20.1.14:37480 dest: /172.20.1.17:9866
2025-03-26 02:24:35,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742207_1383 src: /172.20.1.17:60658 dest: /172.20.1.16:9866
2025-03-26 02:24:36,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60658, dest: /172.20.1.16:9866, bytes: 3111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742207_1383, duration(ns): 663293
2025-03-26 02:24:36,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742207_1383, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37480, dest: /172.20.1.17:9866, bytes: 3111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742207_1383, duration(ns): 13776359
2025-03-26 02:24:36,005 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,005 INFO terminating
2025-03-26 02:24:36,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742208_1384, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:24:36,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,010 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,010 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,010 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742208_1384 src: /172.20.1.14:37490 dest: /172.20.1.17:9866
2025-03-26 02:24:36,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742208_1384 src: /172.20.1.17:60674 dest: /172.20.1.16:9866
2025-03-26 02:24:36,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60674, dest: /172.20.1.16:9866, bytes: 2167, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742208_1384, duration(ns): 1628358
2025-03-26 02:24:36,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742208_1384, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,060 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37490, dest: /172.20.1.17:9866, bytes: 2167, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742208_1384, duration(ns): 4268521
2025-03-26 02:24:36,060 INFO terminating
2025-03-26 02:24:36,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742209_1385, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala._COPYING_
2025-03-26 02:24:36,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,066 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,066 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,066 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742209_1385 src: /172.20.1.14:37500 dest: /172.20.1.17:9866
2025-03-26 02:24:36,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742209_1385 src: /172.20.1.17:60684 dest: /172.20.1.16:9866
2025-03-26 02:24:36,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60684, dest: /172.20.1.16:9866, bytes: 2408, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742209_1385, duration(ns): 1279467
2025-03-26 02:24:36,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742209_1385, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,081 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37500, dest: /172.20.1.17:9866, bytes: 2408, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742209_1385, duration(ns): 1603250
2025-03-26 02:24:36,081 INFO terminating
2025-03-26 02:24:36,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742210_1386, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala._COPYING_
2025-03-26 02:24:36,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,085 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,085 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,085 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742210_1386 src: /172.20.1.14:37506 dest: /172.20.1.17:9866
2025-03-26 02:24:36,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742210_1386 src: /172.20.1.17:60688 dest: /172.20.1.16:9866
2025-03-26 02:24:36,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60688, dest: /172.20.1.16:9866, bytes: 2005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742210_1386, duration(ns): 2727486
2025-03-26 02:24:36,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742210_1386, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,103 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37506, dest: /172.20.1.17:9866, bytes: 2005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742210_1386, duration(ns): 1512216
2025-03-26 02:24:36,103 INFO terminating
2025-03-26 02:24:36,107 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742211_1387, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala._COPYING_
2025-03-26 02:24:36,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,107 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,107 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,107 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742211_1387 src: /172.20.1.14:37508 dest: /172.20.1.17:9866
2025-03-26 02:24:36,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742211_1387 src: /172.20.1.17:60694 dest: /172.20.1.16:9866
2025-03-26 02:24:36,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37508, dest: /172.20.1.17:9866, bytes: 3423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742211_1387, duration(ns): 1253510
2025-03-26 02:24:36,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60694, dest: /172.20.1.16:9866, bytes: 3423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742211_1387, duration(ns): 746883
2025-03-26 02:24:36,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742211_1387, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,113 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,113 INFO terminating
2025-03-26 02:24:36,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742212_1388, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala._COPYING_
2025-03-26 02:24:36,117 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,117 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,117 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742212_1388 src: /172.20.1.14:37518 dest: /172.20.1.17:9866
2025-03-26 02:24:36,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742212_1388 src: /172.20.1.17:60702 dest: /172.20.1.16:9866
2025-03-26 02:24:36,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60702, dest: /172.20.1.16:9866, bytes: 9724, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742212_1388, duration(ns): 770119
2025-03-26 02:24:36,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742212_1388, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,122 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37518, dest: /172.20.1.17:9866, bytes: 9724, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742212_1388, duration(ns): 1321206
2025-03-26 02:24:36,122 INFO terminating
2025-03-26 02:24:36,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,125 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,125 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,125 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742213_1389, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala._COPYING_
2025-03-26 02:24:36,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742213_1389 src: /172.20.1.14:37526 dest: /172.20.1.17:9866
2025-03-26 02:24:36,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742213_1389 src: /172.20.1.17:60710 dest: /172.20.1.16:9866
2025-03-26 02:24:36,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60710, dest: /172.20.1.16:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742213_1389, duration(ns): 780054
2025-03-26 02:24:36,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742213_1389, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37526, dest: /172.20.1.17:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742213_1389, duration(ns): 1165078
2025-03-26 02:24:36,132 INFO terminating
2025-03-26 02:24:36,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742214_1390, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala._COPYING_
2025-03-26 02:24:36,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,136 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,136 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,136 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742214_1390 src: /172.20.1.14:47944 dest: /172.20.1.16:9866
2025-03-26 02:24:36,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742214_1390 src: /172.20.1.16:55070 dest: /172.20.1.17:9866
2025-03-26 02:24:36,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55070, dest: /172.20.1.17:9866, bytes: 1730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742214_1390, duration(ns): 629405
2025-03-26 02:24:36,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742214_1390, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,145 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47944, dest: /172.20.1.16:9866, bytes: 1730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742214_1390, duration(ns): 1296623
2025-03-26 02:24:36,145 INFO terminating
2025-03-26 02:24:36,149 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742215_1391, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala._COPYING_
2025-03-26 02:24:36,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,149 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,149 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,149 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742215_1391 src: /172.20.1.14:37528 dest: /172.20.1.17:9866
2025-03-26 02:24:36,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742215_1391 src: /172.20.1.17:60726 dest: /172.20.1.16:9866
2025-03-26 02:24:36,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60726, dest: /172.20.1.16:9866, bytes: 2185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742215_1391, duration(ns): 613707
2025-03-26 02:24:36,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742215_1391, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37528, dest: /172.20.1.17:9866, bytes: 2185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742215_1391, duration(ns): 737627
2025-03-26 02:24:36,153 INFO terminating
2025-03-26 02:24:36,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,156 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,156 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,156 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,157 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742216_1392, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala._COPYING_
2025-03-26 02:24:36,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742216_1392 src: /172.20.1.14:37534 dest: /172.20.1.17:9866
2025-03-26 02:24:36,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742216_1392 src: /172.20.1.17:60732 dest: /172.20.1.16:9866
2025-03-26 02:24:36,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60732, dest: /172.20.1.16:9866, bytes: 1283, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742216_1392, duration(ns): 620717
2025-03-26 02:24:36,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742216_1392, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,161 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37534, dest: /172.20.1.17:9866, bytes: 1283, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742216_1392, duration(ns): 857297
2025-03-26 02:24:36,161 INFO terminating
2025-03-26 02:24:36,164 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742217_1393, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala._COPYING_
2025-03-26 02:24:36,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,164 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,164 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,164 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742217_1393 src: /172.20.1.14:47956 dest: /172.20.1.16:9866
2025-03-26 02:24:36,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742217_1393 src: /172.20.1.16:55072 dest: /172.20.1.17:9866
2025-03-26 02:24:36,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55072, dest: /172.20.1.17:9866, bytes: 4111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742217_1393, duration(ns): 574147
2025-03-26 02:24:36,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742217_1393, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,169 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47956, dest: /172.20.1.16:9866, bytes: 4111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742217_1393, duration(ns): 1165840
2025-03-26 02:24:36,169 INFO terminating
2025-03-26 02:24:36,178 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742218_1394, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala._COPYING_
2025-03-26 02:24:36,178 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,178 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,178 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,178 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,178 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,178 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742218_1394 src: /172.20.1.14:47964 dest: /172.20.1.16:9866
2025-03-26 02:24:36,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742218_1394 src: /172.20.1.16:55082 dest: /172.20.1.17:9866
2025-03-26 02:24:36,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55082, dest: /172.20.1.17:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742218_1394, duration(ns): 511511
2025-03-26 02:24:36,182 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47964, dest: /172.20.1.16:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742218_1394, duration(ns): 1047413
2025-03-26 02:24:36,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742218_1394, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,182 INFO terminating
2025-03-26 02:24:36,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742219_1395, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala._COPYING_
2025-03-26 02:24:36,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,186 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,186 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,186 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742219_1395 src: /172.20.1.14:37536 dest: /172.20.1.17:9866
2025-03-26 02:24:36,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742219_1395 src: /172.20.1.17:60744 dest: /172.20.1.16:9866
2025-03-26 02:24:36,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60744, dest: /172.20.1.16:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742219_1395, duration(ns): 469377
2025-03-26 02:24:36,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742219_1395, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,190 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37536, dest: /172.20.1.17:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742219_1395, duration(ns): 620629
2025-03-26 02:24:36,190 INFO terminating
2025-03-26 02:24:36,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742220_1396, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala._COPYING_
2025-03-26 02:24:36,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,195 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,195 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,195 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742220_1396 src: /172.20.1.14:37540 dest: /172.20.1.17:9866
2025-03-26 02:24:36,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742220_1396 src: /172.20.1.17:60746 dest: /172.20.1.16:9866
2025-03-26 02:24:36,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37540, dest: /172.20.1.17:9866, bytes: 4039, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742220_1396, duration(ns): 2535714
2025-03-26 02:24:36,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60746, dest: /172.20.1.16:9866, bytes: 4039, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742220_1396, duration(ns): 2865436
2025-03-26 02:24:36,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742220_1396, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,201 INFO terminating
2025-03-26 02:24:36,202 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,205 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742221_1397, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala._COPYING_
2025-03-26 02:24:36,206 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,206 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742221_1397 src: /172.20.1.14:37552 dest: /172.20.1.17:9866
2025-03-26 02:24:36,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742221_1397 src: /172.20.1.17:60758 dest: /172.20.1.16:9866
2025-03-26 02:24:36,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60758, dest: /172.20.1.16:9866, bytes: 2469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742221_1397, duration(ns): 504253
2025-03-26 02:24:36,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742221_1397, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,210 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37552, dest: /172.20.1.17:9866, bytes: 2469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742221_1397, duration(ns): 600634
2025-03-26 02:24:36,210 INFO terminating
2025-03-26 02:24:36,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742222_1398, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala._COPYING_
2025-03-26 02:24:36,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,213 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,213 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,213 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742222_1398 src: /172.20.1.14:37558 dest: /172.20.1.17:9866
2025-03-26 02:24:36,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742222_1398 src: /172.20.1.17:60772 dest: /172.20.1.16:9866
2025-03-26 02:24:36,216 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37558, dest: /172.20.1.17:9866, bytes: 2159, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742222_1398, duration(ns): 703778
2025-03-26 02:24:36,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60772, dest: /172.20.1.16:9866, bytes: 2159, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742222_1398, duration(ns): 471071
2025-03-26 02:24:36,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742222_1398, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,216 INFO terminating
2025-03-26 02:24:36,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742223_1399, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala._COPYING_
2025-03-26 02:24:36,220 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,220 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,220 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742223_1399 src: /172.20.1.14:37562 dest: /172.20.1.17:9866
2025-03-26 02:24:36,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742223_1399 src: /172.20.1.17:60778 dest: /172.20.1.16:9866
2025-03-26 02:24:36,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37562, dest: /172.20.1.17:9866, bytes: 4648, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742223_1399, duration(ns): 736983
2025-03-26 02:24:36,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60778, dest: /172.20.1.16:9866, bytes: 4648, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742223_1399, duration(ns): 490628
2025-03-26 02:24:36,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742223_1399, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,223 INFO terminating
2025-03-26 02:24:36,224 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,228 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742224_1400, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala._COPYING_
2025-03-26 02:24:36,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,228 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,228 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,228 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742224_1400 src: /172.20.1.14:37570 dest: /172.20.1.17:9866
2025-03-26 02:24:36,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742224_1400 src: /172.20.1.17:60782 dest: /172.20.1.16:9866
2025-03-26 02:24:36,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60782, dest: /172.20.1.16:9866, bytes: 2705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742224_1400, duration(ns): 563234
2025-03-26 02:24:36,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742224_1400, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,235 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37570, dest: /172.20.1.17:9866, bytes: 2705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742224_1400, duration(ns): 2511456
2025-03-26 02:24:36,235 INFO terminating
2025-03-26 02:24:36,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742225_1401, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_
2025-03-26 02:24:36,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,238 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,238 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,238 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742225_1401 src: /172.20.1.14:37580 dest: /172.20.1.17:9866
2025-03-26 02:24:36,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742225_1401 src: /172.20.1.17:60798 dest: /172.20.1.16:9866
2025-03-26 02:24:36,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37580, dest: /172.20.1.17:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742225_1401, duration(ns): 768311
2025-03-26 02:24:36,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60798, dest: /172.20.1.16:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742225_1401, duration(ns): 480796
2025-03-26 02:24:36,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742225_1401, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,242 INFO terminating
2025-03-26 02:24:36,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742225_1401 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_
2025-03-26 02:24:36,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742226_1402, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala._COPYING_
2025-03-26 02:24:36,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,653 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,653 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,653 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742226_1402 src: /172.20.1.14:37596 dest: /172.20.1.17:9866
2025-03-26 02:24:36,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742226_1402 src: /172.20.1.17:60802 dest: /172.20.1.16:9866
2025-03-26 02:24:36,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60802, dest: /172.20.1.16:9866, bytes: 1842, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742226_1402, duration(ns): 1898872
2025-03-26 02:24:36,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742226_1402, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37596, dest: /172.20.1.17:9866, bytes: 1842, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742226_1402, duration(ns): 2792819
2025-03-26 02:24:36,665 INFO terminating
2025-03-26 02:24:36,666 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742227_1403, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala._COPYING_
2025-03-26 02:24:36,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,675 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,675 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,675 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742227_1403 src: /172.20.1.14:37600 dest: /172.20.1.17:9866
2025-03-26 02:24:36,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742227_1403 src: /172.20.1.17:60810 dest: /172.20.1.16:9866
2025-03-26 02:24:36,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60810, dest: /172.20.1.16:9866, bytes: 1669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742227_1403, duration(ns): 2011444
2025-03-26 02:24:36,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742227_1403, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37600, dest: /172.20.1.17:9866, bytes: 1669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742227_1403, duration(ns): 2934236
2025-03-26 02:24:36,686 INFO terminating
2025-03-26 02:24:36,687 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,696 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742228_1404, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala._COPYING_
2025-03-26 02:24:36,696 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,696 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,696 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,696 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,696 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,696 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742228_1404 src: /172.20.1.14:37608 dest: /172.20.1.17:9866
2025-03-26 02:24:36,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742228_1404 src: /172.20.1.17:60812 dest: /172.20.1.16:9866
2025-03-26 02:24:36,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60812, dest: /172.20.1.16:9866, bytes: 1920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742228_1404, duration(ns): 1460549
2025-03-26 02:24:36,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742228_1404, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37608, dest: /172.20.1.17:9866, bytes: 1920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742228_1404, duration(ns): 2030897
2025-03-26 02:24:36,704 INFO terminating
2025-03-26 02:24:36,705 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,716 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,716 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,717 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742229_1405, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala._COPYING_
2025-03-26 02:24:36,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,717 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,717 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,717 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742229_1405 src: /172.20.1.14:37624 dest: /172.20.1.17:9866
2025-03-26 02:24:36,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742229_1405 src: /172.20.1.17:60816 dest: /172.20.1.16:9866
2025-03-26 02:24:36,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37624, dest: /172.20.1.17:9866, bytes: 5351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742229_1405, duration(ns): 830591
2025-03-26 02:24:36,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60816, dest: /172.20.1.16:9866, bytes: 5351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742229_1405, duration(ns): 661331
2025-03-26 02:24:36,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742229_1405, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,720 INFO terminating
2025-03-26 02:24:36,721 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742230_1406, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala._COPYING_
2025-03-26 02:24:36,727 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,727 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,727 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,727 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,727 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,727 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742230_1406 src: /172.20.1.14:37632 dest: /172.20.1.17:9866
2025-03-26 02:24:36,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742230_1406 src: /172.20.1.17:60822 dest: /172.20.1.16:9866
2025-03-26 02:24:36,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37632, dest: /172.20.1.17:9866, bytes: 3444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742230_1406, duration(ns): 697411
2025-03-26 02:24:36,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60822, dest: /172.20.1.16:9866, bytes: 3444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742230_1406, duration(ns): 453050
2025-03-26 02:24:36,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742230_1406, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,731 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,731 INFO terminating
2025-03-26 02:24:36,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742231_1407, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_
2025-03-26 02:24:36,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,735 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,735 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,735 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742231_1407 src: /172.20.1.14:37636 dest: /172.20.1.17:9866
2025-03-26 02:24:36,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742231_1407 src: /172.20.1.17:60826 dest: /172.20.1.16:9866
2025-03-26 02:24:36,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37636, dest: /172.20.1.17:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742231_1407, duration(ns): 1374452
2025-03-26 02:24:36,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60826, dest: /172.20.1.16:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742231_1407, duration(ns): 1117284
2025-03-26 02:24:36,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742231_1407, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,739 INFO terminating
2025-03-26 02:24:36,740 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,744 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742232_1408, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala._COPYING_
2025-03-26 02:24:36,744 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,744 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,744 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,744 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,744 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,744 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742232_1408 src: /172.20.1.14:47966 dest: /172.20.1.16:9866
2025-03-26 02:24:36,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742232_1408 src: /172.20.1.16:55084 dest: /172.20.1.17:9866
2025-03-26 02:24:36,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47966, dest: /172.20.1.16:9866, bytes: 15338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742232_1408, duration(ns): 766755
2025-03-26 02:24:36,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55084, dest: /172.20.1.17:9866, bytes: 15338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742232_1408, duration(ns): 510586
2025-03-26 02:24:36,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742232_1408, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,748 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,748 INFO terminating
2025-03-26 02:24:36,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742233_1409, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_
2025-03-26 02:24:36,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,753 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,753 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,753 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742233_1409 src: /172.20.1.14:37642 dest: /172.20.1.17:9866
2025-03-26 02:24:36,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742233_1409 src: /172.20.1.17:60830 dest: /172.20.1.16:9866
2025-03-26 02:24:36,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60830, dest: /172.20.1.16:9866, bytes: 5661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742233_1409, duration(ns): 463164
2025-03-26 02:24:36,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742233_1409, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,757 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37642, dest: /172.20.1.17:9866, bytes: 5661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742233_1409, duration(ns): 733261
2025-03-26 02:24:36,757 INFO terminating
2025-03-26 02:24:36,760 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742234_1410, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala._COPYING_
2025-03-26 02:24:36,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,760 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,760 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,760 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742234_1410 src: /172.20.1.14:37652 dest: /172.20.1.17:9866
2025-03-26 02:24:36,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742234_1410 src: /172.20.1.17:60836 dest: /172.20.1.16:9866
2025-03-26 02:24:36,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37652, dest: /172.20.1.17:9866, bytes: 3236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742234_1410, duration(ns): 658041
2025-03-26 02:24:36,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60836, dest: /172.20.1.16:9866, bytes: 3236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742234_1410, duration(ns): 425230
2025-03-26 02:24:36,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742234_1410, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,763 INFO terminating
2025-03-26 02:24:36,764 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,766 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742235_1411, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala._COPYING_
2025-03-26 02:24:36,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,766 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,766 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,766 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742235_1411 src: /172.20.1.14:37660 dest: /172.20.1.17:9866
2025-03-26 02:24:36,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742235_1411 src: /172.20.1.17:60842 dest: /172.20.1.16:9866
2025-03-26 02:24:36,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60842, dest: /172.20.1.16:9866, bytes: 2552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742235_1411, duration(ns): 426664
2025-03-26 02:24:36,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742235_1411, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,770 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37660, dest: /172.20.1.17:9866, bytes: 2552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742235_1411, duration(ns): 657243
2025-03-26 02:24:36,770 INFO terminating
2025-03-26 02:24:36,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742236_1412, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala._COPYING_
2025-03-26 02:24:36,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,773 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,773 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,773 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742236_1412 src: /172.20.1.14:47978 dest: /172.20.1.16:9866
2025-03-26 02:24:36,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742236_1412 src: /172.20.1.16:55090 dest: /172.20.1.17:9866
2025-03-26 02:24:36,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47978, dest: /172.20.1.16:9866, bytes: 8698, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742236_1412, duration(ns): 654202
2025-03-26 02:24:36,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55090, dest: /172.20.1.17:9866, bytes: 8698, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742236_1412, duration(ns): 415439
2025-03-26 02:24:36,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742236_1412, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,776 INFO terminating
2025-03-26 02:24:36,777 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,781 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,782 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742237_1413, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala._COPYING_
2025-03-26 02:24:36,782 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,782 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,782 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,782 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,782 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742237_1413 src: /172.20.1.14:47980 dest: /172.20.1.16:9866
2025-03-26 02:24:36,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742237_1413 src: /172.20.1.16:55102 dest: /172.20.1.17:9866
2025-03-26 02:24:36,785 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:47980, dest: /172.20.1.16:9866, bytes: 2443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742237_1413, duration(ns): 655570
2025-03-26 02:24:36,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55102, dest: /172.20.1.17:9866, bytes: 2443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742237_1413, duration(ns): 409330
2025-03-26 02:24:36,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742237_1413, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,785 INFO terminating
2025-03-26 02:24:36,788 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742238_1414, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala._COPYING_
2025-03-26 02:24:36,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,788 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,788 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,788 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742238_1414 src: /172.20.1.14:37662 dest: /172.20.1.17:9866
2025-03-26 02:24:36,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742238_1414 src: /172.20.1.17:60858 dest: /172.20.1.16:9866
2025-03-26 02:24:36,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60858, dest: /172.20.1.16:9866, bytes: 4044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742238_1414, duration(ns): 427927
2025-03-26 02:24:36,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742238_1414, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37662, dest: /172.20.1.17:9866, bytes: 4044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742238_1414, duration(ns): 657012
2025-03-26 02:24:36,792 INFO terminating
2025-03-26 02:24:36,794 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,797 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742239_1415, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala._COPYING_
2025-03-26 02:24:36,797 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,797 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,797 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,797 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,797 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,797 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742239_1415 src: /172.20.1.14:37664 dest: /172.20.1.17:9866
2025-03-26 02:24:36,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742239_1415 src: /172.20.1.17:60862 dest: /172.20.1.16:9866
2025-03-26 02:24:36,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37664, dest: /172.20.1.17:9866, bytes: 5410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742239_1415, duration(ns): 666164
2025-03-26 02:24:36,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60862, dest: /172.20.1.16:9866, bytes: 5410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742239_1415, duration(ns): 425054
2025-03-26 02:24:36,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742239_1415, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,800 INFO terminating
2025-03-26 02:24:36,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742240_1416, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala._COPYING_
2025-03-26 02:24:36,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,804 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,804 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,804 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742240_1416 src: /172.20.1.14:37674 dest: /172.20.1.17:9866
2025-03-26 02:24:36,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742240_1416 src: /172.20.1.17:60872 dest: /172.20.1.16:9866
2025-03-26 02:24:36,807 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:36,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37674, dest: /172.20.1.17:9866, bytes: 3440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742240_1416, duration(ns): 645814
2025-03-26 02:24:36,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60872, dest: /172.20.1.16:9866, bytes: 3440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742240_1416, duration(ns): 449034
2025-03-26 02:24:36,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742240_1416, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,807 INFO terminating
2025-03-26 02:24:36,810 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742241_1417, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_
2025-03-26 02:24:36,810 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,810 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,810 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:36,810 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:36,810 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:36,810 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:36,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742241_1417 src: /172.20.1.14:37678 dest: /172.20.1.17:9866
2025-03-26 02:24:36,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742241_1417 src: /172.20.1.17:60880 dest: /172.20.1.16:9866
2025-03-26 02:24:36,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:60880, dest: /172.20.1.16:9866, bytes: 11092, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742241_1417, duration(ns): 1565732
2025-03-26 02:24:36,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742241_1417, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:36,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:37678, dest: /172.20.1.17:9866, bytes: 11092, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742241_1417, duration(ns): 1809619
2025-03-26 02:24:36,815 INFO terminating
2025-03-26 02:24:36,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742241_1417 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_
2025-03-26 02:24:37,220 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,229 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742242_1418, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala._COPYING_
2025-03-26 02:24:37,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,229 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,229 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,229 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742242_1418 src: /172.20.1.14:41614 dest: /172.20.1.16:9866
2025-03-26 02:24:37,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742242_1418 src: /172.20.1.16:55658 dest: /172.20.1.17:9866
2025-03-26 02:24:37,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55658, dest: /172.20.1.17:9866, bytes: 3139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742242_1418, duration(ns): 2061815
2025-03-26 02:24:37,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742242_1418, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41614, dest: /172.20.1.16:9866, bytes: 3139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742242_1418, duration(ns): 3016709
2025-03-26 02:24:37,241 INFO terminating
2025-03-26 02:24:37,242 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,254 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,254 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,254 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,255 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742243_1419, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala._COPYING_
2025-03-26 02:24:37,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742243_1419 src: /172.20.1.14:41630 dest: /172.20.1.16:9866
2025-03-26 02:24:37,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742243_1419 src: /172.20.1.16:55672 dest: /172.20.1.17:9866
2025-03-26 02:24:37,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41630, dest: /172.20.1.16:9866, bytes: 3234, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742243_1419, duration(ns): 1419012
2025-03-26 02:24:37,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55672, dest: /172.20.1.17:9866, bytes: 3234, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742243_1419, duration(ns): 1009314
2025-03-26 02:24:37,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742243_1419, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,260 INFO terminating
2025-03-26 02:24:37,261 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742244_1420, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_
2025-03-26 02:24:37,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,267 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,267 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,267 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742244_1420 src: /172.20.1.14:41634 dest: /172.20.1.16:9866
2025-03-26 02:24:37,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742244_1420 src: /172.20.1.16:55678 dest: /172.20.1.17:9866
2025-03-26 02:24:37,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55678, dest: /172.20.1.17:9866, bytes: 2178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742244_1420, duration(ns): 3988330
2025-03-26 02:24:37,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742244_1420, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,275 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41634, dest: /172.20.1.16:9866, bytes: 2178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742244_1420, duration(ns): 4331878
2025-03-26 02:24:37,275 INFO terminating
2025-03-26 02:24:37,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742245_1421, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala._COPYING_
2025-03-26 02:24:37,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,283 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,283 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,283 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742245_1421 src: /172.20.1.14:43130 dest: /172.20.1.17:9866
2025-03-26 02:24:37,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742245_1421 src: /172.20.1.17:34450 dest: /172.20.1.16:9866
2025-03-26 02:24:37,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43130, dest: /172.20.1.17:9866, bytes: 1575, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742245_1421, duration(ns): 916004
2025-03-26 02:24:37,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34450, dest: /172.20.1.16:9866, bytes: 1575, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742245_1421, duration(ns): 704449
2025-03-26 02:24:37,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742245_1421, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,287 INFO terminating
2025-03-26 02:24:37,288 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,291 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742246_1422, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala._COPYING_
2025-03-26 02:24:37,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,291 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,291 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,291 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742246_1422 src: /172.20.1.14:43134 dest: /172.20.1.17:9866
2025-03-26 02:24:37,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742246_1422 src: /172.20.1.17:34458 dest: /172.20.1.16:9866
2025-03-26 02:24:37,295 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43134, dest: /172.20.1.17:9866, bytes: 3268, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742246_1422, duration(ns): 775359
2025-03-26 02:24:37,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34458, dest: /172.20.1.16:9866, bytes: 3268, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742246_1422, duration(ns): 634264
2025-03-26 02:24:37,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742246_1422, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,295 INFO terminating
2025-03-26 02:24:37,298 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742247_1423, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala._COPYING_
2025-03-26 02:24:37,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,298 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,298 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,298 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742247_1423 src: /172.20.1.14:43146 dest: /172.20.1.17:9866
2025-03-26 02:24:37,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742247_1423 src: /172.20.1.17:34464 dest: /172.20.1.16:9866
2025-03-26 02:24:37,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43146, dest: /172.20.1.17:9866, bytes: 2670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742247_1423, duration(ns): 522673
2025-03-26 02:24:37,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34464, dest: /172.20.1.16:9866, bytes: 2670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742247_1423, duration(ns): 437868
2025-03-26 02:24:37,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742247_1423, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,301 INFO terminating
2025-03-26 02:24:37,302 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,304 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,304 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,304 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,304 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,304 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,304 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,305 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742248_1424, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala._COPYING_
2025-03-26 02:24:37,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742248_1424 src: /172.20.1.14:41644 dest: /172.20.1.16:9866
2025-03-26 02:24:37,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742248_1424 src: /172.20.1.16:55690 dest: /172.20.1.17:9866
2025-03-26 02:24:37,309 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41644, dest: /172.20.1.16:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742248_1424, duration(ns): 709885
2025-03-26 02:24:37,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55690, dest: /172.20.1.17:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742248_1424, duration(ns): 378569
2025-03-26 02:24:37,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742248_1424, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,309 INFO terminating
2025-03-26 02:24:37,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742249_1425, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala._COPYING_
2025-03-26 02:24:37,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,313 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,313 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,313 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742249_1425 src: /172.20.1.14:41652 dest: /172.20.1.16:9866
2025-03-26 02:24:37,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742249_1425 src: /172.20.1.16:55706 dest: /172.20.1.17:9866
2025-03-26 02:24:37,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41652, dest: /172.20.1.16:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742249_1425, duration(ns): 688351
2025-03-26 02:24:37,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55706, dest: /172.20.1.17:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742249_1425, duration(ns): 467810
2025-03-26 02:24:37,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742249_1425, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,317 INFO terminating
2025-03-26 02:24:37,318 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742250_1426, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala._COPYING_
2025-03-26 02:24:37,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,321 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,321 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,321 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742250_1426 src: /172.20.1.14:43158 dest: /172.20.1.17:9866
2025-03-26 02:24:37,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742250_1426 src: /172.20.1.17:34480 dest: /172.20.1.16:9866
2025-03-26 02:24:37,324 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43158, dest: /172.20.1.17:9866, bytes: 5326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742250_1426, duration(ns): 618458
2025-03-26 02:24:37,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34480, dest: /172.20.1.16:9866, bytes: 5326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742250_1426, duration(ns): 399553
2025-03-26 02:24:37,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742250_1426, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,324 INFO terminating
2025-03-26 02:24:37,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742251_1427, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala._COPYING_
2025-03-26 02:24:37,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,329 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,329 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,329 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742251_1427 src: /172.20.1.14:43174 dest: /172.20.1.17:9866
2025-03-26 02:24:37,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742251_1427 src: /172.20.1.17:34482 dest: /172.20.1.16:9866
2025-03-26 02:24:37,332 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43174, dest: /172.20.1.17:9866, bytes: 3737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742251_1427, duration(ns): 628387
2025-03-26 02:24:37,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34482, dest: /172.20.1.16:9866, bytes: 3737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742251_1427, duration(ns): 380754
2025-03-26 02:24:37,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742251_1427, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,332 INFO terminating
2025-03-26 02:24:37,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742252_1428, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_
2025-03-26 02:24:37,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,336 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,336 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,336 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742252_1428 src: /172.20.1.14:41660 dest: /172.20.1.16:9866
2025-03-26 02:24:37,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742252_1428 src: /172.20.1.16:55718 dest: /172.20.1.17:9866
2025-03-26 02:24:37,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55718, dest: /172.20.1.17:9866, bytes: 4800, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742252_1428, duration(ns): 449761
2025-03-26 02:24:37,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742252_1428, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,341 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41660, dest: /172.20.1.16:9866, bytes: 4800, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742252_1428, duration(ns): 703796
2025-03-26 02:24:37,341 INFO terminating
2025-03-26 02:24:37,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742253_1429, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala._COPYING_
2025-03-26 02:24:37,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,346 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,346 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,346 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742253_1429 src: /172.20.1.14:41670 dest: /172.20.1.16:9866
2025-03-26 02:24:37,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742253_1429 src: /172.20.1.16:55720 dest: /172.20.1.17:9866
2025-03-26 02:24:37,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41670, dest: /172.20.1.16:9866, bytes: 3780, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742253_1429, duration(ns): 661297
2025-03-26 02:24:37,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55720, dest: /172.20.1.17:9866, bytes: 3780, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742253_1429, duration(ns): 403139
2025-03-26 02:24:37,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742253_1429, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,349 INFO terminating
2025-03-26 02:24:37,350 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742254_1430, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala._COPYING_
2025-03-26 02:24:37,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,352 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,352 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,352 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742254_1430 src: /172.20.1.14:41682 dest: /172.20.1.16:9866
2025-03-26 02:24:37,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742254_1430 src: /172.20.1.16:55722 dest: /172.20.1.17:9866
2025-03-26 02:24:37,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41682, dest: /172.20.1.16:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742254_1430, duration(ns): 594243
2025-03-26 02:24:37,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55722, dest: /172.20.1.17:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742254_1430, duration(ns): 355172
2025-03-26 02:24:37,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742254_1430, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,355 INFO terminating
2025-03-26 02:24:37,356 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,358 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,358 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,358 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742255_1431, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_
2025-03-26 02:24:37,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742255_1431 src: /172.20.1.14:41688 dest: /172.20.1.16:9866
2025-03-26 02:24:37,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742255_1431 src: /172.20.1.16:55732 dest: /172.20.1.17:9866
2025-03-26 02:24:37,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41688, dest: /172.20.1.16:9866, bytes: 6363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742255_1431, duration(ns): 672008
2025-03-26 02:24:37,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55732, dest: /172.20.1.17:9866, bytes: 6363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742255_1431, duration(ns): 411812
2025-03-26 02:24:37,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742255_1431, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,362 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742255_1431 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_
2025-03-26 02:24:37,362 INFO terminating
2025-03-26 02:24:37,763 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,777 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,778 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742256_1432, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala._COPYING_
2025-03-26 02:24:37,778 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,778 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742256_1432 src: /172.20.1.14:41692 dest: /172.20.1.16:9866
2025-03-26 02:24:37,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742256_1432 src: /172.20.1.16:55736 dest: /172.20.1.17:9866
2025-03-26 02:24:37,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55736, dest: /172.20.1.17:9866, bytes: 3786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742256_1432, duration(ns): 2607620
2025-03-26 02:24:37,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742256_1432, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,790 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41692, dest: /172.20.1.16:9866, bytes: 3786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742256_1432, duration(ns): 3707410
2025-03-26 02:24:37,790 INFO terminating
2025-03-26 02:24:37,803 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742257_1433, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_
2025-03-26 02:24:37,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,803 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,803 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,803 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742257_1433 src: /172.20.1.14:41696 dest: /172.20.1.16:9866
2025-03-26 02:24:37,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742257_1433 src: /172.20.1.16:55752 dest: /172.20.1.17:9866
2025-03-26 02:24:37,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41696, dest: /172.20.1.16:9866, bytes: 4303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742257_1433, duration(ns): 1077831
2025-03-26 02:24:37,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55752, dest: /172.20.1.17:9866, bytes: 4303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742257_1433, duration(ns): 666150
2025-03-26 02:24:37,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742257_1433, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,807 INFO terminating
2025-03-26 02:24:37,808 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742258_1434, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java._COPYING_
2025-03-26 02:24:37,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,814 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,814 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,814 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742258_1434 src: /172.20.1.14:43188 dest: /172.20.1.17:9866
2025-03-26 02:24:37,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742258_1434 src: /172.20.1.17:34488 dest: /172.20.1.16:9866
2025-03-26 02:24:37,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43188, dest: /172.20.1.17:9866, bytes: 4032, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742258_1434, duration(ns): 1344871
2025-03-26 02:24:37,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34488, dest: /172.20.1.16:9866, bytes: 4032, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742258_1434, duration(ns): 778641
2025-03-26 02:24:37,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742258_1434, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,819 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,819 INFO terminating
2025-03-26 02:24:37,822 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742259_1435, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java._COPYING_
2025-03-26 02:24:37,822 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,822 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,822 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,822 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,822 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,822 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742259_1435 src: /172.20.1.14:41706 dest: /172.20.1.16:9866
2025-03-26 02:24:37,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742259_1435 src: /172.20.1.16:55768 dest: /172.20.1.17:9866
2025-03-26 02:24:37,826 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41706, dest: /172.20.1.16:9866, bytes: 3436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742259_1435, duration(ns): 725486
2025-03-26 02:24:37,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55768, dest: /172.20.1.17:9866, bytes: 3436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742259_1435, duration(ns): 548312
2025-03-26 02:24:37,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742259_1435, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,826 INFO terminating
2025-03-26 02:24:37,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742260_1436, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java._COPYING_
2025-03-26 02:24:37,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,830 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,830 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,830 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742260_1436 src: /172.20.1.14:41710 dest: /172.20.1.16:9866
2025-03-26 02:24:37,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742260_1436 src: /172.20.1.16:55776 dest: /172.20.1.17:9866
2025-03-26 02:24:37,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55776, dest: /172.20.1.17:9866, bytes: 2411, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742260_1436, duration(ns): 547737
2025-03-26 02:24:37,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742260_1436, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,834 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41710, dest: /172.20.1.16:9866, bytes: 2411, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742260_1436, duration(ns): 872638
2025-03-26 02:24:37,834 INFO terminating
2025-03-26 02:24:37,838 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742261_1437, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_
2025-03-26 02:24:37,838 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,838 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,838 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,838 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,838 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,838 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742261_1437 src: /172.20.1.14:43192 dest: /172.20.1.17:9866
2025-03-26 02:24:37,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742261_1437 src: /172.20.1.17:34498 dest: /172.20.1.16:9866
2025-03-26 02:24:37,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43192, dest: /172.20.1.17:9866, bytes: 3708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742261_1437, duration(ns): 744861
2025-03-26 02:24:37,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34498, dest: /172.20.1.16:9866, bytes: 3708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742261_1437, duration(ns): 529398
2025-03-26 02:24:37,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742261_1437, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,841 INFO terminating
2025-03-26 02:24:37,842 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,843 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,846 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742262_1438, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java._COPYING_
2025-03-26 02:24:37,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,846 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,846 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,846 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742262_1438 src: /172.20.1.14:43194 dest: /172.20.1.17:9866
2025-03-26 02:24:37,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742262_1438 src: /172.20.1.17:34504 dest: /172.20.1.16:9866
2025-03-26 02:24:37,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34504, dest: /172.20.1.16:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742262_1438, duration(ns): 453936
2025-03-26 02:24:37,850 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43194, dest: /172.20.1.17:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742262_1438, duration(ns): 1010634
2025-03-26 02:24:37,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742262_1438, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,850 INFO terminating
2025-03-26 02:24:37,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742263_1439, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_
2025-03-26 02:24:37,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,854 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,854 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,854 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742263_1439 src: /172.20.1.14:41712 dest: /172.20.1.16:9866
2025-03-26 02:24:37,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742263_1439 src: /172.20.1.16:55790 dest: /172.20.1.17:9866
2025-03-26 02:24:37,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55790, dest: /172.20.1.17:9866, bytes: 3387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742263_1439, duration(ns): 502540
2025-03-26 02:24:37,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742263_1439, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,858 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41712, dest: /172.20.1.16:9866, bytes: 3387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742263_1439, duration(ns): 714824
2025-03-26 02:24:37,858 INFO terminating
2025-03-26 02:24:37,862 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742264_1440, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_
2025-03-26 02:24:37,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,862 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,862 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,862 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742264_1440 src: /172.20.1.14:43198 dest: /172.20.1.17:9866
2025-03-26 02:24:37,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742264_1440 src: /172.20.1.17:34510 dest: /172.20.1.16:9866
2025-03-26 02:24:37,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43198, dest: /172.20.1.17:9866, bytes: 3631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742264_1440, duration(ns): 1083297
2025-03-26 02:24:37,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34510, dest: /172.20.1.16:9866, bytes: 3631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742264_1440, duration(ns): 511662
2025-03-26 02:24:37,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742264_1440, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,865 INFO terminating
2025-03-26 02:24:37,866 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742265_1441, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java._COPYING_
2025-03-26 02:24:37,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,869 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,869 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,869 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742265_1441 src: /172.20.1.14:43214 dest: /172.20.1.17:9866
2025-03-26 02:24:37,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742265_1441 src: /172.20.1.17:34524 dest: /172.20.1.16:9866
2025-03-26 02:24:37,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43214, dest: /172.20.1.17:9866, bytes: 3580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742265_1441, duration(ns): 1139122
2025-03-26 02:24:37,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34524, dest: /172.20.1.16:9866, bytes: 3580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742265_1441, duration(ns): 551711
2025-03-26 02:24:37,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742265_1441, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,873 INFO terminating
2025-03-26 02:24:37,874 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,877 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,877 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,877 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742266_1442, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java._COPYING_
2025-03-26 02:24:37,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742266_1442 src: /172.20.1.14:41728 dest: /172.20.1.16:9866
2025-03-26 02:24:37,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742266_1442 src: /172.20.1.16:55800 dest: /172.20.1.17:9866
2025-03-26 02:24:37,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55800, dest: /172.20.1.17:9866, bytes: 3223, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742266_1442, duration(ns): 646442
2025-03-26 02:24:37,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742266_1442, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,885 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41728, dest: /172.20.1.16:9866, bytes: 3223, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742266_1442, duration(ns): 862674
2025-03-26 02:24:37,885 INFO terminating
2025-03-26 02:24:37,888 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742267_1443, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java._COPYING_
2025-03-26 02:24:37,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,888 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,888 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,888 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742267_1443 src: /172.20.1.14:41744 dest: /172.20.1.16:9866
2025-03-26 02:24:37,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742267_1443 src: /172.20.1.16:55814 dest: /172.20.1.17:9866
2025-03-26 02:24:37,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55814, dest: /172.20.1.17:9866, bytes: 2239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742267_1443, duration(ns): 507065
2025-03-26 02:24:37,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742267_1443, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,892 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41744, dest: /172.20.1.16:9866, bytes: 2239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742267_1443, duration(ns): 625222
2025-03-26 02:24:37,892 INFO terminating
2025-03-26 02:24:37,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742268_1444, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java._COPYING_
2025-03-26 02:24:37,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,895 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,895 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,895 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742268_1444 src: /172.20.1.14:41754 dest: /172.20.1.16:9866
2025-03-26 02:24:37,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742268_1444 src: /172.20.1.16:55830 dest: /172.20.1.17:9866
2025-03-26 02:24:37,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55830, dest: /172.20.1.17:9866, bytes: 2778, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742268_1444, duration(ns): 514125
2025-03-26 02:24:37,898 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41754, dest: /172.20.1.16:9866, bytes: 2778, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742268_1444, duration(ns): 600118
2025-03-26 02:24:37,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742268_1444, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,898 INFO terminating
2025-03-26 02:24:37,901 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742269_1445, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_
2025-03-26 02:24:37,901 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,901 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,901 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,901 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,901 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,901 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742269_1445 src: /172.20.1.14:43216 dest: /172.20.1.17:9866
2025-03-26 02:24:37,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742269_1445 src: /172.20.1.17:34540 dest: /172.20.1.16:9866
2025-03-26 02:24:37,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34540, dest: /172.20.1.16:9866, bytes: 2602, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742269_1445, duration(ns): 14462275
2025-03-26 02:24:37,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742269_1445, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,919 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43216, dest: /172.20.1.17:9866, bytes: 2602, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742269_1445, duration(ns): 15127739
2025-03-26 02:24:37,919 INFO terminating
2025-03-26 02:24:37,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742270_1446, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 02:24:37,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,922 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,922 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,922 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742270_1446 src: /172.20.1.14:43222 dest: /172.20.1.17:9866
2025-03-26 02:24:37,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742270_1446 src: /172.20.1.17:34556 dest: /172.20.1.16:9866
2025-03-26 02:24:37,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34556, dest: /172.20.1.16:9866, bytes: 3240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742270_1446, duration(ns): 468399
2025-03-26 02:24:37,926 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43222, dest: /172.20.1.17:9866, bytes: 3240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742270_1446, duration(ns): 992371
2025-03-26 02:24:37,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742270_1446, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,926 INFO terminating
2025-03-26 02:24:37,929 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742271_1447, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java._COPYING_
2025-03-26 02:24:37,929 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,929 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,929 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,929 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,929 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,929 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742271_1447 src: /172.20.1.14:41758 dest: /172.20.1.16:9866
2025-03-26 02:24:37,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742271_1447 src: /172.20.1.16:55834 dest: /172.20.1.17:9866
2025-03-26 02:24:37,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55834, dest: /172.20.1.17:9866, bytes: 3102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742271_1447, duration(ns): 531480
2025-03-26 02:24:37,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742271_1447, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,933 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41758, dest: /172.20.1.16:9866, bytes: 3102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742271_1447, duration(ns): 858651
2025-03-26 02:24:37,933 INFO terminating
2025-03-26 02:24:37,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,935 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,935 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,935 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,936 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742272_1448, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java._COPYING_
2025-03-26 02:24:37,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742272_1448 src: /172.20.1.14:43234 dest: /172.20.1.17:9866
2025-03-26 02:24:37,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742272_1448 src: /172.20.1.17:34570 dest: /172.20.1.16:9866
2025-03-26 02:24:37,940 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43234, dest: /172.20.1.17:9866, bytes: 3773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742272_1448, duration(ns): 1040668
2025-03-26 02:24:37,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34570, dest: /172.20.1.16:9866, bytes: 3773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742272_1448, duration(ns): 479711
2025-03-26 02:24:37,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742272_1448, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,940 INFO terminating
2025-03-26 02:24:37,945 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742273_1449, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java._COPYING_
2025-03-26 02:24:37,945 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,945 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,945 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,945 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,945 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,945 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742273_1449 src: /172.20.1.14:43242 dest: /172.20.1.17:9866
2025-03-26 02:24:37,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742273_1449 src: /172.20.1.17:34586 dest: /172.20.1.16:9866
2025-03-26 02:24:37,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43242, dest: /172.20.1.17:9866, bytes: 2761, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742273_1449, duration(ns): 1082427
2025-03-26 02:24:37,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34586, dest: /172.20.1.16:9866, bytes: 2761, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742273_1449, duration(ns): 481340
2025-03-26 02:24:37,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742273_1449, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,949 INFO terminating
2025-03-26 02:24:37,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,952 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742274_1450, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java._COPYING_
2025-03-26 02:24:37,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,952 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,952 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,952 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742274_1450 src: /172.20.1.14:43258 dest: /172.20.1.17:9866
2025-03-26 02:24:37,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742274_1450 src: /172.20.1.17:34592 dest: /172.20.1.16:9866
2025-03-26 02:24:37,956 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43258, dest: /172.20.1.17:9866, bytes: 2415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742274_1450, duration(ns): 1023771
2025-03-26 02:24:37,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34592, dest: /172.20.1.16:9866, bytes: 2415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742274_1450, duration(ns): 465302
2025-03-26 02:24:37,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742274_1450, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,956 INFO terminating
2025-03-26 02:24:37,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742275_1451, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java._COPYING_
2025-03-26 02:24:37,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,959 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,959 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,959 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742275_1451 src: /172.20.1.14:43268 dest: /172.20.1.17:9866
2025-03-26 02:24:37,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742275_1451 src: /172.20.1.17:34594 dest: /172.20.1.16:9866
2025-03-26 02:24:37,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34594, dest: /172.20.1.16:9866, bytes: 1913, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742275_1451, duration(ns): 383526
2025-03-26 02:24:37,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742275_1451, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,963 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43268, dest: /172.20.1.17:9866, bytes: 1913, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742275_1451, duration(ns): 983362
2025-03-26 02:24:37,963 INFO terminating
2025-03-26 02:24:37,966 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742276_1452, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java._COPYING_
2025-03-26 02:24:37,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,966 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,966 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,966 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742276_1452 src: /172.20.1.14:41764 dest: /172.20.1.16:9866
2025-03-26 02:24:37,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742276_1452 src: /172.20.1.16:55842 dest: /172.20.1.17:9866
2025-03-26 02:24:37,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55842, dest: /172.20.1.17:9866, bytes: 3157, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742276_1452, duration(ns): 524542
2025-03-26 02:24:37,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742276_1452, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,970 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41764, dest: /172.20.1.16:9866, bytes: 3157, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742276_1452, duration(ns): 591041
2025-03-26 02:24:37,970 INFO terminating
2025-03-26 02:24:37,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742277_1453, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java._COPYING_
2025-03-26 02:24:37,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,973 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,973 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,973 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742277_1453 src: /172.20.1.14:43274 dest: /172.20.1.17:9866
2025-03-26 02:24:37,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742277_1453 src: /172.20.1.17:34602 dest: /172.20.1.16:9866
2025-03-26 02:24:37,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34602, dest: /172.20.1.16:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742277_1453, duration(ns): 488771
2025-03-26 02:24:37,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742277_1453, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43274, dest: /172.20.1.17:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742277_1453, duration(ns): 973219
2025-03-26 02:24:37,985 INFO terminating
2025-03-26 02:24:37,986 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,988 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742278_1454, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java._COPYING_
2025-03-26 02:24:37,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,988 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,988 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,988 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742278_1454 src: /172.20.1.14:43276 dest: /172.20.1.17:9866
2025-03-26 02:24:37,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742278_1454 src: /172.20.1.17:34608 dest: /172.20.1.16:9866
2025-03-26 02:24:37,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43276, dest: /172.20.1.17:9866, bytes: 2137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742278_1454, duration(ns): 1094056
2025-03-26 02:24:37,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34608, dest: /172.20.1.16:9866, bytes: 2137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742278_1454, duration(ns): 501857
2025-03-26 02:24:37,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742278_1454, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,992 INFO terminating
2025-03-26 02:24:37,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742279_1455, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java._COPYING_
2025-03-26 02:24:37,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,995 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:37,995 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:37,995 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:37,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742279_1455 src: /172.20.1.14:43278 dest: /172.20.1.17:9866
2025-03-26 02:24:37,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742279_1455 src: /172.20.1.17:34620 dest: /172.20.1.16:9866
2025-03-26 02:24:37,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34620, dest: /172.20.1.16:9866, bytes: 2741, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742279_1455, duration(ns): 409718
2025-03-26 02:24:37,999 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:37,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43278, dest: /172.20.1.17:9866, bytes: 2741, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742279_1455, duration(ns): 953612
2025-03-26 02:24:37,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742279_1455, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:37,999 INFO terminating
2025-03-26 02:24:38,002 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742280_1456, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java._COPYING_
2025-03-26 02:24:38,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,002 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,002 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,002 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742280_1456 src: /172.20.1.14:41778 dest: /172.20.1.16:9866
2025-03-26 02:24:38,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742280_1456 src: /172.20.1.16:55856 dest: /172.20.1.17:9866
2025-03-26 02:24:38,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55856, dest: /172.20.1.17:9866, bytes: 2802, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742280_1456, duration(ns): 592541
2025-03-26 02:24:38,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742280_1456, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,006 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41778, dest: /172.20.1.16:9866, bytes: 2802, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742280_1456, duration(ns): 922394
2025-03-26 02:24:38,006 INFO terminating
2025-03-26 02:24:38,009 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742281_1457, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_
2025-03-26 02:24:38,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,009 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,009 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,009 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742281_1457 src: /172.20.1.14:41790 dest: /172.20.1.16:9866
2025-03-26 02:24:38,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742281_1457 src: /172.20.1.16:55862 dest: /172.20.1.17:9866
2025-03-26 02:24:38,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55862, dest: /172.20.1.17:9866, bytes: 2715, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742281_1457, duration(ns): 535938
2025-03-26 02:24:38,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742281_1457, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,013 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41790, dest: /172.20.1.16:9866, bytes: 2715, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742281_1457, duration(ns): 681000
2025-03-26 02:24:38,013 INFO terminating
2025-03-26 02:24:38,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742282_1458, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java._COPYING_
2025-03-26 02:24:38,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,016 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,016 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,016 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742282_1458 src: /172.20.1.14:41804 dest: /172.20.1.16:9866
2025-03-26 02:24:38,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742282_1458 src: /172.20.1.16:55864 dest: /172.20.1.17:9866
2025-03-26 02:24:38,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55864, dest: /172.20.1.17:9866, bytes: 2899, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742282_1458, duration(ns): 571894
2025-03-26 02:24:38,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742282_1458, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,020 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41804, dest: /172.20.1.16:9866, bytes: 2899, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742282_1458, duration(ns): 682551
2025-03-26 02:24:38,020 INFO terminating
2025-03-26 02:24:38,023 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742283_1459, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java._COPYING_
2025-03-26 02:24:38,023 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,023 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,023 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,023 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,023 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,023 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742283_1459 src: /172.20.1.14:41814 dest: /172.20.1.16:9866
2025-03-26 02:24:38,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742283_1459 src: /172.20.1.16:55870 dest: /172.20.1.17:9866
2025-03-26 02:24:38,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55870, dest: /172.20.1.17:9866, bytes: 2085, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742283_1459, duration(ns): 435897
2025-03-26 02:24:38,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742283_1459, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,027 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41814, dest: /172.20.1.16:9866, bytes: 2085, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742283_1459, duration(ns): 587865
2025-03-26 02:24:38,027 INFO terminating
2025-03-26 02:24:38,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742284_1460, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java._COPYING_
2025-03-26 02:24:38,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,030 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,030 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,030 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742284_1460 src: /172.20.1.14:41818 dest: /172.20.1.16:9866
2025-03-26 02:24:38,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742284_1460 src: /172.20.1.16:55872 dest: /172.20.1.17:9866
2025-03-26 02:24:38,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55872, dest: /172.20.1.17:9866, bytes: 3180, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742284_1460, duration(ns): 7526638
2025-03-26 02:24:38,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742284_1460, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,041 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41818, dest: /172.20.1.16:9866, bytes: 3180, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742284_1460, duration(ns): 7728915
2025-03-26 02:24:38,041 INFO terminating
2025-03-26 02:24:38,050 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742285_1461, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java._COPYING_
2025-03-26 02:24:38,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,050 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,050 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,050 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742285_1461 src: /172.20.1.14:41832 dest: /172.20.1.16:9866
2025-03-26 02:24:38,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742285_1461 src: /172.20.1.16:55878 dest: /172.20.1.17:9866
2025-03-26 02:24:38,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55878, dest: /172.20.1.17:9866, bytes: 2623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742285_1461, duration(ns): 771993
2025-03-26 02:24:38,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742285_1461, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41832, dest: /172.20.1.16:9866, bytes: 2623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742285_1461, duration(ns): 1017941
2025-03-26 02:24:38,058 INFO terminating
2025-03-26 02:24:38,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742286_1462, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java._COPYING_
2025-03-26 02:24:38,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,061 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,061 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,061 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742286_1462 src: /172.20.1.14:41838 dest: /172.20.1.16:9866
2025-03-26 02:24:38,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742286_1462 src: /172.20.1.16:55882 dest: /172.20.1.17:9866
2025-03-26 02:24:38,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55882, dest: /172.20.1.17:9866, bytes: 3973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742286_1462, duration(ns): 552268
2025-03-26 02:24:38,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742286_1462, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,065 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41838, dest: /172.20.1.16:9866, bytes: 3973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742286_1462, duration(ns): 713872
2025-03-26 02:24:38,065 INFO terminating
2025-03-26 02:24:38,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742287_1463, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java._COPYING_
2025-03-26 02:24:38,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,068 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,068 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,068 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742287_1463 src: /172.20.1.14:43280 dest: /172.20.1.17:9866
2025-03-26 02:24:38,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742287_1463 src: /172.20.1.17:34632 dest: /172.20.1.16:9866
2025-03-26 02:24:38,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43280, dest: /172.20.1.17:9866, bytes: 3265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742287_1463, duration(ns): 1001236
2025-03-26 02:24:38,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34632, dest: /172.20.1.16:9866, bytes: 3265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742287_1463, duration(ns): 472732
2025-03-26 02:24:38,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742287_1463, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,071 INFO terminating
2025-03-26 02:24:38,072 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742288_1464, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java._COPYING_
2025-03-26 02:24:38,074 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,074 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,074 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,074 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,074 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,074 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742288_1464 src: /172.20.1.14:43290 dest: /172.20.1.17:9866
2025-03-26 02:24:38,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742288_1464 src: /172.20.1.17:34634 dest: /172.20.1.16:9866
2025-03-26 02:24:38,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34634, dest: /172.20.1.16:9866, bytes: 2238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742288_1464, duration(ns): 439631
2025-03-26 02:24:38,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742288_1464, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,082 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43290, dest: /172.20.1.17:9866, bytes: 2238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742288_1464, duration(ns): 5213334
2025-03-26 02:24:38,082 INFO terminating
2025-03-26 02:24:38,090 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742289_1465, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_
2025-03-26 02:24:38,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,090 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,090 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,090 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742289_1465 src: /172.20.1.14:41844 dest: /172.20.1.16:9866
2025-03-26 02:24:38,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742289_1465 src: /172.20.1.16:55898 dest: /172.20.1.17:9866
2025-03-26 02:24:38,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55898, dest: /172.20.1.17:9866, bytes: 2546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742289_1465, duration(ns): 522761
2025-03-26 02:24:38,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742289_1465, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41844, dest: /172.20.1.16:9866, bytes: 2546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742289_1465, duration(ns): 685036
2025-03-26 02:24:38,094 INFO terminating
2025-03-26 02:24:38,095 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742290_1466, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java._COPYING_
2025-03-26 02:24:38,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,097 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,097 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,097 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,097 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742290_1466 src: /172.20.1.14:41854 dest: /172.20.1.16:9866
2025-03-26 02:24:38,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742290_1466 src: /172.20.1.16:55900 dest: /172.20.1.17:9866
2025-03-26 02:24:38,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55900, dest: /172.20.1.17:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742290_1466, duration(ns): 565681
2025-03-26 02:24:38,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742290_1466, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,102 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41854, dest: /172.20.1.16:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742290_1466, duration(ns): 726319
2025-03-26 02:24:38,102 INFO terminating
2025-03-26 02:24:38,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742291_1467, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java._COPYING_
2025-03-26 02:24:38,105 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,105 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,105 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,105 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,105 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,105 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742291_1467 src: /172.20.1.14:41862 dest: /172.20.1.16:9866
2025-03-26 02:24:38,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742291_1467 src: /172.20.1.16:55914 dest: /172.20.1.17:9866
2025-03-26 02:24:38,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55914, dest: /172.20.1.17:9866, bytes: 5729, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742291_1467, duration(ns): 551506
2025-03-26 02:24:38,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742291_1467, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,109 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41862, dest: /172.20.1.16:9866, bytes: 5729, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742291_1467, duration(ns): 679173
2025-03-26 02:24:38,109 INFO terminating
2025-03-26 02:24:38,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742292_1468, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java._COPYING_
2025-03-26 02:24:38,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,112 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,112 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,112 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742292_1468 src: /172.20.1.14:43298 dest: /172.20.1.17:9866
2025-03-26 02:24:38,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742292_1468 src: /172.20.1.17:34640 dest: /172.20.1.16:9866
2025-03-26 02:24:38,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34640, dest: /172.20.1.16:9866, bytes: 2123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742292_1468, duration(ns): 494165
2025-03-26 02:24:38,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742292_1468, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,116 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43298, dest: /172.20.1.17:9866, bytes: 2123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742292_1468, duration(ns): 1033602
2025-03-26 02:24:38,116 INFO terminating
2025-03-26 02:24:38,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742293_1469, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java._COPYING_
2025-03-26 02:24:38,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,122 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,122 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,122 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742293_1469 src: /172.20.1.14:41874 dest: /172.20.1.16:9866
2025-03-26 02:24:38,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742293_1469 src: /172.20.1.16:55920 dest: /172.20.1.17:9866
2025-03-26 02:24:38,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55920, dest: /172.20.1.17:9866, bytes: 3381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742293_1469, duration(ns): 529573
2025-03-26 02:24:38,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742293_1469, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,126 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41874, dest: /172.20.1.16:9866, bytes: 3381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742293_1469, duration(ns): 618360
2025-03-26 02:24:38,126 INFO terminating
2025-03-26 02:24:38,131 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742294_1470, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java._COPYING_
2025-03-26 02:24:38,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,131 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,131 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,131 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742294_1470 src: /172.20.1.14:41878 dest: /172.20.1.16:9866
2025-03-26 02:24:38,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742294_1470 src: /172.20.1.16:55930 dest: /172.20.1.17:9866
2025-03-26 02:24:38,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55930, dest: /172.20.1.17:9866, bytes: 1258, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742294_1470, duration(ns): 506801
2025-03-26 02:24:38,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742294_1470, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,135 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41878, dest: /172.20.1.16:9866, bytes: 1258, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742294_1470, duration(ns): 675674
2025-03-26 02:24:38,135 INFO terminating
2025-03-26 02:24:38,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,139 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,139 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,139 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742295_1471, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java._COPYING_
2025-03-26 02:24:38,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742295_1471 src: /172.20.1.14:41888 dest: /172.20.1.16:9866
2025-03-26 02:24:38,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742295_1471 src: /172.20.1.16:55934 dest: /172.20.1.17:9866
2025-03-26 02:24:38,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55934, dest: /172.20.1.17:9866, bytes: 3202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742295_1471, duration(ns): 504299
2025-03-26 02:24:38,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742295_1471, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41888, dest: /172.20.1.16:9866, bytes: 3202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742295_1471, duration(ns): 675408
2025-03-26 02:24:38,143 INFO terminating
2025-03-26 02:24:38,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742296_1472, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_
2025-03-26 02:24:38,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,146 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,146 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,146 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742296_1472 src: /172.20.1.14:43300 dest: /172.20.1.17:9866
2025-03-26 02:24:38,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742296_1472 src: /172.20.1.17:34642 dest: /172.20.1.16:9866
2025-03-26 02:24:38,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34642, dest: /172.20.1.16:9866, bytes: 2846, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742296_1472, duration(ns): 464768
2025-03-26 02:24:38,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742296_1472, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43300, dest: /172.20.1.17:9866, bytes: 2846, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742296_1472, duration(ns): 1063542
2025-03-26 02:24:38,150 INFO terminating
2025-03-26 02:24:38,151 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742297_1473, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java._COPYING_
2025-03-26 02:24:38,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,155 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,155 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,155 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742297_1473 src: /172.20.1.14:43308 dest: /172.20.1.17:9866
2025-03-26 02:24:38,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742297_1473 src: /172.20.1.17:34650 dest: /172.20.1.16:9866
2025-03-26 02:24:38,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34650, dest: /172.20.1.16:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742297_1473, duration(ns): 461177
2025-03-26 02:24:38,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742297_1473, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43308, dest: /172.20.1.17:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742297_1473, duration(ns): 960664
2025-03-26 02:24:38,159 INFO terminating
2025-03-26 02:24:38,162 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,170 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742298_1474, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java._COPYING_
2025-03-26 02:24:38,170 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,170 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,170 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,170 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,170 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,170 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742298_1474 src: /172.20.1.14:43322 dest: /172.20.1.17:9866
2025-03-26 02:24:38,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742298_1474 src: /172.20.1.17:34662 dest: /172.20.1.16:9866
2025-03-26 02:24:38,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43322, dest: /172.20.1.17:9866, bytes: 3553, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742298_1474, duration(ns): 1133572
2025-03-26 02:24:38,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34662, dest: /172.20.1.16:9866, bytes: 3553, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742298_1474, duration(ns): 527069
2025-03-26 02:24:38,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742298_1474, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,174 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,174 INFO terminating
2025-03-26 02:24:38,176 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,176 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,176 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,176 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,176 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,176 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,177 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742299_1475, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java._COPYING_
2025-03-26 02:24:38,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742299_1475 src: /172.20.1.14:41900 dest: /172.20.1.16:9866
2025-03-26 02:24:38,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742299_1475 src: /172.20.1.16:55946 dest: /172.20.1.17:9866
2025-03-26 02:24:38,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41900, dest: /172.20.1.16:9866, bytes: 2506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742299_1475, duration(ns): 959549
2025-03-26 02:24:38,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55946, dest: /172.20.1.17:9866, bytes: 2506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742299_1475, duration(ns): 522563
2025-03-26 02:24:38,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742299_1475, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,181 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,181 INFO terminating
2025-03-26 02:24:38,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742300_1476, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_
2025-03-26 02:24:38,183 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,183 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,183 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,183 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,183 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,183 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742300_1476 src: /172.20.1.14:43336 dest: /172.20.1.17:9866
2025-03-26 02:24:38,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742300_1476 src: /172.20.1.17:34678 dest: /172.20.1.16:9866
2025-03-26 02:24:38,187 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43336, dest: /172.20.1.17:9866, bytes: 5226, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742300_1476, duration(ns): 993710
2025-03-26 02:24:38,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34678, dest: /172.20.1.16:9866, bytes: 5226, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742300_1476, duration(ns): 457416
2025-03-26 02:24:38,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742300_1476, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,187 INFO terminating
2025-03-26 02:24:38,191 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742301_1477, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java._COPYING_
2025-03-26 02:24:38,191 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,191 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,191 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,191 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,191 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,191 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742301_1477 src: /172.20.1.14:41908 dest: /172.20.1.16:9866
2025-03-26 02:24:38,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742301_1477 src: /172.20.1.16:55962 dest: /172.20.1.17:9866
2025-03-26 02:24:38,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55962, dest: /172.20.1.17:9866, bytes: 2612, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742301_1477, duration(ns): 596359
2025-03-26 02:24:38,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41908, dest: /172.20.1.16:9866, bytes: 2612, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742301_1477, duration(ns): 5059066
2025-03-26 02:24:38,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742301_1477, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,206 INFO terminating
2025-03-26 02:24:38,207 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,211 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,211 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,211 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,211 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,211 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,211 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742302_1478, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java._COPYING_
2025-03-26 02:24:38,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742302_1478 src: /172.20.1.14:41920 dest: /172.20.1.16:9866
2025-03-26 02:24:38,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742302_1478 src: /172.20.1.16:55968 dest: /172.20.1.17:9866
2025-03-26 02:24:38,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55968, dest: /172.20.1.17:9866, bytes: 4317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742302_1478, duration(ns): 622685
2025-03-26 02:24:38,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742302_1478, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,216 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41920, dest: /172.20.1.16:9866, bytes: 4317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742302_1478, duration(ns): 727159
2025-03-26 02:24:38,216 INFO terminating
2025-03-26 02:24:38,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742303_1479, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java._COPYING_
2025-03-26 02:24:38,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,219 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,219 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,219 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742303_1479 src: /172.20.1.14:41932 dest: /172.20.1.16:9866
2025-03-26 02:24:38,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742303_1479 src: /172.20.1.16:55976 dest: /172.20.1.17:9866
2025-03-26 02:24:38,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55976, dest: /172.20.1.17:9866, bytes: 3304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742303_1479, duration(ns): 1897139
2025-03-26 02:24:38,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742303_1479, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,224 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41932, dest: /172.20.1.16:9866, bytes: 3304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742303_1479, duration(ns): 726668
2025-03-26 02:24:38,224 INFO terminating
2025-03-26 02:24:38,228 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742304_1480, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java._COPYING_
2025-03-26 02:24:38,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,228 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,228 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,228 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742304_1480 src: /172.20.1.14:41944 dest: /172.20.1.16:9866
2025-03-26 02:24:38,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742304_1480 src: /172.20.1.16:55992 dest: /172.20.1.17:9866
2025-03-26 02:24:38,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55992, dest: /172.20.1.17:9866, bytes: 2450, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742304_1480, duration(ns): 587218
2025-03-26 02:24:38,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742304_1480, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,237 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41944, dest: /172.20.1.16:9866, bytes: 2450, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742304_1480, duration(ns): 825131
2025-03-26 02:24:38,237 INFO terminating
2025-03-26 02:24:38,240 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742305_1481, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java._COPYING_
2025-03-26 02:24:38,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,240 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,240 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,240 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742305_1481 src: /172.20.1.14:41952 dest: /172.20.1.16:9866
2025-03-26 02:24:38,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742305_1481 src: /172.20.1.16:55998 dest: /172.20.1.17:9866
2025-03-26 02:24:38,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:55998, dest: /172.20.1.17:9866, bytes: 2467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742305_1481, duration(ns): 544292
2025-03-26 02:24:38,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742305_1481, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,244 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41952, dest: /172.20.1.16:9866, bytes: 2467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742305_1481, duration(ns): 620995
2025-03-26 02:24:38,244 INFO terminating
2025-03-26 02:24:38,247 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742306_1482, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java._COPYING_
2025-03-26 02:24:38,247 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,247 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,247 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,247 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,247 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,247 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742306_1482 src: /172.20.1.14:41960 dest: /172.20.1.16:9866
2025-03-26 02:24:38,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742306_1482 src: /172.20.1.16:56008 dest: /172.20.1.17:9866
2025-03-26 02:24:38,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56008, dest: /172.20.1.17:9866, bytes: 3122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742306_1482, duration(ns): 399431
2025-03-26 02:24:38,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742306_1482, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,254 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41960, dest: /172.20.1.16:9866, bytes: 3122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742306_1482, duration(ns): 2096203
2025-03-26 02:24:38,254 INFO terminating
2025-03-26 02:24:38,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742307_1483, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java._COPYING_
2025-03-26 02:24:38,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,257 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,257 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,257 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742307_1483 src: /172.20.1.14:41962 dest: /172.20.1.16:9866
2025-03-26 02:24:38,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742307_1483 src: /172.20.1.16:56016 dest: /172.20.1.17:9866
2025-03-26 02:24:38,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56016, dest: /172.20.1.17:9866, bytes: 2851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742307_1483, duration(ns): 568079
2025-03-26 02:24:38,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742307_1483, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,262 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41962, dest: /172.20.1.16:9866, bytes: 2851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742307_1483, duration(ns): 661319
2025-03-26 02:24:38,262 INFO terminating
2025-03-26 02:24:38,265 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742308_1484, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java._COPYING_
2025-03-26 02:24:38,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,265 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,265 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,265 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742308_1484 src: /172.20.1.14:43346 dest: /172.20.1.17:9866
2025-03-26 02:24:38,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742308_1484 src: /172.20.1.17:34684 dest: /172.20.1.16:9866
2025-03-26 02:24:38,268 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43346, dest: /172.20.1.17:9866, bytes: 2349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742308_1484, duration(ns): 984923
2025-03-26 02:24:38,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34684, dest: /172.20.1.16:9866, bytes: 2349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742308_1484, duration(ns): 441712
2025-03-26 02:24:38,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742308_1484, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,268 INFO terminating
2025-03-26 02:24:38,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742309_1485, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java._COPYING_
2025-03-26 02:24:38,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,271 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,271 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,271 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742309_1485 src: /172.20.1.14:43354 dest: /172.20.1.17:9866
2025-03-26 02:24:38,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742309_1485 src: /172.20.1.17:34690 dest: /172.20.1.16:9866
2025-03-26 02:24:38,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43354, dest: /172.20.1.17:9866, bytes: 2213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742309_1485, duration(ns): 959672
2025-03-26 02:24:38,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34690, dest: /172.20.1.16:9866, bytes: 2213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742309_1485, duration(ns): 400707
2025-03-26 02:24:38,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742309_1485, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,274 INFO terminating
2025-03-26 02:24:38,275 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742310_1486, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java._COPYING_
2025-03-26 02:24:38,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,277 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,277 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,277 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742310_1486 src: /172.20.1.14:41974 dest: /172.20.1.16:9866
2025-03-26 02:24:38,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742310_1486 src: /172.20.1.16:56032 dest: /172.20.1.17:9866
2025-03-26 02:24:38,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56032, dest: /172.20.1.17:9866, bytes: 4024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742310_1486, duration(ns): 527484
2025-03-26 02:24:38,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742310_1486, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,281 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41974, dest: /172.20.1.16:9866, bytes: 4024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742310_1486, duration(ns): 632726
2025-03-26 02:24:38,281 INFO terminating
2025-03-26 02:24:38,284 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742311_1487, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java._COPYING_
2025-03-26 02:24:38,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,284 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,284 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,284 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742311_1487 src: /172.20.1.14:43356 dest: /172.20.1.17:9866
2025-03-26 02:24:38,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742311_1487 src: /172.20.1.17:34698 dest: /172.20.1.16:9866
2025-03-26 02:24:38,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43356, dest: /172.20.1.17:9866, bytes: 2548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742311_1487, duration(ns): 916334
2025-03-26 02:24:38,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34698, dest: /172.20.1.16:9866, bytes: 2548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742311_1487, duration(ns): 384830
2025-03-26 02:24:38,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742311_1487, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,287 INFO terminating
2025-03-26 02:24:38,288 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,292 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742312_1488, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_
2025-03-26 02:24:38,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,292 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,292 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,292 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742312_1488 src: /172.20.1.14:43364 dest: /172.20.1.17:9866
2025-03-26 02:24:38,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742312_1488 src: /172.20.1.17:34702 dest: /172.20.1.16:9866
2025-03-26 02:24:38,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34702, dest: /172.20.1.16:9866, bytes: 3273, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742312_1488, duration(ns): 452383
2025-03-26 02:24:38,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742312_1488, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,296 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43364, dest: /172.20.1.17:9866, bytes: 3273, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742312_1488, duration(ns): 993484
2025-03-26 02:24:38,296 INFO terminating
2025-03-26 02:24:38,299 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742313_1489, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java._COPYING_
2025-03-26 02:24:38,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,299 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,299 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,299 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742313_1489 src: /172.20.1.14:43374 dest: /172.20.1.17:9866
2025-03-26 02:24:38,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742313_1489 src: /172.20.1.17:34714 dest: /172.20.1.16:9866
2025-03-26 02:24:38,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43374, dest: /172.20.1.17:9866, bytes: 2758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742313_1489, duration(ns): 1056797
2025-03-26 02:24:38,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34714, dest: /172.20.1.16:9866, bytes: 2758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742313_1489, duration(ns): 511362
2025-03-26 02:24:38,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742313_1489, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,303 INFO terminating
2025-03-26 02:24:38,304 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,306 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742314_1490, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java._COPYING_
2025-03-26 02:24:38,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,306 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,306 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,306 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742314_1490 src: /172.20.1.14:43382 dest: /172.20.1.17:9866
2025-03-26 02:24:38,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742314_1490 src: /172.20.1.17:34720 dest: /172.20.1.16:9866
2025-03-26 02:24:38,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43382, dest: /172.20.1.17:9866, bytes: 4577, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742314_1490, duration(ns): 1045910
2025-03-26 02:24:38,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34720, dest: /172.20.1.16:9866, bytes: 4577, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742314_1490, duration(ns): 478985
2025-03-26 02:24:38,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742314_1490, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,310 INFO terminating
2025-03-26 02:24:38,311 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742315_1491, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java._COPYING_
2025-03-26 02:24:38,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,313 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,313 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,313 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742315_1491 src: /172.20.1.14:43390 dest: /172.20.1.17:9866
2025-03-26 02:24:38,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742315_1491 src: /172.20.1.17:34730 dest: /172.20.1.16:9866
2025-03-26 02:24:38,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43390, dest: /172.20.1.17:9866, bytes: 1827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742315_1491, duration(ns): 1058928
2025-03-26 02:24:38,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34730, dest: /172.20.1.16:9866, bytes: 1827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742315_1491, duration(ns): 465592
2025-03-26 02:24:38,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742315_1491, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,317 INFO terminating
2025-03-26 02:24:38,318 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742316_1492, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_
2025-03-26 02:24:38,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,321 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,321 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,321 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742316_1492 src: /172.20.1.14:41986 dest: /172.20.1.16:9866
2025-03-26 02:24:38,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742316_1492 src: /172.20.1.16:56042 dest: /172.20.1.17:9866
2025-03-26 02:24:38,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56042, dest: /172.20.1.17:9866, bytes: 2627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742316_1492, duration(ns): 565227
2025-03-26 02:24:38,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742316_1492, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,325 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41986, dest: /172.20.1.16:9866, bytes: 2627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742316_1492, duration(ns): 914388
2025-03-26 02:24:38,325 INFO terminating
2025-03-26 02:24:38,334 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742317_1493, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java._COPYING_
2025-03-26 02:24:38,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,334 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,334 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,334 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742317_1493 src: /172.20.1.14:43402 dest: /172.20.1.17:9866
2025-03-26 02:24:38,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742317_1493 src: /172.20.1.17:34736 dest: /172.20.1.16:9866
2025-03-26 02:24:38,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43402, dest: /172.20.1.17:9866, bytes: 4114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742317_1493, duration(ns): 1108550
2025-03-26 02:24:38,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34736, dest: /172.20.1.16:9866, bytes: 4114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742317_1493, duration(ns): 554524
2025-03-26 02:24:38,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742317_1493, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,340 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,340 INFO terminating
2025-03-26 02:24:38,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742318_1494, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java._COPYING_
2025-03-26 02:24:38,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,343 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,343 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,343 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742318_1494 src: /172.20.1.14:43418 dest: /172.20.1.17:9866
2025-03-26 02:24:38,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742318_1494 src: /172.20.1.17:34738 dest: /172.20.1.16:9866
2025-03-26 02:24:38,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43418, dest: /172.20.1.17:9866, bytes: 2611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742318_1494, duration(ns): 1161391
2025-03-26 02:24:38,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34738, dest: /172.20.1.16:9866, bytes: 2611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742318_1494, duration(ns): 558833
2025-03-26 02:24:38,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742318_1494, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,347 INFO terminating
2025-03-26 02:24:38,348 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,351 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,351 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,351 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742319_1495, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java._COPYING_
2025-03-26 02:24:38,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742319_1495 src: /172.20.1.14:43428 dest: /172.20.1.17:9866
2025-03-26 02:24:38,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742319_1495 src: /172.20.1.17:34746 dest: /172.20.1.16:9866
2025-03-26 02:24:38,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43428, dest: /172.20.1.17:9866, bytes: 2390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742319_1495, duration(ns): 1118323
2025-03-26 02:24:38,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34746, dest: /172.20.1.16:9866, bytes: 2390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742319_1495, duration(ns): 500610
2025-03-26 02:24:38,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742319_1495, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,355 INFO terminating
2025-03-26 02:24:38,356 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742320_1496, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java._COPYING_
2025-03-26 02:24:38,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,361 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,361 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,361 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742320_1496 src: /172.20.1.14:41988 dest: /172.20.1.16:9866
2025-03-26 02:24:38,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742320_1496 src: /172.20.1.16:56056 dest: /172.20.1.17:9866
2025-03-26 02:24:38,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56056, dest: /172.20.1.17:9866, bytes: 3047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742320_1496, duration(ns): 3345631
2025-03-26 02:24:38,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742320_1496, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,368 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41988, dest: /172.20.1.16:9866, bytes: 3047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742320_1496, duration(ns): 3602756
2025-03-26 02:24:38,368 INFO terminating
2025-03-26 02:24:38,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,374 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,374 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,375 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742321_1497, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java._COPYING_
2025-03-26 02:24:38,375 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742321_1497 src: /172.20.1.14:43438 dest: /172.20.1.17:9866
2025-03-26 02:24:38,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742321_1497 src: /172.20.1.17:34748 dest: /172.20.1.16:9866
2025-03-26 02:24:38,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34748, dest: /172.20.1.16:9866, bytes: 2317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742321_1497, duration(ns): 525265
2025-03-26 02:24:38,381 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43438, dest: /172.20.1.17:9866, bytes: 2317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742321_1497, duration(ns): 3599661
2025-03-26 02:24:38,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742321_1497, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,381 INFO terminating
2025-03-26 02:24:38,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742322_1498, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java._COPYING_
2025-03-26 02:24:38,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,384 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,384 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,384 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742322_1498 src: /172.20.1.14:41996 dest: /172.20.1.16:9866
2025-03-26 02:24:38,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742322_1498 src: /172.20.1.16:56060 dest: /172.20.1.17:9866
2025-03-26 02:24:38,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56060, dest: /172.20.1.17:9866, bytes: 2861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742322_1498, duration(ns): 567735
2025-03-26 02:24:38,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742322_1498, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,390 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:41996, dest: /172.20.1.16:9866, bytes: 2861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742322_1498, duration(ns): 674563
2025-03-26 02:24:38,390 INFO terminating
2025-03-26 02:24:38,393 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742323_1499, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java._COPYING_
2025-03-26 02:24:38,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,393 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,393 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,393 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742323_1499 src: /172.20.1.14:42006 dest: /172.20.1.16:9866
2025-03-26 02:24:38,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742323_1499 src: /172.20.1.16:56066 dest: /172.20.1.17:9866
2025-03-26 02:24:38,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56066, dest: /172.20.1.17:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742323_1499, duration(ns): 558744
2025-03-26 02:24:38,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742323_1499, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42006, dest: /172.20.1.16:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742323_1499, duration(ns): 671013
2025-03-26 02:24:38,402 INFO terminating
2025-03-26 02:24:38,403 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,405 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742324_1500, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java._COPYING_
2025-03-26 02:24:38,405 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,405 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,405 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,405 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,405 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,405 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742324_1500 src: /172.20.1.14:43454 dest: /172.20.1.17:9866
2025-03-26 02:24:38,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742324_1500 src: /172.20.1.17:34760 dest: /172.20.1.16:9866
2025-03-26 02:24:38,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34760, dest: /172.20.1.16:9866, bytes: 3947, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742324_1500, duration(ns): 500521
2025-03-26 02:24:38,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742324_1500, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,411 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43454, dest: /172.20.1.17:9866, bytes: 3947, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742324_1500, duration(ns): 2566274
2025-03-26 02:24:38,411 INFO terminating
2025-03-26 02:24:38,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742325_1501, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 02:24:38,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,414 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,414 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,414 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742325_1501 src: /172.20.1.14:43460 dest: /172.20.1.17:9866
2025-03-26 02:24:38,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742325_1501 src: /172.20.1.17:34768 dest: /172.20.1.16:9866
2025-03-26 02:24:38,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34768, dest: /172.20.1.16:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742325_1501, duration(ns): 518568
2025-03-26 02:24:38,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742325_1501, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43460, dest: /172.20.1.17:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742325_1501, duration(ns): 2445698
2025-03-26 02:24:38,420 INFO terminating
2025-03-26 02:24:38,423 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742326_1502, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java._COPYING_
2025-03-26 02:24:38,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,423 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,423 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,423 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742326_1502 src: /172.20.1.14:43472 dest: /172.20.1.17:9866
2025-03-26 02:24:38,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742326_1502 src: /172.20.1.17:34784 dest: /172.20.1.16:9866
2025-03-26 02:24:38,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43472, dest: /172.20.1.17:9866, bytes: 2630, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742326_1502, duration(ns): 8175726
2025-03-26 02:24:38,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34784, dest: /172.20.1.16:9866, bytes: 2630, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742326_1502, duration(ns): 2484332
2025-03-26 02:24:38,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742326_1502, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,439 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,439 INFO terminating
2025-03-26 02:24:38,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742327_1503, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java._COPYING_
2025-03-26 02:24:38,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,442 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,442 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,442 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742327_1503 src: /172.20.1.14:43480 dest: /172.20.1.17:9866
2025-03-26 02:24:38,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742327_1503 src: /172.20.1.17:34786 dest: /172.20.1.16:9866
2025-03-26 02:24:38,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34786, dest: /172.20.1.16:9866, bytes: 2309, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742327_1503, duration(ns): 460909
2025-03-26 02:24:38,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742327_1503, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,450 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43480, dest: /172.20.1.17:9866, bytes: 2309, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742327_1503, duration(ns): 971540
2025-03-26 02:24:38,450 INFO terminating
2025-03-26 02:24:38,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742328_1504, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java._COPYING_
2025-03-26 02:24:38,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,453 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,453 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,453 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742328_1504 src: /172.20.1.14:42022 dest: /172.20.1.16:9866
2025-03-26 02:24:38,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742328_1504 src: /172.20.1.16:56078 dest: /172.20.1.17:9866
2025-03-26 02:24:38,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56078, dest: /172.20.1.17:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742328_1504, duration(ns): 554478
2025-03-26 02:24:38,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742328_1504, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42022, dest: /172.20.1.16:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742328_1504, duration(ns): 686524
2025-03-26 02:24:38,458 INFO terminating
2025-03-26 02:24:38,459 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,462 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742329_1505, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java._COPYING_
2025-03-26 02:24:38,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,462 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,462 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,462 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742329_1505 src: /172.20.1.14:43490 dest: /172.20.1.17:9866
2025-03-26 02:24:38,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742329_1505 src: /172.20.1.17:34788 dest: /172.20.1.16:9866
2025-03-26 02:24:38,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34788, dest: /172.20.1.16:9866, bytes: 2187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742329_1505, duration(ns): 515177
2025-03-26 02:24:38,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742329_1505, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,466 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43490, dest: /172.20.1.17:9866, bytes: 2187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742329_1505, duration(ns): 1079027
2025-03-26 02:24:38,466 INFO terminating
2025-03-26 02:24:38,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742330_1506, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java._COPYING_
2025-03-26 02:24:38,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,469 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742330_1506 src: /172.20.1.14:42028 dest: /172.20.1.16:9866
2025-03-26 02:24:38,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742330_1506 src: /172.20.1.16:56090 dest: /172.20.1.17:9866
2025-03-26 02:24:38,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56090, dest: /172.20.1.17:9866, bytes: 2422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742330_1506, duration(ns): 556797
2025-03-26 02:24:38,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42028, dest: /172.20.1.16:9866, bytes: 2422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742330_1506, duration(ns): 690045
2025-03-26 02:24:38,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742330_1506, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,473 INFO terminating
2025-03-26 02:24:38,474 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742331_1507, replicas=172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java._COPYING_
2025-03-26 02:24:38,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,477 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,477 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,477 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742331_1507 src: /172.20.1.14:42032 dest: /172.20.1.16:9866
2025-03-26 02:24:38,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742331_1507 src: /172.20.1.16:56092 dest: /172.20.1.17:9866
2025-03-26 02:24:38,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56092, dest: /172.20.1.17:9866, bytes: 2270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742331_1507, duration(ns): 894237
2025-03-26 02:24:38,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742331_1507, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42032, dest: /172.20.1.16:9866, bytes: 2270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742331_1507, duration(ns): 1313803
2025-03-26 02:24:38,482 INFO terminating
2025-03-26 02:24:38,483 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,493 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742332_1508, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_
2025-03-26 02:24:38,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,493 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,493 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,493 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742332_1508 src: /172.20.1.14:43504 dest: /172.20.1.17:9866
2025-03-26 02:24:38,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742332_1508 src: /172.20.1.17:34796 dest: /172.20.1.16:9866
2025-03-26 02:24:38,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34796, dest: /172.20.1.16:9866, bytes: 3520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742332_1508, duration(ns): 572746
2025-03-26 02:24:38,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742332_1508, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,497 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43504, dest: /172.20.1.17:9866, bytes: 3520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742332_1508, duration(ns): 1203233
2025-03-26 02:24:38,497 INFO terminating
2025-03-26 02:24:38,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,506 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,506 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,506 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,507 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742333_1509, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java._COPYING_
2025-03-26 02:24:38,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742333_1509 src: /172.20.1.14:43512 dest: /172.20.1.17:9866
2025-03-26 02:24:38,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742333_1509 src: /172.20.1.17:34798 dest: /172.20.1.16:9866
2025-03-26 02:24:38,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34798, dest: /172.20.1.16:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742333_1509, duration(ns): 603651
2025-03-26 02:24:38,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742333_1509, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43512, dest: /172.20.1.17:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742333_1509, duration(ns): 1251555
2025-03-26 02:24:38,518 INFO terminating
2025-03-26 02:24:38,519 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,523 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742334_1510, replicas=172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_
2025-03-26 02:24:38,523 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,523 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,523 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,523 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:38,523 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:38,523 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:38,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742334_1510 src: /172.20.1.14:43524 dest: /172.20.1.17:9866
2025-03-26 02:24:38,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742334_1510 src: /172.20.1.17:34808 dest: /172.20.1.16:9866
2025-03-26 02:24:38,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43524, dest: /172.20.1.17:9866, bytes: 1271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742334_1510, duration(ns): 805930
2025-03-26 02:24:38,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34808, dest: /172.20.1.16:9866, bytes: 1271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742334_1510, duration(ns): 480058
2025-03-26 02:24:38,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742334_1510, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,527 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742334_1510 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_
2025-03-26 02:24:38,527 INFO terminating
2025-03-26 02:24:38,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,931 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742335_1511, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java._COPYING_
2025-03-26 02:24:38,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742335_1511 src: /172.20.1.14:42034 dest: /172.20.1.16:9866
2025-03-26 02:24:38,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742335_1511 src: /172.20.1.16:45536 dest: /172.20.1.15:9866
2025-03-26 02:24:38,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742335_1511 src: /172.20.1.15:48132 dest: /172.20.1.17:9866
2025-03-26 02:24:38,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48132, dest: /172.20.1.17:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742335_1511, duration(ns): 2072576
2025-03-26 02:24:38,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45536, dest: /172.20.1.15:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742335_1511, duration(ns): 2382860
2025-03-26 02:24:38,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742335_1511, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,938 INFO terminating
2025-03-26 02:24:38,939 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42034, dest: /172.20.1.16:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742335_1511, duration(ns): 2729059
2025-03-26 02:24:38,939 INFO terminating
2025-03-26 02:24:38,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742336_1512, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java._COPYING_
2025-03-26 02:24:38,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742336_1512 src: /172.20.1.14:42036 dest: /172.20.1.16:9866
2025-03-26 02:24:38,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742336_1512 src: /172.20.1.16:45550 dest: /172.20.1.15:9866
2025-03-26 02:24:38,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742336_1512 src: /172.20.1.15:48146 dest: /172.20.1.17:9866
2025-03-26 02:24:38,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48146, dest: /172.20.1.17:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742336_1512, duration(ns): 910180
2025-03-26 02:24:38,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45550, dest: /172.20.1.15:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742336_1512, duration(ns): 1683838
2025-03-26 02:24:38,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742336_1512, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,953 INFO terminating
2025-03-26 02:24:38,954 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42036, dest: /172.20.1.16:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742336_1512, duration(ns): 1706882
2025-03-26 02:24:38,954 INFO terminating
2025-03-26 02:24:38,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742337_1513, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java._COPYING_
2025-03-26 02:24:38,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742337_1513 src: /172.20.1.14:43526 dest: /172.20.1.17:9866
2025-03-26 02:24:38,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742337_1513 src: /172.20.1.17:34812 dest: /172.20.1.16:9866
2025-03-26 02:24:38,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742337_1513 src: /172.20.1.16:45566 dest: /172.20.1.15:9866
2025-03-26 02:24:38,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45566, dest: /172.20.1.15:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742337_1513, duration(ns): 812631
2025-03-26 02:24:38,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742337_1513, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34812, dest: /172.20.1.16:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742337_1513, duration(ns): 3296259
2025-03-26 02:24:38,968 INFO terminating
2025-03-26 02:24:38,969 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43526, dest: /172.20.1.17:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742337_1513, duration(ns): 4177620
2025-03-26 02:24:38,969 INFO terminating
2025-03-26 02:24:38,972 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742338_1514, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java._COPYING_
2025-03-26 02:24:38,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742338_1514 src: /172.20.1.14:55138 dest: /172.20.1.15:9866
2025-03-26 02:24:38,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742338_1514 src: /172.20.1.15:46142 dest: /172.20.1.16:9866
2025-03-26 02:24:38,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742338_1514 src: /172.20.1.16:56094 dest: /172.20.1.17:9866
2025-03-26 02:24:38,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55138, dest: /172.20.1.15:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742338_1514, duration(ns): 1584556
2025-03-26 02:24:38,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46142, dest: /172.20.1.16:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742338_1514, duration(ns): 1154788
2025-03-26 02:24:38,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56094, dest: /172.20.1.17:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742338_1514, duration(ns): 859216
2025-03-26 02:24:38,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742338_1514, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,977 INFO terminating
2025-03-26 02:24:38,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,978 INFO terminating
2025-03-26 02:24:38,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742339_1515, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java._COPYING_
2025-03-26 02:24:38,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742339_1515 src: /172.20.1.14:42044 dest: /172.20.1.16:9866
2025-03-26 02:24:38,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742339_1515 src: /172.20.1.15:48150 dest: /172.20.1.17:9866
2025-03-26 02:24:38,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742339_1515 src: /172.20.1.16:45572 dest: /172.20.1.15:9866
2025-03-26 02:24:38,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42044, dest: /172.20.1.16:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742339_1515, duration(ns): 2073320
2025-03-26 02:24:38,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48150, dest: /172.20.1.17:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742339_1515, duration(ns): 1233665
2025-03-26 02:24:38,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45572, dest: /172.20.1.15:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742339_1515, duration(ns): 1833225
2025-03-26 02:24:38,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742339_1515, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:38,994 INFO terminating
2025-03-26 02:24:38,994 INFO terminating
2025-03-26 02:24:38,995 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:38,998 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742340_1516, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_
2025-03-26 02:24:38,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,998 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742340_1516 src: /172.20.1.14:42056 dest: /172.20.1.16:9866
2025-03-26 02:24:39,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742340_1516 src: /172.20.1.16:56110 dest: /172.20.1.17:9866
2025-03-26 02:24:39,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742340_1516 src: /172.20.1.17:40694 dest: /172.20.1.15:9866
2025-03-26 02:24:39,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42056, dest: /172.20.1.16:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742340_1516, duration(ns): 1088387
2025-03-26 02:24:39,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56110, dest: /172.20.1.17:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742340_1516, duration(ns): 842225
2025-03-26 02:24:39,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40694, dest: /172.20.1.15:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742340_1516, duration(ns): 672961
2025-03-26 02:24:39,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742340_1516, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,002 INFO terminating
2025-03-26 02:24:39,003 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,003 INFO terminating
2025-03-26 02:24:39,007 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742341_1517, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java._COPYING_
2025-03-26 02:24:39,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742341_1517 src: /172.20.1.14:42070 dest: /172.20.1.16:9866
2025-03-26 02:24:39,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742341_1517 src: /172.20.1.16:45576 dest: /172.20.1.15:9866
2025-03-26 02:24:39,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742341_1517 src: /172.20.1.15:48164 dest: /172.20.1.17:9866
2025-03-26 02:24:39,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48164, dest: /172.20.1.17:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742341_1517, duration(ns): 505202
2025-03-26 02:24:39,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45576, dest: /172.20.1.15:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742341_1517, duration(ns): 792440
2025-03-26 02:24:39,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742341_1517, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,011 INFO terminating
2025-03-26 02:24:39,012 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42070, dest: /172.20.1.16:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742341_1517, duration(ns): 1025813
2025-03-26 02:24:39,012 INFO terminating
2025-03-26 02:24:39,015 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742342_1518, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java._COPYING_
2025-03-26 02:24:39,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742342_1518 src: /172.20.1.14:55148 dest: /172.20.1.15:9866
2025-03-26 02:24:39,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742342_1518 src: /172.20.1.15:48174 dest: /172.20.1.17:9866
2025-03-26 02:24:39,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742342_1518 src: /172.20.1.17:34828 dest: /172.20.1.16:9866
2025-03-26 02:24:39,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34828, dest: /172.20.1.16:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742342_1518, duration(ns): 628741
2025-03-26 02:24:39,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742342_1518, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48174, dest: /172.20.1.17:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742342_1518, duration(ns): 809822
2025-03-26 02:24:39,020 INFO terminating
2025-03-26 02:24:39,021 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55148, dest: /172.20.1.15:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742342_1518, duration(ns): 1557613
2025-03-26 02:24:39,021 INFO terminating
2025-03-26 02:24:39,024 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742343_1519, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java._COPYING_
2025-03-26 02:24:39,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742343_1519 src: /172.20.1.14:55164 dest: /172.20.1.15:9866
2025-03-26 02:24:39,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742343_1519 src: /172.20.1.15:48178 dest: /172.20.1.17:9866
2025-03-26 02:24:39,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742343_1519 src: /172.20.1.17:34838 dest: /172.20.1.16:9866
2025-03-26 02:24:39,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48178, dest: /172.20.1.17:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742343_1519, duration(ns): 948518
2025-03-26 02:24:39,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34838, dest: /172.20.1.16:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742343_1519, duration(ns): 758005
2025-03-26 02:24:39,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742343_1519, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,028 INFO terminating
2025-03-26 02:24:39,030 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55164, dest: /172.20.1.15:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742343_1519, duration(ns): 1268120
2025-03-26 02:24:39,030 INFO terminating
2025-03-26 02:24:39,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742344_1520, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java._COPYING_
2025-03-26 02:24:39,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742344_1520 src: /172.20.1.14:42076 dest: /172.20.1.16:9866
2025-03-26 02:24:39,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742344_1520 src: /172.20.1.16:56124 dest: /172.20.1.17:9866
2025-03-26 02:24:39,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742344_1520 src: /172.20.1.17:40698 dest: /172.20.1.15:9866
2025-03-26 02:24:39,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40698, dest: /172.20.1.15:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742344_1520, duration(ns): 1002862
2025-03-26 02:24:39,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742344_1520, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42076, dest: /172.20.1.16:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742344_1520, duration(ns): 1575768
2025-03-26 02:24:39,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56124, dest: /172.20.1.17:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742344_1520, duration(ns): 1238392
2025-03-26 02:24:39,039 INFO terminating
2025-03-26 02:24:39,039 INFO terminating
2025-03-26 02:24:39,040 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742345_1521, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:24:39,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742345_1521 src: /172.20.1.14:42082 dest: /172.20.1.16:9866
2025-03-26 02:24:39,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742345_1521 src: /172.20.1.16:56126 dest: /172.20.1.17:9866
2025-03-26 02:24:39,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742345_1521 src: /172.20.1.17:40700 dest: /172.20.1.15:9866
2025-03-26 02:24:39,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56126, dest: /172.20.1.17:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742345_1521, duration(ns): 769846
2025-03-26 02:24:39,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40700, dest: /172.20.1.15:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742345_1521, duration(ns): 615127
2025-03-26 02:24:39,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742345_1521, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,049 INFO terminating
2025-03-26 02:24:39,050 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42082, dest: /172.20.1.16:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742345_1521, duration(ns): 1051340
2025-03-26 02:24:39,050 INFO terminating
2025-03-26 02:24:39,053 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742346_1522, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java._COPYING_
2025-03-26 02:24:39,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742346_1522 src: /172.20.1.14:43534 dest: /172.20.1.17:9866
2025-03-26 02:24:39,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742346_1522 src: /172.20.1.17:34840 dest: /172.20.1.16:9866
2025-03-26 02:24:39,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742346_1522 src: /172.20.1.16:45586 dest: /172.20.1.15:9866
2025-03-26 02:24:39,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45586, dest: /172.20.1.15:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742346_1522, duration(ns): 623889
2025-03-26 02:24:39,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34840, dest: /172.20.1.16:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742346_1522, duration(ns): 777552
2025-03-26 02:24:39,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742346_1522, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,057 INFO terminating
2025-03-26 02:24:39,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43534, dest: /172.20.1.17:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742346_1522, duration(ns): 1046605
2025-03-26 02:24:39,058 INFO terminating
2025-03-26 02:24:39,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742347_1523, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java._COPYING_
2025-03-26 02:24:39,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742347_1523 src: /172.20.1.14:43548 dest: /172.20.1.17:9866
2025-03-26 02:24:39,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742347_1523 src: /172.20.1.17:34854 dest: /172.20.1.16:9866
2025-03-26 02:24:39,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742347_1523 src: /172.20.1.16:45596 dest: /172.20.1.15:9866
2025-03-26 02:24:39,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43548, dest: /172.20.1.17:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742347_1523, duration(ns): 990605
2025-03-26 02:24:39,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45596, dest: /172.20.1.15:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742347_1523, duration(ns): 575152
2025-03-26 02:24:39,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34854, dest: /172.20.1.16:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742347_1523, duration(ns): 741671
2025-03-26 02:24:39,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742347_1523, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,065 INFO terminating
2025-03-26 02:24:39,066 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,066 INFO terminating
2025-03-26 02:24:39,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742348_1524, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java._COPYING_
2025-03-26 02:24:39,074 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,074 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742348_1524 src: /172.20.1.14:55168 dest: /172.20.1.15:9866
2025-03-26 02:24:39,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742348_1524 src: /172.20.1.15:48186 dest: /172.20.1.17:9866
2025-03-26 02:24:39,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742348_1524 src: /172.20.1.17:34858 dest: /172.20.1.16:9866
2025-03-26 02:24:39,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48186, dest: /172.20.1.17:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742348_1524, duration(ns): 838020
2025-03-26 02:24:39,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34858, dest: /172.20.1.16:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742348_1524, duration(ns): 572487
2025-03-26 02:24:39,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742348_1524, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,078 INFO terminating
2025-03-26 02:24:39,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55168, dest: /172.20.1.15:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742348_1524, duration(ns): 1166471
2025-03-26 02:24:39,079 INFO terminating
2025-03-26 02:24:39,080 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742349_1525, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java._COPYING_
2025-03-26 02:24:39,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742349_1525 src: /172.20.1.14:43564 dest: /172.20.1.17:9866
2025-03-26 02:24:39,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742349_1525 src: /172.20.1.17:40712 dest: /172.20.1.15:9866
2025-03-26 02:24:39,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742349_1525 src: /172.20.1.15:46154 dest: /172.20.1.16:9866
2025-03-26 02:24:39,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46154, dest: /172.20.1.16:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742349_1525, duration(ns): 548307
2025-03-26 02:24:39,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40712, dest: /172.20.1.15:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742349_1525, duration(ns): 785717
2025-03-26 02:24:39,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742349_1525, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,091 INFO terminating
2025-03-26 02:24:39,092 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43564, dest: /172.20.1.17:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742349_1525, duration(ns): 1041068
2025-03-26 02:24:39,092 INFO terminating
2025-03-26 02:24:39,100 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742350_1526, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java._COPYING_
2025-03-26 02:24:39,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742350_1526 src: /172.20.1.14:42086 dest: /172.20.1.16:9866
2025-03-26 02:24:39,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742350_1526 src: /172.20.1.16:45604 dest: /172.20.1.15:9866
2025-03-26 02:24:39,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742350_1526 src: /172.20.1.15:48194 dest: /172.20.1.17:9866
2025-03-26 02:24:39,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48194, dest: /172.20.1.17:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742350_1526, duration(ns): 721287
2025-03-26 02:24:39,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742350_1526, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42086, dest: /172.20.1.16:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742350_1526, duration(ns): 1583913
2025-03-26 02:24:39,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45604, dest: /172.20.1.15:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742350_1526, duration(ns): 997832
2025-03-26 02:24:39,105 INFO terminating
2025-03-26 02:24:39,105 INFO terminating
2025-03-26 02:24:39,107 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,118 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742351_1527, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:24:39,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742351_1527 src: /172.20.1.14:43570 dest: /172.20.1.17:9866
2025-03-26 02:24:39,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742351_1527 src: /172.20.1.17:40716 dest: /172.20.1.15:9866
2025-03-26 02:24:39,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742351_1527 src: /172.20.1.15:46164 dest: /172.20.1.16:9866
2025-03-26 02:24:39,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43570, dest: /172.20.1.17:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742351_1527, duration(ns): 1460356
2025-03-26 02:24:39,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46164, dest: /172.20.1.16:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742351_1527, duration(ns): 1012154
2025-03-26 02:24:39,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40716, dest: /172.20.1.15:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742351_1527, duration(ns): 1285654
2025-03-26 02:24:39,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742351_1527, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,123 INFO terminating
2025-03-26 02:24:39,124 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,124 INFO terminating
2025-03-26 02:24:39,127 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,128 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742352_1528, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java._COPYING_
2025-03-26 02:24:39,128 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742352_1528 src: /172.20.1.14:42090 dest: /172.20.1.16:9866
2025-03-26 02:24:39,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742352_1528 src: /172.20.1.16:56140 dest: /172.20.1.17:9866
2025-03-26 02:24:39,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742352_1528 src: /172.20.1.17:40726 dest: /172.20.1.15:9866
2025-03-26 02:24:39,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56140, dest: /172.20.1.17:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742352_1528, duration(ns): 1492724
2025-03-26 02:24:39,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40726, dest: /172.20.1.15:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742352_1528, duration(ns): 963230
2025-03-26 02:24:39,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742352_1528, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,137 INFO terminating
2025-03-26 02:24:39,138 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42090, dest: /172.20.1.16:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742352_1528, duration(ns): 1769089
2025-03-26 02:24:39,138 INFO terminating
2025-03-26 02:24:39,142 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742353_1529, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java._COPYING_
2025-03-26 02:24:39,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742353_1529 src: /172.20.1.14:42104 dest: /172.20.1.16:9866
2025-03-26 02:24:39,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742353_1529 src: /172.20.1.16:45608 dest: /172.20.1.15:9866
2025-03-26 02:24:39,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742353_1529 src: /172.20.1.15:48208 dest: /172.20.1.17:9866
2025-03-26 02:24:39,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48208, dest: /172.20.1.17:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742353_1529, duration(ns): 9005283
2025-03-26 02:24:39,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742353_1529, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45608, dest: /172.20.1.15:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742353_1529, duration(ns): 1348817
2025-03-26 02:24:39,158 INFO terminating
2025-03-26 02:24:39,159 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42104, dest: /172.20.1.16:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742353_1529, duration(ns): 3870526
2025-03-26 02:24:39,159 INFO terminating
2025-03-26 02:24:39,164 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742354_1530, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:24:39,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742354_1530 src: /172.20.1.14:55184 dest: /172.20.1.15:9866
2025-03-26 02:24:39,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742354_1530 src: /172.20.1.15:48222 dest: /172.20.1.17:9866
2025-03-26 02:24:39,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742354_1530 src: /172.20.1.17:34874 dest: /172.20.1.16:9866
2025-03-26 02:24:39,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55184, dest: /172.20.1.15:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742354_1530, duration(ns): 1335136
2025-03-26 02:24:39,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48222, dest: /172.20.1.17:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742354_1530, duration(ns): 1005392
2025-03-26 02:24:39,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34874, dest: /172.20.1.16:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742354_1530, duration(ns): 783629
2025-03-26 02:24:39,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742354_1530, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,169 INFO terminating
2025-03-26 02:24:39,170 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,170 INFO terminating
2025-03-26 02:24:39,173 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742355_1531, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java._COPYING_
2025-03-26 02:24:39,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742355_1531 src: /172.20.1.14:43578 dest: /172.20.1.17:9866
2025-03-26 02:24:39,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742355_1531 src: /172.20.1.16:45614 dest: /172.20.1.15:9866
2025-03-26 02:24:39,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742355_1531 src: /172.20.1.17:34878 dest: /172.20.1.16:9866
2025-03-26 02:24:39,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45614, dest: /172.20.1.15:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742355_1531, duration(ns): 739032
2025-03-26 02:24:39,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34878, dest: /172.20.1.16:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742355_1531, duration(ns): 847489
2025-03-26 02:24:39,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742355_1531, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,178 INFO terminating
2025-03-26 02:24:39,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43578, dest: /172.20.1.17:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742355_1531, duration(ns): 1136873
2025-03-26 02:24:39,179 INFO terminating
2025-03-26 02:24:39,180 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742356_1532, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java._COPYING_
2025-03-26 02:24:39,182 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,182 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742356_1532 src: /172.20.1.14:55200 dest: /172.20.1.15:9866
2025-03-26 02:24:39,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742356_1532 src: /172.20.1.15:46180 dest: /172.20.1.16:9866
2025-03-26 02:24:39,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742356_1532 src: /172.20.1.16:56148 dest: /172.20.1.17:9866
2025-03-26 02:24:39,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46180, dest: /172.20.1.16:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742356_1532, duration(ns): 1765289
2025-03-26 02:24:39,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56148, dest: /172.20.1.17:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742356_1532, duration(ns): 1483826
2025-03-26 02:24:39,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742356_1532, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,190 INFO terminating
2025-03-26 02:24:39,191 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55200, dest: /172.20.1.15:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742356_1532, duration(ns): 2070815
2025-03-26 02:24:39,191 INFO terminating
2025-03-26 02:24:39,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742357_1533, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java._COPYING_
2025-03-26 02:24:39,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742357_1533 src: /172.20.1.14:55216 dest: /172.20.1.15:9866
2025-03-26 02:24:39,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742357_1533 src: /172.20.1.15:48226 dest: /172.20.1.17:9866
2025-03-26 02:24:39,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742357_1533 src: /172.20.1.17:34880 dest: /172.20.1.16:9866
2025-03-26 02:24:39,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34880, dest: /172.20.1.16:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742357_1533, duration(ns): 675110
2025-03-26 02:24:39,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742357_1533, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55216, dest: /172.20.1.15:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742357_1533, duration(ns): 1193238
2025-03-26 02:24:39,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48226, dest: /172.20.1.17:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742357_1533, duration(ns): 894610
2025-03-26 02:24:39,199 INFO terminating
2025-03-26 02:24:39,199 INFO terminating
2025-03-26 02:24:39,214 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,218 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742358_1534, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java._COPYING_
2025-03-26 02:24:39,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742358_1534 src: /172.20.1.14:42120 dest: /172.20.1.16:9866
2025-03-26 02:24:39,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742358_1534 src: /172.20.1.16:56160 dest: /172.20.1.17:9866
2025-03-26 02:24:39,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742358_1534 src: /172.20.1.17:40732 dest: /172.20.1.15:9866
2025-03-26 02:24:39,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56160, dest: /172.20.1.17:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742358_1534, duration(ns): 1158218
2025-03-26 02:24:39,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40732, dest: /172.20.1.15:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742358_1534, duration(ns): 969153
2025-03-26 02:24:39,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742358_1534, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,223 INFO terminating
2025-03-26 02:24:39,224 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42120, dest: /172.20.1.16:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742358_1534, duration(ns): 1356479
2025-03-26 02:24:39,224 INFO terminating
2025-03-26 02:24:39,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742359_1535, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java._COPYING_
2025-03-26 02:24:39,227 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,227 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742359_1535 src: /172.20.1.14:55226 dest: /172.20.1.15:9866
2025-03-26 02:24:39,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742359_1535 src: /172.20.1.15:48242 dest: /172.20.1.17:9866
2025-03-26 02:24:39,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742359_1535 src: /172.20.1.17:34890 dest: /172.20.1.16:9866
2025-03-26 02:24:39,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55226, dest: /172.20.1.15:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742359_1535, duration(ns): 1212928
2025-03-26 02:24:39,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48242, dest: /172.20.1.17:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742359_1535, duration(ns): 881832
2025-03-26 02:24:39,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34890, dest: /172.20.1.16:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742359_1535, duration(ns): 666663
2025-03-26 02:24:39,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742359_1535, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,231 INFO terminating
2025-03-26 02:24:39,231 INFO terminating
2025-03-26 02:24:39,232 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742360_1536, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java._COPYING_
2025-03-26 02:24:39,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742360_1536 src: /172.20.1.14:55240 dest: /172.20.1.15:9866
2025-03-26 02:24:39,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742360_1536 src: /172.20.1.15:46194 dest: /172.20.1.16:9866
2025-03-26 02:24:39,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742360_1536 src: /172.20.1.16:56176 dest: /172.20.1.17:9866
2025-03-26 02:24:39,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56176, dest: /172.20.1.17:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742360_1536, duration(ns): 1226488
2025-03-26 02:24:39,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742360_1536, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55240, dest: /172.20.1.15:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742360_1536, duration(ns): 1821693
2025-03-26 02:24:39,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46194, dest: /172.20.1.16:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742360_1536, duration(ns): 1496836
2025-03-26 02:24:39,242 INFO terminating
2025-03-26 02:24:39,242 INFO terminating
2025-03-26 02:24:39,243 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,245 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742361_1537, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java._COPYING_
2025-03-26 02:24:39,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742361_1537 src: /172.20.1.14:55248 dest: /172.20.1.15:9866
2025-03-26 02:24:39,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742361_1537 src: /172.20.1.15:48250 dest: /172.20.1.17:9866
2025-03-26 02:24:39,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742361_1537 src: /172.20.1.17:34896 dest: /172.20.1.16:9866
2025-03-26 02:24:39,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48250, dest: /172.20.1.17:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742361_1537, duration(ns): 812058
2025-03-26 02:24:39,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34896, dest: /172.20.1.16:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742361_1537, duration(ns): 588452
2025-03-26 02:24:39,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742361_1537, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,249 INFO terminating
2025-03-26 02:24:39,250 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55248, dest: /172.20.1.15:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742361_1537, duration(ns): 1142277
2025-03-26 02:24:39,250 INFO terminating
2025-03-26 02:24:39,253 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742362_1538, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java._COPYING_
2025-03-26 02:24:39,253 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,253 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742362_1538 src: /172.20.1.14:43582 dest: /172.20.1.17:9866
2025-03-26 02:24:39,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742362_1538 src: /172.20.1.17:34900 dest: /172.20.1.16:9866
2025-03-26 02:24:39,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742362_1538 src: /172.20.1.16:45616 dest: /172.20.1.15:9866
2025-03-26 02:24:39,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45616, dest: /172.20.1.15:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742362_1538, duration(ns): 626355
2025-03-26 02:24:39,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34900, dest: /172.20.1.16:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742362_1538, duration(ns): 1113646
2025-03-26 02:24:39,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742362_1538, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,257 INFO terminating
2025-03-26 02:24:39,258 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43582, dest: /172.20.1.17:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742362_1538, duration(ns): 1366234
2025-03-26 02:24:39,258 INFO terminating
2025-03-26 02:24:39,262 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742363_1539, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_
2025-03-26 02:24:39,262 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,262 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742363_1539 src: /172.20.1.14:43584 dest: /172.20.1.17:9866
2025-03-26 02:24:39,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742363_1539 src: /172.20.1.17:34914 dest: /172.20.1.16:9866
2025-03-26 02:24:39,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742363_1539 src: /172.20.1.16:45624 dest: /172.20.1.15:9866
2025-03-26 02:24:39,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43584, dest: /172.20.1.17:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742363_1539, duration(ns): 988039
2025-03-26 02:24:39,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45624, dest: /172.20.1.15:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742363_1539, duration(ns): 563475
2025-03-26 02:24:39,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34914, dest: /172.20.1.16:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742363_1539, duration(ns): 696815
2025-03-26 02:24:39,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742363_1539, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,266 INFO terminating
2025-03-26 02:24:39,267 INFO terminating
2025-03-26 02:24:39,270 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742364_1540, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java._COPYING_
2025-03-26 02:24:39,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742364_1540 src: /172.20.1.14:42132 dest: /172.20.1.16:9866
2025-03-26 02:24:39,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742364_1540 src: /172.20.1.16:56178 dest: /172.20.1.17:9866
2025-03-26 02:24:39,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742364_1540 src: /172.20.1.17:40742 dest: /172.20.1.15:9866
2025-03-26 02:24:39,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56178, dest: /172.20.1.17:9866, bytes: 2645, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742364_1540, duration(ns): 796383
2025-03-26 02:24:39,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40742, dest: /172.20.1.15:9866, bytes: 2645, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742364_1540, duration(ns): 654811
2025-03-26 02:24:39,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742364_1540, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,281 INFO terminating
2025-03-26 02:24:39,282 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42132, dest: /172.20.1.16:9866, bytes: 2645, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742364_1540, duration(ns): 1079277
2025-03-26 02:24:39,282 INFO terminating
2025-03-26 02:24:39,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742365_1541, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java._COPYING_
2025-03-26 02:24:39,290 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,290 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742365_1541 src: /172.20.1.14:55262 dest: /172.20.1.15:9866
2025-03-26 02:24:39,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742365_1541 src: /172.20.1.15:48266 dest: /172.20.1.17:9866
2025-03-26 02:24:39,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742365_1541 src: /172.20.1.17:34924 dest: /172.20.1.16:9866
2025-03-26 02:24:39,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48266, dest: /172.20.1.17:9866, bytes: 4683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742365_1541, duration(ns): 933882
2025-03-26 02:24:39,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34924, dest: /172.20.1.16:9866, bytes: 4683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742365_1541, duration(ns): 637123
2025-03-26 02:24:39,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742365_1541, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,294 INFO terminating
2025-03-26 02:24:39,295 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55262, dest: /172.20.1.15:9866, bytes: 4683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742365_1541, duration(ns): 1111159
2025-03-26 02:24:39,295 INFO terminating
2025-03-26 02:24:39,298 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742366_1542, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java._COPYING_
2025-03-26 02:24:39,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742366_1542 src: /172.20.1.14:55270 dest: /172.20.1.15:9866
2025-03-26 02:24:39,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742366_1542 src: /172.20.1.15:46208 dest: /172.20.1.16:9866
2025-03-26 02:24:39,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742366_1542 src: /172.20.1.16:56194 dest: /172.20.1.17:9866
2025-03-26 02:24:39,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56194, dest: /172.20.1.17:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742366_1542, duration(ns): 571354
2025-03-26 02:24:39,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55270, dest: /172.20.1.15:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742366_1542, duration(ns): 1102470
2025-03-26 02:24:39,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46208, dest: /172.20.1.16:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742366_1542, duration(ns): 801937
2025-03-26 02:24:39,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742366_1542, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,302 INFO terminating
2025-03-26 02:24:39,302 INFO terminating
2025-03-26 02:24:39,303 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,309 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742367_1543, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_
2025-03-26 02:24:39,309 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,309 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742367_1543 src: /172.20.1.14:55278 dest: /172.20.1.15:9866
2025-03-26 02:24:39,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742367_1543 src: /172.20.1.15:48276 dest: /172.20.1.17:9866
2025-03-26 02:24:39,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742367_1543 src: /172.20.1.17:34926 dest: /172.20.1.16:9866
2025-03-26 02:24:39,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34926, dest: /172.20.1.16:9866, bytes: 1968, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742367_1543, duration(ns): 579584
2025-03-26 02:24:39,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742367_1543, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,314 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55278, dest: /172.20.1.15:9866, bytes: 1968, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742367_1543, duration(ns): 1179275
2025-03-26 02:24:39,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48276, dest: /172.20.1.17:9866, bytes: 1968, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742367_1543, duration(ns): 831477
2025-03-26 02:24:39,314 INFO terminating
2025-03-26 02:24:39,314 INFO terminating
2025-03-26 02:24:39,325 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742368_1544, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java._COPYING_
2025-03-26 02:24:39,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742368_1544 src: /172.20.1.14:43594 dest: /172.20.1.17:9866
2025-03-26 02:24:39,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742368_1544 src: /172.20.1.16:45640 dest: /172.20.1.15:9866
2025-03-26 02:24:39,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742368_1544 src: /172.20.1.17:34934 dest: /172.20.1.16:9866
2025-03-26 02:24:39,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45640, dest: /172.20.1.15:9866, bytes: 4506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742368_1544, duration(ns): 3788103
2025-03-26 02:24:39,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34934, dest: /172.20.1.16:9866, bytes: 4506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742368_1544, duration(ns): 3916576
2025-03-26 02:24:39,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742368_1544, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,332 INFO terminating
2025-03-26 02:24:39,333 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43594, dest: /172.20.1.17:9866, bytes: 4506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742368_1544, duration(ns): 4238696
2025-03-26 02:24:39,333 INFO terminating
2025-03-26 02:24:39,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742369_1545, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java._COPYING_
2025-03-26 02:24:39,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742369_1545 src: /172.20.1.14:42142 dest: /172.20.1.16:9866
2025-03-26 02:24:39,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742369_1545 src: /172.20.1.16:56196 dest: /172.20.1.17:9866
2025-03-26 02:24:39,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742369_1545 src: /172.20.1.17:40756 dest: /172.20.1.15:9866
2025-03-26 02:24:39,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56196, dest: /172.20.1.17:9866, bytes: 2721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742369_1545, duration(ns): 1429910
2025-03-26 02:24:39,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40756, dest: /172.20.1.15:9866, bytes: 2721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742369_1545, duration(ns): 802493
2025-03-26 02:24:39,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742369_1545, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42142, dest: /172.20.1.16:9866, bytes: 2721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742369_1545, duration(ns): 1708686
2025-03-26 02:24:39,341 INFO terminating
2025-03-26 02:24:39,341 INFO terminating
2025-03-26 02:24:39,342 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742370_1546, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaTC.java._COPYING_
2025-03-26 02:24:39,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742370_1546 src: /172.20.1.14:43610 dest: /172.20.1.17:9866
2025-03-26 02:24:39,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742370_1546 src: /172.20.1.17:34944 dest: /172.20.1.16:9866
2025-03-26 02:24:39,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742370_1546 src: /172.20.1.16:45644 dest: /172.20.1.15:9866
2025-03-26 02:24:39,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45644, dest: /172.20.1.15:9866, bytes: 3473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742370_1546, duration(ns): 794802
2025-03-26 02:24:39,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742370_1546, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,351 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaTC.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43610, dest: /172.20.1.17:9866, bytes: 3473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742370_1546, duration(ns): 1314474
2025-03-26 02:24:39,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34944, dest: /172.20.1.16:9866, bytes: 3473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742370_1546, duration(ns): 1005959
2025-03-26 02:24:39,351 INFO terminating
2025-03-26 02:24:39,351 INFO terminating
2025-03-26 02:24:39,355 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742371_1547, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java._COPYING_
2025-03-26 02:24:39,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742371_1547 src: /172.20.1.14:55292 dest: /172.20.1.15:9866
2025-03-26 02:24:39,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742371_1547 src: /172.20.1.15:48282 dest: /172.20.1.17:9866
2025-03-26 02:24:39,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742371_1547 src: /172.20.1.17:34954 dest: /172.20.1.16:9866
2025-03-26 02:24:39,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48282, dest: /172.20.1.17:9866, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742371_1547, duration(ns): 1267240
2025-03-26 02:24:39,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34954, dest: /172.20.1.16:9866, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742371_1547, duration(ns): 630150
2025-03-26 02:24:39,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742371_1547, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,361 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55292, dest: /172.20.1.15:9866, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742371_1547, duration(ns): 1896487
2025-03-26 02:24:39,361 INFO terminating
2025-03-26 02:24:39,361 INFO terminating
2025-03-26 02:24:39,364 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742372_1548, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java._COPYING_
2025-03-26 02:24:39,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742372_1548 src: /172.20.1.14:42146 dest: /172.20.1.16:9866
2025-03-26 02:24:39,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742372_1548 src: /172.20.1.16:56198 dest: /172.20.1.17:9866
2025-03-26 02:24:39,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742372_1548 src: /172.20.1.17:40770 dest: /172.20.1.15:9866
2025-03-26 02:24:39,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40770, dest: /172.20.1.15:9866, bytes: 4979, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742372_1548, duration(ns): 658588
2025-03-26 02:24:39,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742372_1548, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42146, dest: /172.20.1.16:9866, bytes: 4979, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742372_1548, duration(ns): 1058128
2025-03-26 02:24:39,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56198, dest: /172.20.1.17:9866, bytes: 4979, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742372_1548, duration(ns): 805346
2025-03-26 02:24:39,373 INFO terminating
2025-03-26 02:24:39,373 INFO terminating
2025-03-26 02:24:39,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,382 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742373_1549, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java._COPYING_
2025-03-26 02:24:39,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742373_1549 src: /172.20.1.14:42150 dest: /172.20.1.16:9866
2025-03-26 02:24:39,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742373_1549 src: /172.20.1.16:56210 dest: /172.20.1.17:9866
2025-03-26 02:24:39,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742373_1549 src: /172.20.1.17:40778 dest: /172.20.1.15:9866
2025-03-26 02:24:39,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56210, dest: /172.20.1.17:9866, bytes: 10904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742373_1549, duration(ns): 848367
2025-03-26 02:24:39,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40778, dest: /172.20.1.15:9866, bytes: 10904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742373_1549, duration(ns): 696621
2025-03-26 02:24:39,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742373_1549, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,387 INFO terminating
2025-03-26 02:24:39,388 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42150, dest: /172.20.1.16:9866, bytes: 10904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742373_1549, duration(ns): 1142552
2025-03-26 02:24:39,388 INFO terminating
2025-03-26 02:24:39,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742374_1550, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java._COPYING_
2025-03-26 02:24:39,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742374_1550 src: /172.20.1.14:43624 dest: /172.20.1.17:9866
2025-03-26 02:24:39,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742374_1550 src: /172.20.1.17:40780 dest: /172.20.1.15:9866
2025-03-26 02:24:39,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742374_1550 src: /172.20.1.15:46222 dest: /172.20.1.16:9866
2025-03-26 02:24:39,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43624, dest: /172.20.1.17:9866, bytes: 17432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742374_1550, duration(ns): 1058984
2025-03-26 02:24:39,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46222, dest: /172.20.1.16:9866, bytes: 17432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742374_1550, duration(ns): 631742
2025-03-26 02:24:39,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40780, dest: /172.20.1.15:9866, bytes: 17432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742374_1550, duration(ns): 874756
2025-03-26 02:24:39,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742374_1550, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,396 INFO terminating
2025-03-26 02:24:39,397 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,397 INFO terminating
2025-03-26 02:24:39,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742375_1551, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java._COPYING_
2025-03-26 02:24:39,403 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,403 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742375_1551 src: /172.20.1.14:42158 dest: /172.20.1.16:9866
2025-03-26 02:24:39,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742375_1551 src: /172.20.1.16:56226 dest: /172.20.1.17:9866
2025-03-26 02:24:39,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742375_1551 src: /172.20.1.17:40792 dest: /172.20.1.15:9866
2025-03-26 02:24:39,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42158, dest: /172.20.1.16:9866, bytes: 4187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742375_1551, duration(ns): 1081839
2025-03-26 02:24:39,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56226, dest: /172.20.1.17:9866, bytes: 4187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742375_1551, duration(ns): 769845
2025-03-26 02:24:39,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40792, dest: /172.20.1.15:9866, bytes: 4187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742375_1551, duration(ns): 623416
2025-03-26 02:24:39,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742375_1551, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,407 INFO terminating
2025-03-26 02:24:39,407 INFO terminating
2025-03-26 02:24:39,410 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,419 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742376_1552, replicas=172.20.1.17:9866, 172.20.1.16:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java._COPYING_
2025-03-26 02:24:39,419 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,419 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742376_1552 src: /172.20.1.14:43632 dest: /172.20.1.17:9866
2025-03-26 02:24:39,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742376_1552 src: /172.20.1.17:34960 dest: /172.20.1.16:9866
2025-03-26 02:24:39,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742376_1552 src: /172.20.1.16:45646 dest: /172.20.1.15:9866
2025-03-26 02:24:39,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45646, dest: /172.20.1.15:9866, bytes: 2898, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742376_1552, duration(ns): 723568
2025-03-26 02:24:39,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34960, dest: /172.20.1.16:9866, bytes: 2898, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742376_1552, duration(ns): 939194
2025-03-26 02:24:39,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742376_1552, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,423 INFO terminating
2025-03-26 02:24:39,424 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43632, dest: /172.20.1.17:9866, bytes: 2898, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742376_1552, duration(ns): 1254906
2025-03-26 02:24:39,424 INFO terminating
2025-03-26 02:24:39,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742377_1553, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java._COPYING_
2025-03-26 02:24:39,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742377_1553 src: /172.20.1.14:43648 dest: /172.20.1.17:9866
2025-03-26 02:24:39,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742377_1553 src: /172.20.1.17:40802 dest: /172.20.1.15:9866
2025-03-26 02:24:39,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742377_1553 src: /172.20.1.15:46230 dest: /172.20.1.16:9866
2025-03-26 02:24:39,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46230, dest: /172.20.1.16:9866, bytes: 16348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742377_1553, duration(ns): 919558
2025-03-26 02:24:39,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43648, dest: /172.20.1.17:9866, bytes: 16348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742377_1553, duration(ns): 1444440
2025-03-26 02:24:39,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40802, dest: /172.20.1.15:9866, bytes: 16348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742377_1553, duration(ns): 1156894
2025-03-26 02:24:39,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742377_1553, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,436 INFO terminating
2025-03-26 02:24:39,436 INFO terminating
2025-03-26 02:24:39,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,440 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742378_1554, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_
2025-03-26 02:24:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742378_1554 src: /172.20.1.14:42170 dest: /172.20.1.16:9866
2025-03-26 02:24:39,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742378_1554 src: /172.20.1.16:45652 dest: /172.20.1.15:9866
2025-03-26 02:24:39,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742378_1554 src: /172.20.1.15:48296 dest: /172.20.1.17:9866
2025-03-26 02:24:39,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48296, dest: /172.20.1.17:9866, bytes: 5473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742378_1554, duration(ns): 659208
2025-03-26 02:24:39,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742378_1554, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,445 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42170, dest: /172.20.1.16:9866, bytes: 5473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742378_1554, duration(ns): 1134335
2025-03-26 02:24:39,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45652, dest: /172.20.1.15:9866, bytes: 5473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742378_1554, duration(ns): 885812
2025-03-26 02:24:39,445 INFO terminating
2025-03-26 02:24:39,445 INFO terminating
2025-03-26 02:24:39,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742379_1555, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java._COPYING_
2025-03-26 02:24:39,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742379_1555 src: /172.20.1.14:42174 dest: /172.20.1.16:9866
2025-03-26 02:24:39,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742379_1555 src: /172.20.1.16:56228 dest: /172.20.1.17:9866
2025-03-26 02:24:39,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742379_1555 src: /172.20.1.17:40810 dest: /172.20.1.15:9866
2025-03-26 02:24:39,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42174, dest: /172.20.1.16:9866, bytes: 4663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742379_1555, duration(ns): 1126952
2025-03-26 02:24:39,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56228, dest: /172.20.1.17:9866, bytes: 4663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742379_1555, duration(ns): 804044
2025-03-26 02:24:39,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40810, dest: /172.20.1.15:9866, bytes: 4663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742379_1555, duration(ns): 645175
2025-03-26 02:24:39,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742379_1555, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,453 INFO terminating
2025-03-26 02:24:39,454 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,454 INFO terminating
2025-03-26 02:24:39,457 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742380_1556, replicas=172.20.1.15:9866, 172.20.1.17:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_
2025-03-26 02:24:39,457 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,457 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742380_1556 src: /172.20.1.14:55308 dest: /172.20.1.15:9866
2025-03-26 02:24:39,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742380_1556 src: /172.20.1.15:48308 dest: /172.20.1.17:9866
2025-03-26 02:24:39,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742380_1556 src: /172.20.1.17:34968 dest: /172.20.1.16:9866
2025-03-26 02:24:39,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55308, dest: /172.20.1.15:9866, bytes: 3479, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742380_1556, duration(ns): 2355385
2025-03-26 02:24:39,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48308, dest: /172.20.1.17:9866, bytes: 3479, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742380_1556, duration(ns): 2103486
2025-03-26 02:24:39,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:34968, dest: /172.20.1.16:9866, bytes: 3479, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742380_1556, duration(ns): 1892858
2025-03-26 02:24:39,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742380_1556, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,467 INFO terminating
2025-03-26 02:24:39,467 INFO terminating
2025-03-26 02:24:39,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742381_1557, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_
2025-03-26 02:24:39,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742381_1557 src: /172.20.1.14:55324 dest: /172.20.1.15:9866
2025-03-26 02:24:39,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742381_1557 src: /172.20.1.15:46234 dest: /172.20.1.16:9866
2025-03-26 02:24:39,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742381_1557 src: /172.20.1.16:56232 dest: /172.20.1.17:9866
2025-03-26 02:24:39,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56232, dest: /172.20.1.17:9866, bytes: 3285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742381_1557, duration(ns): 587649
2025-03-26 02:24:39,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742381_1557, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,481 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55324, dest: /172.20.1.15:9866, bytes: 3285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742381_1557, duration(ns): 1121295
2025-03-26 02:24:39,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46234, dest: /172.20.1.16:9866, bytes: 3285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742381_1557, duration(ns): 845867
2025-03-26 02:24:39,481 INFO terminating
2025-03-26 02:24:39,481 INFO terminating
2025-03-26 02:24:39,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,485 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742382_1558, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java._COPYING_
2025-03-26 02:24:39,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742382_1558 src: /172.20.1.14:55326 dest: /172.20.1.15:9866
2025-03-26 02:24:39,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742382_1558 src: /172.20.1.15:46246 dest: /172.20.1.16:9866
2025-03-26 02:24:39,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742382_1558 src: /172.20.1.16:56236 dest: /172.20.1.17:9866
2025-03-26 02:24:39,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46246, dest: /172.20.1.16:9866, bytes: 2742, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742382_1558, duration(ns): 782598
2025-03-26 02:24:39,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56236, dest: /172.20.1.17:9866, bytes: 2742, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742382_1558, duration(ns): 538938
2025-03-26 02:24:39,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742382_1558, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,488 INFO terminating
2025-03-26 02:24:39,489 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55326, dest: /172.20.1.15:9866, bytes: 2742, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742382_1558, duration(ns): 1061219
2025-03-26 02:24:39,489 INFO terminating
2025-03-26 02:24:39,494 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742383_1559, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java._COPYING_
2025-03-26 02:24:39,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742383_1559 src: /172.20.1.14:42180 dest: /172.20.1.16:9866
2025-03-26 02:24:39,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742383_1559 src: /172.20.1.16:56246 dest: /172.20.1.17:9866
2025-03-26 02:24:39,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742383_1559 src: /172.20.1.17:40814 dest: /172.20.1.15:9866
2025-03-26 02:24:39,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40814, dest: /172.20.1.15:9866, bytes: 6228, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742383_1559, duration(ns): 629501
2025-03-26 02:24:39,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42180, dest: /172.20.1.16:9866, bytes: 6228, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742383_1559, duration(ns): 1090752
2025-03-26 02:24:39,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56246, dest: /172.20.1.17:9866, bytes: 6228, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742383_1559, duration(ns): 781436
2025-03-26 02:24:39,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742383_1559, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,498 INFO terminating
2025-03-26 02:24:39,498 INFO terminating
2025-03-26 02:24:39,499 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,502 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742384_1560, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_
2025-03-26 02:24:39,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742384_1560 src: /172.20.1.14:42186 dest: /172.20.1.16:9866
2025-03-26 02:24:39,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742384_1560 src: /172.20.1.15:48318 dest: /172.20.1.17:9866
2025-03-26 02:24:39,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742384_1560 src: /172.20.1.16:45660 dest: /172.20.1.15:9866
2025-03-26 02:24:39,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48318, dest: /172.20.1.17:9866, bytes: 1121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742384_1560, duration(ns): 569698
2025-03-26 02:24:39,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742384_1560, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42186, dest: /172.20.1.16:9866, bytes: 1121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742384_1560, duration(ns): 1061146
2025-03-26 02:24:39,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45660, dest: /172.20.1.15:9866, bytes: 1121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742384_1560, duration(ns): 840067
2025-03-26 02:24:39,506 INFO terminating
2025-03-26 02:24:39,506 INFO terminating
2025-03-26 02:24:39,507 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742385_1561, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java._COPYING_
2025-03-26 02:24:39,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742385_1561 src: /172.20.1.14:42190 dest: /172.20.1.16:9866
2025-03-26 02:24:39,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742385_1561 src: /172.20.1.16:45674 dest: /172.20.1.15:9866
2025-03-26 02:24:39,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742385_1561 src: /172.20.1.15:48330 dest: /172.20.1.17:9866
2025-03-26 02:24:39,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48330, dest: /172.20.1.17:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742385_1561, duration(ns): 610165
2025-03-26 02:24:39,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45674, dest: /172.20.1.15:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742385_1561, duration(ns): 836027
2025-03-26 02:24:39,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742385_1561, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,514 INFO terminating
2025-03-26 02:24:39,515 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42190, dest: /172.20.1.16:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742385_1561, duration(ns): 1132185
2025-03-26 02:24:39,515 INFO terminating
2025-03-26 02:24:39,519 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742386_1562, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java._COPYING_
2025-03-26 02:24:39,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742386_1562 src: /172.20.1.14:42196 dest: /172.20.1.16:9866
2025-03-26 02:24:39,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742386_1562 src: /172.20.1.16:56258 dest: /172.20.1.17:9866
2025-03-26 02:24:39,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742386_1562 src: /172.20.1.17:40816 dest: /172.20.1.15:9866
2025-03-26 02:24:39,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40816, dest: /172.20.1.15:9866, bytes: 4153, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742386_1562, duration(ns): 681433
2025-03-26 02:24:39,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742386_1562, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42196, dest: /172.20.1.16:9866, bytes: 4153, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742386_1562, duration(ns): 1154798
2025-03-26 02:24:39,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56258, dest: /172.20.1.17:9866, bytes: 4153, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742386_1562, duration(ns): 837513
2025-03-26 02:24:39,523 INFO terminating
2025-03-26 02:24:39,524 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,524 INFO terminating
2025-03-26 02:24:39,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,528 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742387_1563, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java._COPYING_
2025-03-26 02:24:39,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742387_1563 src: /172.20.1.14:55342 dest: /172.20.1.15:9866
2025-03-26 02:24:39,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742387_1563 src: /172.20.1.15:46248 dest: /172.20.1.16:9866
2025-03-26 02:24:39,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742387_1563 src: /172.20.1.16:56260 dest: /172.20.1.17:9866
2025-03-26 02:24:39,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46248, dest: /172.20.1.16:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742387_1563, duration(ns): 898517
2025-03-26 02:24:39,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56260, dest: /172.20.1.17:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742387_1563, duration(ns): 638783
2025-03-26 02:24:39,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742387_1563, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,532 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55342, dest: /172.20.1.15:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742387_1563, duration(ns): 1184418
2025-03-26 02:24:39,532 INFO terminating
2025-03-26 02:24:39,532 INFO terminating
2025-03-26 02:24:39,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742388_1564, replicas=172.20.1.17:9866, 172.20.1.15:9866, 172.20.1.16:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java._COPYING_
2025-03-26 02:24:39,535 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,535 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742388_1564 src: /172.20.1.14:43656 dest: /172.20.1.17:9866
2025-03-26 02:24:39,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742388_1564 src: /172.20.1.17:40832 dest: /172.20.1.15:9866
2025-03-26 02:24:39,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742388_1564 src: /172.20.1.15:46250 dest: /172.20.1.16:9866
2025-03-26 02:24:39,539 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:43656, dest: /172.20.1.17:9866, bytes: 5118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742388_1564, duration(ns): 944413
2025-03-26 02:24:39,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46250, dest: /172.20.1.16:9866, bytes: 5118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742388_1564, duration(ns): 565234
2025-03-26 02:24:39,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40832, dest: /172.20.1.15:9866, bytes: 5118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742388_1564, duration(ns): 812529
2025-03-26 02:24:39,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742388_1564, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,539 INFO terminating
2025-03-26 02:24:39,539 INFO terminating
2025-03-26 02:24:39,542 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742389_1565, replicas=172.20.1.16:9866, 172.20.1.15:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java._COPYING_
2025-03-26 02:24:39,542 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,542 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742389_1565 src: /172.20.1.14:42202 dest: /172.20.1.16:9866
2025-03-26 02:24:39,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742389_1565 src: /172.20.1.16:45678 dest: /172.20.1.15:9866
2025-03-26 02:24:39,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742389_1565 src: /172.20.1.15:48340 dest: /172.20.1.17:9866
2025-03-26 02:24:39,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42202, dest: /172.20.1.16:9866, bytes: 2485, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742389_1565, duration(ns): 896843
2025-03-26 02:24:39,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:48340, dest: /172.20.1.17:9866, bytes: 2485, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742389_1565, duration(ns): 479423
2025-03-26 02:24:39,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:45678, dest: /172.20.1.15:9866, bytes: 2485, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742389_1565, duration(ns): 724808
2025-03-26 02:24:39,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742389_1565, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,546 INFO terminating
2025-03-26 02:24:39,546 INFO terminating
2025-03-26 02:24:39,547 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742390_1566, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java._COPYING_
2025-03-26 02:24:39,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742390_1566 src: /172.20.1.14:55348 dest: /172.20.1.15:9866
2025-03-26 02:24:39,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742390_1566 src: /172.20.1.15:46254 dest: /172.20.1.16:9866
2025-03-26 02:24:39,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742390_1566 src: /172.20.1.16:56264 dest: /172.20.1.17:9866
2025-03-26 02:24:39,553 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55348, dest: /172.20.1.15:9866, bytes: 4343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742390_1566, duration(ns): 1002221
2025-03-26 02:24:39,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46254, dest: /172.20.1.16:9866, bytes: 4343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742390_1566, duration(ns): 748625
2025-03-26 02:24:39,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56264, dest: /172.20.1.17:9866, bytes: 4343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742390_1566, duration(ns): 500728
2025-03-26 02:24:39,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742390_1566, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,553 INFO terminating
2025-03-26 02:24:39,553 INFO terminating
2025-03-26 02:24:39,556 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742391_1567, replicas=172.20.1.16:9866, 172.20.1.17:9866, 172.20.1.15:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_
2025-03-26 02:24:39,556 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,556 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742391_1567 src: /172.20.1.14:42204 dest: /172.20.1.16:9866
2025-03-26 02:24:39,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742391_1567 src: /172.20.1.16:56270 dest: /172.20.1.17:9866
2025-03-26 02:24:39,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742391_1567 src: /172.20.1.17:40846 dest: /172.20.1.15:9866
2025-03-26 02:24:39,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.17:40846, dest: /172.20.1.15:9866, bytes: 7759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742391_1567, duration(ns): 552939
2025-03-26 02:24:39,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742391_1567, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,560 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:42204, dest: /172.20.1.16:9866, bytes: 7759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742391_1567, duration(ns): 1154316
2025-03-26 02:24:39,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56270, dest: /172.20.1.17:9866, bytes: 7759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742391_1567, duration(ns): 670895
2025-03-26 02:24:39,560 INFO terminating
2025-03-26 02:24:39,560 INFO terminating
2025-03-26 02:24:39,564 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742392_1568, replicas=172.20.1.15:9866, 172.20.1.16:9866, 172.20.1.17:9866 for /user/root/examples/src/main/scripts/getGpusResources.sh._COPYING_
2025-03-26 02:24:39,564 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,564 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:39,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742392_1568 src: /172.20.1.14:55362 dest: /172.20.1.15:9866
2025-03-26 02:24:39,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742392_1568 src: /172.20.1.15:46258 dest: /172.20.1.16:9866
2025-03-26 02:24:39,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742392_1568 src: /172.20.1.16:56276 dest: /172.20.1.17:9866
2025-03-26 02:24:39,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.15:46258, dest: /172.20.1.16:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 384fe65f-ef29-4d78-98dd-23ce87539aac, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742392_1568, duration(ns): 781825
2025-03-26 02:24:39,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.16:56276, dest: /172.20.1.17:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: ad43188f-88d6-4817-9e88-53b2d31ec3cb, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742392_1568, duration(ns): 487246
2025-03-26 02:24:39,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1984027250-172.20.1.14-1742955844230:blk_1073742392_1568, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:39,567 INFO terminating
2025-03-26 02:24:39,568 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scripts/getGpusResources.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_-204483661_1
2025-03-26 02:24:39,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.14:55362, dest: /172.20.1.15:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-204483661_1, offset: 0, srvID: 6d56b89c-125c-462b-baba-7781dfcf9a36, blockid: BP-1984027250-172.20.1.14-1742955844230:blk_1073742392_1568, duration(ns): 1060162
2025-03-26 02:24:39,568 INFO terminating
2025-03-26 02:24:40,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:40,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:40,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:40,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:42,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742196_1372 to 172.20.1.15:9866
2025-03-26 02:24:42,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742197_1373 to 172.20.1.15:9866
2025-03-26 02:24:42,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742196_1372 src: /172.20.1.17:40850 dest: /172.20.1.15:9866
2025-03-26 02:24:42,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742197_1373 src: /172.20.1.17:40862 dest: /172.20.1.15:9866
2025-03-26 02:24:42,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742196_1372 (numBytes=2906) to /172.20.1.15:9866
2025-03-26 02:24:42,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742197_1373 (numBytes=2064) to /172.20.1.15:9866
2025-03-26 02:24:42,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742197_1373 src: /172.20.1.17:40862 dest: /172.20.1.15:9866 of size 2064
2025-03-26 02:24:42,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742196_1372 src: /172.20.1.17:40850 dest: /172.20.1.15:9866 of size 2906
2025-03-26 02:24:42,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742198_1374 to 172.20.1.15:9866
2025-03-26 02:24:42,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742199_1375 to 172.20.1.15:9866
2025-03-26 02:24:42,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742198_1374 src: /172.20.1.16:45686 dest: /172.20.1.15:9866
2025-03-26 02:24:42,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742199_1375 src: /172.20.1.16:45696 dest: /172.20.1.15:9866
2025-03-26 02:24:42,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742198_1374 (numBytes=1918) to /172.20.1.15:9866
2025-03-26 02:24:42,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742199_1375 (numBytes=1695) to /172.20.1.15:9866
2025-03-26 02:24:42,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742198_1374 src: /172.20.1.16:45686 dest: /172.20.1.15:9866 of size 1918
2025-03-26 02:24:42,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742199_1375 src: /172.20.1.16:45696 dest: /172.20.1.15:9866 of size 1695
2025-03-26 02:24:43,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:43,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:43,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:43,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:45,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742202_1378 to 172.20.1.15:9866
2025-03-26 02:24:45,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742204_1380 to 172.20.1.15:9866
2025-03-26 02:24:45,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742202_1378 src: /172.20.1.17:40870 dest: /172.20.1.15:9866
2025-03-26 02:24:45,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742202_1378 (numBytes=1822) to /172.20.1.15:9866
2025-03-26 02:24:45,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742202_1378 src: /172.20.1.17:40870 dest: /172.20.1.15:9866 of size 1822
2025-03-26 02:24:45,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742204_1380 src: /172.20.1.17:40876 dest: /172.20.1.15:9866
2025-03-26 02:24:45,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742204_1380 (numBytes=3245) to /172.20.1.15:9866
2025-03-26 02:24:45,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742204_1380 src: /172.20.1.17:40876 dest: /172.20.1.15:9866 of size 3245
2025-03-26 02:24:45,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742203_1379 to 172.20.1.15:9866
2025-03-26 02:24:45,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742205_1381 to 172.20.1.15:9866
2025-03-26 02:24:45,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742203_1379 src: /172.20.1.16:45706 dest: /172.20.1.15:9866
2025-03-26 02:24:45,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742205_1381 src: /172.20.1.16:45708 dest: /172.20.1.15:9866
2025-03-26 02:24:45,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742203_1379 (numBytes=2248) to /172.20.1.15:9866
2025-03-26 02:24:45,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742203_1379 src: /172.20.1.16:45706 dest: /172.20.1.15:9866 of size 2248
2025-03-26 02:24:45,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742205_1381 (numBytes=3465) to /172.20.1.15:9866
2025-03-26 02:24:45,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742205_1381 src: /172.20.1.16:45708 dest: /172.20.1.15:9866 of size 3465
2025-03-26 02:24:46,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:46,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:46,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:46,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:48,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742208_1384 to 172.20.1.15:9866
2025-03-26 02:24:48,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742210_1386 to 172.20.1.15:9866
2025-03-26 02:24:48,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742210_1386 src: /172.20.1.17:52072 dest: /172.20.1.15:9866
2025-03-26 02:24:48,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742210_1386 (numBytes=2005) to /172.20.1.15:9866
2025-03-26 02:24:48,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742210_1386 src: /172.20.1.17:52072 dest: /172.20.1.15:9866 of size 2005
2025-03-26 02:24:48,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742208_1384 src: /172.20.1.17:52084 dest: /172.20.1.15:9866
2025-03-26 02:24:48,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742208_1384 (numBytes=2167) to /172.20.1.15:9866
2025-03-26 02:24:48,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742208_1384 src: /172.20.1.17:52084 dest: /172.20.1.15:9866 of size 2167
2025-03-26 02:24:48,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742209_1385 to 172.20.1.15:9866
2025-03-26 02:24:48,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742211_1387 to 172.20.1.15:9866
2025-03-26 02:24:48,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742209_1385 (numBytes=2408) to /172.20.1.15:9866
2025-03-26 02:24:48,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742209_1385 src: /172.20.1.16:58474 dest: /172.20.1.15:9866
2025-03-26 02:24:48,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742209_1385 src: /172.20.1.16:58474 dest: /172.20.1.15:9866 of size 2408
2025-03-26 02:24:48,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742211_1387 (numBytes=3423) to /172.20.1.15:9866
2025-03-26 02:24:48,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742211_1387 src: /172.20.1.16:58466 dest: /172.20.1.15:9866
2025-03-26 02:24:48,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742211_1387 src: /172.20.1.16:58466 dest: /172.20.1.15:9866 of size 3423
2025-03-26 02:24:49,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:49,849 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:49,849 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:49,849 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:51,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742214_1390 to 172.20.1.15:9866
2025-03-26 02:24:51,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742216_1392 to 172.20.1.15:9866
2025-03-26 02:24:51,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742214_1390 (numBytes=1730) to /172.20.1.15:9866
2025-03-26 02:24:51,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742216_1392 (numBytes=1283) to /172.20.1.15:9866
2025-03-26 02:24:51,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742216_1392 src: /172.20.1.17:52094 dest: /172.20.1.15:9866 of size 1283
2025-03-26 02:24:51,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742214_1390 src: /172.20.1.17:52106 dest: /172.20.1.15:9866
2025-03-26 02:24:51,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742216_1392 src: /172.20.1.17:52094 dest: /172.20.1.15:9866
2025-03-26 02:24:51,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742214_1390 src: /172.20.1.17:52106 dest: /172.20.1.15:9866 of size 1730
2025-03-26 02:24:51,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742215_1391 to 172.20.1.15:9866
2025-03-26 02:24:51,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742217_1393 to 172.20.1.15:9866
2025-03-26 02:24:51,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742215_1391 (numBytes=2185) to /172.20.1.15:9866
2025-03-26 02:24:51,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742217_1393 (numBytes=4111) to /172.20.1.15:9866
2025-03-26 02:24:51,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742215_1391 src: /172.20.1.16:58484 dest: /172.20.1.15:9866 of size 2185
2025-03-26 02:24:51,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742215_1391 src: /172.20.1.16:58484 dest: /172.20.1.15:9866
2025-03-26 02:24:51,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742217_1393 src: /172.20.1.16:58486 dest: /172.20.1.15:9866
2025-03-26 02:24:51,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742217_1393 src: /172.20.1.16:58486 dest: /172.20.1.15:9866 of size 4111
2025-03-26 02:24:52,849 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:52,849 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:52,849 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:52,849 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:54,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742221_1397 to 172.20.1.15:9866
2025-03-26 02:24:54,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742223_1399 to 172.20.1.15:9866
2025-03-26 02:24:54,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742223_1399 (numBytes=4648) to /172.20.1.15:9866
2025-03-26 02:24:54,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742223_1399 src: /172.20.1.17:52122 dest: /172.20.1.15:9866
2025-03-26 02:24:54,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742221_1397 (numBytes=2469) to /172.20.1.15:9866
2025-03-26 02:24:54,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742223_1399 src: /172.20.1.17:52122 dest: /172.20.1.15:9866 of size 4648
2025-03-26 02:24:54,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742221_1397 src: /172.20.1.17:52124 dest: /172.20.1.15:9866
2025-03-26 02:24:54,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742221_1397 src: /172.20.1.17:52124 dest: /172.20.1.15:9866 of size 2469
2025-03-26 02:24:54,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742220_1396 to 172.20.1.15:9866
2025-03-26 02:24:54,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742222_1398 to 172.20.1.15:9866
2025-03-26 02:24:54,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742220_1396 (numBytes=4039) to /172.20.1.15:9866
2025-03-26 02:24:54,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742222_1398 (numBytes=2159) to /172.20.1.15:9866
2025-03-26 02:24:54,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742220_1396 src: /172.20.1.16:58506 dest: /172.20.1.15:9866
2025-03-26 02:24:54,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742222_1398 src: /172.20.1.16:58514 dest: /172.20.1.15:9866
2025-03-26 02:24:54,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742220_1396 src: /172.20.1.16:58506 dest: /172.20.1.15:9866 of size 4039
2025-03-26 02:24:54,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742222_1398 src: /172.20.1.16:58514 dest: /172.20.1.15:9866 of size 2159
2025-03-26 02:24:55,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:55,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:55,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:55,851 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:57,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742228_1404 to 172.20.1.15:9866
2025-03-26 02:24:57,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742229_1405 to 172.20.1.15:9866
2025-03-26 02:24:57,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742228_1404 src: /172.20.1.17:44760 dest: /172.20.1.15:9866
2025-03-26 02:24:57,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742228_1404 (numBytes=1920) to /172.20.1.15:9866
2025-03-26 02:24:57,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742229_1405 (numBytes=5351) to /172.20.1.15:9866
2025-03-26 02:24:57,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742228_1404 src: /172.20.1.17:44760 dest: /172.20.1.15:9866 of size 1920
2025-03-26 02:24:57,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742229_1405 src: /172.20.1.17:44770 dest: /172.20.1.15:9866 of size 5351
2025-03-26 02:24:57,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742229_1405 src: /172.20.1.17:44770 dest: /172.20.1.15:9866
2025-03-26 02:24:57,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742226_1402 to 172.20.1.15:9866
2025-03-26 02:24:57,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742227_1403 to 172.20.1.15:9866
2025-03-26 02:24:57,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742226_1402 src: /172.20.1.16:40940 dest: /172.20.1.15:9866
2025-03-26 02:24:57,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742227_1403 src: /172.20.1.16:40942 dest: /172.20.1.15:9866
2025-03-26 02:24:57,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742226_1402 (numBytes=1842) to /172.20.1.15:9866
2025-03-26 02:24:57,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742227_1403 (numBytes=1669) to /172.20.1.15:9866
2025-03-26 02:24:57,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742226_1402 src: /172.20.1.16:40940 dest: /172.20.1.15:9866 of size 1842
2025-03-26 02:24:57,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742227_1403 src: /172.20.1.16:40942 dest: /172.20.1.15:9866 of size 1669
2025-03-26 02:24:58,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:58,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:58,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:58,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:00,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742232_1408 to 172.20.1.15:9866
2025-03-26 02:25:00,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742235_1411 to 172.20.1.15:9866
2025-03-26 02:25:00,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742232_1408 (numBytes=15338) to /172.20.1.15:9866
2025-03-26 02:25:00,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742235_1411 (numBytes=2552) to /172.20.1.15:9866
2025-03-26 02:25:00,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742232_1408 src: /172.20.1.17:44784 dest: /172.20.1.15:9866
2025-03-26 02:25:00,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742232_1408 src: /172.20.1.17:44784 dest: /172.20.1.15:9866 of size 15338
2025-03-26 02:25:00,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742235_1411 src: /172.20.1.17:44792 dest: /172.20.1.15:9866 of size 2552
2025-03-26 02:25:00,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742235_1411 src: /172.20.1.17:44792 dest: /172.20.1.15:9866
2025-03-26 02:25:00,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742233_1409 to 172.20.1.15:9866
2025-03-26 02:25:00,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742234_1410 to 172.20.1.15:9866
2025-03-26 02:25:00,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742233_1409 (numBytes=5661) to /172.20.1.15:9866
2025-03-26 02:25:00,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742234_1410 (numBytes=3236) to /172.20.1.15:9866
2025-03-26 02:25:00,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742234_1410 src: /172.20.1.16:40954 dest: /172.20.1.15:9866 of size 3236
2025-03-26 02:25:00,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742233_1409 src: /172.20.1.16:40956 dest: /172.20.1.15:9866
2025-03-26 02:25:00,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742234_1410 src: /172.20.1.16:40954 dest: /172.20.1.15:9866
2025-03-26 02:25:00,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742233_1409 src: /172.20.1.16:40956 dest: /172.20.1.15:9866 of size 5661
2025-03-26 02:25:01,200 DEBUG org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-26 02:25:01,223 DEBUG org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-26 02:25:01,266 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-26 02:25:01,268 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-26 02:25:01,269 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-26 02:25:01,269 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-26 02:25:01,269 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-26 02:25:01,270 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-26 02:25:01,282 DEBUG org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-26 02:25:01,291 DEBUG org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-26 02:25:01,291 DEBUG org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-26 02:25:01,291 DEBUG org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-26 02:25:01,291 DEBUG org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-26 02:25:01,291 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-26 02:25:01,292 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-26 02:25:01,292 DEBUG org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-26 02:25:01,337 DEBUG org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-26 02:25:01,339 DEBUG org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-26 02:25:01,340 DEBUG org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-26 02:25:01,341 DEBUG org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-26 02:25:01,342 DEBUG org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-26 02:25:01,342 DEBUG org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-26 02:25:01,342 DEBUG org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-26 02:25:01,343 DEBUG org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.000s
2025-03-26 02:25:01,343 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:25:01,344 DEBUG org.apache.hadoop.fs.FileSystem: Loading filesystems
2025-03-26 02:25:01,344 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Creating FS file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:25:01,350 DEBUG org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.fs.LocalFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:25:01,353 DEBUG org.apache.hadoop.fs.FileSystem: viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:25:01,354 DEBUG org.apache.hadoop.fs.FileSystem: har:// = class org.apache.hadoop.fs.HarFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:25:01,355 DEBUG org.apache.hadoop.fs.FileSystem: http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:25:01,355 DEBUG org.apache.hadoop.fs.FileSystem: https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:25:01,359 DEBUG org.apache.hadoop.fs.FileSystem: hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:25:01,363 DEBUG org.apache.hadoop.fs.FileSystem: swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:25:01,363 DEBUG org.apache.hadoop.fs.FileSystem: webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:25:01,364 DEBUG org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem from /spark/jars/hive-exec-2.3.9-core.jar
2025-03-26 02:25:01,364 DEBUG org.apache.hadoop.fs.FileSystem: nullscan:// = class org.apache.hadoop.hive.ql.io.NullScanFileSystem from /spark/jars/hive-exec-2.3.9-core.jar
2025-03-26 02:25:01,365 DEBUG org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 02:25:01,365 DEBUG org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 02:25:01,380 DEBUG org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 02:25:01,380 DEBUG org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 02:25:01,382 DEBUG org.apache.hadoop.fs.FileSystem: Creating FS file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.038s
2025-03-26 02:25:01,383 DEBUG org.apache.hadoop.fs.Globber: Created Globber for path=file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar, symlinks=true
2025-03-26 02:25:01,383 DEBUG org.apache.hadoop.fs.Globber: Filesystem glob /spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:25:01,383 DEBUG org.apache.hadoop.fs.Globber: Pattern: /spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:25:01,383 DEBUG org.apache.hadoop.fs.Globber: Starting: glob file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:25:01,402 DEBUG org.apache.hadoop.fs.Globber: Component spark, patterned=false
2025-03-26 02:25:01,404 DEBUG org.apache.hadoop.fs.Globber: Component examples, patterned=false
2025-03-26 02:25:01,404 DEBUG org.apache.hadoop.fs.Globber: Component jars, patterned=false
2025-03-26 02:25:01,406 DEBUG org.apache.hadoop.fs.Globber: Component spark-examples_2.12-3.3.2.jar, patterned=false
2025-03-26 02:25:01,407 DEBUG org.apache.hadoop.fs.Globber: glob file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.024s
2025-03-26 02:25:01,475 DEBUG org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.YarnClientImpl entered state INITED
2025-03-26 02:25:01,500 DEBUG org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.RMProxy$1@184497d1] java.lang.Exception at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852) at org.apache.hadoop.yarn.client.RMProxy.getProxy(RMProxy.java:145) at org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider.init(DefaultNoHARMFailoverProxyProvider.java:65) at org.apache.hadoop.yarn.client.RMProxy.createNonHaRMFailoverProxyProvider(RMProxy.java:172) at org.apache.hadoop.yarn.client.RMProxy.newProxyInstance(RMProxy.java:132) at org.apache.hadoop.yarn.client.RMProxy.createRMProxy(RMProxy.java:103) at org.apache.hadoop.yarn.client.ClientRMProxy.createRMProxy(ClientRMProxy.java:73) at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceStart(YarnClientImpl.java:242) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194) at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:192) at org.apache.spark.deploy.yarn.Client.run(Client.scala:1327) at org.apache.spark.deploy.yarn.YarnClusterApplication.start(Client.scala:1764) at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958) at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180) at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203) at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90) at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046) at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055) at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2025-03-26 02:25:01,500 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.14:8032
2025-03-26 02:25:01,501 DEBUG org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 02:25:01,502 DEBUG org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ApplicationClientProtocol
2025-03-26 02:25:01,514 DEBUG org.apache.hadoop.ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker@3bde62ff
2025-03-26 02:25:01,517 DEBUG org.apache.hadoop.ipc.Client: getting client out of cache: Client-e258df92d26a4279982e6b91d7800c2d
2025-03-26 02:25:01,576 DEBUG org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.YarnClientImpl is started
2025-03-26 02:25:01,616 DEBUG org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 02:25:01,617 DEBUG org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.14:8032
2025-03-26 02:25:01,617 DEBUG org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.14:8032
2025-03-26 02:25:01,631 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:8032 from root sending #0 org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getClusterMetrics
2025-03-26 02:25:01,631 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:8032 from root: starting, having connections 1
2025-03-26 02:25:01,647 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:8032 from root got value #0
2025-03-26 02:25:01,647 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getClusterMetrics took 54ms
2025-03-26 02:25:01,649 DEBUG org.apache.spark.deploy.yarn.Client: Requesting a new application from cluster with 3 NodeManagers
2025-03-26 02:25:01,661 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:8032 from root sending #1 org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getNewApplication
2025-03-26 02:25:01,666 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2025-03-26 02:25:01,669 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:8032 from root got value #1
2025-03-26 02:25:01,669 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getNewApplication took 9ms
2025-03-26 02:25:01,672 DEBUG org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for hdfs://master:9000: duration 0:00.000s
2025-03-26 02:25:01,672 DEBUG org.apache.hadoop.fs.FileSystem: FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2025-03-26 02:25:01,672 DEBUG org.apache.hadoop.fs.FileSystem: Looking for FS supporting hdfs
2025-03-26 02:25:01,672 DEBUG org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 02:25:01,672 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for hdfs://master:9000
2025-03-26 02:25:01,672 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Creating FS hdfs://master:9000
2025-03-26 02:25:01,672 DEBUG org.apache.hadoop.fs.FileSystem: looking for configuration option fs.hdfs.impl
2025-03-26 02:25:01,681 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.domain.socket.data.traffic = false
2025-03-26 02:25:01,681 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.read.shortcircuit = false
2025-03-26 02:25:01,681 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.use.legacy.blockreader.local = false
2025-03-26 02:25:01,681 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.domain.socket.path =
2025-03-26 02:25:01,683 DEBUG org.apache.hadoop.hdfs.DFSClient: Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2025-03-26 02:25:01,685 DEBUG org.apache.hadoop.io.retry.RetryUtils: multipleLinearRandomRetry = null
2025-03-26 02:25:01,687 DEBUG org.apache.hadoop.ipc.Client: getting client out of cache: Client-e258df92d26a4279982e6b91d7800c2d
2025-03-26 02:25:01,841 DEBUG org.apache.hadoop.util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
2025-03-26 02:25:01,844 DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2025-03-26 02:25:01,845 DEBUG org.apache.hadoop.fs.FileSystem: Creating FS hdfs://master:9000: duration 0:00.173s
2025-03-26 02:25:01,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:01,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:01,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:01,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:01,881 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:25:01,882 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:25:01,884 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
2025-03-26 02:25:01,884 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE
2025-03-26 02:25:01,884 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-mb'
2025-03-26 02:25:01,884 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-mb'
2025-03-26 02:25:01,884 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-vcores'
2025-03-26 02:25:01,884 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-vcores'
2025-03-26 02:25:01,888 INFO org.apache.spark.deploy.yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
2025-03-26 02:25:01,890 DEBUG org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.14:9000
2025-03-26 02:25:01,890 DEBUG org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.14:9000
2025-03-26 02:25:01,890 DEBUG org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 02:25:01,891 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:9000 from root sending #2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete
2025-03-26 02:25:01,891 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:9000 from root: starting, having connections 2
2025-03-26 02:25:01,895 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.14:9000 from root got value #2
2025-03-26 02:25:01,895 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: delete took 5ms
2025-03-26 02:25:01,897 INFO org.apache.spark.util.ShutdownHookManager: Deleting directory /tmp/spark-7ffd1607-dc36-47bb-b304-0babbde0b68d
2025-03-26 02:25:01,897 INFO org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-26 02:25:01,898 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:1518)); Key: (root (auth:SIMPLE))@hdfs://master:9000; URI: hdfs://master:9000; Object Identity Hash: 4c19b7f1
2025-03-26 02:25:01,899 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (root (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 202608f3
2025-03-26 02:25:01,899 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 384077b6
2025-03-26 02:25:01,899 DEBUG org.apache.hadoop.ipc.Client: stopping client from cache: Client-e258df92d26a4279982e6b91d7800c2d
2025-03-26 02:25:01,899 DEBUG org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.003 seconds; Timeouts: 0
2025-03-26 02:25:01,907 DEBUG org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
2025-03-26 02:25:03,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742239_1415 to 172.20.1.15:9866
2025-03-26 02:25:03,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742241_1417 to 172.20.1.15:9866
2025-03-26 02:25:03,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742239_1415 src: /172.20.1.17:44804 dest: /172.20.1.15:9866
2025-03-26 02:25:03,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742239_1415 (numBytes=5410) to /172.20.1.15:9866
2025-03-26 02:25:03,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742241_1417 (numBytes=11092) to /172.20.1.15:9866
2025-03-26 02:25:03,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742239_1415 src: /172.20.1.17:44804 dest: /172.20.1.15:9866 of size 5410
2025-03-26 02:25:03,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742241_1417 src: /172.20.1.17:44806 dest: /172.20.1.15:9866
2025-03-26 02:25:03,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742241_1417 src: /172.20.1.17:44806 dest: /172.20.1.15:9866 of size 11092
2025-03-26 02:25:03,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742238_1414 to 172.20.1.15:9866
2025-03-26 02:25:03,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742240_1416 to 172.20.1.15:9866
2025-03-26 02:25:03,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742238_1414 (numBytes=4044) to /172.20.1.15:9866
2025-03-26 02:25:03,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742240_1416 (numBytes=3440) to /172.20.1.15:9866
2025-03-26 02:25:03,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742240_1416 src: /172.20.1.16:40974 dest: /172.20.1.15:9866
2025-03-26 02:25:03,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742240_1416 src: /172.20.1.16:40974 dest: /172.20.1.15:9866 of size 3440
2025-03-26 02:25:03,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742238_1414 src: /172.20.1.16:40972 dest: /172.20.1.15:9866
2025-03-26 02:25:03,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742238_1414 src: /172.20.1.16:40972 dest: /172.20.1.15:9866 of size 4044
2025-03-26 02:25:04,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:04,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:04,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:04,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:06,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742244_1420 to 172.20.1.15:9866
2025-03-26 02:25:06,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742247_1423 to 172.20.1.15:9866
2025-03-26 02:25:06,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742244_1420 (numBytes=2178) to /172.20.1.15:9866
2025-03-26 02:25:06,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742244_1420 src: /172.20.1.17:44816 dest: /172.20.1.15:9866
2025-03-26 02:25:06,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742247_1423 (numBytes=2670) to /172.20.1.15:9866
2025-03-26 02:25:06,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742244_1420 src: /172.20.1.17:44816 dest: /172.20.1.15:9866 of size 2178
2025-03-26 02:25:06,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742247_1423 src: /172.20.1.17:44820 dest: /172.20.1.15:9866
2025-03-26 02:25:06,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742247_1423 src: /172.20.1.17:44820 dest: /172.20.1.15:9866 of size 2670
2025-03-26 02:25:06,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742245_1421 to 172.20.1.15:9866
2025-03-26 02:25:06,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742246_1422 to 172.20.1.15:9866
2025-03-26 02:25:06,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742245_1421 src: /172.20.1.16:40990 dest: /172.20.1.15:9866
2025-03-26 02:25:06,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742246_1422 src: /172.20.1.16:41000 dest: /172.20.1.15:9866
2025-03-26 02:25:06,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742245_1421 (numBytes=1575) to /172.20.1.15:9866
2025-03-26 02:25:06,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742245_1421 src: /172.20.1.16:40990 dest: /172.20.1.15:9866 of size 1575
2025-03-26 02:25:06,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742246_1422 (numBytes=3268) to /172.20.1.15:9866
2025-03-26 02:25:06,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742246_1422 src: /172.20.1.16:41000 dest: /172.20.1.15:9866 of size 3268
2025-03-26 02:25:07,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:07,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:07,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:07,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:09,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742251_1427 to 172.20.1.15:9866
2025-03-26 02:25:09,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742253_1429 to 172.20.1.15:9866
2025-03-26 02:25:09,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742251_1427 src: /172.20.1.17:50222 dest: /172.20.1.15:9866
2025-03-26 02:25:09,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742251_1427 (numBytes=3737) to /172.20.1.15:9866
2025-03-26 02:25:09,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742253_1429 (numBytes=3780) to /172.20.1.15:9866
2025-03-26 02:25:09,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742251_1427 src: /172.20.1.17:50222 dest: /172.20.1.15:9866 of size 3737
2025-03-26 02:25:09,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742253_1429 src: /172.20.1.17:50226 dest: /172.20.1.15:9866 of size 3780
2025-03-26 02:25:09,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742253_1429 src: /172.20.1.17:50226 dest: /172.20.1.15:9866
2025-03-26 02:25:09,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742250_1426 to 172.20.1.15:9866
2025-03-26 02:25:09,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742252_1428 to 172.20.1.15:9866
2025-03-26 02:25:09,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742250_1426 src: /172.20.1.16:40248 dest: /172.20.1.15:9866
2025-03-26 02:25:09,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742250_1426 (numBytes=5326) to /172.20.1.15:9866
2025-03-26 02:25:09,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742250_1426 src: /172.20.1.16:40248 dest: /172.20.1.15:9866 of size 5326
2025-03-26 02:25:09,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742252_1428 (numBytes=4800) to /172.20.1.15:9866
2025-03-26 02:25:09,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742252_1428 src: /172.20.1.16:40262 dest: /172.20.1.15:9866
2025-03-26 02:25:09,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742252_1428 src: /172.20.1.16:40262 dest: /172.20.1.15:9866 of size 4800
2025-03-26 02:25:10,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:10,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:10,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:10,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:12,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742256_1432 to 172.20.1.15:9866
2025-03-26 02:25:12,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742257_1433 to 172.20.1.15:9866
2025-03-26 02:25:12,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742256_1432 src: /172.20.1.17:50236 dest: /172.20.1.15:9866
2025-03-26 02:25:12,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742256_1432 src: /172.20.1.17:50236 dest: /172.20.1.15:9866 of size 3786
2025-03-26 02:25:12,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742256_1432 (numBytes=3786) to /172.20.1.15:9866
2025-03-26 02:25:12,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742257_1433 (numBytes=4303) to /172.20.1.15:9866
2025-03-26 02:25:12,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742257_1433 src: /172.20.1.17:50240 dest: /172.20.1.15:9866 of size 4303
2025-03-26 02:25:12,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742257_1433 src: /172.20.1.17:50240 dest: /172.20.1.15:9866
2025-03-26 02:25:12,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742258_1434 to 172.20.1.15:9866
2025-03-26 02:25:12,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742259_1435 to 172.20.1.15:9866
2025-03-26 02:25:12,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742258_1434 src: /172.20.1.16:40278 dest: /172.20.1.15:9866
2025-03-26 02:25:12,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742258_1434 (numBytes=4032) to /172.20.1.15:9866
2025-03-26 02:25:12,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742258_1434 src: /172.20.1.16:40278 dest: /172.20.1.15:9866 of size 4032
2025-03-26 02:25:12,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742259_1435 src: /172.20.1.16:40286 dest: /172.20.1.15:9866
2025-03-26 02:25:12,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742259_1435 (numBytes=3436) to /172.20.1.15:9866
2025-03-26 02:25:12,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742259_1435 src: /172.20.1.16:40286 dest: /172.20.1.15:9866 of size 3436
2025-03-26 02:25:12,768 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 3467
2025-03-26 02:25:12,768 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3468 Total time for transactions(ms): 65 Number of transactions batched in Syncs: 773 Number of syncs: 2695 SyncTimes(ms): 1028
2025-03-26 02:25:12,768 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2025-03-26 02:25:12,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.20.1.14
2025-03-26 02:25:12,769 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3468 Total time for transactions(ms): 65 Number of transactions batched in Syncs: 773 Number of syncs: 2696 SyncTimes(ms): 1028
2025-03-26 02:25:12,769 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000003468
2025-03-26 02:25:12,787 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3469
2025-03-26 02:25:12,822 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2025-03-26 02:25:12,824 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master:9870/imagetransfer?getimage=1&txid=0&storageInfo=-66:1756216927:1742955844230:CID-fc4bf978-470d-4144-a2a8-dca27d119a9d&bootstrapstandby=false
2025-03-26 02:25:12,871 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/name/current/fsimage_0000000000000000000, fileSize: 399. Sent total: 399 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:25:12,876 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.01s. The file download took 0.01s at 0.00 KB/s. Synchronous (fsync) write to disk of /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000000000 took 0.00s.
2025-03-26 02:25:12,876 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 399 bytes.
2025-03-26 02:25:12,882 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master:9870/imagetransfer?getedit=1&startTxId=1&endTxId=3468&storageInfo=-66:1756216927:1742955844230:CID-fc4bf978-470d-4144-a2a8-dca27d119a9d
2025-03-26 02:25:12,885 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000003468, fileSize: 479326. Sent total: 479326 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:25:12,888 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 468000.00 KB/s. Synchronous (fsync) write to disk of /data/tmp/dfs/namesecondary/current/edits_tmp_0000000000000000001-0000000000000003468_0000000000007246824 took 0.00s.
2025-03-26 02:25:12,888 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000003468_0000000000007246824 size 0 bytes.
2025-03-26 02:25:12,934 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2025-03-26 02:25:12,938 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
2025-03-26 02:25:12,943 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-26 02:25:12,947 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/tmp/dfs/namesecondary/current/fsimage_0000000000000000000
2025-03-26 02:25:12,947 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2025-03-26 02:25:12,947 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2025-03-26 02:25:12,951 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2025-03-26 02:25:12,955 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468 expecting start txid #1
2025-03-26 02:25:12,955 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468 maxTxnsToRead = 9223372036854775807
2025-03-26 02:25:13,179 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded 1 edits file(s) (the last named /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468) of total size 479326.0, total edits 3468.0, total load time 210.0 ms
2025-03-26 02:25:13,203 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003468 using no compression
2025-03-26 02:25:13,270 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003468 of size 54040 bytes saved in 0 seconds .
2025-03-26 02:25:13,272 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/namesecondary
2025-03-26 02:25:13,276 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/namesecondary
2025-03-26 02:25:13,298 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2025-03-26 02:25:13,299 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/namesecondary/current/fsimage_0000000000000003468, fileSize: 54040. Sent total: 54040 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:25:13,302 INFO org.apache.hadoop.hdfs.server.namenode.ImageServlet: Rejecting a fsimage due to small time delta and txnid delta. Time since previous checkpoint is 68 expecting at least 2700 txnid delta since previous checkpoint is 3468 expecting at least 1000000
2025-03-26 02:25:13,305 WARN [SecondaryNameNode Status Name Node Address      : master/172.20.1.14:9000 Start Time             : Wed Mar 26 02:24:11 GMT 2025 Last Checkpoint        : -- (7186 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 54040
2025-03-26 02:25:13,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:13,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:13,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:13,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:15,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742263_1439 to 172.20.1.15:9866
2025-03-26 02:25:15,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742265_1441 to 172.20.1.15:9866
2025-03-26 02:25:15,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742263_1439 src: /172.20.1.17:50254 dest: /172.20.1.15:9866
2025-03-26 02:25:15,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742265_1441 src: /172.20.1.17:50256 dest: /172.20.1.15:9866
2025-03-26 02:25:15,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742265_1441 (numBytes=3580) to /172.20.1.15:9866
2025-03-26 02:25:15,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742265_1441 src: /172.20.1.17:50256 dest: /172.20.1.15:9866 of size 3580
2025-03-26 02:25:15,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742263_1439 (numBytes=3387) to /172.20.1.15:9866
2025-03-26 02:25:15,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742263_1439 src: /172.20.1.17:50254 dest: /172.20.1.15:9866 of size 3387
2025-03-26 02:25:15,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742262_1438 to 172.20.1.15:9866
2025-03-26 02:25:15,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742264_1440 to 172.20.1.15:9866
2025-03-26 02:25:15,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742262_1438 src: /172.20.1.16:40312 dest: /172.20.1.15:9866
2025-03-26 02:25:15,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742264_1440 src: /172.20.1.16:40296 dest: /172.20.1.15:9866
2025-03-26 02:25:15,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742264_1440 (numBytes=3631) to /172.20.1.15:9866
2025-03-26 02:25:15,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742262_1438 (numBytes=2173) to /172.20.1.15:9866
2025-03-26 02:25:15,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742262_1438 src: /172.20.1.16:40312 dest: /172.20.1.15:9866 of size 2173
2025-03-26 02:25:15,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742264_1440 src: /172.20.1.16:40296 dest: /172.20.1.15:9866 of size 3631
2025-03-26 02:25:16,858 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:16,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:16,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:16,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:18,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742270_1446 to 172.20.1.15:9866
2025-03-26 02:25:18,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742271_1447 to 172.20.1.15:9866
2025-03-26 02:25:18,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742270_1446 src: /172.20.1.17:40376 dest: /172.20.1.15:9866
2025-03-26 02:25:18,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742270_1446 (numBytes=3240) to /172.20.1.15:9866
2025-03-26 02:25:18,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742271_1447 (numBytes=3102) to /172.20.1.15:9866
2025-03-26 02:25:18,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742271_1447 src: /172.20.1.17:40380 dest: /172.20.1.15:9866
2025-03-26 02:25:18,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742271_1447 src: /172.20.1.17:40380 dest: /172.20.1.15:9866 of size 3102
2025-03-26 02:25:18,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742270_1446 src: /172.20.1.17:40376 dest: /172.20.1.15:9866 of size 3240
2025-03-26 02:25:18,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742268_1444 to 172.20.1.15:9866
2025-03-26 02:25:18,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742269_1445 to 172.20.1.15:9866
2025-03-26 02:25:18,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742268_1444 src: /172.20.1.16:51688 dest: /172.20.1.15:9866
2025-03-26 02:25:18,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742269_1445 (numBytes=2602) to /172.20.1.15:9866
2025-03-26 02:25:18,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742269_1445 src: /172.20.1.16:51690 dest: /172.20.1.15:9866
2025-03-26 02:25:18,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742268_1444 (numBytes=2778) to /172.20.1.15:9866
2025-03-26 02:25:18,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742268_1444 src: /172.20.1.16:51688 dest: /172.20.1.15:9866 of size 2778
2025-03-26 02:25:18,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742269_1445 src: /172.20.1.16:51690 dest: /172.20.1.15:9866 of size 2602
2025-03-26 02:25:19,860 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:19,860 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:19,860 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:19,860 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:21,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742274_1450 to 172.20.1.15:9866
2025-03-26 02:25:21,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.17:9866, datanodeUuid=ad43188f-88d6-4817-9e88-53b2d31ec3cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742276_1452 to 172.20.1.15:9866
2025-03-26 02:25:21,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742274_1450 src: /172.20.1.17:40388 dest: /172.20.1.15:9866
2025-03-26 02:25:21,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742276_1452 src: /172.20.1.17:40394 dest: /172.20.1.15:9866
2025-03-26 02:25:21,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742274_1450 (numBytes=2415) to /172.20.1.15:9866
2025-03-26 02:25:21,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742276_1452 (numBytes=3157) to /172.20.1.15:9866
2025-03-26 02:25:21,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742274_1450 src: /172.20.1.17:40388 dest: /172.20.1.15:9866 of size 2415
2025-03-26 02:25:21,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742276_1452 src: /172.20.1.17:40394 dest: /172.20.1.15:9866 of size 3157
2025-03-26 02:25:21,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742275_1451 to 172.20.1.15:9866
2025-03-26 02:25:21,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.16:9866, datanodeUuid=384fe65f-ef29-4d78-98dd-23ce87539aac, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-fc4bf978-470d-4144-a2a8-dca27d119a9d;nsid=1756216927;c=1742955844230) Starting thread to transfer BP-1984027250-172.20.1.14-1742955844230:blk_1073742277_1453 to 172.20.1.15:9866
2025-03-26 02:25:21,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742275_1451 src: /172.20.1.16:51700 dest: /172.20.1.15:9866
2025-03-26 02:25:21,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742275_1451 (numBytes=1913) to /172.20.1.15:9866
2025-03-26 02:25:21,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1984027250-172.20.1.14-1742955844230:blk_1073742277_1453 (numBytes=2977) to /172.20.1.15:9866
2025-03-26 02:25:21,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1984027250-172.20.1.14-1742955844230:blk_1073742277_1453 src: /172.20.1.16:51706 dest: /172.20.1.15:9866
2025-03-26 02:25:21,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742275_1451 src: /172.20.1.16:51700 dest: /172.20.1.15:9866 of size 1913
2025-03-26 02:25:21,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1984027250-172.20.1.14-1742955844230:blk_1073742277_1453 src: /172.20.1.16:51706 dest: /172.20.1.15:9866 of size 2977
