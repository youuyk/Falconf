program=ml.DeveloperApiExample
SPARKLORD_MODE=CONFIG_INJECTION
cpu_cores=2
cpu_util=200
memory=4g
config_file_name=spark-defaults.conf
config_key=spark.scheduler.listenerbus.eventqueue.executorManagement.capacity
config_value=1

2025-03-26 04:41:05,468 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for TERM
2025-03-26 04:41:05,472 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for HUP
2025-03-26 04:41:05,472 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for INT
2025-03-26 04:41:05,688 DEBUG [main] org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-26 04:41:05,860 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:41:05,860 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:41:05,862 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:41:05,863 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:41:05,863 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:41:05,930 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-26 04:41:05,935 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-26 04:41:05,936 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-26 04:41:05,936 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-26 04:41:05,936 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-26 04:41:05,937 DEBUG [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-26 04:41:05,951 DEBUG [main] org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-26 04:41:05,956 DEBUG [main] org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-26 04:41:05,957 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-26 04:41:05,957 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-26 04:41:05,957 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-26 04:41:05,957 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-26 04:41:05,957 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-26 04:41:05,958 DEBUG [main] org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-26 04:41:05,993 DEBUG [main] org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-26 04:41:06,066 DEBUG [main] org.apache.spark.deploy.SparkHadoopUtil: creating UGI for user: root
2025-03-26 04:41:06,069 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-26 04:41:06,069 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-26 04:41:06,070 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-26 04:41:06,071 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-26 04:41:06,071 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-26 04:41:06,072 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Reading credentials from location /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000001/container_tokens
2025-03-26 04:41:06,074 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Loaded 1 tokens from /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000001/container_tokens
2025-03-26 04:41:06,074 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-26 04:41:06,075 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3@1522d8a0]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:41:06,080 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1742964012349_0001_000001
2025-03-26 04:41:06,082 DEBUG [main] org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-26 04:41:06,103 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Starting the user application in a separate Thread
2025-03-26 04:41:06,104 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Waiting for spark context initialization...
2025-03-26 04:41:06,151 INFO [Driver] org.apache.spark.SparkContext: Running Spark version 3.3.2
2025-03-26 04:41:06,169 INFO [Driver] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:41:06,170 INFO [Driver] org.apache.spark.resource.ResourceUtils: No custom resources configured for spark.driver.
2025-03-26 04:41:06,170 INFO [Driver] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:41:06,170 INFO [Driver] org.apache.spark.SparkContext: Submitted application: DeveloperApiExample
2025-03-26 04:41:06,183 INFO [Driver] org.apache.spark.resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-26 04:41:06,186 INFO [Driver] org.apache.spark.resource.ResourceProfile: Limiting resource is cpus at 2 tasks per executor
2025-03-26 04:41:06,187 INFO [Driver] org.apache.spark.resource.ResourceProfileManager: Added ResourceProfile id: 0
2025-03-26 04:41:06,217 INFO [Driver] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:41:06,217 INFO [Driver] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:41:06,217 INFO [Driver] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:41:06,217 INFO [Driver] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:41:06,217 INFO [Driver] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:41:06,256 DEBUG [Driver] io.netty.util.internal.logging.InternalLoggerFactory: Using SLF4J as the default logging framework
2025-03-26 04:41:06,259 DEBUG [Driver] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2025-03-26 04:41:06,259 DEBUG [Driver] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2025-03-26 04:41:06,266 DEBUG [Driver] io.netty.channel.MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 4
2025-03-26 04:41:06,286 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: -Dio.netty.noUnsafe: false
2025-03-26 04:41:06,286 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: Java version: 8
2025-03-26 04:41:06,286 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
2025-03-26 04:41:06,286 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
2025-03-26 04:41:06,287 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.Buffer.address: available
2025-03-26 04:41:06,287 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: direct buffer constructor: available
2025-03-26 04:41:06,287 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.Bits.unaligned: available, true
2025-03-26 04:41:06,287 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2025-03-26 04:41:06,287 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
2025-03-26 04:41:06,287 DEBUG [Driver] io.netty.util.internal.PlatformDependent: sun.misc.Unsafe: available
2025-03-26 04:41:06,287 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.tmpdir: /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000001/tmp (java.io.tmpdir)
2025-03-26 04:41:06,287 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
2025-03-26 04:41:06,288 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.maxDirectMemory: 3817865216 bytes
2025-03-26 04:41:06,288 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.uninitializedArrayAllocationThreshold: -1
2025-03-26 04:41:06,288 DEBUG [Driver] io.netty.util.internal.CleanerJava6: java.nio.ByteBuffer.cleaner(): available
2025-03-26 04:41:06,288 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.noPreferDirect: false
2025-03-26 04:41:06,289 DEBUG [Driver] io.netty.channel.nio.NioEventLoop: -Dio.netty.noKeySetOptimization: false
2025-03-26 04:41:06,289 DEBUG [Driver] io.netty.channel.nio.NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
2025-03-26 04:41:06,291 DEBUG [Driver] io.netty.util.internal.PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
2025-03-26 04:41:06,298 DEBUG [Driver] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
2025-03-26 04:41:06,299 DEBUG [Driver] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.targetRecords: 4
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 4
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 4
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.useCacheForAllThreads: true
2025-03-26 04:41:06,300 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2025-03-26 04:41:06,314 DEBUG [Driver] io.netty.channel.DefaultChannelId: -Dio.netty.processId: 1505 (auto-detected)
2025-03-26 04:41:06,315 DEBUG [Driver] io.netty.util.NetUtil: -Djava.net.preferIPv4Stack: false
2025-03-26 04:41:06,315 DEBUG [Driver] io.netty.util.NetUtil: -Djava.net.preferIPv6Addresses: false
2025-03-26 04:41:06,316 DEBUG [Driver] io.netty.util.NetUtilInitializations: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2025-03-26 04:41:06,316 DEBUG [Driver] io.netty.util.NetUtil: /proc/sys/net/core/somaxconn: 4096
2025-03-26 04:41:06,316 DEBUG [Driver] io.netty.channel.DefaultChannelId: -Dio.netty.machineId: 02:42:ac:ff:fe:14:01:0f (auto-detected)
2025-03-26 04:41:06,325 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.allocator.type: pooled
2025-03-26 04:41:06,325 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 0
2025-03-26 04:41:06,325 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
2025-03-26 04:41:06,332 DEBUG [Driver] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 38775
2025-03-26 04:41:06,338 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'sparkDriver' on port 38775.
2025-03-26 04:41:06,339 DEBUG [Driver] org.apache.spark.SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
2025-03-26 04:41:06,356 INFO [Driver] org.apache.spark.SparkEnv: Registering MapOutputTracker
2025-03-26 04:41:06,356 DEBUG [Driver] org.apache.spark.MapOutputTrackerMasterEndpoint: init
2025-03-26 04:41:06,380 INFO [Driver] org.apache.spark.SparkEnv: Registering BlockManagerMaster
2025-03-26 04:41:06,395 INFO [Driver] org.apache.spark.storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-26 04:41:06,395 INFO [Driver] org.apache.spark.storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-03-26 04:41:06,432 INFO [Driver] org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2025-03-26 04:41:06,457 INFO [Driver] org.apache.spark.storage.DiskBlockManager: Created local directory at /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/blockmgr-fbf1e294-c74a-4d29-acd1-2171ff656033
2025-03-26 04:41:06,459 DEBUG [Driver] org.apache.spark.storage.DiskBlockManager: Adding shutdown hook
2025-03-26 04:41:06,479 INFO [Driver] org.apache.spark.storage.memory.MemoryStore: MemoryStore started with capacity 2004.6 MiB
2025-03-26 04:41:06,522 INFO [Driver] org.apache.spark.SparkEnv: Registering OutputCommitCoordinator
2025-03-26 04:41:06,523 DEBUG [Driver] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: init
2025-03-26 04:41:06,530 DEBUG [Driver] org.apache.spark.SecurityManager: Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2025-03-26 04:41:06,683 DEBUG [Driver] org.apache.spark.ui.JettyUtils: Using requestHeaderSize: 8192
2025-03-26 04:41:06,699 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'SparkUI' on port 34163.
2025-03-26 04:41:06,701 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,763 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Created YarnClusterScheduler
2025-03-26 04:41:06,806 DEBUG [Driver] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 39591
2025-03-26 04:41:06,806 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39591.
2025-03-26 04:41:06,806 INFO [Driver] org.apache.spark.network.netty.NettyBlockTransferService: Server created on slave0:39591
2025-03-26 04:41:06,808 INFO [Driver] org.apache.spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-26 04:41:06,812 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, slave0, 39591, None)
2025-03-26 04:41:06,814 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave0
2025-03-26 04:41:06,815 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave0:39591 with 2004.6 MiB RAM, BlockManagerId(driver, slave0, 39591, None)
2025-03-26 04:41:06,817 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, slave0, 39591, None)
2025-03-26 04:41:06,818 INFO [Driver] org.apache.spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, slave0, 39591, None)
2025-03-26 04:41:06,886 ERROR [Driver] org.apache.spark.scheduler.AsyncEventQueue: Dropping event from queue executorManagement. This likely means one of the listeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
2025-03-26 04:41:06,887 WARN [Driver] org.apache.spark.scheduler.AsyncEventQueue: Dropped 1 events from executorManagement since the application started.
2025-03-26 04:41:06,917 DEBUG [Driver] org.apache.spark.util.YarnContainerInfoHelper: Base URL for logs: http://slave0:8042/node/containerlogs/container_1742964012349_0001_01_000001/root
2025-03-26 04:41:06,936 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,937 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,938 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,939 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,940 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,941 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,941 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,942 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,943 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/pool: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,944 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/pool/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,945 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,945 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,946 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/rdd: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,947 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/rdd/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,948 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /environment: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,948 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /environment/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,949 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,950 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,951 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/threadDump: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,951 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/threadDump/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,952 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /static: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,961 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,962 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /api: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,964 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,965 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,968 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:06,969 DEBUG [Driver] org.apache.spark.SparkContext: Adding shutdown hook
2025-03-26 04:41:06,974 DEBUG [main] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl entered state INITED
2025-03-26 04:41:06,980 INFO [main] org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.14:8030
2025-03-26 04:41:06,980 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.RMProxy$1@12dae582]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.RMProxy.getProxy(RMProxy.java:145)
	at org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider.init(DefaultNoHARMFailoverProxyProvider.java:65)
	at org.apache.hadoop.yarn.client.RMProxy.createNonHaRMFailoverProxyProvider(RMProxy.java:172)
	at org.apache.hadoop.yarn.client.RMProxy.newProxyInstance(RMProxy.java:132)
	at org.apache.hadoop.yarn.client.RMProxy.createRMProxy(RMProxy.java:103)
	at org.apache.hadoop.yarn.client.ClientRMProxy.createRMProxy(ClientRMProxy.java:73)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.serviceStart(AMRMClientImpl.java:193)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.spark.deploy.yarn.YarnRMClient.register(YarnRMClient.scala:63)
	at org.apache.spark.deploy.yarn.ApplicationMaster.registerAM(ApplicationMaster.scala:440)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:518)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:41:06,981 DEBUG [main] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:41:06,981 DEBUG [main] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ApplicationMasterProtocol
2025-03-26 04:41:06,991 DEBUG [main] org.apache.hadoop.ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker@2611b9a3
2025-03-26 04:41:06,995 DEBUG [main] org.apache.hadoop.ipc.Client: getting client out of cache: Client-2221fe05e0004349bd143c6ccc31e208
2025-03-26 04:41:07,007 DEBUG [main] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl is started
2025-03-26 04:41:07,008 INFO [main] org.apache.spark.deploy.yarn.YarnRMClient: Registering the ApplicationMaster
2025-03-26 04:41:07,039 DEBUG [main] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:41:07,040 DEBUG [main] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.14:8030
2025-03-26 04:41:07,040 DEBUG [main] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.14:8030
2025-03-26 04:41:07,042 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@3ebff828]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy31.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.registerApplicationMaster(ApplicationMasterProtocolPBClientImpl.java:108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy32.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:247)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:234)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:214)
	at org.apache.spark.deploy.yarn.YarnRMClient.register(YarnRMClient.scala:72)
	at org.apache.spark.deploy.yarn.ApplicationMaster.registerAM(ApplicationMaster.scala:440)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:518)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:41:07,080 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:41:07,093 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB info:org.apache.hadoop.yarn.security.SchedulerSecurityInfo$1@2a76b80a
2025-03-26 04:41:07,094 DEBUG [main] org.apache.hadoop.yarn.security.AMRMTokenSelector: Looking for a token with service 172.20.1.14:8030
2025-03-26 04:41:07,094 DEBUG [main] org.apache.hadoop.yarn.security.AMRMTokenSelector: Token kind is YARN_AM_RM_TOKEN and the token's service name is 172.20.1.14:8030
2025-03-26 04:41:07,097 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:41:07,098 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ApplicationMasterProtocolPB
2025-03-26 04:41:07,099 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEL3qgIbdMhABELCX9skD
2025-03-26 04:41:07,099 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:41:07,099 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:41:07,100 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEL3qgIbdMhABELCX9skD\",realm=\"default\",nonce=\"jBtuL+XwB4GI+wJhxQSVnZhQDqeUUqLYBMuE/j+8\",nc=00000001,cnonce=\"UUnbY5S9l5wDJmZ0gmFQICNZVI8zOUN+zwdfDhDU\",digest-uri=\"/default\",maxbuf=65536,response=671353e83fc3510ebffba7ade2aabdf2,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:41:07,103 DEBUG [main] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:41:07,105 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root: starting, having connections 1
2025-03-26 04:41:07,107 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #0 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.registerApplicationMaster
2025-03-26 04:41:07,122 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #0
2025-03-26 04:41:07,122 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: registerApplicationMaster took 110ms
2025-03-26 04:41:07,132 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Preparing Local resources
2025-03-26 04:41:07,167 DEBUG [main] org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for hdfs://master:9000/user/root/.sparkStaging/application_1742964012349_0001/__spark_conf__.zip
2025-03-26 04:41:07,167 DEBUG [main] org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for hdfs://master:9000/user/root/.sparkStaging/application_1742964012349_0001/__spark_conf__.zip: duration 0:00.001s
2025-03-26 04:41:07,167 DEBUG [main] org.apache.hadoop.fs.FileSystem: Starting: Creating FS hdfs://master:9000/user/root/.sparkStaging/application_1742964012349_0001/__spark_conf__.zip
2025-03-26 04:41:07,167 DEBUG [main] org.apache.hadoop.fs.FileSystem: Loading filesystems
2025-03-26 04:41:07,172 DEBUG [main] org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.fs.LocalFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__3803478787456165379.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:41:07,174 DEBUG [main] org.apache.hadoop.fs.FileSystem: viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__3803478787456165379.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:41:07,175 DEBUG [main] org.apache.hadoop.fs.FileSystem: har:// = class org.apache.hadoop.fs.HarFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__3803478787456165379.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:41:07,176 DEBUG [main] org.apache.hadoop.fs.FileSystem: http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__3803478787456165379.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:41:07,176 DEBUG [main] org.apache.hadoop.fs.FileSystem: https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__3803478787456165379.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:41:07,180 DEBUG [main] org.apache.hadoop.fs.FileSystem: hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__3803478787456165379.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:41:07,184 DEBUG [main] org.apache.hadoop.fs.FileSystem: webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__3803478787456165379.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:41:07,184 DEBUG [main] org.apache.hadoop.fs.FileSystem: swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__3803478787456165379.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:41:07,184 DEBUG [main] org.apache.hadoop.fs.FileSystem: nullscan:// = class org.apache.hadoop.hive.ql.io.NullScanFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__3803478787456165379.zip/hive-exec-2.3.9-core.jar
2025-03-26 04:41:07,185 DEBUG [main] org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__3803478787456165379.zip/hive-exec-2.3.9-core.jar
2025-03-26 04:41:07,185 DEBUG [main] org.apache.hadoop.fs.FileSystem: Looking for FS supporting hdfs
2025-03-26 04:41:07,185 DEBUG [main] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.hdfs.impl
2025-03-26 04:41:07,197 DEBUG [main] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:41:07,197 DEBUG [main] org.apache.hadoop.fs.FileSystem: FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2025-03-26 04:41:07,208 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.use.legacy.blockreader.local = false
2025-03-26 04:41:07,208 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.read.shortcircuit = false
2025-03-26 04:41:07,208 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.domain.socket.data.traffic = false
2025-03-26 04:41:07,208 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.domain.socket.path = 
2025-03-26 04:41:07,211 DEBUG [main] org.apache.hadoop.hdfs.DFSClient: Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2025-03-26 04:41:07,213 DEBUG [main] org.apache.hadoop.io.retry.RetryUtils: multipleLinearRandomRetry = null
2025-03-26 04:41:07,215 DEBUG [main] org.apache.hadoop.ipc.Client: getting client out of cache: Client-2221fe05e0004349bd143c6ccc31e208
2025-03-26 04:41:07,358 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
2025-03-26 04:41:07,361 DEBUG [main] org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2025-03-26 04:41:07,362 DEBUG [main] org.apache.hadoop.fs.FileSystem: Creating FS hdfs://master:9000/user/root/.sparkStaging/application_1742964012349_0001/__spark_conf__.zip: duration 0:00.195s
2025-03-26 04:41:07,364 DEBUG [main] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:41:07,364 DEBUG [main] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.14:9000
2025-03-26 04:41:07,364 DEBUG [main] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.14:9000
2025-03-26 04:41:07,365 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@322803db]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy36.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:965)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy37.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1739)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1753)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1750)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1765)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$prepareLocalResources$4(ApplicationMaster.scala:200)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$prepareLocalResources$4$adapted(ApplicationMaster.scala:197)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.deploy.yarn.ApplicationMaster.prepareLocalResources(ApplicationMaster.scala:197)
	at org.apache.spark.deploy.yarn.ApplicationMaster.createAllocator(ApplicationMaster.scala:463)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:523)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:41:07,365 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:41:07,366 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSelector)
2025-03-26 04:41:07,366 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: tokens aren't supported for this protocol or user doesn't have one
2025-03-26 04:41:07,366 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Use SIMPLE authentication for protocol ClientNamenodeProtocolPB
2025-03-26 04:41:07,366 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

2025-03-26 04:41:07,366 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root sending #1 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2025-03-26 04:41:07,366 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root: starting, having connections 2
2025-03-26 04:41:07,366 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root got value #1
2025-03-26 04:41:07,366 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getFileInfo took 2ms
2025-03-26 04:41:07,385 DEBUG [main] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:41:07,408 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: 
===============================================================================
Default YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_YARN_STAGING_DIR -> hdfs://master:9000/user/root/.sparkStaging/application_1742964012349_0001
    SPARK_USER -> root

  command:
    {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx2048m \ 
      '-XX:+IgnoreUnrecognizedVMOptions' \ 
      '--add-opens=java.base/java.lang=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.lang.invoke=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.lang.reflect=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.io=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.net=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.nio=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util.concurrent=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.nio.ch=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.nio.cs=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.security.action=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.util.calendar=ALL-UNNAMED' \ 
      '--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED' \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.driver.port=38775' \ 
      '-Dspark.ui.port=0' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.YarnCoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@slave0:38775 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      2 \ 
      --app-id \ 
      application_1742964012349_0001 \ 
      --resourceProfileId \ 
      0 \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    __app__.jar -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742964012349_0001/scopt_2.12-3.7.1.jar" } size: 78803 timestamp: 1742964062067 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742964012349_0001/__spark_libs__3803478787456165379.zip" } size: 301733843 timestamp: 1742964062017 type: ARCHIVE visibility: PRIVATE
    __spark_conf__ -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742964012349_0001/__spark_conf__.zip" } size: 947023 timestamp: 1742964062199 type: ARCHIVE visibility: PRIVATE
    spark-examples_2.12-3.3.2.jar -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742964012349_0001/spark-examples_2.12-3.3.2.jar" } size: 1567446 timestamp: 1742964062093 type: FILE visibility: PRIVATE

===============================================================================
2025-03-26 04:41:07,432 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Resource profile 0 doesn't exist, adding it
2025-03-26 04:41:07,456 INFO [main] org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 04:41:07,456 INFO [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 04:41:07,459 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
2025-03-26 04:41:07,459 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE
2025-03-26 04:41:07,459 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-mb'
2025-03-26 04:41:07,459 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-mb'
2025-03-26 04:41:07,459 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-vcores'
2025-03-26 04:41:07,459 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-vcores'
2025-03-26 04:41:07,461 DEBUG [main] org.apache.spark.deploy.yarn.ResourceRequestHelper: Custom resources requested: Map()
2025-03-26 04:41:07,461 DEBUG [main] org.apache.spark.deploy.yarn.YarnAllocator: Created resource capability: <memory:2432, vCores:2>
2025-03-26 04:41:07,463 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@slave0:38775)
2025-03-26 04:41:07,465 DEBUG [main] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-26 04:41:07,469 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-26 04:41:07,479 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:41:07,480 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-26 04:41:07,481 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-26 04:41:07,491 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #2 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:41:07,507 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #2
2025-03-26 04:41:07,507 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 16ms
2025-03-26 04:41:07,515 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
2025-03-26 04:41:07,516 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:41:07,518 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-26 04:41:07,518 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #3 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:41:07,520 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #3
2025-03-26 04:41:07,520 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-26 04:41:07,721 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200102722/200.
2025-03-26 04:41:07,722 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:41:07,722 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-26 04:41:07,722 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #4 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:41:07,724 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #4
2025-03-26 04:41:07,724 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-26 04:41:08,125 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400237964/400.
2025-03-26 04:41:08,125 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:41:08,126 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-26 04:41:08,127 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #5 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:41:08,136 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #5
2025-03-26 04:41:08,136 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 10ms
2025-03-26 04:41:08,140 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave0:37519
2025-03-26 04:41:08,146 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 1. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:16384, vCores:22>.
2025-03-26 04:41:08,147 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-26 04:41:08,151 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:41:08,154 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:41:08,155 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-26 04:41:08,155 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-26 04:41:08,155 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-26 04:41:08,155 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742964012349_0001_01_000002 on host slave0 for executor with ID 1 for ResourceProfile Id 0
2025-03-26 04:41:08,157 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
2025-03-26 04:41:08,157 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:41:08,158 DEBUG [ContainerLauncher-0] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-26 04:41:08,159 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-26 04:41:08,160 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-26 04:41:08,160 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:41:08,160 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-26 04:41:08,169 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:37519
2025-03-26 04:41:08,182 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.15:37519, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964012349 } attemptId: 1 } nodeId { host: "slave0" port: 37519 } appSubmitter: "root" keyId: 1967072149)
2025-03-26 04:41:08,183 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964012349_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@53dbe74b]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:41:08,183 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-26 04:41:08,187 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: getting client out of cache: Client-2221fe05e0004349bd143c6ccc31e208
2025-03-26 04:41:08,270 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:41:08,271 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.15:37519
2025-03-26 04:41:08,271 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.15:37519
2025-03-26 04:41:08,271 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964012349_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@9412bd5]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:41:08,271 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:41:08,272 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@66f5ae99
2025-03-26 04:41:08,272 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.15:37519. Current token is Kind: NMToken, Service: 172.20.1.15:37519, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964012349 } attemptId: 1 } nodeId { host: "slave0" port: 37519 } appSubmitter: "root" keyId: 1967072149)
2025-03-26 04:41:08,272 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:41:08,273 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-26 04:41:08,273 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEL3qgIbdMhABEgwKBnNsYXZlMBCPpQIaBHJvb3Qglcf8qQc=
2025-03-26 04:41:08,273 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:41:08,273 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:41:08,273 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEL3qgIbdMhABEgwKBnNsYXZlMBCPpQIaBHJvb3Qglcf8qQc=\",realm=\"default\",nonce=\"R1493w1nycc3M+wACE6LuUMjHr9GFONfV0sqQIgx\",nc=00000001,cnonce=\"loBz99EmgSz0TGyiaGnn6Oh/0oToznYIy1KD+nsc\",digest-uri=\"/default\",maxbuf=65536,response=c4af68a6d6027a911e5464c07ba177c3,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:41:08,275 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:41:08,275 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.15:37519 from appattempt_1742964012349_0001_000001 sending #6 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-26 04:41:08,275 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.15:37519 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.15:37519 from appattempt_1742964012349_0001_000001: starting, having connections 3
2025-03-26 04:41:08,278 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.15:37519 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.15:37519 from appattempt_1742964012349_0001_000001 got value #6
2025-03-26 04:41:08,278 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 8ms
2025-03-26 04:41:08,280 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.15:37519 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.15:37519 from appattempt_1742964012349_0001_000001: closed
2025-03-26 04:41:08,280 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.15:37519 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.15:37519 from appattempt_1742964012349_0001_000001: stopped, remaining connections 2
2025-03-26 04:41:08,958 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 2. Slept for 800064619/800.
2025-03-26 04:41:08,958 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:41:08,958 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 2, running: 1, executorsStarting: 0
2025-03-26 04:41:08,959 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #7 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:41:08,961 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #7
2025-03-26 04:41:08,962 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-26 04:41:08,962 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave1:39811
2025-03-26 04:41:08,962 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave2:44993
2025-03-26 04:41:08,962 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 2. Current executor count: 1. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-26 04:41:08,962 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-26 04:41:08,962 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-26 04:41:08,971 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:41:08,971 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:41:08,972 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:41:08,972 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-26 04:41:08,972 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-26 04:41:08,972 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-26 04:41:08,972 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:41:08,972 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-26 04:41:08,972 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-26 04:41:08,972 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-26 04:41:08,972 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742964012349_0001_01_000003 on host slave1 for executor with ID 2 for ResourceProfile Id 0
2025-03-26 04:41:08,973 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742964012349_0001_01_000004 on host slave2 for executor with ID 3 for ResourceProfile Id 0
2025-03-26 04:41:08,982 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 2 containers from YARN, launching executors on 2 of them.
2025-03-26 04:41:08,982 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:41:08,982 DEBUG [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-26 04:41:08,982 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-26 04:41:08,983 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-26 04:41:08,983 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:41:08,983 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-26 04:41:08,981 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:41:08,986 DEBUG [ContainerLauncher-1] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-26 04:41:08,986 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-26 04:41:08,987 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-26 04:41:08,987 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:41:08,987 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-26 04:41:08,989 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:44993
2025-03-26 04:41:08,990 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.17:44993, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964012349 } attemptId: 1 } nodeId { host: "slave2" port: 44993 } appSubmitter: "root" keyId: 1967072149)
2025-03-26 04:41:08,990 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964012349_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@28259a52]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:41:08,990 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-26 04:41:08,990 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:39811
2025-03-26 04:41:08,991 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.16:39811, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964012349 } attemptId: 1 } nodeId { host: "slave1" port: 39811 } appSubmitter: "root" keyId: 1967072149)
2025-03-26 04:41:08,991 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964012349_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@7ac1e80e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:41:08,991 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-26 04:41:08,992 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: getting client out of cache: Client-2221fe05e0004349bd143c6ccc31e208
2025-03-26 04:41:08,992 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:41:08,992 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.16:39811
2025-03-26 04:41:08,992 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.16:39811
2025-03-26 04:41:08,992 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964012349_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@5fec867d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:41:08,993 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:41:08,994 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: getting client out of cache: Client-2221fe05e0004349bd143c6ccc31e208
2025-03-26 04:41:08,995 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:41:08,995 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.17:44993
2025-03-26 04:41:08,995 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.17:44993
2025-03-26 04:41:08,996 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964012349_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@d08ee7d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:41:08,996 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:41:09,000 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@6046103b
2025-03-26 04:41:09,000 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.16:39811. Current token is Kind: NMToken, Service: 172.20.1.16:39811, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964012349 } attemptId: 1 } nodeId { host: "slave1" port: 39811 } appSubmitter: "root" keyId: 1967072149)
2025-03-26 04:41:09,001 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:41:09,001 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-26 04:41:09,001 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEL3qgIbdMhABEgwKBnNsYXZlMRCDtwIaBHJvb3Qglcf8qQc=
2025-03-26 04:41:09,001 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:41:09,001 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:41:09,002 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEL3qgIbdMhABEgwKBnNsYXZlMRCDtwIaBHJvb3Qglcf8qQc=\",realm=\"default\",nonce=\"w4RRnRYsi+EAGpUtyvdWN8+C6EGapmJwlHjK+yr1\",nc=00000001,cnonce=\"BWWqsrx+Z5lhIvoek6rrvGCiap1RG74v/Sp3vAyM\",digest-uri=\"/default\",maxbuf=65536,response=2ddf463501f02795370346bfed1054e5,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:41:09,004 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@43f772d1
2025-03-26 04:41:09,004 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.17:44993. Current token is Kind: NMToken, Service: 172.20.1.17:44993, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964012349 } attemptId: 1 } nodeId { host: "slave2" port: 44993 } appSubmitter: "root" keyId: 1967072149)
2025-03-26 04:41:09,005 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:41:09,006 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-26 04:41:09,012 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEL3qgIbdMhABEgwKBnNsYXZlMhDB3wIaBHJvb3Qglcf8qQc=
2025-03-26 04:41:09,013 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:41:09,013 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:41:09,013 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEL3qgIbdMhABEgwKBnNsYXZlMhDB3wIaBHJvb3Qglcf8qQc=\",realm=\"default\",nonce=\"LXG+E7rUqttxKySQ5qY9R0xf4/KZdl/wwYQM9GSD\",nc=00000001,cnonce=\"kOG2AoSV/fcdo6G508kt+M/HSBNjZvxfcd5lCtoG\",digest-uri=\"/default\",maxbuf=65536,response=b21882424ddf416baede042d92810fde,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:41:09,014 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:41:09,025 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.16:39811 from appattempt_1742964012349_0001_000001 sending #8 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-26 04:41:09,026 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:41:09,027 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.17:44993 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.17:44993 from appattempt_1742964012349_0001_000001: starting, having connections 4
2025-03-26 04:41:09,027 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.16:39811 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.16:39811 from appattempt_1742964012349_0001_000001: starting, having connections 4
2025-03-26 04:41:09,036 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.17:44993 from appattempt_1742964012349_0001_000001 sending #9 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-26 04:41:09,102 INFO [main] org.apache.spark.executor.CoarseGrainedExecutorBackend: Started daemon with process name: 1581@slave0
2025-03-26 04:41:09,108 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for TERM
2025-03-26 04:41:09,109 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for HUP
2025-03-26 04:41:09,109 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for INT
2025-03-26 04:41:09,209 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.16:39811 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.16:39811 from appattempt_1742964012349_0001_000001 got value #8
2025-03-26 04:41:09,209 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.16:39811 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.16:39811 from appattempt_1742964012349_0001_000001: closed
2025-03-26 04:41:09,209 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.16:39811 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.16:39811 from appattempt_1742964012349_0001_000001: stopped, remaining connections 3
2025-03-26 04:41:09,209 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 217ms
2025-03-26 04:41:09,211 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.17:44993 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.17:44993 from appattempt_1742964012349_0001_000001 got value #9
2025-03-26 04:41:09,211 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.17:44993 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.17:44993 from appattempt_1742964012349_0001_000001: closed
2025-03-26 04:41:09,211 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.17:44993 from appattempt_1742964012349_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.17:44993 from appattempt_1742964012349_0001_000001: stopped, remaining connections 2
2025-03-26 04:41:09,213 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 218ms
2025-03-26 04:41:09,382 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-26 04:41:09,387 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-26 04:41:09,387 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-26 04:41:09,387 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-26 04:41:09,387 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-26 04:41:09,388 DEBUG [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-26 04:41:09,414 DEBUG [main] org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-26 04:41:09,414 DEBUG [main] org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-26 04:41:09,418 DEBUG [main] org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-26 04:41:09,420 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-26 04:41:09,420 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-26 04:41:09,420 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-26 04:41:09,420 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-26 04:41:09,420 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-26 04:41:09,421 DEBUG [main] org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-26 04:41:09,483 DEBUG [main] org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-26 04:41:09,486 DEBUG [main] org.apache.spark.deploy.SparkHadoopUtil: creating UGI for user: root
2025-03-26 04:41:09,489 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-26 04:41:09,489 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-26 04:41:09,491 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-26 04:41:09,492 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-26 04:41:09,493 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-26 04:41:09,493 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Reading credentials from location /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000002/container_tokens
2025-03-26 04:41:09,499 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Loaded 1 tokens from /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000002/container_tokens
2025-03-26 04:41:09,500 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-26 04:41:09,500 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.spark.deploy.SparkHadoopUtil$$anon$1@59d2400d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:61)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:427)
	at org.apache.spark.executor.YarnCoarseGrainedExecutorBackend$.main(YarnCoarseGrainedExecutorBackend.scala:83)
	at org.apache.spark.executor.YarnCoarseGrainedExecutorBackend.main(YarnCoarseGrainedExecutorBackend.scala)
2025-03-26 04:41:09,515 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:41:09,515 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:41:09,516 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:41:09,516 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:41:09,518 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:41:09,607 DEBUG [main] io.netty.util.internal.logging.InternalLoggerFactory: Using SLF4J as the default logging framework
2025-03-26 04:41:09,610 DEBUG [main] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2025-03-26 04:41:09,610 DEBUG [main] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2025-03-26 04:41:09,618 DEBUG [main] io.netty.channel.MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 4
2025-03-26 04:41:09,636 DEBUG [main] io.netty.util.internal.PlatformDependent0: -Dio.netty.noUnsafe: false
2025-03-26 04:41:09,636 DEBUG [main] io.netty.util.internal.PlatformDependent0: Java version: 8
2025-03-26 04:41:09,636 DEBUG [main] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
2025-03-26 04:41:09,637 DEBUG [main] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
2025-03-26 04:41:09,637 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.Buffer.address: available
2025-03-26 04:41:09,637 DEBUG [main] io.netty.util.internal.PlatformDependent0: direct buffer constructor: available
2025-03-26 04:41:09,638 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.Bits.unaligned: available, true
2025-03-26 04:41:09,638 DEBUG [main] io.netty.util.internal.PlatformDependent0: jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2025-03-26 04:41:09,638 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
2025-03-26 04:41:09,638 DEBUG [main] io.netty.util.internal.PlatformDependent: sun.misc.Unsafe: available
2025-03-26 04:41:09,638 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.tmpdir: /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000002/tmp (java.io.tmpdir)
2025-03-26 04:41:09,638 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
2025-03-26 04:41:09,639 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.maxDirectMemory: 1908932608 bytes
2025-03-26 04:41:09,639 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.uninitializedArrayAllocationThreshold: -1
2025-03-26 04:41:09,639 DEBUG [main] io.netty.util.internal.CleanerJava6: java.nio.ByteBuffer.cleaner(): available
2025-03-26 04:41:09,639 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.noPreferDirect: false
2025-03-26 04:41:09,640 DEBUG [main] io.netty.channel.nio.NioEventLoop: -Dio.netty.noKeySetOptimization: false
2025-03-26 04:41:09,640 DEBUG [main] io.netty.channel.nio.NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
2025-03-26 04:41:09,644 DEBUG [main] io.netty.util.internal.PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
2025-03-26 04:41:09,652 DEBUG [main] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
2025-03-26 04:41:09,652 DEBUG [main] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.targetRecords: 4
2025-03-26 04:41:09,653 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 4
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 4
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.useCacheForAllThreads: true
2025-03-26 04:41:09,654 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2025-03-26 04:41:09,691 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Creating new connection to slave0/172.20.1.15:38775
2025-03-26 04:41:09,702 DEBUG [netty-rpc-connection-0] io.netty.channel.DefaultChannelId: -Dio.netty.processId: 1581 (auto-detected)
2025-03-26 04:41:09,704 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: -Djava.net.preferIPv4Stack: false
2025-03-26 04:41:09,704 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: -Djava.net.preferIPv6Addresses: false
2025-03-26 04:41:09,705 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtilInitializations: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2025-03-26 04:41:09,706 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: /proc/sys/net/core/somaxconn: 4096
2025-03-26 04:41:09,706 DEBUG [netty-rpc-connection-0] io.netty.channel.DefaultChannelId: -Dio.netty.machineId: 02:42:ac:ff:fe:14:01:0f (auto-detected)
2025-03-26 04:41:09,725 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.allocator.type: pooled
2025-03-26 04:41:09,725 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 0
2025-03-26 04:41:09,725 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
2025-03-26 04:41:09,743 DEBUG [rpc-client-1-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkAccessible: true
2025-03-26 04:41:09,743 DEBUG [rpc-client-1-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkBounds: true
2025-03-26 04:41:09,744 DEBUG [rpc-client-1-1] io.netty.util.ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@423237b6
2025-03-26 04:41:09,755 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b] REGISTERED
2025-03-26 04:41:09,755 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b] CONNECT: slave0/172.20.1.15:38775
2025-03-26 04:41:09,757 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Connection to slave0/172.20.1.15:38775 successful, running bootstraps...
2025-03-26 04:41:09,757 INFO [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Successfully created connection to slave0/172.20.1.15:38775 after 57 ms (0 ms spent in bootstraps)
2025-03-26 04:41:09,761 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.maxCapacityPerThread: 4096
2025-03-26 04:41:09,761 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.ratio: 8
2025-03-26 04:41:09,761 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.chunkSize: 32
2025-03-26 04:41:09,761 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.blocking: false
2025-03-26 04:41:09,762 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] ACTIVE
2025-03-26 04:41:09,770 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 168]
2025-03-26 04:41:09,770 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:09,772 DEBUG [rpc-server-4-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.15:47092.
2025-03-26 04:41:09,784 DEBUG [rpc-server-4-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkAccessible: true
2025-03-26 04:41:09,784 DEBUG [rpc-server-4-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkBounds: true
2025-03-26 04:41:09,785 DEBUG [rpc-server-4-1] io.netty.util.ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@4dd19bb5
2025-03-26 04:41:09,792 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] REGISTERED
2025-03-26 04:41:09,792 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] ACTIVE
2025-03-26 04:41:09,795 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.maxCapacityPerThread: 4096
2025-03-26 04:41:09,795 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.ratio: 8
2025-03-26 04:41:09,795 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.chunkSize: 32
2025-03-26 04:41:09,795 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.blocking: false
2025-03-26 04:41:09,799 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] READ 189B
2025-03-26 04:41:09,810 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] READ COMPLETE
2025-03-26 04:41:09,814 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:09,814 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] FLUSH
2025-03-26 04:41:09,816 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] READ 21B
2025-03-26 04:41:09,818 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:09,818 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] READ 47B
2025-03-26 04:41:09,828 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:09,828 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 169]
2025-03-26 04:41:09,828 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:09,829 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] READ 190B
2025-03-26 04:41:09,831 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] READ COMPLETE
2025-03-26 04:41:09,858 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 4395]
2025-03-26 04:41:09,858 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] FLUSH
2025-03-26 04:41:09,859 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] READ 1024B
2025-03-26 04:41:09,859 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] READ 3392B
2025-03-26 04:41:09,882 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:09,882 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 - R:slave0/172.20.1.15:38775] CLOSE
2025-03-26 04:41:09,883 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 - R:/172.20.1.15:47092] READ COMPLETE
2025-03-26 04:41:09,883 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 ! R:/172.20.1.15:47092] INACTIVE
2025-03-26 04:41:09,884 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x42c2fc0f, L:/172.20.1.15:38775 ! R:/172.20.1.15:47092] UNREGISTERED
2025-03-26 04:41:09,885 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 ! R:slave0/172.20.1.15:38775] INACTIVE
2025-03-26 04:41:09,885 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xf3a3dc6b, L:/172.20.1.15:47092 ! R:slave0/172.20.1.15:38775] UNREGISTERED
2025-03-26 04:41:09,895 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:41:09,896 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:41:09,896 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:41:09,896 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:41:09,896 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:41:09,918 DEBUG [main] org.apache.spark.SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
2025-03-26 04:41:09,935 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Creating new connection to slave0/172.20.1.15:38775
2025-03-26 04:41:09,938 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff] REGISTERED
2025-03-26 04:41:09,938 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff] CONNECT: slave0/172.20.1.15:38775
2025-03-26 04:41:09,939 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] ACTIVE
2025-03-26 04:41:09,939 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Connection to slave0/172.20.1.15:38775 successful, running bootstraps...
2025-03-26 04:41:09,939 INFO [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Successfully created connection to slave0/172.20.1.15:38775 after 3 ms (0 ms spent in bootstraps)
2025-03-26 04:41:09,939 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 162]
2025-03-26 04:41:09,939 DEBUG [rpc-server-4-2] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.15:47096.
2025-03-26 04:41:09,939 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:09,940 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] REGISTERED
2025-03-26 04:41:09,940 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] ACTIVE
2025-03-26 04:41:09,940 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ 183B
2025-03-26 04:41:09,941 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ COMPLETE
2025-03-26 04:41:09,941 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:09,941 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] FLUSH
2025-03-26 04:41:09,942 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ 68B
2025-03-26 04:41:09,942 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:09,969 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 164]
2025-03-26 04:41:09,969 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:09,970 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ 185B
2025-03-26 04:41:09,971 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ COMPLETE
2025-03-26 04:41:09,971 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:09,973 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] FLUSH
2025-03-26 04:41:09,973 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ 21B
2025-03-26 04:41:09,973 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:09,973 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ 47B
2025-03-26 04:41:09,974 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:09,976 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 173]
2025-03-26 04:41:09,976 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:09,976 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ 194B
2025-03-26 04:41:09,977 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ COMPLETE
2025-03-26 04:41:09,977 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:09,977 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] FLUSH
2025-03-26 04:41:09,977 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ 68B
2025-03-26 04:41:09,978 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:09,992 INFO [main] org.apache.spark.storage.DiskBlockManager: Created local directory at /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/blockmgr-4a8e4697-64a0-4efe-872c-1380537bd55e
2025-03-26 04:41:09,993 DEBUG [main] org.apache.spark.storage.DiskBlockManager: Adding shutdown hook
2025-03-26 04:41:09,994 DEBUG [main] org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-26 04:41:10,019 INFO [main] org.apache.spark.storage.memory.MemoryStore: MemoryStore started with capacity 912.3 MiB
2025-03-26 04:41:10,209 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 169]
2025-03-26 04:41:10,209 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:10,209 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ 190B
2025-03-26 04:41:10,210 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ COMPLETE
2025-03-26 04:41:10,210 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:10,210 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] FLUSH
2025-03-26 04:41:10,210 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ 68B
2025-03-26 04:41:10,210 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:10,228 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@slave0:38775
2025-03-26 04:41:10,252 DEBUG [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Resource profile id is: 0
2025-03-26 04:41:10,258 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:41:10,258 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: No custom resources configured for spark.executor.
2025-03-26 04:41:10,258 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:41:10,259 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 168]
2025-03-26 04:41:10,259 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:10,259 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ 189B
2025-03-26 04:41:10,260 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ COMPLETE
2025-03-26 04:41:10,260 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:10,262 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] FLUSH
2025-03-26 04:41:10,262 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ 68B
2025-03-26 04:41:10,290 DEBUG [rpc-client-3-1] org.apache.spark.util.YarnContainerInfoHelper: Base URL for logs: http://slave0:8042/node/containerlogs/container_1742964012349_0001_01_000002/root
2025-03-26 04:41:10,313 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 1916]
2025-03-26 04:41:10,313 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:10,314 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ 512B
2025-03-26 04:41:10,314 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:10,316 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ 1425B
2025-03-26 04:41:10,333 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.1.15:47096) with ID 1,  ResourceProfileId 0
2025-03-26 04:41:10,334 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ COMPLETE
2025-03-26 04:41:10,335 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:10,335 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] FLUSH
2025-03-26 04:41:10,336 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ 68B
2025-03-26 04:41:10,339 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Successfully registered with driver
2025-03-26 04:41:10,344 INFO [dispatcher-Executor] org.apache.spark.executor.Executor: Starting executor ID 1 on host slave0
2025-03-26 04:41:10,348 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:10,372 DEBUG [dispatcher-Executor] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 36011
2025-03-26 04:41:10,373 INFO [dispatcher-Executor] org.apache.spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36011.
2025-03-26 04:41:10,373 INFO [dispatcher-Executor] org.apache.spark.network.netty.NettyBlockTransferService: Server created on slave0:36011
2025-03-26 04:41:10,374 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-26 04:41:10,380 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, slave0, 36011, None)
2025-03-26 04:41:10,384 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 1456]
2025-03-26 04:41:10,384 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:10,384 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ 1477B
2025-03-26 04:41:10,387 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ COMPLETE
2025-03-26 04:41:10,388 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave0
2025-03-26 04:41:10,388 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave0:36011 with 912.3 MiB RAM, BlockManagerId(1, slave0, 36011, None)
2025-03-26 04:41:10,395 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 79]
2025-03-26 04:41:10,395 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] FLUSH
2025-03-26 04:41:10,395 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ 100B
2025-03-26 04:41:10,396 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:10,396 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, slave0, 36011, None)
2025-03-26 04:41:10,397 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(1, slave0, 36011, None)
2025-03-26 04:41:10,403 INFO [dispatcher-Executor] org.apache.spark.executor.Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000002/__app__.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000002/spark-examples_2.12-3.3.2.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000002/__app__.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000002/spark-examples_2.12-3.3.2.jar'
2025-03-26 04:41:10,409 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 163]
2025-03-26 04:41:10,409 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:10,409 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ 184B
2025-03-26 04:41:10,410 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ COMPLETE
2025-03-26 04:41:10,410 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:10,410 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] FLUSH
2025-03-26 04:41:10,410 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ 68B
2025-03-26 04:41:10,411 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:10,433 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 177]
2025-03-26 04:41:10,434 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] FLUSH
2025-03-26 04:41:10,434 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ 190B
2025-03-26 04:41:10,436 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ COMPLETE
2025-03-26 04:41:11,982 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000129812/3000.
2025-03-26 04:41:11,982 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:41:11,982 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 3, executorsStarting: 0
2025-03-26 04:41:11,983 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #10 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:41:11,987 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #10
2025-03-26 04:41:11,987 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-26 04:41:11,987 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 2. Current executor count: 3. Launching executor count: 0. Cluster resources: <memory:4096, vCores:18>.
2025-03-26 04:41:11,987 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-26 04:41:11,987 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-26 04:41:11,987 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:41:11,988 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:41:11,988 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:41:11,988 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:41:11,988 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Releasing 2 unneeded containers that were allocated to us
2025-03-26 04:41:11,988 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 2 containers from YARN, launching executors on 0 of them.
2025-03-26 04:41:13,693 DEBUG [rpc-server-4-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.17:33490.
2025-03-26 04:41:13,693 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] REGISTERED
2025-03-26 04:41:13,694 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] ACTIVE
2025-03-26 04:41:13,709 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] READ 189B
2025-03-26 04:41:13,710 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] READ COMPLETE
2025-03-26 04:41:13,710 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:13,710 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] FLUSH
2025-03-26 04:41:13,722 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] READ 190B
2025-03-26 04:41:13,723 DEBUG [rpc-server-4-2] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.16:37096.
2025-03-26 04:41:13,723 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] READ COMPLETE
2025-03-26 04:41:13,724 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] REGISTERED
2025-03-26 04:41:13,724 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] ACTIVE
2025-03-26 04:41:13,724 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 4395]
2025-03-26 04:41:13,724 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] FLUSH
2025-03-26 04:41:13,738 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] READ 189B
2025-03-26 04:41:13,739 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] READ COMPLETE
2025-03-26 04:41:13,739 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:13,740 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] FLUSH
2025-03-26 04:41:13,753 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] READ 190B
2025-03-26 04:41:13,753 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] READ COMPLETE
2025-03-26 04:41:13,754 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 4395]
2025-03-26 04:41:13,754 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] FLUSH
2025-03-26 04:41:13,758 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 - R:/172.20.1.17:33490] READ COMPLETE
2025-03-26 04:41:13,758 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 ! R:/172.20.1.17:33490] INACTIVE
2025-03-26 04:41:13,758 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xd9074541, L:/172.20.1.15:38775 ! R:/172.20.1.17:33490] UNREGISTERED
2025-03-26 04:41:13,793 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 - R:/172.20.1.16:37096] READ COMPLETE
2025-03-26 04:41:13,793 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 ! R:/172.20.1.16:37096] INACTIVE
2025-03-26 04:41:13,793 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xffe25733, L:/172.20.1.15:38775 ! R:/172.20.1.16:37096] UNREGISTERED
2025-03-26 04:41:13,824 DEBUG [rpc-server-4-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.17:33494.
2025-03-26 04:41:13,824 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] REGISTERED
2025-03-26 04:41:13,824 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] ACTIVE
2025-03-26 04:41:13,826 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ 183B
2025-03-26 04:41:13,826 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ COMPLETE
2025-03-26 04:41:13,827 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:13,827 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] FLUSH
2025-03-26 04:41:13,866 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ 185B
2025-03-26 04:41:13,866 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ COMPLETE
2025-03-26 04:41:13,867 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:13,867 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] FLUSH
2025-03-26 04:41:13,869 DEBUG [rpc-server-4-2] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.16:37104.
2025-03-26 04:41:13,869 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] REGISTERED
2025-03-26 04:41:13,869 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] ACTIVE
2025-03-26 04:41:13,870 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 21B
2025-03-26 04:41:13,870 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:13,870 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 162B
2025-03-26 04:41:13,871 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:13,871 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:13,871 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:13,872 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ 194B
2025-03-26 04:41:13,872 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ COMPLETE
2025-03-26 04:41:13,872 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:13,872 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] FLUSH
2025-03-26 04:41:13,912 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 185B
2025-03-26 04:41:13,913 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:13,913 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:13,913 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:13,916 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 194B
2025-03-26 04:41:13,917 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:13,917 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:13,917 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:14,142 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ 190B
2025-03-26 04:41:14,143 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ COMPLETE
2025-03-26 04:41:14,143 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:14,143 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] FLUSH
2025-03-26 04:41:14,200 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 190B
2025-03-26 04:41:14,200 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:14,201 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:14,201 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:14,216 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ 189B
2025-03-26 04:41:14,217 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ COMPLETE
2025-03-26 04:41:14,217 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:14,217 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] FLUSH
2025-03-26 04:41:14,288 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ 512B
2025-03-26 04:41:14,289 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ 1425B
2025-03-26 04:41:14,290 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.1.17:33494) with ID 3,  ResourceProfileId 0
2025-03-26 04:41:14,290 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ COMPLETE
2025-03-26 04:41:14,290 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:14,290 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] FLUSH
2025-03-26 04:41:14,297 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 189B
2025-03-26 04:41:14,297 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:14,297 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:14,297 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:14,363 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ 1477B
2025-03-26 04:41:14,364 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave2
2025-03-26 04:41:14,364 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ COMPLETE
2025-03-26 04:41:14,364 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave2:44391 with 912.3 MiB RAM, BlockManagerId(3, slave2, 44391, None)
2025-03-26 04:41:14,365 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 79]
2025-03-26 04:41:14,365 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] FLUSH
2025-03-26 04:41:14,384 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ 184B
2025-03-26 04:41:14,384 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ COMPLETE
2025-03-26 04:41:14,385 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:14,385 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] FLUSH
2025-03-26 04:41:14,385 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 496B
2025-03-26 04:41:14,385 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 1441B
2025-03-26 04:41:14,386 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.1.16:37104) with ID 2,  ResourceProfileId 0
2025-03-26 04:41:14,387 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:14,387 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:14,387 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:14,401 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ 190B
2025-03-26 04:41:14,402 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ COMPLETE
2025-03-26 04:41:14,458 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2025-03-26 04:41:14,458 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterScheduler: YarnClusterScheduler.postStartHook done
2025-03-26 04:41:14,466 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 1477B
2025-03-26 04:41:14,467 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:14,467 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave1
2025-03-26 04:41:14,467 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave1:46211 with 912.3 MiB RAM, BlockManagerId(2, slave1, 46211, None)
2025-03-26 04:41:14,468 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 79]
2025-03-26 04:41:14,468 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:14,486 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 184B
2025-03-26 04:41:14,487 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:14,487 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:14,487 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:14,500 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 190B
2025-03-26 04:41:14,500 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:14,989 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000061956/3000.
2025-03-26 04:41:14,989 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:41:14,989 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 3, executorsStarting: 0
2025-03-26 04:41:14,994 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #11 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:41:14,999 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #11
2025-03-26 04:41:14,999 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 10ms
2025-03-26 04:41:15,002 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 2 containers
2025-03-26 04:41:15,003 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 2 completed containers. Current running executor count: 3.
2025-03-26 04:41:15,199 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 04:41:15,199 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 04:41:15,199 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:41:15,199 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:41:15,200 INFO [Driver] org.apache.spark.sql.internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-26 04:41:15,201 DEBUG [Driver] org.apache.spark.sql.internal.SharedState: Applying other initial session options to HadoopConf: spark.app.name -> DeveloperApiExample
2025-03-26 04:41:15,201 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000001/spark-warehouse
2025-03-26 04:41:15,201 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000001/spark-warehouse: duration 0:00.000s
2025-03-26 04:41:15,201 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Starting: Creating FS file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000001/spark-warehouse
2025-03-26 04:41:15,201 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 04:41:15,201 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 04:41:15,201 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:41:15,201 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:41:15,201 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Creating FS file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000001/spark-warehouse: duration 0:00.000s
2025-03-26 04:41:15,201 INFO [Driver] org.apache.spark.sql.internal.SharedState: Warehouse path is 'file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/container_1742964012349_0001_01_000001/spark-warehouse'.
2025-03-26 04:41:15,208 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:15,209 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol http
2025-03-26 04:41:15,209 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Unknown protocol http, delegating to default implementation
2025-03-26 04:41:15,209 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:15,210 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:15,210 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:15,211 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol jar
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting jar
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.jar.impl
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Unknown protocol jar, delegating to default implementation
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol file
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Found implementation of file: class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:41:15,212 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Using handler for protocol file
2025-03-26 04:41:15,629 DEBUG [Driver] org.apache.spark.sql.catalyst.parser.CatalystSqlParser: Parsing command: spark_grouping_id
2025-03-26 04:41:16,095 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegression: Input schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}}]}
2025-03-26 04:41:16,098 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegression: Expected output schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}},{"name":"prediction","type":"double","nullable":false,"metadata":{}},{"name":"rawPrediction","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":false,"metadata":{}}]}
2025-03-26 04:41:16,119 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#0
2025-03-26 04:41:16,137 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#7
2025-03-26 04:41:16,137 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'features to features#1
2025-03-26 04:41:16,557 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for input[0, double, false],input[1, vector, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */     double value_0 = i.getDouble(0);
/* 036 */     mutableStateArray_0[0].write(0, value_0);
/* 037 */
/* 038 */     boolean isNull_1 = i.isNullAt(1);
/* 039 */     InternalRow value_1 = isNull_1 ?
/* 040 */     null : (i.getStruct(1, 4));
/* 041 */     if (isNull_1) {
/* 042 */       mutableStateArray_0[0].setNullAt(1);
/* 043 */     } else {
/* 044 */       final InternalRow tmpInput_0 = value_1;
/* 045 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 046 */         mutableStateArray_0[0].write(1, (UnsafeRow) tmpInput_0);
/* 047 */       } else {
/* 048 */         // Remember the current cursor so that we can calculate how many bytes are
/* 049 */         // written later.
/* 050 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 051 */
/* 052 */         mutableStateArray_0[1].resetRowWriter();
/* 053 */
/* 054 */
/* 055 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 056 */
/* 057 */
/* 058 */         if ((tmpInput_0.isNullAt(1))) {
/* 059 */           mutableStateArray_0[1].setNullAt(1);
/* 060 */         } else {
/* 061 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 062 */         }
/* 063 */
/* 064 */
/* 065 */         if ((tmpInput_0.isNullAt(2))) {
/* 066 */           mutableStateArray_0[1].setNullAt(2);
/* 067 */         } else {
/* 068 */           // Remember the current cursor so that we can calculate how many bytes are
/* 069 */           // written later.
/* 070 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 071 */
/* 072 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 073 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 074 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 075 */           } else {
/* 076 */             final int numElements_0 = tmpInput_1.numElements();
/* 077 */             mutableStateArray_1[0].initialize(numElements_0);
/* 078 */
/* 079 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 080 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 081 */             }
/* 082 */           }
/* 083 */
/* 084 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 085 */         }
/* 086 */
/* 087 */
/* 088 */         if ((tmpInput_0.isNullAt(3))) {
/* 089 */           mutableStateArray_0[1].setNullAt(3);
/* 090 */         } else {
/* 091 */           // Remember the current cursor so that we can calculate how many bytes are
/* 092 */           // written later.
/* 093 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 094 */
/* 095 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 096 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 097 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 098 */           } else {
/* 099 */             final int numElements_1 = tmpInput_2.numElements();
/* 100 */             mutableStateArray_1[1].initialize(numElements_1);
/* 101 */
/* 102 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 103 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 104 */             }
/* 105 */           }
/* 106 */
/* 107 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 108 */         }
/* 109 */
/* 110 */
/* 111 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(1, previousCursor_0);
/* 112 */       }
/* 113 */     }
/* 114 */     return (mutableStateArray_0[0].getRow());
/* 115 */   }
/* 116 */
/* 117 */
/* 118 */ }

2025-03-26 04:41:16,568 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */     double value_0 = i.getDouble(0);
/* 036 */     mutableStateArray_0[0].write(0, value_0);
/* 037 */
/* 038 */     boolean isNull_1 = i.isNullAt(1);
/* 039 */     InternalRow value_1 = isNull_1 ?
/* 040 */     null : (i.getStruct(1, 4));
/* 041 */     if (isNull_1) {
/* 042 */       mutableStateArray_0[0].setNullAt(1);
/* 043 */     } else {
/* 044 */       final InternalRow tmpInput_0 = value_1;
/* 045 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 046 */         mutableStateArray_0[0].write(1, (UnsafeRow) tmpInput_0);
/* 047 */       } else {
/* 048 */         // Remember the current cursor so that we can calculate how many bytes are
/* 049 */         // written later.
/* 050 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 051 */
/* 052 */         mutableStateArray_0[1].resetRowWriter();
/* 053 */
/* 054 */
/* 055 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 056 */
/* 057 */
/* 058 */         if ((tmpInput_0.isNullAt(1))) {
/* 059 */           mutableStateArray_0[1].setNullAt(1);
/* 060 */         } else {
/* 061 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 062 */         }
/* 063 */
/* 064 */
/* 065 */         if ((tmpInput_0.isNullAt(2))) {
/* 066 */           mutableStateArray_0[1].setNullAt(2);
/* 067 */         } else {
/* 068 */           // Remember the current cursor so that we can calculate how many bytes are
/* 069 */           // written later.
/* 070 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 071 */
/* 072 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 073 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 074 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 075 */           } else {
/* 076 */             final int numElements_0 = tmpInput_1.numElements();
/* 077 */             mutableStateArray_1[0].initialize(numElements_0);
/* 078 */
/* 079 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 080 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 081 */             }
/* 082 */           }
/* 083 */
/* 084 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 085 */         }
/* 086 */
/* 087 */
/* 088 */         if ((tmpInput_0.isNullAt(3))) {
/* 089 */           mutableStateArray_0[1].setNullAt(3);
/* 090 */         } else {
/* 091 */           // Remember the current cursor so that we can calculate how many bytes are
/* 092 */           // written later.
/* 093 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 094 */
/* 095 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 096 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 097 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 098 */           } else {
/* 099 */             final int numElements_1 = tmpInput_2.numElements();
/* 100 */             mutableStateArray_1[1].initialize(numElements_1);
/* 101 */
/* 102 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 103 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 104 */             }
/* 105 */           }
/* 106 */
/* 107 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 108 */         }
/* 109 */
/* 110 */
/* 111 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(1, previousCursor_0);
/* 112 */       }
/* 113 */     }
/* 114 */     return (mutableStateArray_0[0].getRow());
/* 115 */   }
/* 116 */
/* 117 */
/* 118 */ }

2025-03-26 04:41:16,687 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 129.69372 ms
2025-03-26 04:41:16,700 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$doExecute$1
2025-03-26 04:41:16,710 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$doExecute$1) is now cleaned +++
2025-03-26 04:41:16,719 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$rdd$1
2025-03-26 04:41:16,725 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2025-03-26 04:41:16,742 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$extractLabeledPoints$1
2025-03-26 04:41:16,742 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$extractLabeledPoints$1) is now cleaned +++
2025-03-26 04:41:16,749 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$take$2
2025-03-26 04:41:16,753 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$take$2) is now cleaned +++
2025-03-26 04:41:16,807 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5
2025-03-26 04:41:16,810 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2025-03-26 04:41:16,812 INFO [Driver] org.apache.spark.SparkContext: Starting job: take at DeveloperApiExample.scala:127
2025-03-26 04:41:16,814 DEBUG [Driver] org.apache.spark.scheduler.DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 5 took 0.000594 seconds
2025-03-26 04:41:16,815 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Merging stage rdd profiles: Set()
2025-03-26 04:41:16,823 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Got job 0 (take at DeveloperApiExample.scala:127) with 1 output partitions
2025-03-26 04:41:16,823 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 0 (take at DeveloperApiExample.scala:127)
2025-03-26 04:41:16,823 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()
2025-03-26 04:41:16,824 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Missing parents: List()
2025-03-26 04:41:16,825 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: submitStage(ResultStage 0 (name=take at DeveloperApiExample.scala:127;jobs=0))
2025-03-26 04:41:16,825 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: missing: List()
2025-03-26 04:41:16,833 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at Predictor.scala:185), which has no missing parents
2025-03-26 04:41:16,833 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: submitMissingTasks(ResultStage 0)
2025-03-26 04:41:16,864 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.0 KiB, free 2004.6 MiB)
2025-03-26 04:41:16,865 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Put block broadcast_0 locally took 13 ms
2025-03-26 04:41:16,866 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Putting block broadcast_0 without replication took 14 ms
2025-03-26 04:41:16,890 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 2004.6 MiB)
2025-03-26 04:41:16,891 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(driver, slave0, 39591, None)
2025-03-26 04:41:16,891 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on slave0:39591 (size: 9.4 KiB, free: 2004.6 MiB)
2025-03-26 04:41:16,898 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
2025-03-26 04:41:16,898 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Told master about block broadcast_0_piece0
2025-03-26 04:41:16,899 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Put block broadcast_0_piece0 locally took 9 ms
2025-03-26 04:41:16,899 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Putting block broadcast_0_piece0 without replication took 9 ms
2025-03-26 04:41:16,899 INFO [dag-scheduler-event-loop] org.apache.spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
2025-03-26 04:41:16,910 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at Predictor.scala:185) (first 15 tasks are for partitions Vector(0))
2025-03-26 04:41:16,911 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Adding task set 0.0 with 1 tasks resource profile 0
2025-03-26 04:41:16,922 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Epoch for TaskSet 0.0: 0
2025-03-26 04:41:16,923 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Adding pending tasks took 1 ms
2025-03-26 04:41:16,925 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2025-03-26 04:41:16,927 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-26 04:41:16,942 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (slave1, executor 2, partition 0, PROCESS_LOCAL, 4702 bytes) taskResourceAssignments Map()
2025-03-26 04:41:16,951 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
2025-03-26 04:41:16,954 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Launching task 0 on executor id: 2 hostname: slave1.
2025-03-26 04:41:16,958 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 5149]
2025-03-26 04:41:16,958 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:16,989 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 1024B
2025-03-26 04:41:16,989 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 618B
2025-03-26 04:41:16,993 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:17,111 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 338B
2025-03-26 04:41:17,119 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:17,119 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 760]
2025-03-26 04:41:17,120 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:17,139 DEBUG [shuffle-server-7-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.16:33396.
2025-03-26 04:41:17,140 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] REGISTERED
2025-03-26 04:41:17,140 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] ACTIVE
2025-03-26 04:41:17,143 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] READ 92B
2025-03-26 04:41:17,169 DEBUG [shuffle-server-7-1] org.apache.spark.storage.BlockManager: Getting local block broadcast_0_piece0 as bytes
2025-03-26 04:41:17,170 DEBUG [shuffle-server-7-1] org.apache.spark.storage.BlockManager: Level for block broadcast_0_piece0 is StorageLevel(disk, memory, 1 replicas)
2025-03-26 04:41:17,174 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 13]
2025-03-26 04:41:17,175 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] FLUSH
2025-03-26 04:41:17,175 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] READ COMPLETE
2025-03-26 04:41:17,180 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] READ 21B
2025-03-26 04:41:17,182 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 9656]
2025-03-26 04:41:17,182 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] FLUSH
2025-03-26 04:41:17,183 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] READ COMPLETE
2025-03-26 04:41:17,198 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 194B
2025-03-26 04:41:17,199 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:17,199 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(2, slave1, 46211, None)
2025-03-26 04:41:17,200 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on slave1:46211 (size: 9.4 KiB, free: 912.3 MiB)
2025-03-26 04:41:17,200 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:41:17,200 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:17,367 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root: closed
2025-03-26 04:41:17,367 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root: stopped, remaining connections 1
2025-03-26 04:41:18,003 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000066425/3000.
2025-03-26 04:41:18,004 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:41:18,004 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 3, executorsStarting: 0
2025-03-26 04:41:18,004 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #12 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:41:18,006 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #12
2025-03-26 04:41:18,006 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-26 04:41:19,546 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ 3069B
2025-03-26 04:41:19,547 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:19,554 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2625 ms on slave1 (executor 2) (1/1)
2025-03-26 04:41:19,555 INFO [task-result-getter-0] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-26 04:41:19,559 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: ResultStage 0 (take at DeveloperApiExample.scala:127) finished in 2.718 s
2025-03-26 04:41:19,561 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: After removal of stage 0, remaining stages = 0
2025-03-26 04:41:19,562 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-26 04:41:19,563 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Killing all running tasks in stage 0: Stage finished
2025-03-26 04:41:19,564 INFO [Driver] org.apache.spark.scheduler.DAGScheduler: Job 0 finished: take at DeveloperApiExample.scala:127, took 2.751686 s
2025-03-26 04:41:19,590 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegressionModel: Input schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}}]}
2025-03-26 04:41:19,601 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegressionModel: Expected output schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}},{"name":"prediction","type":"double","nullable":false,"metadata":{"ml_attr":{"type":"nominal","num_vals":2}}},{"name":"rawPrediction","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":false,"metadata":{"ml_attr":{"num_attrs":2}}}]}
2025-03-26 04:41:19,627 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'features to features#14
2025-03-26 04:41:19,646 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'rawPrediction to rawPrediction#19
2025-03-26 04:41:19,666 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'features to features#14
2025-03-26 04:41:19,666 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#13
2025-03-26 04:41:19,666 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'prediction to prediction#26
2025-03-26 04:41:19,706 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for newInstance(class org.apache.spark.ml.linalg.VectorUDT).serialize:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private boolean resultIsNull_0;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private org.apache.spark.ml.linalg.Vector[] mutableStateArray_0 = new org.apache.spark.ml.linalg.Vector[1];
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */
/* 016 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 017 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_1[0], 4);
/* 018 */     mutableStateArray_2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 4);
/* 019 */     mutableStateArray_2[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 8);
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public void initialize(int partitionIndex) {
/* 024 */
/* 025 */   }
/* 026 */
/* 027 */   // Scala.Function1 need this
/* 028 */   public java.lang.Object apply(java.lang.Object row) {
/* 029 */     return apply((InternalRow) row);
/* 030 */   }
/* 031 */
/* 032 */   public UnsafeRow apply(InternalRow i) {
/* 033 */     mutableStateArray_1[0].reset();
/* 034 */
/* 035 */
/* 036 */     mutableStateArray_1[0].zeroOutNullBytes();
/* 037 */
/* 038 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 039 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 040 */     boolean isNull_0 = true;
/* 041 */     InternalRow value_0 = null;
/* 042 */     resultIsNull_0 = false;
/* 043 */     if (!resultIsNull_0) {
/* 044 */       boolean isNull_2 = i.isNullAt(0);
/* 045 */       org.apache.spark.ml.linalg.Vector value_2 = isNull_2 ?
/* 046 */       null : ((org.apache.spark.ml.linalg.Vector)i.get(0, null));
/* 047 */       resultIsNull_0 = isNull_2;
/* 048 */       mutableStateArray_0[0] = value_2;
/* 049 */     }
/* 050 */
/* 051 */     isNull_0 = resultIsNull_0;
/* 052 */     if (!isNull_0) {
/* 053 */
/* 054 */       Object funcResult_0 = null;
/* 055 */       funcResult_0 = value_1.serialize(mutableStateArray_0[0]);
/* 056 */
/* 057 */       if (funcResult_0 != null) {
/* 058 */         value_0 = (InternalRow) funcResult_0;
/* 059 */       } else {
/* 060 */         isNull_0 = true;
/* 061 */       }
/* 062 */
/* 063 */
/* 064 */     }
/* 065 */     if (isNull_0) {
/* 066 */       mutableStateArray_1[0].setNullAt(0);
/* 067 */     } else {
/* 068 */       final InternalRow tmpInput_0 = value_0;
/* 069 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 070 */         mutableStateArray_1[0].write(0, (UnsafeRow) tmpInput_0);
/* 071 */       } else {
/* 072 */         // Remember the current cursor so that we can calculate how many bytes are
/* 073 */         // written later.
/* 074 */         final int previousCursor_0 = mutableStateArray_1[0].cursor();
/* 075 */
/* 076 */         mutableStateArray_1[1].resetRowWriter();
/* 077 */
/* 078 */
/* 079 */         mutableStateArray_1[1].write(0, (tmpInput_0.getByte(0)));
/* 080 */
/* 081 */
/* 082 */         if ((tmpInput_0.isNullAt(1))) {
/* 083 */           mutableStateArray_1[1].setNullAt(1);
/* 084 */         } else {
/* 085 */           mutableStateArray_1[1].write(1, (tmpInput_0.getInt(1)));
/* 086 */         }
/* 087 */
/* 088 */
/* 089 */         if ((tmpInput_0.isNullAt(2))) {
/* 090 */           mutableStateArray_1[1].setNullAt(2);
/* 091 */         } else {
/* 092 */           // Remember the current cursor so that we can calculate how many bytes are
/* 093 */           // written later.
/* 094 */           final int previousCursor_1 = mutableStateArray_1[1].cursor();
/* 095 */
/* 096 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 097 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 098 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_1);
/* 099 */           } else {
/* 100 */             final int numElements_0 = tmpInput_1.numElements();
/* 101 */             mutableStateArray_2[0].initialize(numElements_0);
/* 102 */
/* 103 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 104 */               mutableStateArray_2[0].write(index_0, tmpInput_1.getInt(index_0));
/* 105 */             }
/* 106 */           }
/* 107 */
/* 108 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 109 */         }
/* 110 */
/* 111 */
/* 112 */         if ((tmpInput_0.isNullAt(3))) {
/* 113 */           mutableStateArray_1[1].setNullAt(3);
/* 114 */         } else {
/* 115 */           // Remember the current cursor so that we can calculate how many bytes are
/* 116 */           // written later.
/* 117 */           final int previousCursor_2 = mutableStateArray_1[1].cursor();
/* 118 */
/* 119 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 120 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 121 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_2);
/* 122 */           } else {
/* 123 */             final int numElements_1 = tmpInput_2.numElements();
/* 124 */             mutableStateArray_2[1].initialize(numElements_1);
/* 125 */
/* 126 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 127 */               mutableStateArray_2[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 128 */             }
/* 129 */           }
/* 130 */
/* 131 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 132 */         }
/* 133 */
/* 134 */
/* 135 */         mutableStateArray_1[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 136 */       }
/* 137 */     }
/* 138 */     return (mutableStateArray_1[0].getRow());
/* 139 */   }
/* 140 */
/* 141 */
/* 142 */ }

2025-03-26 04:41:19,712 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private boolean resultIsNull_0;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private org.apache.spark.ml.linalg.Vector[] mutableStateArray_0 = new org.apache.spark.ml.linalg.Vector[1];
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */
/* 016 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 017 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_1[0], 4);
/* 018 */     mutableStateArray_2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 4);
/* 019 */     mutableStateArray_2[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 8);
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public void initialize(int partitionIndex) {
/* 024 */
/* 025 */   }
/* 026 */
/* 027 */   // Scala.Function1 need this
/* 028 */   public java.lang.Object apply(java.lang.Object row) {
/* 029 */     return apply((InternalRow) row);
/* 030 */   }
/* 031 */
/* 032 */   public UnsafeRow apply(InternalRow i) {
/* 033 */     mutableStateArray_1[0].reset();
/* 034 */
/* 035 */
/* 036 */     mutableStateArray_1[0].zeroOutNullBytes();
/* 037 */
/* 038 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 039 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 040 */     boolean isNull_0 = true;
/* 041 */     InternalRow value_0 = null;
/* 042 */     resultIsNull_0 = false;
/* 043 */     if (!resultIsNull_0) {
/* 044 */       boolean isNull_2 = i.isNullAt(0);
/* 045 */       org.apache.spark.ml.linalg.Vector value_2 = isNull_2 ?
/* 046 */       null : ((org.apache.spark.ml.linalg.Vector)i.get(0, null));
/* 047 */       resultIsNull_0 = isNull_2;
/* 048 */       mutableStateArray_0[0] = value_2;
/* 049 */     }
/* 050 */
/* 051 */     isNull_0 = resultIsNull_0;
/* 052 */     if (!isNull_0) {
/* 053 */
/* 054 */       Object funcResult_0 = null;
/* 055 */       funcResult_0 = value_1.serialize(mutableStateArray_0[0]);
/* 056 */
/* 057 */       if (funcResult_0 != null) {
/* 058 */         value_0 = (InternalRow) funcResult_0;
/* 059 */       } else {
/* 060 */         isNull_0 = true;
/* 061 */       }
/* 062 */
/* 063 */
/* 064 */     }
/* 065 */     if (isNull_0) {
/* 066 */       mutableStateArray_1[0].setNullAt(0);
/* 067 */     } else {
/* 068 */       final InternalRow tmpInput_0 = value_0;
/* 069 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 070 */         mutableStateArray_1[0].write(0, (UnsafeRow) tmpInput_0);
/* 071 */       } else {
/* 072 */         // Remember the current cursor so that we can calculate how many bytes are
/* 073 */         // written later.
/* 074 */         final int previousCursor_0 = mutableStateArray_1[0].cursor();
/* 075 */
/* 076 */         mutableStateArray_1[1].resetRowWriter();
/* 077 */
/* 078 */
/* 079 */         mutableStateArray_1[1].write(0, (tmpInput_0.getByte(0)));
/* 080 */
/* 081 */
/* 082 */         if ((tmpInput_0.isNullAt(1))) {
/* 083 */           mutableStateArray_1[1].setNullAt(1);
/* 084 */         } else {
/* 085 */           mutableStateArray_1[1].write(1, (tmpInput_0.getInt(1)));
/* 086 */         }
/* 087 */
/* 088 */
/* 089 */         if ((tmpInput_0.isNullAt(2))) {
/* 090 */           mutableStateArray_1[1].setNullAt(2);
/* 091 */         } else {
/* 092 */           // Remember the current cursor so that we can calculate how many bytes are
/* 093 */           // written later.
/* 094 */           final int previousCursor_1 = mutableStateArray_1[1].cursor();
/* 095 */
/* 096 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 097 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 098 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_1);
/* 099 */           } else {
/* 100 */             final int numElements_0 = tmpInput_1.numElements();
/* 101 */             mutableStateArray_2[0].initialize(numElements_0);
/* 102 */
/* 103 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 104 */               mutableStateArray_2[0].write(index_0, tmpInput_1.getInt(index_0));
/* 105 */             }
/* 106 */           }
/* 107 */
/* 108 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 109 */         }
/* 110 */
/* 111 */
/* 112 */         if ((tmpInput_0.isNullAt(3))) {
/* 113 */           mutableStateArray_1[1].setNullAt(3);
/* 114 */         } else {
/* 115 */           // Remember the current cursor so that we can calculate how many bytes are
/* 116 */           // written later.
/* 117 */           final int previousCursor_2 = mutableStateArray_1[1].cursor();
/* 118 */
/* 119 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 120 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 121 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_2);
/* 122 */           } else {
/* 123 */             final int numElements_1 = tmpInput_2.numElements();
/* 124 */             mutableStateArray_2[1].initialize(numElements_1);
/* 125 */
/* 126 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 127 */               mutableStateArray_2[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 128 */             }
/* 129 */           }
/* 130 */
/* 131 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 132 */         }
/* 133 */
/* 134 */
/* 135 */         mutableStateArray_1[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 136 */       }
/* 137 */     }
/* 138 */     return (mutableStateArray_1[0].getRow());
/* 139 */   }
/* 140 */
/* 141 */
/* 142 */ }

2025-03-26 04:41:19,725 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 19.091396 ms
2025-03-26 04:41:19,734 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection: code for newInstance(class org.apache.spark.ml.linalg.VectorUDT).deserialize:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 026 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 027 */     boolean isNull_0 = true;
/* 028 */     org.apache.spark.ml.linalg.Vector value_0 = null;
/* 029 */     resultIsNull_0 = false;
/* 030 */     if (!resultIsNull_0) {
/* 031 */       boolean isNull_2 = i.isNullAt(0);
/* 032 */       InternalRow value_2 = isNull_2 ?
/* 033 */       null : (i.getStruct(0, 4));
/* 034 */       resultIsNull_0 = isNull_2;
/* 035 */       mutableStateArray_0[0] = value_2;
/* 036 */     }
/* 037 */
/* 038 */     isNull_0 = resultIsNull_0;
/* 039 */     if (!isNull_0) {
/* 040 */
/* 041 */       Object funcResult_0 = null;
/* 042 */       funcResult_0 = value_1.deserialize(mutableStateArray_0[0]);
/* 043 */
/* 044 */       if (funcResult_0 != null) {
/* 045 */         value_0 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 046 */       } else {
/* 047 */         isNull_0 = true;
/* 048 */       }
/* 049 */
/* 050 */
/* 051 */     }
/* 052 */     if (isNull_0) {
/* 053 */       mutableRow.setNullAt(0);
/* 054 */     } else {
/* 055 */
/* 056 */       mutableRow.update(0, value_0);
/* 057 */     }
/* 058 */
/* 059 */     return mutableRow;
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }

2025-03-26 04:41:19,735 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 026 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 027 */     boolean isNull_0 = true;
/* 028 */     org.apache.spark.ml.linalg.Vector value_0 = null;
/* 029 */     resultIsNull_0 = false;
/* 030 */     if (!resultIsNull_0) {
/* 031 */       boolean isNull_2 = i.isNullAt(0);
/* 032 */       InternalRow value_2 = isNull_2 ?
/* 033 */       null : (i.getStruct(0, 4));
/* 034 */       resultIsNull_0 = isNull_2;
/* 035 */       mutableStateArray_0[0] = value_2;
/* 036 */     }
/* 037 */
/* 038 */     isNull_0 = resultIsNull_0;
/* 039 */     if (!isNull_0) {
/* 040 */
/* 041 */       Object funcResult_0 = null;
/* 042 */       funcResult_0 = value_1.deserialize(mutableStateArray_0[0]);
/* 043 */
/* 044 */       if (funcResult_0 != null) {
/* 045 */         value_0 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 046 */       } else {
/* 047 */         isNull_0 = true;
/* 048 */       }
/* 049 */
/* 050 */
/* 051 */     }
/* 052 */     if (isNull_0) {
/* 053 */       mutableRow.setNullAt(0);
/* 054 */     } else {
/* 055 */
/* 056 */       mutableRow.update(0, value_0);
/* 057 */     }
/* 058 */
/* 059 */     return mutableRow;
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }

2025-03-26 04:41:19,741 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.313728 ms
2025-03-26 04:41:19,745 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for input[0, double, false]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     double value_0 = i.getDouble(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

2025-03-26 04:41:19,745 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     double value_0 = i.getDouble(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

2025-03-26 04:41:19,750 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 4.7267 ms
2025-03-26 04:41:19,779 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for input[0, vector, true],input[1, double, false],input[2, double, false]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */     writeFields_0_0(i);
/* 035 */     writeFields_0_1(i);
/* 036 */     return (mutableStateArray_0[0].getRow());
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */   private void writeFields_0_1(InternalRow i) {
/* 041 */
/* 042 */     double value_1 = i.getDouble(1);
/* 043 */     mutableStateArray_0[0].write(1, value_1);
/* 044 */
/* 045 */     double value_2 = i.getDouble(2);
/* 046 */     mutableStateArray_0[0].write(2, value_2);
/* 047 */
/* 048 */   }
/* 049 */
/* 050 */
/* 051 */   private void writeFields_0_0(InternalRow i) {
/* 052 */
/* 053 */     boolean isNull_0 = i.isNullAt(0);
/* 054 */     InternalRow value_0 = isNull_0 ?
/* 055 */     null : (i.getStruct(0, 4));
/* 056 */     if (isNull_0) {
/* 057 */       mutableStateArray_0[0].setNullAt(0);
/* 058 */     } else {
/* 059 */       final InternalRow tmpInput_0 = value_0;
/* 060 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 061 */         mutableStateArray_0[0].write(0, (UnsafeRow) tmpInput_0);
/* 062 */       } else {
/* 063 */         // Remember the current cursor so that we can calculate how many bytes are
/* 064 */         // written later.
/* 065 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 066 */
/* 067 */         mutableStateArray_0[1].resetRowWriter();
/* 068 */
/* 069 */
/* 070 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 071 */
/* 072 */
/* 073 */         if ((tmpInput_0.isNullAt(1))) {
/* 074 */           mutableStateArray_0[1].setNullAt(1);
/* 075 */         } else {
/* 076 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 077 */         }
/* 078 */
/* 079 */
/* 080 */         if ((tmpInput_0.isNullAt(2))) {
/* 081 */           mutableStateArray_0[1].setNullAt(2);
/* 082 */         } else {
/* 083 */           // Remember the current cursor so that we can calculate how many bytes are
/* 084 */           // written later.
/* 085 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 086 */
/* 087 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 088 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 089 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 090 */           } else {
/* 091 */             final int numElements_0 = tmpInput_1.numElements();
/* 092 */             mutableStateArray_1[0].initialize(numElements_0);
/* 093 */
/* 094 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 095 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 096 */             }
/* 097 */           }
/* 098 */
/* 099 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 100 */         }
/* 101 */
/* 102 */
/* 103 */         if ((tmpInput_0.isNullAt(3))) {
/* 104 */           mutableStateArray_0[1].setNullAt(3);
/* 105 */         } else {
/* 106 */           // Remember the current cursor so that we can calculate how many bytes are
/* 107 */           // written later.
/* 108 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 109 */
/* 110 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 111 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 112 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 113 */           } else {
/* 114 */             final int numElements_1 = tmpInput_2.numElements();
/* 115 */             mutableStateArray_1[1].initialize(numElements_1);
/* 116 */
/* 117 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 118 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 119 */             }
/* 120 */           }
/* 121 */
/* 122 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 123 */         }
/* 124 */
/* 125 */
/* 126 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 127 */       }
/* 128 */     }
/* 129 */
/* 130 */   }
/* 131 */
/* 132 */ }

2025-03-26 04:41:19,779 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */     writeFields_0_0(i);
/* 035 */     writeFields_0_1(i);
/* 036 */     return (mutableStateArray_0[0].getRow());
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */   private void writeFields_0_1(InternalRow i) {
/* 041 */
/* 042 */     double value_1 = i.getDouble(1);
/* 043 */     mutableStateArray_0[0].write(1, value_1);
/* 044 */
/* 045 */     double value_2 = i.getDouble(2);
/* 046 */     mutableStateArray_0[0].write(2, value_2);
/* 047 */
/* 048 */   }
/* 049 */
/* 050 */
/* 051 */   private void writeFields_0_0(InternalRow i) {
/* 052 */
/* 053 */     boolean isNull_0 = i.isNullAt(0);
/* 054 */     InternalRow value_0 = isNull_0 ?
/* 055 */     null : (i.getStruct(0, 4));
/* 056 */     if (isNull_0) {
/* 057 */       mutableStateArray_0[0].setNullAt(0);
/* 058 */     } else {
/* 059 */       final InternalRow tmpInput_0 = value_0;
/* 060 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 061 */         mutableStateArray_0[0].write(0, (UnsafeRow) tmpInput_0);
/* 062 */       } else {
/* 063 */         // Remember the current cursor so that we can calculate how many bytes are
/* 064 */         // written later.
/* 065 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 066 */
/* 067 */         mutableStateArray_0[1].resetRowWriter();
/* 068 */
/* 069 */
/* 070 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 071 */
/* 072 */
/* 073 */         if ((tmpInput_0.isNullAt(1))) {
/* 074 */           mutableStateArray_0[1].setNullAt(1);
/* 075 */         } else {
/* 076 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 077 */         }
/* 078 */
/* 079 */
/* 080 */         if ((tmpInput_0.isNullAt(2))) {
/* 081 */           mutableStateArray_0[1].setNullAt(2);
/* 082 */         } else {
/* 083 */           // Remember the current cursor so that we can calculate how many bytes are
/* 084 */           // written later.
/* 085 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 086 */
/* 087 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 088 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 089 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 090 */           } else {
/* 091 */             final int numElements_0 = tmpInput_1.numElements();
/* 092 */             mutableStateArray_1[0].initialize(numElements_0);
/* 093 */
/* 094 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 095 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 096 */             }
/* 097 */           }
/* 098 */
/* 099 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 100 */         }
/* 101 */
/* 102 */
/* 103 */         if ((tmpInput_0.isNullAt(3))) {
/* 104 */           mutableStateArray_0[1].setNullAt(3);
/* 105 */         } else {
/* 106 */           // Remember the current cursor so that we can calculate how many bytes are
/* 107 */           // written later.
/* 108 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 109 */
/* 110 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 111 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 112 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 113 */           } else {
/* 114 */             final int numElements_1 = tmpInput_2.numElements();
/* 115 */             mutableStateArray_1[1].initialize(numElements_1);
/* 116 */
/* 117 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 118 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 119 */             }
/* 120 */           }
/* 121 */
/* 122 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 123 */         }
/* 124 */
/* 125 */
/* 126 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 127 */       }
/* 128 */     }
/* 129 */
/* 130 */   }
/* 131 */
/* 132 */ }

2025-03-26 04:41:19,791 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.447281 ms
2025-03-26 04:41:19,797 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection: code for createexternalrow(newInstance(class org.apache.spark.ml.linalg.VectorUDT).deserialize, input[1, double, false], input[2, double, false], StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true), StructField(label,DoubleType,false), StructField(prediction,DoubleType,false)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     org.apache.spark.sql.Row value_6 = CreateExternalRow_0(i);
/* 026 */     if (false) {
/* 027 */       mutableRow.setNullAt(0);
/* 028 */     } else {
/* 029 */
/* 030 */       mutableRow.update(0, value_6);
/* 031 */     }
/* 032 */
/* 033 */     return mutableRow;
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */   private org.apache.spark.sql.Row CreateExternalRow_0(InternalRow i) {
/* 038 */     Object[] values_0 = new Object[3];
/* 039 */
/* 040 */     final org.apache.spark.ml.linalg.VectorUDT value_2 = false ?
/* 041 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 042 */     boolean isNull_1 = true;
/* 043 */     org.apache.spark.ml.linalg.Vector value_1 = null;
/* 044 */     resultIsNull_0 = false;
/* 045 */     if (!resultIsNull_0) {
/* 046 */       boolean isNull_3 = i.isNullAt(0);
/* 047 */       InternalRow value_3 = isNull_3 ?
/* 048 */       null : (i.getStruct(0, 4));
/* 049 */       resultIsNull_0 = isNull_3;
/* 050 */       mutableStateArray_0[0] = value_3;
/* 051 */     }
/* 052 */
/* 053 */     isNull_1 = resultIsNull_0;
/* 054 */     if (!isNull_1) {
/* 055 */
/* 056 */       Object funcResult_0 = null;
/* 057 */       funcResult_0 = value_2.deserialize(mutableStateArray_0[0]);
/* 058 */
/* 059 */       if (funcResult_0 != null) {
/* 060 */         value_1 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 061 */       } else {
/* 062 */         isNull_1 = true;
/* 063 */       }
/* 064 */
/* 065 */
/* 066 */     }
/* 067 */     if (isNull_1) {
/* 068 */       values_0[0] = null;
/* 069 */     } else {
/* 070 */       values_0[0] = value_1;
/* 071 */     }
/* 072 */
/* 073 */     double value_4 = i.getDouble(1);
/* 074 */     if (false) {
/* 075 */       values_0[1] = null;
/* 076 */     } else {
/* 077 */       values_0[1] = value_4;
/* 078 */     }
/* 079 */
/* 080 */     double value_5 = i.getDouble(2);
/* 081 */     if (false) {
/* 082 */       values_0[2] = null;
/* 083 */     } else {
/* 084 */       values_0[2] = value_5;
/* 085 */     }
/* 086 */
/* 087 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 088 */
/* 089 */     return value_0;
/* 090 */   }
/* 091 */
/* 092 */ }

2025-03-26 04:41:19,798 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     org.apache.spark.sql.Row value_6 = CreateExternalRow_0(i);
/* 026 */     if (false) {
/* 027 */       mutableRow.setNullAt(0);
/* 028 */     } else {
/* 029 */
/* 030 */       mutableRow.update(0, value_6);
/* 031 */     }
/* 032 */
/* 033 */     return mutableRow;
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */   private org.apache.spark.sql.Row CreateExternalRow_0(InternalRow i) {
/* 038 */     Object[] values_0 = new Object[3];
/* 039 */
/* 040 */     final org.apache.spark.ml.linalg.VectorUDT value_2 = false ?
/* 041 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 042 */     boolean isNull_1 = true;
/* 043 */     org.apache.spark.ml.linalg.Vector value_1 = null;
/* 044 */     resultIsNull_0 = false;
/* 045 */     if (!resultIsNull_0) {
/* 046 */       boolean isNull_3 = i.isNullAt(0);
/* 047 */       InternalRow value_3 = isNull_3 ?
/* 048 */       null : (i.getStruct(0, 4));
/* 049 */       resultIsNull_0 = isNull_3;
/* 050 */       mutableStateArray_0[0] = value_3;
/* 051 */     }
/* 052 */
/* 053 */     isNull_1 = resultIsNull_0;
/* 054 */     if (!isNull_1) {
/* 055 */
/* 056 */       Object funcResult_0 = null;
/* 057 */       funcResult_0 = value_2.deserialize(mutableStateArray_0[0]);
/* 058 */
/* 059 */       if (funcResult_0 != null) {
/* 060 */         value_1 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 061 */       } else {
/* 062 */         isNull_1 = true;
/* 063 */       }
/* 064 */
/* 065 */
/* 066 */     }
/* 067 */     if (isNull_1) {
/* 068 */       values_0[0] = null;
/* 069 */     } else {
/* 070 */       values_0[0] = value_1;
/* 071 */     }
/* 072 */
/* 073 */     double value_4 = i.getDouble(1);
/* 074 */     if (false) {
/* 075 */       values_0[1] = null;
/* 076 */     } else {
/* 077 */       values_0[1] = value_4;
/* 078 */     }
/* 079 */
/* 080 */     double value_5 = i.getDouble(2);
/* 081 */     if (false) {
/* 082 */       values_0[2] = null;
/* 083 */     } else {
/* 084 */       values_0[2] = value_5;
/* 085 */     }
/* 086 */
/* 087 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 088 */
/* 089 */     return value_0;
/* 090 */   }
/* 091 */
/* 092 */ }

2025-03-26 04:41:19,805 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 7.785605 ms
2025-03-26 04:41:19,820 INFO [Driver] org.apache.spark.ui.SparkUI: Stopped Spark web UI at http://slave0:34163
2025-03-26 04:41:19,824 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterSchedulerBackend: Shutting down all executors
2025-03-26 04:41:19,824 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
2025-03-26 04:41:19,825 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 122]
2025-03-26 04:41:19,825 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] FLUSH
2025-03-26 04:41:19,826 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 122]
2025-03-26 04:41:19,826 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] FLUSH
2025-03-26 04:41:19,826 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 122]
2025-03-26 04:41:19,826 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] FLUSH
2025-03-26 04:41:19,826 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ 135B
2025-03-26 04:41:19,829 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] READ COMPLETE
2025-03-26 04:41:19,831 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Driver commanded a shutdown
2025-03-26 04:41:19,836 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 - R:/172.20.1.16:33396] READ COMPLETE
2025-03-26 04:41:19,836 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 ! R:/172.20.1.16:33396] INACTIVE
2025-03-26 04:41:19,836 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0x37cc454f, L:/172.20.1.15:39591 ! R:/172.20.1.16:33396] UNREGISTERED
2025-03-26 04:41:19,842 INFO [dispatcher-event-loop-1] org.apache.spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-03-26 04:41:19,851 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 - R:/172.20.1.16:37104] READ COMPLETE
2025-03-26 04:41:19,851 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 ! R:/172.20.1.16:37104] INACTIVE
2025-03-26 04:41:19,851 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xed8edd22, L:/172.20.1.15:38775 ! R:/172.20.1.16:37104] UNREGISTERED
2025-03-26 04:41:19,856 INFO [CoarseGrainedExecutorBackend-stop-executor] org.apache.spark.storage.memory.MemoryStore: MemoryStore cleared
2025-03-26 04:41:19,857 INFO [CoarseGrainedExecutorBackend-stop-executor] org.apache.spark.storage.BlockManager: BlockManager stopped
2025-03-26 04:41:19,860 INFO [Driver] org.apache.spark.storage.memory.MemoryStore: MemoryStore cleared
2025-03-26 04:41:19,860 INFO [Driver] org.apache.spark.storage.BlockManager: BlockManager stopped
2025-03-26 04:41:19,863 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 - R:slave0/172.20.1.15:38775] CLOSE
2025-03-26 04:41:19,863 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 ! R:slave0/172.20.1.15:38775] INACTIVE
2025-03-26 04:41:19,863 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 - R:/172.20.1.15:47096] READ COMPLETE
2025-03-26 04:41:19,863 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xadd217ff, L:/172.20.1.15:47096 ! R:slave0/172.20.1.15:38775] UNREGISTERED
2025-03-26 04:41:19,863 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 ! R:/172.20.1.15:47096] INACTIVE
2025-03-26 04:41:19,863 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x626bb555, L:/172.20.1.15:38775 ! R:/172.20.1.15:47096] UNREGISTERED
2025-03-26 04:41:19,873 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 - R:/172.20.1.17:33494] READ COMPLETE
2025-03-26 04:41:19,873 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 ! R:/172.20.1.17:33494] INACTIVE
2025-03-26 04:41:19,873 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xdaaf17bb, L:/172.20.1.15:38775 ! R:/172.20.1.17:33494] UNREGISTERED
2025-03-26 04:41:19,875 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: BlockManagerMaster stopped
2025-03-26 04:41:19,877 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-03-26 04:41:19,889 INFO [shutdown-hook-0] org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-26 04:41:19,890 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.011 seconds; Timeouts: 0
2025-03-26 04:41:19,897 INFO [Driver] org.apache.spark.SparkContext: Successfully stopped SparkContext
2025-03-26 04:41:19,897 INFO [Driver] org.apache.spark.deploy.yarn.ApplicationMaster: Final app status: SUCCEEDED, exitCode: 0
2025-03-26 04:41:19,901 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
2025-03-26 04:41:19,904 DEBUG [Driver] org.apache.spark.deploy.yarn.ApplicationMaster: shutting down reporter thread
2025-03-26 04:41:19,904 DEBUG [Driver] org.apache.spark.deploy.yarn.ApplicationMaster: Done running user class
2025-03-26 04:41:19,911 INFO [shutdown-hook-0] org.apache.spark.deploy.yarn.ApplicationMaster: Unregistering ApplicationMaster with SUCCEEDED
2025-03-26 04:41:19,914 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #13 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.finishApplicationMaster
2025-03-26 04:41:19,918 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #13
2025-03-26 04:41:19,918 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: finishApplicationMaster took 5ms
2025-03-26 04:41:19,919 INFO [shutdown-hook-0] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Waiting for application to be successfully unregistered.
2025-03-26 04:41:20,020 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #14 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.finishApplicationMaster
2025-03-26 04:41:20,021 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #14
2025-03-26 04:41:20,021 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: finishApplicationMaster took 1ms
2025-03-26 04:41:20,021 DEBUG [shutdown-hook-0] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl entered state STOPPED
2025-03-26 04:41:20,021 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: stopping client from cache: Client-2221fe05e0004349bd143c6ccc31e208
2025-03-26 04:41:20,022 INFO [shutdown-hook-0] org.apache.spark.deploy.yarn.ApplicationMaster: Deleting staging directory hdfs://master:9000/user/root/.sparkStaging/application_1742964012349_0001
2025-03-26 04:41:20,024 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:41:20,024 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.14:9000
2025-03-26 04:41:20,024 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.14:9000
2025-03-26 04:41:20,024 DEBUG [shutdown-hook-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@7cf204af]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy36.delete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:655)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy37.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1662)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:992)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:989)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:999)
	at org.apache.spark.deploy.yarn.ApplicationMaster.cleanupStagingDir(ApplicationMaster.scala:686)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$run$2(ApplicationMaster.scala:265)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:41:20,025 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:41:20,027 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSelector)
2025-03-26 04:41:20,027 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: tokens aren't supported for this protocol or user doesn't have one
2025-03-26 04:41:20,027 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Use SIMPLE authentication for protocol ClientNamenodeProtocolPB
2025-03-26 04:41:20,027 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

2025-03-26 04:41:20,036 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root sending #15 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete
2025-03-26 04:41:20,037 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root: starting, having connections 2
2025-03-26 04:41:20,044 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root got value #15
2025-03-26 04:41:20,044 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: delete took 20ms
2025-03-26 04:41:20,045 INFO [shutdown-hook-0] org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-26 04:41:20,046 INFO [shutdown-hook-0] org.apache.spark.util.ShutdownHookManager: Deleting directory /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964012349_0001/spark-3c59317d-32a2-4863-90fb-e8b5192f2585
2025-03-26 04:41:20,048 DEBUG [shutdown-hook-0] org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (root (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 2667ec7c
2025-03-26 04:41:20,048 DEBUG [shutdown-hook-0] org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 41057d13
2025-03-26 04:41:20,048 DEBUG [shutdown-hook-0] org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:1518)); Key: (root (auth:SIMPLE))@hdfs://master:9000; URI: hdfs://master:9000; Object Identity Hash: 1dbc5b4f
2025-03-26 04:41:20,048 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: stopping client from cache: Client-2221fe05e0004349bd143c6ccc31e208
2025-03-26 04:41:20,051 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.145 seconds; Timeouts: 0
2025-03-26 04:41:20,074 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
