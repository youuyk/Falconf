2025-03-26 02:23:32,678 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NameNode STARTUP_MSG:   host = master/172.20.1.10 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:23:32,683 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:23:32,751 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2025-03-26 02:23:32,840 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:23:32,910 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2025-03-26 02:23:32,910 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:23:32,919 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use master:9000 to access this namenode/service.
2025-03-26 02:23:32,919 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://master:9000
2025-03-26 02:23:33,054 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:23:33,060 INFO org.apache.hadoop.hdfs.DFSUtil: Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-03-26 02:23:33,062 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
2025-03-26 02:23:33,069 INFO org.eclipse.jetty.util.log: Logging initialized @658ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:23:33,129 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:33,133 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2025-03-26 02:23:33,138 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:23:33,139 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2025-03-26 02:23:33,140 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:23:33,140 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:23:33,142 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2025-03-26 02:23:33,142 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-03-26 02:23:33,142 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-03-26 02:23:33,161 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2025-03-26 02:23:33,166 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2025-03-26 02:23:33,167 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:23:33,183 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:23:33,183 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:23:33,184 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:23:33,193 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:33,194 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b4c50bc{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:23:33,195 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@79207381{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:23:33,229 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@c7045b9{hdfs,/,file:///hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/hdfs}
2025-03-26 02:23:33,232 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@17503f6b{HTTP/1.1, (http/1.1)}{0.0.0.0:9870}
2025-03-26 02:23:33,232 INFO org.eclipse.jetty.server.Server: Started @820ms
2025-03-26 02:23:33,379 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-03-26 02:23:33,379 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-03-26 02:23:33,405 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2025-03-26 02:23:33,428 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2025-03-26 02:23:33,429 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2025-03-26 02:23:33,429 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2025-03-26 02:23:33,433 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2025-03-26 02:23:33,433 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)
2025-03-26 02:23:33,433 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled    = true
2025-03-26 02:23:33,433 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isStoragePolicyEnabled = true
2025-03-26 02:23:33,433 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup             = supergroup
2025-03-26 02:23:33,448 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:23:33,452 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.11" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:23:33,452 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.12" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:23:33,452 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.13" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:23:33,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-26 02:23:33,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-26 02:23:33,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2025 Mar 26 02:23:33
2025-03-26 02:23:33,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-26 02:23:33,456 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2025-03-26 02:23:33,456 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:23:33,457 INFO org.apache.hadoop.util.GSet: 2.0% max memory 910.5 MB = 18.2 MB
2025-03-26 02:23:33,457 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2025-03-26 02:23:33,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Storage policy satisfier is disabled
2025-03-26 02:23:33,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2025-03-26 02:23:33,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2025-03-26 02:23:33,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2025-03-26 02:23:33,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2025-03-26 02:23:33,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2025-03-26 02:23:33,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2025-03-26 02:23:33,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2025-03-26 02:23:33,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2025-03-26 02:23:33,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2025-03-26 02:23:33,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2025-03-26 02:23:33,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
2025-03-26 02:23:33,477 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2025-03-26 02:23:33,477 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2025-03-26 02:23:33,477 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2025-03-26 02:23:33,477 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2025-03-26 02:23:33,484 INFO org.apache.hadoop.util.GSet: 1.0% max memory 910.5 MB = 9.1 MB
2025-03-26 02:23:33,484 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2025-03-26 02:23:33,484 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:23:33,484 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2025-03-26 02:23:33,486 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? true
2025-03-26 02:23:33,486 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2025-03-26 02:23:33,486 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2025-03-26 02:23:33,486 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2025-03-26 02:23:33,489 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-03-26 02:23:33,490 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2025-03-26 02:23:33,492 INFO org.apache.hadoop.util.GSet: 0.25% max memory 910.5 MB = 2.3 MB
2025-03-26 02:23:33,492 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2025-03-26 02:23:33,492 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:23:33,492 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2025-03-26 02:23:33,503 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2025-03-26 02:23:33,503 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-26 02:23:33,504 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-26 02:23:33,506 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2025-03-26 02:23:33,506 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2025-03-26 02:23:33,507 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 910.5 MB = 279.7 KB
2025-03-26 02:23:33,507 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2025-03-26 02:23:33,507 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:23:33,507 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2025-03-26 02:23:33,649 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/name/in_use.lock acquired by nodename 261@master
2025-03-26 02:23:33,664 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /data/tmp/dfs/name/current
2025-03-26 02:23:33,665 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2025-03-26 02:23:33,665 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/data/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2025-03-26 02:23:33,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2025-03-26 02:23:33,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
2025-03-26 02:23:33,703 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-26 02:23:33,706 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/tmp/dfs/name/current/fsimage_0000000000000000000
2025-03-26 02:23:33,706 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2025-03-26 02:23:33,709 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2025-03-26 02:23:33,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2025-03-26 02:23:34,238 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 730 msecs
2025-03-26 02:23:34,238 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2025-03-26 02:23:34,321 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master:9000
2025-03-26 02:23:34,322 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Enable NameNode state context:false
2025-03-26 02:23:34,327 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:34,333 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2025-03-26 02:23:34,443 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2025-03-26 02:23:34,447 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2025-03-26 02:23:34,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor: Initialized the Default Decommission and Maintenance monitor
2025-03-26 02:23:34,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Start MarkedDeleteBlockScrubber thread
2025-03-26 02:23:34,454 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2025-03-26 02:23:34,454 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2025-03-26 02:23:34,454 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2025-03-26 02:23:34,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2025-03-26 02:23:34,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2025-03-26 02:23:34,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2025-03-26 02:23:34,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2025-03-26 02:23:34,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2025-03-26 02:23:34,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2025-03-26 02:23:34,522 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 51 msec
2025-03-26 02:23:34,523 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:34,550 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2025-03-26 02:23:34,583 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master/172.20.1.10:9000
2025-03-26 02:23:34,585 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 12 thread(s)
2025-03-26 02:23:34,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2025-03-26 02:23:34,606 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 21 milliseconds name space=1 storage space=0 storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2025-03-26 02:23:34,610 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2025-03-26 02:23:35,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave0/172.20.1.11 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:23:35,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave2/172.20.1.13 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:23:35,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting DataNode STARTUP_MSG:   host = slave1/172.20.1.12 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:23:35,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:23:35,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:23:35,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:23:35,346 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:23:35,354 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:23:35,376 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/data/tmp/dfs/data
2025-03-26 02:23:35,410 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:23:35,423 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:23:35,442 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:23:35,453 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:23:35,454 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:23:35,467 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:23:35,468 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:23:35,485 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2025-03-26 02:23:35,485 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:23:35,577 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:23:35,585 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:23:35,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave2
2025-03-26 02:23:35,589 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:23:35,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:23:35,595 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:23:35,599 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:23:35,603 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:23:35,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:23:35,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:23:35,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:23:35,606 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:23:35,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave0
2025-03-26 02:23:35,607 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2025-03-26 02:23:35,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is slave1
2025-03-26 02:23:35,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:23:35,610 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:23:35,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2025-03-26 02:23:35,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:23:35,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:23:35,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:23:35,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2025-03-26 02:23:35,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2025-03-26 02:23:35,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2025-03-26 02:23:35,631 INFO org.eclipse.jetty.util.log: Logging initialized @882ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:23:35,646 INFO org.eclipse.jetty.util.log: Logging initialized @883ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:23:35,648 INFO org.eclipse.jetty.util.log: Logging initialized @905ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:23:35,698 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:35,703 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:23:35,708 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:23:35,709 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:23:35,709 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:23:35,709 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:23:35,715 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:35,715 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:35,720 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:23:35,720 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2025-03-26 02:23:35,725 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:23:35,726 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:23:35,726 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:23:35,726 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:23:35,726 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:23:35,727 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2025-03-26 02:23:35,728 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:23:35,728 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:23:35,763 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35875
2025-03-26 02:23:35,764 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:23:35,778 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:23:35,779 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:23:35,779 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:23:35,781 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35287
2025-03-26 02:23:35,781 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:23:35,786 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34953
2025-03-26 02:23:35,787 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:23:35,788 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2a3888c1{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:23:35,789 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68f1b17f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:23:35,795 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:23:35,795 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:23:35,796 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:23:35,803 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:23:35,803 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:23:35,804 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2a3888c1{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:23:35,804 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68f1b17f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:23:35,804 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:23:35,812 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2a3888c1{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:23:35,812 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68f1b17f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:23:35,838 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@49964d75{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:23:35,842 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@49964d75{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:23:35,843 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@63eef88a{HTTP/1.1, (http/1.1)}{localhost:35875}
2025-03-26 02:23:35,844 INFO org.eclipse.jetty.server.Server: Started @1095ms
2025-03-26 02:23:35,848 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@63eef88a{HTTP/1.1, (http/1.1)}{localhost:35287}
2025-03-26 02:23:35,848 INFO org.eclipse.jetty.server.Server: Started @1105ms
2025-03-26 02:23:35,848 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@49964d75{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2025-03-26 02:23:35,853 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@63eef88a{HTTP/1.1, (http/1.1)}{localhost:34953}
2025-03-26 02:23:35,853 INFO org.eclipse.jetty.server.Server: Started @1090ms
2025-03-26 02:23:35,886 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:23:35,890 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:23:35,892 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2025-03-26 02:23:35,933 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:23:35,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:23:35,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:23:35,952 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:23:35,967 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:23:35,968 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2025-03-26 02:23:35,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:23:35,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:23:35,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2025-03-26 02:23:35,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2025-03-26 02:23:35,978 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:35,983 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:23:35,985 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:23:35,993 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:23:36,003 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:36,004 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:36,015 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:23:36,019 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2025-03-26 02:23:36,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:23:36,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:23:36,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2025-03-26 02:23:36,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:23:36,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:23:36,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000 starting to offer service
2025-03-26 02:23:36,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:23:36,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2025-03-26 02:23:36,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:23:36,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2025-03-26 02:23:36,183 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:36,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000 starting to offer service
2025-03-26 02:23:36,187 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:23:36,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000 starting to offer service
2025-03-26 02:23:36,192 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:36,192 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:23:36,211 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:36,211 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2025-03-26 02:23:36,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000
2025-03-26 02:23:36,348 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:23:36,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000
2025-03-26 02:23:36,350 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:23:36,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.20.1.10:9000
2025-03-26 02:23:36,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2025-03-26 02:23:36,434 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 94@slave0
2025-03-26 02:23:36,434 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 94@slave2
2025-03-26 02:23:36,434 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/data/in_use.lock acquired by nodename 97@slave1
2025-03-26 02:23:36,436 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-1ca7a827-c477-46b4-a666-508fe9657cc2 for directory /data/tmp/dfs/data
2025-03-26 02:23:36,436 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-78285236-5ee6-4952-9463-bd83c51c88fe for directory /data/tmp/dfs/data
2025-03-26 02:23:36,436 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-a133335d-0103-40b1-8216-843957ba2970 for directory /data/tmp/dfs/data
2025-03-26 02:23:36,436 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 424945276. Formatting...
2025-03-26 02:23:36,436 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 424945276. Formatting...
2025-03-26 02:23:36,436 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/data/tmp/dfs/data is not formatted for namespace 424945276. Formatting...
2025-03-26 02:23:36,607 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,607 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,607 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,607 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,608 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,608 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1623824107-172.20.1.10-1742955811035 is not formatted. Formatting ...
2025-03-26 02:23:36,608 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1623824107-172.20.1.10-1742955811035 is not formatted. Formatting ...
2025-03-26 02:23:36,608 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/data/tmp/dfs/data and block pool id BP-1623824107-172.20.1.10-1742955811035 is not formatted. Formatting ...
2025-03-26 02:23:36,608 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1623824107-172.20.1.10-1742955811035 directory /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035/current
2025-03-26 02:23:36,608 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1623824107-172.20.1.10-1742955811035 directory /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035/current
2025-03-26 02:23:36,608 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1623824107-172.20.1.10-1742955811035 directory /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035/current
2025-03-26 02:23:36,608 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=424945276;bpid=BP-1623824107-172.20.1.10-1742955811035;lv=-57;nsInfo=lv=-66;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035;bpid=BP-1623824107-172.20.1.10-1742955811035;dnuuid=null
2025-03-26 02:23:36,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=424945276;bpid=BP-1623824107-172.20.1.10-1742955811035;lv=-57;nsInfo=lv=-66;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035;bpid=BP-1623824107-172.20.1.10-1742955811035;dnuuid=null
2025-03-26 02:23:36,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=424945276;bpid=BP-1623824107-172.20.1.10-1742955811035;lv=-57;nsInfo=lv=-66;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035;bpid=BP-1623824107-172.20.1.10-1742955811035;dnuuid=null
2025-03-26 02:23:36,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 8ddc3d11-0e3c-4077-bb7c-318b56db161c
2025-03-26 02:23:36,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 903bdc20-a9b6-4db4-8b5b-e6a9770aac21
2025-03-26 02:23:36,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID cd114bfc-65b3-46fa-95af-8f400926efdc
2025-03-26 02:23:36,816 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:23:36,817 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:23:36,818 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2025-03-26 02:23:36,865 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1ca7a827-c477-46b4-a666-508fe9657cc2
2025-03-26 02:23:36,865 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-a133335d-0103-40b1-8216-843957ba2970
2025-03-26 02:23:36,865 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:23:36,865 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:23:36,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:23:36,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:23:36,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:23:36,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:23:36,874 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,874 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data...
2025-03-26 02:23:36,875 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,875 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data...
2025-03-26 02:23:36,879 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035/current, will proceed with Du for space computation calculation,
2025-03-26 02:23:36,880 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035/current, will proceed with Du for space computation calculation,
2025-03-26 02:23:36,884 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-78285236-5ee6-4952-9463-bd83c51c88fe
2025-03-26 02:23:36,884 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/data/tmp/dfs/data, StorageType: DISK
2025-03-26 02:23:36,888 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2025-03-26 02:23:36,890 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2025-03-26 02:23:36,895 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,896 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data...
2025-03-26 02:23:36,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035/current/replicas doesn't exist
2025-03-26 02:23:36,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data...
2025-03-26 02:23:36,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1623824107-172.20.1.10-1742955811035 on /data/tmp/dfs/data: 22ms
2025-03-26 02:23:36,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1623824107-172.20.1.10-1742955811035: 22ms
2025-03-26 02:23:36,898 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:23:36,898 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data: 1ms
2025-03-26 02:23:36,898 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1623824107-172.20.1.10-1742955811035: 1ms
2025-03-26 02:23:36,900 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1623824107-172.20.1.10-1742955811035 on /data/tmp/dfs/data: 25ms
2025-03-26 02:23:36,900 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1623824107-172.20.1.10-1742955811035: 26ms
2025-03-26 02:23:36,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035/current/replicas doesn't exist
2025-03-26 02:23:36,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data...
2025-03-26 02:23:36,902 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:23:36,902 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data: 1ms
2025-03-26 02:23:36,902 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1623824107-172.20.1.10-1742955811035: 2ms
2025-03-26 02:23:36,903 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: dfsUsed file missing in /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035/current, will proceed with Du for space computation calculation,
2025-03-26 02:23:36,914 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:23:36,916 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data
2025-03-26 02:23:36,916 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:23:36,917 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data
2025-03-26 02:23:36,917 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-1ca7a827-c477-46b4-a666-508fe9657cc2): finished scanning block pool BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,918 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:23:36,919 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 19628505ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:23:36,919 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-a133335d-0103-40b1-8216-843957ba2970): finished scanning block pool BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,920 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 15218277ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:23:36,920 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:23:36,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623824107-172.20.1.10-1742955811035 (Datanode Uuid 903bdc20-a9b6-4db4-8b5b-e6a9770aac21) service to master/172.20.1.10:9000 beginning handshake with NN
2025-03-26 02:23:36,924 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-a133335d-0103-40b1-8216-843957ba2970): no suitable block pools found to scan.  Waiting 1814399993 ms.
2025-03-26 02:23:36,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623824107-172.20.1.10-1742955811035 (Datanode Uuid 8ddc3d11-0e3c-4077-bb7c-318b56db161c) service to master/172.20.1.10:9000 beginning handshake with NN
2025-03-26 02:23:36,928 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1623824107-172.20.1.10-1742955811035 on /data/tmp/dfs/data: 32ms
2025-03-26 02:23:36,928 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1623824107-172.20.1.10-1742955811035: 33ms
2025-03-26 02:23:36,929 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /data/tmp/dfs/data/current/BP-1623824107-172.20.1.10-1742955811035/current/replicas doesn't exist
2025-03-26 02:23:36,929 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data...
2025-03-26 02:23:36,944 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /data/tmp/dfs/data
2025-03-26 02:23:36,944 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data: 15ms
2025-03-26 02:23:36,944 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1623824107-172.20.1.10-1742955811035: 16ms
2025-03-26 02:23:36,954 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /data/tmp/dfs/data
2025-03-26 02:23:36,956 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1623824107-172.20.1.10-1742955811035 on volume /data/tmp/dfs/data
2025-03-26 02:23:36,957 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-78285236-5ee6-4952-9463-bd83c51c88fe): finished scanning block pool BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:36,965 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-78285236-5ee6-4952-9463-bd83c51c88fe): no suitable block pools found to scan.  Waiting 1814399991 ms.
2025-03-26 02:23:36,968 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 8216845ms with interval of 21600000ms and throttle limit of -1ms/s
2025-03-26 02:23:36,968 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2025-03-26 02:23:36,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623824107-172.20.1.10-1742955811035 (Datanode Uuid cd114bfc-65b3-46fa-95af-8f400926efdc) service to master/172.20.1.10:9000 beginning handshake with NN
2025-03-26 02:23:36,978 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data/tmp/dfs/data, DS-1ca7a827-c477-46b4-a666-508fe9657cc2): no suitable block pools found to scan.  Waiting 1814399938 ms.
2025-03-26 02:23:37,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) storage 903bdc20-a9b6-4db4-8b5b-e6a9770aac21
2025-03-26 02:23:37,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 903bdc20-a9b6-4db4-8b5b-e6a9770aac21 (172.20.1.11:9866).
2025-03-26 02:23:37,002 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.11:9866
2025-03-26 02:23:37,011 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) storage 8ddc3d11-0e3c-4077-bb7c-318b56db161c
2025-03-26 02:23:37,011 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.13:9866
2025-03-26 02:23:37,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623824107-172.20.1.10-1742955811035 (Datanode Uuid 903bdc20-a9b6-4db4-8b5b-e6a9770aac21) service to master/172.20.1.10:9000 successfully registered with NN
2025-03-26 02:23:37,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.10:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:23:37,013 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 8ddc3d11-0e3c-4077-bb7c-318b56db161c (172.20.1.13:9866).
2025-03-26 02:23:37,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623824107-172.20.1.10-1742955811035 (Datanode Uuid 8ddc3d11-0e3c-4077-bb7c-318b56db161c) service to master/172.20.1.10:9000 successfully registered with NN
2025-03-26 02:23:37,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.10:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:23:37,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-a133335d-0103-40b1-8216-843957ba2970 for DN 172.20.1.13:9866
2025-03-26 02:23:37,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-1ca7a827-c477-46b4-a666-508fe9657cc2 for DN 172.20.1.11:9866
2025-03-26 02:23:37,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) storage cd114bfc-65b3-46fa-95af-8f400926efdc
2025-03-26 02:23:37,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN cd114bfc-65b3-46fa-95af-8f400926efdc (172.20.1.12:9866).
2025-03-26 02:23:37,079 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.20.1.12:9866
2025-03-26 02:23:37,080 INFO BlockStateChange: BLOCK* processReport 0xca8ea76127ae242e with lease ID 0x735b11deecd9e4bb: Processing first storage report for DS-a133335d-0103-40b1-8216-843957ba2970 from datanode DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035)
2025-03-26 02:23:37,081 INFO BlockStateChange: BLOCK* processReport 0xab5a0e42564079f6 with lease ID 0x735b11deecd9e4bc: Processing first storage report for DS-1ca7a827-c477-46b4-a666-508fe9657cc2 from datanode DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035)
2025-03-26 02:23:37,081 INFO BlockStateChange: BLOCK* processReport 0xab5a0e42564079f6 with lease ID 0x735b11deecd9e4bc: from storage DS-1ca7a827-c477-46b4-a666-508fe9657cc2 node DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-26 02:23:37,081 INFO BlockStateChange: BLOCK* processReport 0xca8ea76127ae242e with lease ID 0x735b11deecd9e4bb: from storage DS-a133335d-0103-40b1-8216-843957ba2970 node DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2025-03-26 02:23:37,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1623824107-172.20.1.10-1742955811035 (Datanode Uuid cd114bfc-65b3-46fa-95af-8f400926efdc) service to master/172.20.1.10:9000 successfully registered with NN
2025-03-26 02:23:37,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/172.20.1.10:9000 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2025-03-26 02:23:37,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xca8ea76127ae242e with lease ID 0x735b11deecd9e4bb to namenode: master/172.20.1.10:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msecs to generate and 38 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:23:37,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:37,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xab5a0e42564079f6 with lease ID 0x735b11deecd9e4bc to namenode: master/172.20.1.10:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msecs to generate and 39 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:23:37,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:37,104 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78285236-5ee6-4952-9463-bd83c51c88fe for DN 172.20.1.12:9866
2025-03-26 02:23:37,120 INFO BlockStateChange: BLOCK* processReport 0x372c94b900add5be with lease ID 0x735b11deecd9e4bd: Processing first storage report for DS-78285236-5ee6-4952-9463-bd83c51c88fe from datanode DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035)
2025-03-26 02:23:37,120 INFO BlockStateChange: BLOCK* processReport 0x372c94b900add5be with lease ID 0x735b11deecd9e4bd: from storage DS-78285236-5ee6-4952-9463-bd83c51c88fe node DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2025-03-26 02:23:37,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x372c94b900add5be with lease ID 0x735b11deecd9e4bd to namenode: master/172.20.1.10:9000,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msecs to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2025-03-26 02:23:37,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1623824107-172.20.1.10-1742955811035
2025-03-26 02:23:37,885 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting SecondaryNameNode STARTUP_MSG:   host = master/172.20.1.10 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:23:37,891 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:23:38,176 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:23:38,219 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:23:38,219 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2025-03-26 02:23:38,484 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2025-03-26 02:23:38,551 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /data/tmp/dfs/namesecondary/in_use.lock acquired by nodename 468@master
2025-03-26 02:23:38,584 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2025-03-26 02:23:38,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2025-03-26 02:23:38,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2025-03-26 02:23:38,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2025-03-26 02:23:38,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)
2025-03-26 02:23:38,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled    = true
2025-03-26 02:23:38,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isStoragePolicyEnabled = true
2025-03-26 02:23:38,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup             = supergroup
2025-03-26 02:23:38,610 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-03-26 02:23:38,613 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.11" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:23:38,614 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.12" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:23:38,614 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.13" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:23:38,617 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2025-03-26 02:23:38,617 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2025-03-26 02:23:38,618 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-03-26 02:23:38,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2025 Mar 26 02:23:38
2025-03-26 02:23:38,620 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2025-03-26 02:23:38,620 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:23:38,621 INFO org.apache.hadoop.util.GSet: 2.0% max memory 910.5 MB = 18.2 MB
2025-03-26 02:23:38,621 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2025-03-26 02:23:38,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Storage policy satisfier is disabled
2025-03-26 02:23:38,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2025-03-26 02:23:38,628 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2025-03-26 02:23:38,628 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
2025-03-26 02:23:38,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2025-03-26 02:23:38,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2025-03-26 02:23:38,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2025-03-26 02:23:38,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2025-03-26 02:23:38,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2025-03-26 02:23:38,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2025-03-26 02:23:38,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2025-03-26 02:23:38,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2025-03-26 02:23:38,672 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
2025-03-26 02:23:38,672 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
2025-03-26 02:23:38,672 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
2025-03-26 02:23:38,672 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
2025-03-26 02:23:38,679 INFO org.apache.hadoop.util.GSet: 1.0% max memory 910.5 MB = 9.1 MB
2025-03-26 02:23:38,679 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2025-03-26 02:23:38,679 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:23:38,679 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2025-03-26 02:23:38,680 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? true
2025-03-26 02:23:38,680 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2025-03-26 02:23:38,680 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2025-03-26 02:23:38,680 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2025-03-26 02:23:38,683 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-03-26 02:23:38,684 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2025-03-26 02:23:38,686 INFO org.apache.hadoop.util.GSet: 0.25% max memory 910.5 MB = 2.3 MB
2025-03-26 02:23:38,686 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2025-03-26 02:23:38,686 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2025-03-26 02:23:38,686 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2025-03-26 02:23:38,691 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2025-03-26 02:23:38,691 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-03-26 02:23:38,691 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-03-26 02:23:38,697 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2025-03-26 02:23:38,697 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2025-03-26 02:23:38,698 INFO org.apache.hadoop.hdfs.DFSUtil: Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-03-26 02:23:38,703 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:9868
2025-03-26 02:23:38,715 INFO org.eclipse.jetty.util.log: Logging initialized @1110ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:23:38,763 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:38,767 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2025-03-26 02:23:38,771 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:23:38,772 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:23:38,772 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2025-03-26 02:23:38,773 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:23:38,774 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-03-26 02:23:38,774 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context secondary
2025-03-26 02:23:38,774 INFO org.apache.hadoop.http.HttpServer2: Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-03-26 02:23:38,790 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9868
2025-03-26 02:23:38,791 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:23:38,804 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:23:38,804 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:23:38,804 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:23:38,814 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:38,815 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d9b7a8a{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:23:38,816 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b73be9f{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-03-26 02:23:38,853 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@62e6b5c8{secondary,/,file:///hadoop/share/hadoop/hdfs/webapps/secondary/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/secondary}
2025-03-26 02:23:38,858 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6622fc65{HTTP/1.1, (http/1.1)}{0.0.0.0:9868}
2025-03-26 02:23:38,859 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2025-03-26 02:23:38,859 INFO org.eclipse.jetty.server.Server: Started @1254ms
2025-03-26 02:23:41,563 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting ResourceManager STARTUP_MSG:   host = master/172.20.1.10 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:23:41,569 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:23:41,832 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMInfo MBean
2025-03-26 02:23:41,837 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/hadoop/etc/hadoop/core-site.xml
2025-03-26 02:23:41,874 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:23:41,874 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:23:41,901 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/hadoop/etc/hadoop/yarn-site.xml
2025-03-26 02:23:41,906 INFO org.apache.hadoop.yarn.metrics.GenericEventTypeMetrics: Registering GenericEventTypeMetrics
2025-03-26 02:23:41,908 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2025-03-26 02:23:41,930 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2025-03-26 02:23:41,932 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2025-03-26 02:23:41,942 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2025-03-26 02:23:41,964 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2025-03-26 02:23:41,966 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2025-03-26 02:23:41,966 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2025-03-26 02:23:41,986 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2025-03-26 02:23:41,987 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2025-03-26 02:23:41,987 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2025-03-26 02:23:41,987 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2025-03-26 02:23:42,016 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:23:42,024 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2025-03-26 02:23:42,024 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:23:42,046 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.
2025-03-26 02:23:42,047 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2025-03-26 02:23:42,050 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2025-03-26 02:23:42,290 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2025-03-26 02:23:42,290 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.monitor.RMAppLifetimeMonitor: Application lifelime monitor interval set to 3000 ms.
2025-03-26 02:23:42,293 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: Initializing NodeSortingService=MultiNodeSortingManager
2025-03-26 02:23:42,295 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.11" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:23:42,295 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.12" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:23:42,295 INFO org.apache.hadoop.util.HostsFileReader: Adding a node "172.20.1.13" to the list of included hosts from /hadoop/etc/hadoop/workers
2025-03-26 02:23:42,295 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2025-03-26 02:23:42,298 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/hadoop/etc/hadoop/capacity-scheduler.xml
2025-03-26 02:23:42,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Maximum allocation = <memory:8192, vCores:4>
2025-03-26 02:23:42,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Minimum allocation = <memory:1024, vCores:1>
2025-03-26 02:23:42,332 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2025-03-26 02:23:42,332 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, absoluteCapacity=1.0, maxCapacity=1.0, absoluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*, , reservationsContinueLooking=true, orderingPolicy=utilization, priority=0
2025-03-26 02:23:42,342 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized queue: root
2025-03-26 02:23:42,342 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized queue: root.default
2025-03-26 02:23:42,342 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing root.default capacity = 1.0 [= (float) configuredCapacity / 100 ] absoluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ] maxCapacity = 1.0 [= configuredMaxCapacity ] absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ] effectiveMinResource=<memory:0, vCores:0> , effectiveMaxResource=<memory:0, vCores:0> userLimit = 100 [= configuredUserLimit ] userLimitFactor = 1.0 [= configuredUserLimitFactor ] maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)] maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ] maxParallelApps = 2147483647 usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)] absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory] maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ] minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ] maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ] numContainers = 0 [= currentNumContainers ] state = RUNNING [= configuredState ] acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ] nodeLocalityDelay = 40 rackLocalityAdditionalDelay = -1 labels=*, reservationsContinueLooking = true preemptionDisabled = true defaultAppPriorityPerQueue = 0 priority = 0 maxLifetime = -1 seconds defaultLifetime = -1 seconds
2025-03-26 02:23:42,343 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerQueueManager: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2025-03-26 02:23:42,344 INFO org.apache.hadoop.yarn.server.resourcemanager.placement.UserGroupMappingPlacementRule: Initialized queue mappings, override: false
2025-03-26 02:23:42,344 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.WorkflowPriorityMappingsManager: Initialized workflow priority mappings, override: false
2025-03-26 02:23:42,350 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms,multiNodePlacementEnabled=false, assignMultipleEnabled=true, maxAssignPerHeartbeat=100, offswitchPerHeartbeatLimit=1
2025-03-26 02:23:42,350 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: MultiNode scheduling is 'false', and configured policies are
2025-03-26 02:23:42,352 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2025-03-26 02:23:42,353 INFO org.apache.hadoop.yarn.server.resourcemanager.AMSProcessingChain: Initializing AMS Processing chain. Root Processor=[org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor].
2025-03-26 02:23:42,353 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: disabled placement handler will be used, all scheduling requests will be rejected.
2025-03-26 02:23:42,354 INFO tp top of AMS Processing chain.
2025-03-26 02:23:42,357 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: TimelineServicePublisher is not configured
2025-03-26 02:23:42,374 INFO org.eclipse.jetty.util.log: Logging initialized @1097ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:23:42,461 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:42,463 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2025-03-26 02:23:42,467 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:23:42,469 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2025-03-26 02:23:42,469 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2025-03-26 02:23:42,469 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2025-03-26 02:23:42,469 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2025-03-26 02:23:42,469 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:23:42,469 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:23:42,710 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:23:42,714 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2025-03-26 02:23:42,714 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:23:42,737 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:23:42,737 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:23:42,738 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:23:42,751 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:42,754 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:23:42,755 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2025-03-26 02:23:42,755 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:23:42,764 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@232a7d73{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:23:42,764 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@305a0c5f{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:23:43,403 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@7add323c{cluster,/,file:///tmp/jetty-master-8088-hadoop-yarn-common-3_3_4_jar-_-any-1514747526678927476/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/cluster}
2025-03-26 02:23:43,409 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2025-03-26 02:23:43,409 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@5b068087{HTTP/1.1, (http/1.1)}{master:8088}
2025-03-26 02:23:43,409 INFO org.eclipse.jetty.server.Server: Started @2132ms
2025-03-26 02:23:43,582 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:43,591 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2025-03-26 02:23:43,663 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2025-03-26 02:23:43,664 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:43,664 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2025-03-26 02:23:43,665 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2025-03-26 02:23:43,676 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2025-03-26 02:23:43,676 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:23:43,676 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2025-03-26 02:23:43,676 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2025-03-26 02:23:43,676 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2025-03-26 02:23:43,676 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2025-03-26 02:23:43,676 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2025-03-26 02:23:43,677 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2025-03-26 02:23:43,677 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2025-03-26 02:23:43,677 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2025-03-26 02:23:43,677 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2025-03-26 02:23:43,748 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Created store directory :file:/tmp/hadoop-yarn-root/node-attribute
2025-03-26 02:23:43,766 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Finished create editlog file at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.editlog
2025-03-26 02:23:43,766 INFO org.apache.hadoop.yarn.nodelabels.store.AbstractFSNodeStore: Finished write mirror at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.mirror
2025-03-26 02:23:43,781 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$ForwardingEventHandler
2025-03-26 02:23:43,782 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.placement.MultiNodeSortingManager: Starting NodeSortingService=MultiNodeSortingManager
2025-03-26 02:23:43,791 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:43,791 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2025-03-26 02:23:43,793 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:43,793 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2025-03-26 02:23:43,794 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2025-03-26 02:23:43,801 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:23:43,807 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:43,810 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2025-03-26 02:23:43,814 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2025-03-26 02:23:43,818 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:43,818 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2025-03-26 02:23:43,866 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:43,866 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2025-03-26 02:23:43,868 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2025-03-26 02:23:43,869 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:43,869 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2025-03-26 02:23:43,979 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave1/172.20.1.12 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:23:43,985 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:23:44,024 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave2/172.20.1.13 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:23:44,030 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:23:44,061 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: /************************************************************ STARTUP_MSG: Starting NodeManager STARTUP_MSG:   host = slave0/172.20.1.11 STARTUP_MSG:   args = [] STARTUP_MSG:   version = 3.3.4 STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/gson-2.8.9.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/common/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-kms-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-registry-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.3.4.jar:/hadoop/share/hadoop/common/hadoop-common-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.8.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.77.Final-osx-x86_64.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.77.Final-linux-aarch_64.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.4.7.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.77.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.43.v20210629.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.4-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.4.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4-tests.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.4.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.4.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/share/hadoop/yarn/lib/asm-commons-9.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/hadoop/share/hadoop/yarn/lib/asm-analysis-9.1.jar:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.43.v20210629.jar:/hadoop/share/hadoop/yarn/lib/asm-tree-9.1.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.4.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-documentstore-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.3.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-extras-0.8.0.17.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-validator-1.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-digester-1.8.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-collections4-4.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-1.3.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-commons-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-gateway-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-client-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxjava-string-1.1.1.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/azure-cosmosdb-direct-2.4.5.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/rxnetty-0.4.20.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/java-uuid-generator-3.1.4.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-common-1.4.8.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/hadoop/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.4.8.jar STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a585a73c3e02ac62350c136643a5e7f6095a3dbb; compiled by 'stevel' on 2022-07-29T12:32Z STARTUP_MSG:   java = 1.8.0_432 ************************************************************/
2025-03-26 02:23:44,069 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2025-03-26 02:23:44,137 INFO org.apache.hadoop.yarn.server.webproxy.ProxyCA: Created Certificate for OU=YARN-53384bc8-c645-41de-bc3e-d2eae794570e
2025-03-26 02:23:44,191 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2025-03-26 02:23:44,191 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing CA Certificate and Private Key
2025-03-26 02:23:44,311 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:23:44,311 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:23:44,312 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:23:44,383 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:23:44,383 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:23:44,384 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:23:44,411 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null
2025-03-26 02:23:44,411 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!
2025-03-26 02:23:44,411 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.ResourcePluginManager: The pluggable device framework is not enabled. If you want, please set true to yarn.nodemanager.pluggable-device-framework.enabled
2025-03-26 02:23:44,466 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:23:44,466 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:23:44,467 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:23:44,467 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:23:44,467 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:23:44,468 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:23:44,468 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:23:44,469 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:23:44,482 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:23:44,482 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:23:44,512 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:23:44,546 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:23:44,547 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:23:44,547 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:23:44,547 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:23:44,547 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:23:44,548 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:23:44,548 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:23:44,549 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:23:44,557 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:23:44,558 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:23:44,562 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:23:44,562 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:23:44,567 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2025-03-26 02:23:44,567 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2025-03-26 02:23:44,567 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper
2025-03-26 02:23:44,567 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:23:44,568 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2025-03-26 02:23:44,568 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2025-03-26 02:23:44,568 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2025-03-26 02:23:44,568 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler
2025-03-26 02:23:44,569 INFO org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600
2025-03-26 02:23:44,578 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2025-03-26 02:23:44,579 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2025-03-26 02:23:44,581 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:23:44,585 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:23:44,592 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:23:44,608 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-03-26 02:23:44,633 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:23:44,634 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:23:44,635 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:23:44,635 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:23:44,635 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:23:44,650 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:23:44,656 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:23:44,656 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:23:44,658 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2025-03-26 02:23:44,658 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-03-26 02:23:44,659 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:23:44,661 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:23:44,661 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:23:44,661 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:23:44,664 INFO org.apache.hadoop.yarn.server.nodemanager.health.NodeHealthScriptRunner: Missing location for the node health check script "script".
2025-03-26 02:23:44,674 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:23:44,676 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:23:44,677 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:23:44,677 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:23:44,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:23:44,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:23:44,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:23:44,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:23:44,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:23:44,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:23:44,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:23:44,680 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:23:44,681 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:23:44,681 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:23:44,682 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:23:44,684 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:23:44,684 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:23:44,686 INFO org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.
2025-03-26 02:23:44,713 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:23:44,714 INFO org.apache.hadoop.yarn.server.nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@37e4d7bb
2025-03-26 02:23:44,715 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:23:44,715 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2025-03-26 02:23:44,716 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:23:44,716 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2025-03-26 02:23:44,716 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:23:44,716 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: AMRMProxyService is disabled
2025-03-26 02:23:44,716 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:23:44,716 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2025-03-26 02:23:44,720 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:44,730 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:23:44,731 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2025-03-26 02:23:44,741 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:23:44,742 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerModule: Using traffic control bandwidth handler
2025-03-26 02:23:44,743 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:23:44,744 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorPlugin: org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@12359a82
2025-03-26 02:23:44,744 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:23:44,744 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Using ResourceCalculatorProcessTree: null
2025-03-26 02:23:44,758 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:23:44,758 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:23:44,758 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:23:44,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:23:44,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:23:44,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:23:44,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:23:44,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:23:44,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:23:44,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:23:44,759 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:23:44,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Container Log Monitor Enabled: false
2025-03-26 02:23:44,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: ContainersMonitor enabled: true
2025-03-26 02:23:44,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Elastic memory control enabled: false
2025-03-26 02:23:44,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2025-03-26 02:23:44,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Setting the resources allocated to containers to <memory:8192, vCores:8>
2025-03-26 02:23:44,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Strict memory control enabled: true
2025-03-26 02:23:44,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2025-03-26 02:23:44,761 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:23:44,761 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:23:44,761 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.
2025-03-26 02:23:44,761 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:23:44,762 INFO org.apache.hadoop.conf.Configuration: node-resources.xml not found
2025-03-26 02:23:44,762 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'node-resources.xml'.
2025-03-26 02:23:44,763 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:23:44,763 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:8192, vCores:8>
2025-03-26 02:23:44,765 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:23:44,766 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:23:44,785 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=8192 virtual-memory=17204 virtual-cores=8
2025-03-26 02:23:44,795 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:23:44,796 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:44,796 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:23:44,797 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:44,799 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave1:45207
2025-03-26 02:23:44,804 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:44,805 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:23:44,806 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:23:44,807 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:44,807 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:23:44,808 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:23:44,811 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:23:44,811 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave1/172.20.1.12:45207
2025-03-26 02:23:44,811 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:23:44,815 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:23:44,817 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:44,833 INFO org.eclipse.jetty.util.log: Logging initialized @1161ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:23:44,844 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:23:44,862 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0
2025-03-26 02:23:44,882 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:23:44,884 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:44,884 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:23:44,888 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave0:46743
2025-03-26 02:23:44,893 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:44,894 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:23:44,897 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:44,897 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting
2025-03-26 02:23:44,897 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2025-03-26 02:23:44,897 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:44,900 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:23:44,900 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:23:44,900 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : slave2:46623
2025-03-26 02:23:44,905 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-26 02:23:44,906 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:44,906 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2025-03-26 02:23:44,907 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:23:44,908 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:23:44,908 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:23:44,908 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:23:44,908 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-26 02:23:44,908 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2025-03-26 02:23:44,909 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:23:44,909 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:23:44,909 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:23:44,909 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:23:44,910 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2025-03-26 02:23:44,910 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:23:44,911 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2025-03-26 02:23:44,914 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:23:44,914 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave2/172.20.1.13:46623
2025-03-26 02:23:44,914 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:23:44,917 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:23:44,926 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2025-03-26 02:23:44,926 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at slave0/172.20.1.11:46743
2025-03-26 02:23:44,926 WARN org.apache.hadoop.yarn.server.nodemanager.logaggregation.tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.
2025-03-26 02:23:44,931 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2025-03-26 02:23:44,940 INFO org.eclipse.jetty.util.log: Logging initialized @1216ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:23:44,955 INFO org.eclipse.jetty.util.log: Logging initialized @1199ms to org.eclipse.jetty.util.log.Slf4jLog
2025-03-26 02:23:45,013 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:45,013 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:45,016 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:23:45,016 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2025-03-26 02:23:45,021 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:23:45,022 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-03-26 02:23:45,023 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:23:45,023 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:23:45,023 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:23:45,023 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:23:45,023 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-03-26 02:23:45,023 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:23:45,023 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2025-03-26 02:23:45,023 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:23:45,023 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-03-26 02:23:45,024 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-03-26 02:23:45,024 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node
2025-03-26 02:23:45,024 INFO org.apache.hadoop.http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-03-26 02:23:45,190 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:23:45,191 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:23:45,192 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:23:45,208 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:23:45,208 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:23:45,208 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:23:45,223 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:45,225 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:23:45,226 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:23:45,266 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:23:45,267 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:23:45,267 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:23:45,281 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:23:45,281 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:23:45,281 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2025-03-26 02:23:45,285 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2025-03-26 02:23:45,285 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2025-03-26 02:23:45,286 INFO org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_432-8u432-ga~us1-0ubuntu2~24.04-ga
2025-03-26 02:23:45,298 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:45,300 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:23:45,301 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:23:45,303 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2025-03-26 02:23:45,303 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2025-03-26 02:23:45,304 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2025-03-26 02:23:45,314 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-03-26 02:23:45,315 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef3efa8{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2025-03-26 02:23:45,316 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7446d8d5{static,/static,jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/static,AVAILABLE}
2025-03-26 02:23:45,729 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-693069750789879075/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:23:45,735 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:23:45,736 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:23:45,736 INFO org.eclipse.jetty.server.Server: Started @2064ms
2025-03-26 02:23:45,737 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave1:45207
2025-03-26 02:23:45,742 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.10:8031
2025-03-26 02:23:45,751 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:23:45,830 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-4905727884118390016/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:23:45,835 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:23:45,835 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:23:45,835 INFO org.eclipse.jetty.server.Server: Started @2111ms
2025-03-26 02:23:45,836 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave2:46623
2025-03-26 02:23:45,841 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.10:8031
2025-03-26 02:23:45,862 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:23:45,873 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@2d272b0d{node,/,file:///tmp/jetty-0_0_0_0-8042-hadoop-yarn-common-3_3_4_jar-_-any-4027689904297824181/webapp/,AVAILABLE}{jar:file:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.4.jar!/webapps/node}
2025-03-26 02:23:45,879 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2025-03-26 02:23:45,879 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@546ccad7{HTTP/1.1, (http/1.1)}{0.0.0.0:8042}
2025-03-26 02:23:45,879 INFO org.eclipse.jetty.server.Server: Started @2123ms
2025-03-26 02:23:45,880 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : slave0:46743
2025-03-26 02:23:45,885 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.10:8031
2025-03-26 02:23:45,899 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2025-03-26 02:23:46,140 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave2(cmPort: 46623 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave2:46623
2025-03-26 02:23:46,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave1:45207 Node Transitioned from NEW to RUNNING
2025-03-26 02:23:46,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave2:46623 Node Transitioned from NEW to RUNNING
2025-03-26 02:23:46,148 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave1(cmPort: 45207 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave1:45207
2025-03-26 02:23:46,149 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node slave0(cmPort: 46743 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId slave0:46743
2025-03-26 02:23:46,149 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: slave0:46743 Node Transitioned from NEW to RUNNING
2025-03-26 02:23:46,151 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave2:46623 with total resource of <memory:8192, vCores:8>
2025-03-26 02:23:46,151 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1314814685
2025-03-26 02:23:46,151 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -2134029054
2025-03-26 02:23:46,155 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1314814685
2025-03-26 02:23:46,156 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave1:45207 with total resource of <memory:8192, vCores:8>
2025-03-26 02:23:46,156 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1314814685
2025-03-26 02:23:46,156 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -2134029054
2025-03-26 02:23:46,157 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as slave0:46743 with total resource of <memory:8192, vCores:8>
2025-03-26 02:23:46,157 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -2134029054
2025-03-26 02:23:46,213 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave1:45207 clusterResource: <memory:8192, vCores:8>
2025-03-26 02:23:46,214 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave2:46623 clusterResource: <memory:16384, vCores:16>
2025-03-26 02:23:46,215 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node slave0:46743 clusterResource: <memory:24576, vCores:24>
2025-03-26 02:23:47,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:47,625 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:47,627 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /file.txt._COPYING_
2025-03-26 02:23:47,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741825_1001 src: /172.20.1.10:48268 dest: /172.20.1.12:9866
2025-03-26 02:23:47,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741825_1001 src: /172.20.1.12:52050 dest: /172.20.1.11:9866
2025-03-26 02:23:48,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741825_1001 src: /172.20.1.11:53542 dest: /172.20.1.13:9866
2025-03-26 02:23:48,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:53542, dest: /172.20.1.13:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1242799787_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741825_1001, duration(ns): 19828729
2025-03-26 02:23:48,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2025-03-26 02:23:48,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:52050, dest: /172.20.1.11:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1242799787_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741825_1001, duration(ns): 20482643
2025-03-26 02:23:48,055 INFO terminating
2025-03-26 02:23:48,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48268, dest: /172.20.1.12:9866, bytes: 67, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1242799787_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741825_1001, duration(ns): 21260615
2025-03-26 02:23:48,058 INFO terminating
2025-03-26 02:23:48,064 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /file.txt._COPYING_
2025-03-26 02:23:48,474 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /file.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1242799787_1
2025-03-26 02:23:50,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /cluster.txt._COPYING_
2025-03-26 02:23:50,152 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:50,152 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:50,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741826_1002 src: /172.20.1.10:54078 dest: /172.20.1.13:9866
2025-03-26 02:23:50,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741826_1002 src: /172.20.1.13:58866 dest: /172.20.1.11:9866
2025-03-26 02:23:50,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741826_1002 src: /172.20.1.11:35560 dest: /172.20.1.12:9866
2025-03-26 02:23:50,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35560, dest: /172.20.1.12:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_856861742_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741826_1002, duration(ns): 7075666
2025-03-26 02:23:50,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2025-03-26 02:23:50,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:58866, dest: /172.20.1.11:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_856861742_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741826_1002, duration(ns): 7963470
2025-03-26 02:23:50,284 INFO terminating
2025-03-26 02:23:50,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:54078, dest: /172.20.1.13:9866, bytes: 1864, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_856861742_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741826_1002, duration(ns): 8832739
2025-03-26 02:23:50,285 INFO terminating
2025-03-26 02:23:50,287 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /cluster.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_856861742_1
2025-03-26 02:23:51,948 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /page.txt._COPYING_
2025-03-26 02:23:51,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:51,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:52,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741827_1003 src: /172.20.1.10:51666 dest: /172.20.1.11:9866
2025-03-26 02:23:52,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741827_1003 src: /172.20.1.11:35566 dest: /172.20.1.12:9866
2025-03-26 02:23:52,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741827_1003 src: /172.20.1.12:42244 dest: /172.20.1.13:9866
2025-03-26 02:23:52,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:42244, dest: /172.20.1.13:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1439593148_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741827_1003, duration(ns): 5948917
2025-03-26 02:23:52,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2025-03-26 02:23:52,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35566, dest: /172.20.1.12:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1439593148_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741827_1003, duration(ns): 6467228
2025-03-26 02:23:52,166 INFO terminating
2025-03-26 02:23:52,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51666, dest: /172.20.1.11:9866, bytes: 41, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1439593148_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741827_1003, duration(ns): 7408152
2025-03-26 02:23:52,168 INFO terminating
2025-03-26 02:23:52,170 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /page.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1439593148_1
2025-03-26 02:23:53,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:53,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:53,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /lr_test.txt._COPYING_
2025-03-26 02:23:54,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741828_1004 src: /172.20.1.10:48270 dest: /172.20.1.12:9866
2025-03-26 02:23:54,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741828_1004 src: /172.20.1.12:52056 dest: /172.20.1.11:9866
2025-03-26 02:23:54,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741828_1004 src: /172.20.1.11:53556 dest: /172.20.1.13:9866
2025-03-26 02:23:54,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:53556, dest: /172.20.1.13:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1100029844_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741828_1004, duration(ns): 6324339
2025-03-26 02:23:54,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2025-03-26 02:23:54,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:48270, dest: /172.20.1.12:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1100029844_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741828_1004, duration(ns): 6971780
2025-03-26 02:23:54,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:52056, dest: /172.20.1.11:9866, bytes: 10614, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1100029844_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741828_1004, duration(ns): 6814331
2025-03-26 02:23:54,075 INFO terminating
2025-03-26 02:23:54,076 INFO terminating
2025-03-26 02:23:54,078 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /lr_test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1100029844_1
2025-03-26 02:23:57,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:57,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:57,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/data/graphx/users.txt._COPYING_
2025-03-26 02:23:57,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741829_1005 src: /172.20.1.10:57820 dest: /172.20.1.11:9866
2025-03-26 02:23:57,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741829_1005 src: /172.20.1.11:45950 dest: /172.20.1.12:9866
2025-03-26 02:23:57,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741829_1005 src: /172.20.1.12:41614 dest: /172.20.1.13:9866
2025-03-26 02:23:57,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45950, dest: /172.20.1.12:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741829_1005, duration(ns): 6127514
2025-03-26 02:23:57,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:41614, dest: /172.20.1.13:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741829_1005, duration(ns): 5554600
2025-03-26 02:23:57,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2025-03-26 02:23:57,751 INFO terminating
2025-03-26 02:23:57,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57820, dest: /172.20.1.11:9866, bytes: 169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741829_1005, duration(ns): 6958720
2025-03-26 02:23:57,752 INFO terminating
2025-03-26 02:23:57,753 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/graphx/users.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:23:58,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:58,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:58,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/data/graphx/followers.txt._COPYING_
2025-03-26 02:23:58,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741830_1006 src: /172.20.1.10:57822 dest: /172.20.1.11:9866
2025-03-26 02:23:58,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741830_1006 src: /172.20.1.11:45954 dest: /172.20.1.12:9866
2025-03-26 02:23:58,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741830_1006 src: /172.20.1.12:41620 dest: /172.20.1.13:9866
2025-03-26 02:23:58,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:41620, dest: /172.20.1.13:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741830_1006, duration(ns): 6622931
2025-03-26 02:23:58,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2025-03-26 02:23:58,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45954, dest: /172.20.1.12:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741830_1006, duration(ns): 10467045
2025-03-26 02:23:58,241 INFO terminating
2025-03-26 02:23:58,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57822, dest: /172.20.1.11:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741830_1006, duration(ns): 12021812
2025-03-26 02:23:58,244 INFO terminating
2025-03-26 02:23:58,246 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/graphx/followers.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:23:58,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:58,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:58,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_fpgrowth.txt._COPYING_
2025-03-26 02:23:59,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741831_1007 src: /172.20.1.10:57836 dest: /172.20.1.11:9866
2025-03-26 02:23:59,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741831_1007 src: /172.20.1.11:37272 dest: /172.20.1.13:9866
2025-03-26 02:23:59,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741831_1007 src: /172.20.1.13:56186 dest: /172.20.1.12:9866
2025-03-26 02:23:59,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56186, dest: /172.20.1.12:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741831_1007, duration(ns): 3679995
2025-03-26 02:23:59,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:37272, dest: /172.20.1.13:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741831_1007, duration(ns): 4241122
2025-03-26 02:23:59,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2025-03-26 02:23:59,085 INFO terminating
2025-03-26 02:23:59,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57836, dest: /172.20.1.11:9866, bytes: 68, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741831_1007, duration(ns): 4775507
2025-03-26 02:23:59,086 INFO terminating
2025-03-26 02:23:59,088 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_fpgrowth.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:23:59,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:59,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:59,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/pagerank_data.txt._COPYING_
2025-03-26 02:23:59,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741832_1008 src: /172.20.1.10:34208 dest: /172.20.1.12:9866
2025-03-26 02:23:59,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741832_1008 src: /172.20.1.12:41624 dest: /172.20.1.13:9866
2025-03-26 02:23:59,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741832_1008 src: /172.20.1.13:36418 dest: /172.20.1.11:9866
2025-03-26 02:23:59,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:36418, dest: /172.20.1.11:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741832_1008, duration(ns): 2845977
2025-03-26 02:23:59,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2025-03-26 02:23:59,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:41624, dest: /172.20.1.13:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741832_1008, duration(ns): 3159165
2025-03-26 02:23:59,562 INFO terminating
2025-03-26 02:23:59,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34208, dest: /172.20.1.12:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741832_1008, duration(ns): 6278727
2025-03-26 02:23:59,563 INFO terminating
2025-03-26 02:23:59,564 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/pagerank_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:23:59,911 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:23:59,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/streaming_kmeans_data_test.txt._COPYING_
2025-03-26 02:23:59,912 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:00,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741833_1009 src: /172.20.1.10:34772 dest: /172.20.1.13:9866
2025-03-26 02:24:00,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741833_1009 src: /172.20.1.13:36430 dest: /172.20.1.11:9866
2025-03-26 02:24:00,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741833_1009 src: /172.20.1.11:45960 dest: /172.20.1.12:9866
2025-03-26 02:24:00,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45960, dest: /172.20.1.12:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741833_1009, duration(ns): 6867311
2025-03-26 02:24:00,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:00,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:36430, dest: /172.20.1.11:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741833_1009, duration(ns): 10576363
2025-03-26 02:24:00,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34772, dest: /172.20.1.13:9866, bytes: 46, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741833_1009, duration(ns): 13140195
2025-03-26 02:24:00,146 INFO terminating
2025-03-26 02:24:00,147 INFO terminating
2025-03-26 02:24:00,148 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/streaming_kmeans_data_test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:00,603 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:00,603 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:00,604 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/mllib/sample_lda_data.txt._COPYING_
2025-03-26 02:24:00,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741834_1010 src: /172.20.1.10:34222 dest: /172.20.1.12:9866
2025-03-26 02:24:00,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741834_1010 src: /172.20.1.12:46320 dest: /172.20.1.11:9866
2025-03-26 02:24:00,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741834_1010 src: /172.20.1.11:37280 dest: /172.20.1.13:9866
2025-03-26 02:24:00,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:37280, dest: /172.20.1.13:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741834_1010, duration(ns): 6724157
2025-03-26 02:24:00,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:00,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46320, dest: /172.20.1.11:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741834_1010, duration(ns): 9234850
2025-03-26 02:24:00,740 INFO terminating
2025-03-26 02:24:00,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34222, dest: /172.20.1.12:9866, bytes: 264, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741834_1010, duration(ns): 13448034
2025-03-26 02:24:00,745 INFO terminating
2025-03-26 02:24:00,747 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_lda_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:01,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:01,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:01,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/als/test.data._COPYING_
2025-03-26 02:24:01,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741835_1011 src: /172.20.1.10:34778 dest: /172.20.1.13:9866
2025-03-26 02:24:01,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741835_1011 src: /172.20.1.13:36432 dest: /172.20.1.11:9866
2025-03-26 02:24:01,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741835_1011 src: /172.20.1.11:45972 dest: /172.20.1.12:9866
2025-03-26 02:24:01,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45972, dest: /172.20.1.12:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741835_1011, duration(ns): 9323187
2025-03-26 02:24:01,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:01,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:36432, dest: /172.20.1.11:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741835_1011, duration(ns): 11226344
2025-03-26 02:24:01,351 INFO terminating
2025-03-26 02:24:01,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34778, dest: /172.20.1.13:9866, bytes: 128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741835_1011, duration(ns): 13874897
2025-03-26 02:24:01,354 INFO terminating
2025-03-26 02:24:01,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/als/test.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:01,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:01,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/data/mllib/als/sample_movielens_ratings.txt._COPYING_
2025-03-26 02:24:01,705 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:01,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741836_1012 src: /172.20.1.10:34780 dest: /172.20.1.13:9866
2025-03-26 02:24:01,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741836_1012 src: /172.20.1.13:56190 dest: /172.20.1.12:9866
2025-03-26 02:24:01,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741836_1012 src: /172.20.1.12:46334 dest: /172.20.1.11:9866
2025-03-26 02:24:01,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46334, dest: /172.20.1.11:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741836_1012, duration(ns): 6728122
2025-03-26 02:24:01,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:01,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56190, dest: /172.20.1.12:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741836_1012, duration(ns): 7630544
2025-03-26 02:24:01,947 INFO terminating
2025-03-26 02:24:01,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34780, dest: /172.20.1.13:9866, bytes: 32363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741836_1012, duration(ns): 8643106
2025-03-26 02:24:01,949 INFO terminating
2025-03-26 02:24:01,951 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/als/sample_movielens_ratings.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:02,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:02,294 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:02,295 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/data/mllib/sample_kmeans_data.txt._COPYING_
2025-03-26 02:24:02,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741837_1013 src: /172.20.1.10:57838 dest: /172.20.1.11:9866
2025-03-26 02:24:02,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741837_1013 src: /172.20.1.11:45982 dest: /172.20.1.12:9866
2025-03-26 02:24:02,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741837_1013 src: /172.20.1.12:41636 dest: /172.20.1.13:9866
2025-03-26 02:24:02,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:41636, dest: /172.20.1.13:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741837_1013, duration(ns): 14377549
2025-03-26 02:24:02,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:02,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45982, dest: /172.20.1.12:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741837_1013, duration(ns): 16054868
2025-03-26 02:24:02,440 INFO terminating
2025-03-26 02:24:02,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57838, dest: /172.20.1.11:9866, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741837_1013, duration(ns): 17904623
2025-03-26 02:24:02,442 INFO terminating
2025-03-26 02:24:02,445 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_kmeans_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:02,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:02,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:02,905 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/mllib/ridge-data/lpsa.data._COPYING_
2025-03-26 02:24:03,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741838_1014 src: /172.20.1.10:34224 dest: /172.20.1.12:9866
2025-03-26 02:24:03,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741838_1014 src: /172.20.1.12:46346 dest: /172.20.1.11:9866
2025-03-26 02:24:03,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741838_1014 src: /172.20.1.11:37296 dest: /172.20.1.13:9866
2025-03-26 02:24:03,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:37296, dest: /172.20.1.13:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741838_1014, duration(ns): 3732576
2025-03-26 02:24:03,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:03,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46346, dest: /172.20.1.11:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741838_1014, duration(ns): 4550048
2025-03-26 02:24:03,020 INFO terminating
2025-03-26 02:24:03,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34224, dest: /172.20.1.12:9866, bytes: 10395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741838_1014, duration(ns): 5094567
2025-03-26 02:24:03,021 INFO terminating
2025-03-26 02:24:03,023 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/ridge-data/lpsa.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:03,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:03,387 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:03,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/data/mllib/gmm_data.txt._COPYING_
2025-03-26 02:24:03,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741839_1015 src: /172.20.1.10:57854 dest: /172.20.1.11:9866
2025-03-26 02:24:03,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741839_1015 src: /172.20.1.11:45994 dest: /172.20.1.12:9866
2025-03-26 02:24:03,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741839_1015 src: /172.20.1.12:41650 dest: /172.20.1.13:9866
2025-03-26 02:24:03,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:41650, dest: /172.20.1.13:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741839_1015, duration(ns): 3111788
2025-03-26 02:24:03,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:45994, dest: /172.20.1.12:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741839_1015, duration(ns): 3539743
2025-03-26 02:24:03,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:03,501 INFO terminating
2025-03-26 02:24:03,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57854, dest: /172.20.1.11:9866, bytes: 63973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741839_1015, duration(ns): 4206457
2025-03-26 02:24:03,502 INFO terminating
2025-03-26 02:24:03,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/gmm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:03,825 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:03,825 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:03,826 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/mllib/sample_lda_libsvm_data.txt._COPYING_
2025-03-26 02:24:03,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741840_1016 src: /172.20.1.10:34226 dest: /172.20.1.12:9866
2025-03-26 02:24:03,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741840_1016 src: /172.20.1.12:46358 dest: /172.20.1.11:9866
2025-03-26 02:24:03,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741840_1016 src: /172.20.1.11:37312 dest: /172.20.1.13:9866
2025-03-26 02:24:03,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:37312, dest: /172.20.1.13:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741840_1016, duration(ns): 3617475
2025-03-26 02:24:03,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:03,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46358, dest: /172.20.1.11:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741840_1016, duration(ns): 4733837
2025-03-26 02:24:03,949 INFO terminating
2025-03-26 02:24:03,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34226, dest: /172.20.1.12:9866, bytes: 578, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741840_1016, duration(ns): 6459038
2025-03-26 02:24:03,950 INFO terminating
2025-03-26 02:24:03,951 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_lda_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:04,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:04,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:04,301 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/data/mllib/sample_libsvm_data.txt._COPYING_
2025-03-26 02:24:04,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741841_1017 src: /172.20.1.10:34782 dest: /172.20.1.13:9866
2025-03-26 02:24:04,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741841_1017 src: /172.20.1.13:56194 dest: /172.20.1.12:9866
2025-03-26 02:24:04,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741841_1017 src: /172.20.1.12:46374 dest: /172.20.1.11:9866
2025-03-26 02:24:04,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46374, dest: /172.20.1.11:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741841_1017, duration(ns): 9932853
2025-03-26 02:24:04,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:04,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56194, dest: /172.20.1.12:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741841_1017, duration(ns): 13043561
2025-03-26 02:24:04,544 INFO terminating
2025-03-26 02:24:04,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34782, dest: /172.20.1.13:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741841_1017, duration(ns): 15730533
2025-03-26 02:24:04,549 INFO terminating
2025-03-26 02:24:04,552 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:05,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/mllib/sample_movielens_data.txt._COPYING_
2025-03-26 02:24:05,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:05,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:05,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741842_1018 src: /172.20.1.10:34230 dest: /172.20.1.12:9866
2025-03-26 02:24:05,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741842_1018 src: /172.20.1.12:46386 dest: /172.20.1.11:9866
2025-03-26 02:24:05,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741842_1018 src: /172.20.1.11:37326 dest: /172.20.1.13:9866
2025-03-26 02:24:05,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:37326, dest: /172.20.1.13:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741842_1018, duration(ns): 2893177
2025-03-26 02:24:05,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:05,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46386, dest: /172.20.1.11:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741842_1018, duration(ns): 4185611
2025-03-26 02:24:05,315 INFO terminating
2025-03-26 02:24:05,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34230, dest: /172.20.1.12:9866, bytes: 14351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741842_1018, duration(ns): 5324648
2025-03-26 02:24:05,317 INFO terminating
2025-03-26 02:24:05,318 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_movielens_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:05,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/sample_svm_data.txt._COPYING_
2025-03-26 02:24:05,652 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:05,652 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:05,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741843_1019 src: /172.20.1.10:34232 dest: /172.20.1.12:9866
2025-03-26 02:24:05,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741843_1019 src: /172.20.1.12:41652 dest: /172.20.1.13:9866
2025-03-26 02:24:05,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741843_1019 src: /172.20.1.13:36434 dest: /172.20.1.11:9866
2025-03-26 02:24:05,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:36434, dest: /172.20.1.11:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741843_1019, duration(ns): 2837565
2025-03-26 02:24:05,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:05,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:41652, dest: /172.20.1.13:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741843_1019, duration(ns): 3925708
2025-03-26 02:24:05,895 INFO terminating
2025-03-26 02:24:05,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34232, dest: /172.20.1.12:9866, bytes: 39474, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741843_1019, duration(ns): 4604445
2025-03-26 02:24:05,897 INFO terminating
2025-03-26 02:24:05,898 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_svm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:06,339 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/data/mllib/images/license.txt._COPYING_
2025-03-26 02:24:06,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:06,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:06,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741844_1020 src: /172.20.1.10:34788 dest: /172.20.1.13:9866
2025-03-26 02:24:06,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741844_1020 src: /172.20.1.13:56198 dest: /172.20.1.12:9866
2025-03-26 02:24:06,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741844_1020 src: /172.20.1.12:46400 dest: /172.20.1.11:9866
2025-03-26 02:24:06,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46400, dest: /172.20.1.11:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741844_1020, duration(ns): 3130121
2025-03-26 02:24:06,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:06,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56198, dest: /172.20.1.12:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741844_1020, duration(ns): 4014526
2025-03-26 02:24:06,452 INFO terminating
2025-03-26 02:24:06,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:34788, dest: /172.20.1.13:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741844_1020, duration(ns): 4487563
2025-03-26 02:24:06,453 INFO terminating
2025-03-26 02:24:06,454 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/license.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/images/origin/multi-channel/grayscale.jpg._COPYING_
2025-03-26 02:24:07,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741845_1021 src: /172.20.1.10:44112 dest: /172.20.1.13:9866
2025-03-26 02:24:07,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741845_1021 src: /172.20.1.13:52404 dest: /172.20.1.11:9866
2025-03-26 02:24:07,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741845_1021 src: /172.20.1.11:56536 dest: /172.20.1.12:9866
2025-03-26 02:24:07,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56536, dest: /172.20.1.12:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741845_1021, duration(ns): 2478650
2025-03-26 02:24:07,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44112, dest: /172.20.1.13:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741845_1021, duration(ns): 3651620
2025-03-26 02:24:07,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52404, dest: /172.20.1.11:9866, bytes: 36728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741845_1021, duration(ns): 2969808
2025-03-26 02:24:07,139 INFO terminating
2025-03-26 02:24:07,140 INFO terminating
2025-03-26 02:24:07,141 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/grayscale.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png._COPYING_
2025-03-26 02:24:07,571 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,571 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741846_1022 src: /172.20.1.10:44118 dest: /172.20.1.13:9866
2025-03-26 02:24:07,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741846_1022 src: /172.20.1.13:47016 dest: /172.20.1.12:9866
2025-03-26 02:24:07,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741846_1022 src: /172.20.1.12:45284 dest: /172.20.1.11:9866
2025-03-26 02:24:07,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45284, dest: /172.20.1.11:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741846_1022, duration(ns): 2757151
2025-03-26 02:24:07,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47016, dest: /172.20.1.12:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741846_1022, duration(ns): 3399628
2025-03-26 02:24:07,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,580 INFO terminating
2025-03-26 02:24:07,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44118, dest: /172.20.1.13:9866, bytes: 747, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741846_1022, duration(ns): 3797760
2025-03-26 02:24:07,581 INFO terminating
2025-03-26 02:24:07,582 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,588 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,588 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,589 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/data/mllib/images/origin/multi-channel/BGRA.png._COPYING_
2025-03-26 02:24:07,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741847_1023 src: /172.20.1.10:44128 dest: /172.20.1.13:9866
2025-03-26 02:24:07,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741847_1023 src: /172.20.1.13:47026 dest: /172.20.1.12:9866
2025-03-26 02:24:07,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741847_1023 src: /172.20.1.12:45288 dest: /172.20.1.11:9866
2025-03-26 02:24:07,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45288, dest: /172.20.1.11:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741847_1023, duration(ns): 2330256
2025-03-26 02:24:07,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47026, dest: /172.20.1.12:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741847_1023, duration(ns): 3217878
2025-03-26 02:24:07,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44128, dest: /172.20.1.13:9866, bytes: 683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741847_1023, duration(ns): 4668549
2025-03-26 02:24:07,599 INFO terminating
2025-03-26 02:24:07,600 INFO terminating
2025-03-26 02:24:07,601 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/BGRA.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/data/mllib/images/origin/multi-channel/chr30.4.184.jpg._COPYING_
2025-03-26 02:24:07,611 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,611 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741848_1024 src: /172.20.1.10:47488 dest: /172.20.1.11:9866
2025-03-26 02:24:07,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741848_1024 src: /172.20.1.11:56540 dest: /172.20.1.12:9866
2025-03-26 02:24:07,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741848_1024 src: /172.20.1.12:46524 dest: /172.20.1.13:9866
2025-03-26 02:24:07,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46524, dest: /172.20.1.13:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741848_1024, duration(ns): 2621264
2025-03-26 02:24:07,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47488, dest: /172.20.1.11:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741848_1024, duration(ns): 3477668
2025-03-26 02:24:07,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56540, dest: /172.20.1.12:9866, bytes: 59472, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741848_1024, duration(ns): 3080785
2025-03-26 02:24:07,621 INFO terminating
2025-03-26 02:24:07,621 INFO terminating
2025-03-26 02:24:07,623 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/multi-channel/chr30.4.184.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/mllib/images/origin/license.txt._COPYING_
2025-03-26 02:24:07,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741849_1025 src: /172.20.1.10:41218 dest: /172.20.1.12:9866
2025-03-26 02:24:07,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741849_1025 src: /172.20.1.12:45304 dest: /172.20.1.11:9866
2025-03-26 02:24:07,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741849_1025 src: /172.20.1.11:60702 dest: /172.20.1.13:9866
2025-03-26 02:24:07,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60702, dest: /172.20.1.13:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741849_1025, duration(ns): 7119480
2025-03-26 02:24:07,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45304, dest: /172.20.1.11:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741849_1025, duration(ns): 7533180
2025-03-26 02:24:07,642 INFO terminating
2025-03-26 02:24:07,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41218, dest: /172.20.1.12:9866, bytes: 830, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741849_1025, duration(ns): 8060435
2025-03-26 02:24:07,645 INFO terminating
2025-03-26 02:24:07,647 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/license.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,662 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg._COPYING_
2025-03-26 02:24:07,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741850_1026 src: /172.20.1.10:41220 dest: /172.20.1.12:9866
2025-03-26 02:24:07,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741850_1026 src: /172.20.1.12:46538 dest: /172.20.1.13:9866
2025-03-26 02:24:07,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741850_1026 src: /172.20.1.13:52420 dest: /172.20.1.11:9866
2025-03-26 02:24:07,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52420, dest: /172.20.1.11:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741850_1026, duration(ns): 2424339
2025-03-26 02:24:07,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46538, dest: /172.20.1.13:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741850_1026, duration(ns): 4584859
2025-03-26 02:24:07,671 INFO terminating
2025-03-26 02:24:07,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41220, dest: /172.20.1.12:9866, bytes: 27295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741850_1026, duration(ns): 5489980
2025-03-26 02:24:07,673 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,673 INFO terminating
2025-03-26 02:24:07,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/data/mllib/images/origin/kittens/DP802813.jpg._COPYING_
2025-03-26 02:24:07,681 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,681 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741851_1027 src: /172.20.1.10:47490 dest: /172.20.1.11:9866
2025-03-26 02:24:07,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741851_1027 src: /172.20.1.11:56554 dest: /172.20.1.12:9866
2025-03-26 02:24:07,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741851_1027 src: /172.20.1.12:46540 dest: /172.20.1.13:9866
2025-03-26 02:24:07,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56554, dest: /172.20.1.12:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741851_1027, duration(ns): 3002416
2025-03-26 02:24:07,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46540, dest: /172.20.1.13:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741851_1027, duration(ns): 2303822
2025-03-26 02:24:07,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,690 INFO terminating
2025-03-26 02:24:07,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47490, dest: /172.20.1.11:9866, bytes: 30432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741851_1027, duration(ns): 3903931
2025-03-26 02:24:07,691 INFO terminating
2025-03-26 02:24:07,692 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/DP802813.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,700 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/data/mllib/images/origin/kittens/DP153539.jpg._COPYING_
2025-03-26 02:24:07,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741852_1028 src: /172.20.1.10:44140 dest: /172.20.1.13:9866
2025-03-26 02:24:07,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741852_1028 src: /172.20.1.13:47042 dest: /172.20.1.12:9866
2025-03-26 02:24:07,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741852_1028 src: /172.20.1.12:45310 dest: /172.20.1.11:9866
2025-03-26 02:24:07,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45310, dest: /172.20.1.11:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741852_1028, duration(ns): 2394748
2025-03-26 02:24:07,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47042, dest: /172.20.1.12:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741852_1028, duration(ns): 3267806
2025-03-26 02:24:07,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,708 INFO terminating
2025-03-26 02:24:07,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44140, dest: /172.20.1.13:9866, bytes: 26354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741852_1028, duration(ns): 3658065
2025-03-26 02:24:07,709 INFO terminating
2025-03-26 02:24:07,710 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/DP153539.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/images/origin/kittens/not-image.txt._COPYING_
2025-03-26 02:24:07,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741853_1029 src: /172.20.1.10:47494 dest: /172.20.1.11:9866
2025-03-26 02:24:07,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741853_1029 src: /172.20.1.11:60714 dest: /172.20.1.13:9866
2025-03-26 02:24:07,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741853_1029 src: /172.20.1.13:47048 dest: /172.20.1.12:9866
2025-03-26 02:24:07,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60714, dest: /172.20.1.13:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741853_1029, duration(ns): 3312043
2025-03-26 02:24:07,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47048, dest: /172.20.1.12:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741853_1029, duration(ns): 2933983
2025-03-26 02:24:07,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,730 INFO terminating
2025-03-26 02:24:07,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47494, dest: /172.20.1.11:9866, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741853_1029, duration(ns): 3653954
2025-03-26 02:24:07,731 INFO terminating
2025-03-26 02:24:07,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/not-image.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,741 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/images/origin/kittens/54893.jpg._COPYING_
2025-03-26 02:24:07,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741854_1030 src: /172.20.1.10:44142 dest: /172.20.1.13:9866
2025-03-26 02:24:07,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741854_1030 src: /172.20.1.13:52436 dest: /172.20.1.11:9866
2025-03-26 02:24:07,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741854_1030 src: /172.20.1.11:56568 dest: /172.20.1.12:9866
2025-03-26 02:24:07,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56568, dest: /172.20.1.12:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741854_1030, duration(ns): 3245479
2025-03-26 02:24:07,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52436, dest: /172.20.1.11:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741854_1030, duration(ns): 3578005
2025-03-26 02:24:07,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44142, dest: /172.20.1.13:9866, bytes: 35914, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741854_1030, duration(ns): 4426496
2025-03-26 02:24:07,753 INFO terminating
2025-03-26 02:24:07,753 INFO terminating
2025-03-26 02:24:07,754 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/images/origin/kittens/54893.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,763 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/mllib/sample_linear_regression_data.txt._COPYING_
2025-03-26 02:24:07,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741855_1031 src: /172.20.1.10:41236 dest: /172.20.1.12:9866
2025-03-26 02:24:07,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741855_1031 src: /172.20.1.12:46542 dest: /172.20.1.13:9866
2025-03-26 02:24:07,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741855_1031 src: /172.20.1.13:52440 dest: /172.20.1.11:9866
2025-03-26 02:24:07,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46542, dest: /172.20.1.13:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741855_1031, duration(ns): 2915336
2025-03-26 02:24:07,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52440, dest: /172.20.1.11:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741855_1031, duration(ns): 2576903
2025-03-26 02:24:07,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,770 INFO terminating
2025-03-26 02:24:07,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41236, dest: /172.20.1.12:9866, bytes: 119069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741855_1031, duration(ns): 3441191
2025-03-26 02:24:07,771 INFO terminating
2025-03-26 02:24:07,772 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_linear_regression_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,779 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_binary_classification_data.txt._COPYING_
2025-03-26 02:24:07,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741856_1032 src: /172.20.1.10:47502 dest: /172.20.1.11:9866
2025-03-26 02:24:07,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741856_1032 src: /172.20.1.11:60722 dest: /172.20.1.13:9866
2025-03-26 02:24:07,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741856_1032 src: /172.20.1.13:47058 dest: /172.20.1.12:9866
2025-03-26 02:24:07,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47058, dest: /172.20.1.12:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741856_1032, duration(ns): 9730933
2025-03-26 02:24:07,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60722, dest: /172.20.1.13:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741856_1032, duration(ns): 10260122
2025-03-26 02:24:07,794 INFO terminating
2025-03-26 02:24:07,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47502, dest: /172.20.1.11:9866, bytes: 104736, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741856_1032, duration(ns): 11304033
2025-03-26 02:24:07,795 INFO terminating
2025-03-26 02:24:07,796 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_binary_classification_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,802 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,802 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,803 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_multiclass_classification_data.txt._COPYING_
2025-03-26 02:24:07,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741857_1033 src: /172.20.1.10:44152 dest: /172.20.1.13:9866
2025-03-26 02:24:07,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741857_1033 src: /172.20.1.13:52444 dest: /172.20.1.11:9866
2025-03-26 02:24:07,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741857_1033 src: /172.20.1.11:56584 dest: /172.20.1.12:9866
2025-03-26 02:24:07,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56584, dest: /172.20.1.12:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741857_1033, duration(ns): 1879960
2025-03-26 02:24:07,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52444, dest: /172.20.1.11:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741857_1033, duration(ns): 2305934
2025-03-26 02:24:07,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,810 INFO terminating
2025-03-26 02:24:07,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44152, dest: /172.20.1.13:9866, bytes: 6953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741857_1033, duration(ns): 2909241
2025-03-26 02:24:07,811 INFO terminating
2025-03-26 02:24:07,812 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_multiclass_classification_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,819 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/data/mllib/sample_isotonic_regression_libsvm_data.txt._COPYING_
2025-03-26 02:24:07,819 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,819 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741858_1034 src: /172.20.1.10:44166 dest: /172.20.1.13:9866
2025-03-26 02:24:07,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741858_1034 src: /172.20.1.13:52454 dest: /172.20.1.11:9866
2025-03-26 02:24:07,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741858_1034 src: /172.20.1.11:56600 dest: /172.20.1.12:9866
2025-03-26 02:24:07,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56600, dest: /172.20.1.12:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741858_1034, duration(ns): 2188866
2025-03-26 02:24:07,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44166, dest: /172.20.1.13:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741858_1034, duration(ns): 3219242
2025-03-26 02:24:07,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52454, dest: /172.20.1.11:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741858_1034, duration(ns): 2686647
2025-03-26 02:24:07,827 INFO terminating
2025-03-26 02:24:07,828 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/sample_isotonic_regression_libsvm_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,828 INFO terminating
2025-03-26 02:24:07,837 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/data/mllib/pic_data.txt._COPYING_
2025-03-26 02:24:07,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741859_1035 src: /172.20.1.10:41240 dest: /172.20.1.12:9866
2025-03-26 02:24:07,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741859_1035 src: /172.20.1.12:45314 dest: /172.20.1.11:9866
2025-03-26 02:24:07,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741859_1035 src: /172.20.1.11:60738 dest: /172.20.1.13:9866
2025-03-26 02:24:07,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60738, dest: /172.20.1.13:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741859_1035, duration(ns): 2657574
2025-03-26 02:24:07,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45314, dest: /172.20.1.11:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741859_1035, duration(ns): 2972504
2025-03-26 02:24:07,845 INFO terminating
2025-03-26 02:24:07,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41240, dest: /172.20.1.12:9866, bytes: 164, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741859_1035, duration(ns): 3398201
2025-03-26 02:24:07,846 INFO terminating
2025-03-26 02:24:07,847 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/pic_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,856 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/data/mllib/kmeans_data.txt._COPYING_
2025-03-26 02:24:07,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741860_1036 src: /172.20.1.10:44178 dest: /172.20.1.13:9866
2025-03-26 02:24:07,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741860_1036 src: /172.20.1.13:47072 dest: /172.20.1.12:9866
2025-03-26 02:24:07,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741860_1036 src: /172.20.1.12:45320 dest: /172.20.1.11:9866
2025-03-26 02:24:07,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45320, dest: /172.20.1.11:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741860_1036, duration(ns): 2190169
2025-03-26 02:24:07,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44178, dest: /172.20.1.13:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741860_1036, duration(ns): 3164121
2025-03-26 02:24:07,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47072, dest: /172.20.1.12:9866, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741860_1036, duration(ns): 2747800
2025-03-26 02:24:07,864 INFO terminating
2025-03-26 02:24:07,865 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/mllib/kmeans_data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:07,865 INFO terminating
2025-03-26 02:24:07,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/data/streaming/AFINN-111.txt._COPYING_
2025-03-26 02:24:07,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:07,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741861_1037 src: /172.20.1.10:41246 dest: /172.20.1.12:9866
2025-03-26 02:24:07,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741861_1037 src: /172.20.1.12:46556 dest: /172.20.1.13:9866
2025-03-26 02:24:07,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741861_1037 src: /172.20.1.13:52458 dest: /172.20.1.11:9866
2025-03-26 02:24:07,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52458, dest: /172.20.1.11:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741861_1037, duration(ns): 2067265
2025-03-26 02:24:07,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:07,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41246, dest: /172.20.1.12:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741861_1037, duration(ns): 3071760
2025-03-26 02:24:07,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46556, dest: /172.20.1.13:9866, bytes: 28093, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1146159410_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741861_1037, duration(ns): 2695896
2025-03-26 02:24:07,882 INFO terminating
2025-03-26 02:24:07,882 INFO terminating
2025-03-26 02:24:07,883 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/data/streaming/AFINN-111.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1146159410_1
2025-03-26 02:24:09,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:09,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:09,507 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/jars/scopt_2.12-3.7.1.jar._COPYING_
2025-03-26 02:24:09,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741862_1038 src: /172.20.1.10:47506 dest: /172.20.1.11:9866
2025-03-26 02:24:09,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741862_1038 src: /172.20.1.11:56602 dest: /172.20.1.12:9866
2025-03-26 02:24:09,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741862_1038 src: /172.20.1.12:46560 dest: /172.20.1.13:9866
2025-03-26 02:24:09,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46560, dest: /172.20.1.13:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741862_1038, duration(ns): 10340424
2025-03-26 02:24:09,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56602, dest: /172.20.1.12:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741862_1038, duration(ns): 11649831
2025-03-26 02:24:09,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:09,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47506, dest: /172.20.1.11:9866, bytes: 78803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741862_1038, duration(ns): 12405914
2025-03-26 02:24:09,644 INFO terminating
2025-03-26 02:24:09,645 INFO terminating
2025-03-26 02:24:09,647 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/jars/scopt_2.12-3.7.1.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:09,906 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:09,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/jars/spark-examples_2.12-3.3.2.jar._COPYING_
2025-03-26 02:24:09,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:09,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741863_1039 src: /172.20.1.10:47514 dest: /172.20.1.11:9866
2025-03-26 02:24:09,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741863_1039 src: /172.20.1.11:56606 dest: /172.20.1.12:9866
2025-03-26 02:24:09,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741863_1039 src: /172.20.1.12:46574 dest: /172.20.1.13:9866
2025-03-26 02:24:09,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46574, dest: /172.20.1.13:9866, bytes: 1567446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741863_1039, duration(ns): 7427460
2025-03-26 02:24:09,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:09,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56606, dest: /172.20.1.12:9866, bytes: 1567446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741863_1039, duration(ns): 7194746
2025-03-26 02:24:09,993 INFO terminating
2025-03-26 02:24:09,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47514, dest: /172.20.1.11:9866, bytes: 1567446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741863_1039, duration(ns): 8639038
2025-03-26 02:24:09,995 INFO terminating
2025-03-26 02:24:09,996 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/jars/spark-examples_2.12-3.3.2.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:10,825 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/wordcount.py._COPYING_
2025-03-26 02:24:10,825 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:10,825 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:10,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741864_1040 src: /172.20.1.10:41254 dest: /172.20.1.12:9866
2025-03-26 02:24:10,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741864_1040 src: /172.20.1.12:45324 dest: /172.20.1.11:9866
2025-03-26 02:24:10,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741864_1040 src: /172.20.1.11:60752 dest: /172.20.1.13:9866
2025-03-26 02:24:10,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60752, dest: /172.20.1.13:9866, bytes: 1418, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741864_1040, duration(ns): 4720998
2025-03-26 02:24:10,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:10,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41254, dest: /172.20.1.12:9866, bytes: 1418, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741864_1040, duration(ns): 5733691
2025-03-26 02:24:10,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45324, dest: /172.20.1.11:9866, bytes: 1418, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741864_1040, duration(ns): 5300739
2025-03-26 02:24:10,993 INFO terminating
2025-03-26 02:24:10,994 INFO terminating
2025-03-26 02:24:10,995 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:11,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:11,441 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/transitive_closure.py._COPYING_
2025-03-26 02:24:11,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:11,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741865_1041 src: /172.20.1.10:47528 dest: /172.20.1.11:9866
2025-03-26 02:24:11,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741865_1041 src: /172.20.1.11:60768 dest: /172.20.1.13:9866
2025-03-26 02:24:11,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741865_1041 src: /172.20.1.13:47082 dest: /172.20.1.12:9866
2025-03-26 02:24:11,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47082, dest: /172.20.1.12:9866, bytes: 2445, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741865_1041, duration(ns): 1896127
2025-03-26 02:24:11,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:11,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60768, dest: /172.20.1.13:9866, bytes: 2445, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741865_1041, duration(ns): 2330203
2025-03-26 02:24:11,760 INFO terminating
2025-03-26 02:24:11,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47528, dest: /172.20.1.11:9866, bytes: 2445, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741865_1041, duration(ns): 3290694
2025-03-26 02:24:11,761 INFO terminating
2025-03-26 02:24:11,762 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/transitive_closure.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:12,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:12,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:12,240 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_
2025-03-26 02:24:12,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741866_1042 src: /172.20.1.10:47534 dest: /172.20.1.11:9866
2025-03-26 02:24:12,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741866_1042 src: /172.20.1.11:60782 dest: /172.20.1.13:9866
2025-03-26 02:24:12,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741866_1042 src: /172.20.1.13:47086 dest: /172.20.1.12:9866
2025-03-26 02:24:12,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47086, dest: /172.20.1.12:9866, bytes: 2432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741866_1042, duration(ns): 2098666
2025-03-26 02:24:12,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60782, dest: /172.20.1.13:9866, bytes: 2432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741866_1042, duration(ns): 2680263
2025-03-26 02:24:12,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:12,488 INFO terminating
2025-03-26 02:24:12,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47534, dest: /172.20.1.11:9866, bytes: 2432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741866_1042, duration(ns): 3228222
2025-03-26 02:24:12,489 INFO terminating
2025-03-26 02:24:12,490 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/parquet_inputformat.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:12,721 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:12,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/pi.py._COPYING_
2025-03-26 02:24:12,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:12,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741867_1043 src: /172.20.1.10:47540 dest: /172.20.1.11:9866
2025-03-26 02:24:12,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741867_1043 src: /172.20.1.11:56618 dest: /172.20.1.12:9866
2025-03-26 02:24:12,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741867_1043 src: /172.20.1.12:46584 dest: /172.20.1.13:9866
2025-03-26 02:24:12,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46584, dest: /172.20.1.13:9866, bytes: 1444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741867_1043, duration(ns): 10955956
2025-03-26 02:24:12,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:12,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56618, dest: /172.20.1.12:9866, bytes: 1444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741867_1043, duration(ns): 13972849
2025-03-26 02:24:12,825 INFO terminating
2025-03-26 02:24:12,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47540, dest: /172.20.1.11:9866, bytes: 1444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741867_1043, duration(ns): 17186491
2025-03-26 02:24:12,828 INFO terminating
2025-03-26 02:24:12,832 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/pi.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:13,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:13,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:13,081 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/sort.py._COPYING_
2025-03-26 02:24:13,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741868_1044 src: /172.20.1.10:41258 dest: /172.20.1.12:9866
2025-03-26 02:24:13,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741868_1044 src: /172.20.1.12:45338 dest: /172.20.1.11:9866
2025-03-26 02:24:13,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741868_1044 src: /172.20.1.11:60792 dest: /172.20.1.13:9866
2025-03-26 02:24:13,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60792, dest: /172.20.1.13:9866, bytes: 1594, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741868_1044, duration(ns): 2378990
2025-03-26 02:24:13,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741868_1044, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:13,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41258, dest: /172.20.1.12:9866, bytes: 1594, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741868_1044, duration(ns): 3202142
2025-03-26 02:24:13,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45338, dest: /172.20.1.11:9866, bytes: 1594, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741868_1044, duration(ns): 2758216
2025-03-26 02:24:13,236 INFO terminating
2025-03-26 02:24:13,236 INFO terminating
2025-03-26 02:24:13,238 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sort.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:13,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:13,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:13,467 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/status_api_demo.py._COPYING_
2025-03-26 02:24:13,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741869_1045 src: /172.20.1.10:47552 dest: /172.20.1.11:9866
2025-03-26 02:24:13,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741869_1045 src: /172.20.1.11:60800 dest: /172.20.1.13:9866
2025-03-26 02:24:13,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741869_1045 src: /172.20.1.13:47098 dest: /172.20.1.12:9866
2025-03-26 02:24:13,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60800, dest: /172.20.1.13:9866, bytes: 2368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741869_1045, duration(ns): 2271343
2025-03-26 02:24:13,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47098, dest: /172.20.1.12:9866, bytes: 2368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741869_1045, duration(ns): 1912522
2025-03-26 02:24:13,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741869_1045, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:13,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47552, dest: /172.20.1.11:9866, bytes: 2368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741869_1045, duration(ns): 2854393
2025-03-26 02:24:13,618 INFO terminating
2025-03-26 02:24:13,618 INFO terminating
2025-03-26 02:24:13,619 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/status_api_demo.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:13,843 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/avro_inputformat.py._COPYING_
2025-03-26 02:24:13,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:13,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:13,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741870_1046 src: /172.20.1.10:41264 dest: /172.20.1.12:9866
2025-03-26 02:24:13,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741870_1046 src: /172.20.1.12:46588 dest: /172.20.1.13:9866
2025-03-26 02:24:13,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741870_1046 src: /172.20.1.13:52462 dest: /172.20.1.11:9866
2025-03-26 02:24:13,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52462, dest: /172.20.1.11:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741870_1046, duration(ns): 6209851
2025-03-26 02:24:13,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46588, dest: /172.20.1.13:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741870_1046, duration(ns): 6808687
2025-03-26 02:24:13,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741870_1046, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:13,997 INFO terminating
2025-03-26 02:24:13,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41264, dest: /172.20.1.12:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741870_1046, duration(ns): 7220939
2025-03-26 02:24:13,998 INFO terminating
2025-03-26 02:24:13,999 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/avro_inputformat.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:14,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:14,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:14,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/logistic_regression.py._COPYING_
2025-03-26 02:24:14,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741871_1047 src: /172.20.1.10:44180 dest: /172.20.1.13:9866
2025-03-26 02:24:14,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741871_1047 src: /172.20.1.13:52476 dest: /172.20.1.11:9866
2025-03-26 02:24:14,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741871_1047 src: /172.20.1.11:56628 dest: /172.20.1.12:9866
2025-03-26 02:24:14,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56628, dest: /172.20.1.12:9866, bytes: 3307, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741871_1047, duration(ns): 4711967
2025-03-26 02:24:14,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741871_1047, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:14,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52476, dest: /172.20.1.11:9866, bytes: 3307, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741871_1047, duration(ns): 5429354
2025-03-26 02:24:14,383 INFO terminating
2025-03-26 02:24:14,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44180, dest: /172.20.1.13:9866, bytes: 3307, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741871_1047, duration(ns): 6629283
2025-03-26 02:24:14,384 INFO terminating
2025-03-26 02:24:14,387 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/logistic_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:14,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:14,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:14,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/kmeans.py._COPYING_
2025-03-26 02:24:14,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741872_1048 src: /172.20.1.10:41276 dest: /172.20.1.12:9866
2025-03-26 02:24:14,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741872_1048 src: /172.20.1.12:45342 dest: /172.20.1.11:9866
2025-03-26 02:24:14,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741872_1048 src: /172.20.1.11:60814 dest: /172.20.1.13:9866
2025-03-26 02:24:14,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60814, dest: /172.20.1.13:9866, bytes: 2818, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741872_1048, duration(ns): 2466391
2025-03-26 02:24:14,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741872_1048, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:14,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41276, dest: /172.20.1.12:9866, bytes: 2818, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741872_1048, duration(ns): 3787675
2025-03-26 02:24:14,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45342, dest: /172.20.1.11:9866, bytes: 2818, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741872_1048, duration(ns): 3395166
2025-03-26 02:24:14,785 INFO terminating
2025-03-26 02:24:14,785 INFO terminating
2025-03-26 02:24:14,790 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/kmeans.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:15,106 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/svd_example.py._COPYING_
2025-03-26 02:24:15,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:15,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:15,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741873_1049 src: /172.20.1.10:44186 dest: /172.20.1.13:9866
2025-03-26 02:24:15,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741873_1049 src: /172.20.1.13:52486 dest: /172.20.1.11:9866
2025-03-26 02:24:15,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741873_1049 src: /172.20.1.11:56632 dest: /172.20.1.12:9866
2025-03-26 02:24:15,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56632, dest: /172.20.1.12:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741873_1049, duration(ns): 2119793
2025-03-26 02:24:15,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741873_1049, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:15,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44186, dest: /172.20.1.13:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741873_1049, duration(ns): 3575008
2025-03-26 02:24:15,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52486, dest: /172.20.1.11:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741873_1049, duration(ns): 2890734
2025-03-26 02:24:15,187 INFO terminating
2025-03-26 02:24:15,187 INFO terminating
2025-03-26 02:24:15,188 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/svd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:15,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/random_forest_regression_example.py._COPYING_
2025-03-26 02:24:15,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:15,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:15,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741874_1050 src: /172.20.1.10:41284 dest: /172.20.1.12:9866
2025-03-26 02:24:15,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741874_1050 src: /172.20.1.12:45346 dest: /172.20.1.11:9866
2025-03-26 02:24:15,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741874_1050 src: /172.20.1.11:60826 dest: /172.20.1.13:9866
2025-03-26 02:24:15,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60826, dest: /172.20.1.13:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741874_1050, duration(ns): 2034392
2025-03-26 02:24:15,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45346, dest: /172.20.1.11:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741874_1050, duration(ns): 2756689
2025-03-26 02:24:15,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741874_1050, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:15,585 INFO terminating
2025-03-26 02:24:15,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41284, dest: /172.20.1.12:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741874_1050, duration(ns): 3245019
2025-03-26 02:24:15,586 INFO terminating
2025-03-26 02:24:15,587 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_forest_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,090 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/streaming_linear_regression_example.py._COPYING_
2025-03-26 02:24:16,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741875_1051 src: /172.20.1.10:47566 dest: /172.20.1.11:9866
2025-03-26 02:24:16,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741875_1051 src: /172.20.1.11:56642 dest: /172.20.1.12:9866
2025-03-26 02:24:16,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741875_1051 src: /172.20.1.12:46600 dest: /172.20.1.13:9866
2025-03-26 02:24:16,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46600, dest: /172.20.1.13:9866, bytes: 2082, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741875_1051, duration(ns): 1987721
2025-03-26 02:24:16,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56642, dest: /172.20.1.12:9866, bytes: 2082, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741875_1051, duration(ns): 2428511
2025-03-26 02:24:16,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741875_1051, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47566, dest: /172.20.1.11:9866, bytes: 2082, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741875_1051, duration(ns): 3394668
2025-03-26 02:24:16,112 INFO terminating
2025-03-26 02:24:16,112 INFO terminating
2025-03-26 02:24:16,114 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/streaming_linear_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/recommendation_example.py._COPYING_
2025-03-26 02:24:16,126 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,126 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741876_1052 src: /172.20.1.10:41298 dest: /172.20.1.12:9866
2025-03-26 02:24:16,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741876_1052 src: /172.20.1.12:46614 dest: /172.20.1.13:9866
2025-03-26 02:24:16,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741876_1052 src: /172.20.1.13:52490 dest: /172.20.1.11:9866
2025-03-26 02:24:16,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52490, dest: /172.20.1.11:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741876_1052, duration(ns): 2065086
2025-03-26 02:24:16,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741876_1052, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41298, dest: /172.20.1.12:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741876_1052, duration(ns): 2668583
2025-03-26 02:24:16,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46614, dest: /172.20.1.13:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741876_1052, duration(ns): 2385151
2025-03-26 02:24:16,134 INFO terminating
2025-03-26 02:24:16,134 INFO terminating
2025-03-26 02:24:16,135 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/recommendation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,145 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/random_forest_classification_example.py._COPYING_
2025-03-26 02:24:16,145 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,145 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741877_1053 src: /172.20.1.10:47576 dest: /172.20.1.11:9866
2025-03-26 02:24:16,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741877_1053 src: /172.20.1.11:56648 dest: /172.20.1.12:9866
2025-03-26 02:24:16,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741877_1053 src: /172.20.1.12:46618 dest: /172.20.1.13:9866
2025-03-26 02:24:16,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46618, dest: /172.20.1.13:9866, bytes: 2533, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741877_1053, duration(ns): 1787053
2025-03-26 02:24:16,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741877_1053, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47576, dest: /172.20.1.11:9866, bytes: 2533, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741877_1053, duration(ns): 2824398
2025-03-26 02:24:16,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56648, dest: /172.20.1.12:9866, bytes: 2533, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741877_1053, duration(ns): 2415718
2025-03-26 02:24:16,152 INFO terminating
2025-03-26 02:24:16,152 INFO terminating
2025-03-26 02:24:16,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_forest_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,163 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/gaussian_mixture_model.py._COPYING_
2025-03-26 02:24:16,163 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,163 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741878_1054 src: /172.20.1.10:47580 dest: /172.20.1.11:9866
2025-03-26 02:24:16,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741878_1054 src: /172.20.1.11:60838 dest: /172.20.1.13:9866
2025-03-26 02:24:16,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741878_1054 src: /172.20.1.13:47114 dest: /172.20.1.12:9866
2025-03-26 02:24:16,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60838, dest: /172.20.1.13:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741878_1054, duration(ns): 2124540
2025-03-26 02:24:16,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47114, dest: /172.20.1.12:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741878_1054, duration(ns): 1849030
2025-03-26 02:24:16,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741878_1054, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47580, dest: /172.20.1.11:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741878_1054, duration(ns): 2743168
2025-03-26 02:24:16,171 INFO terminating
2025-03-26 02:24:16,171 INFO terminating
2025-03-26 02:24:16,172 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gaussian_mixture_model.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/stratified_sampling_example.py._COPYING_
2025-03-26 02:24:16,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741879_1055 src: /172.20.1.10:47588 dest: /172.20.1.11:9866
2025-03-26 02:24:16,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741879_1055 src: /172.20.1.11:60854 dest: /172.20.1.13:9866
2025-03-26 02:24:16,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741879_1055 src: /172.20.1.13:47122 dest: /172.20.1.12:9866
2025-03-26 02:24:16,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60854, dest: /172.20.1.13:9866, bytes: 1329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741879_1055, duration(ns): 1758371
2025-03-26 02:24:16,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47122, dest: /172.20.1.12:9866, bytes: 1329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741879_1055, duration(ns): 1444947
2025-03-26 02:24:16,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741879_1055, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47588, dest: /172.20.1.11:9866, bytes: 1329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741879_1055, duration(ns): 2282736
2025-03-26 02:24:16,191 INFO terminating
2025-03-26 02:24:16,191 INFO terminating
2025-03-26 02:24:16,192 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/stratified_sampling_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,199 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/tf_idf_example.py._COPYING_
2025-03-26 02:24:16,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741880_1056 src: /172.20.1.10:41302 dest: /172.20.1.12:9866
2025-03-26 02:24:16,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741880_1056 src: /172.20.1.12:46620 dest: /172.20.1.13:9866
2025-03-26 02:24:16,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741880_1056 src: /172.20.1.13:52498 dest: /172.20.1.11:9866
2025-03-26 02:24:16,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46620, dest: /172.20.1.13:9866, bytes: 2027, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741880_1056, duration(ns): 6960936
2025-03-26 02:24:16,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52498, dest: /172.20.1.11:9866, bytes: 2027, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741880_1056, duration(ns): 6219313
2025-03-26 02:24:16,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741880_1056, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41302, dest: /172.20.1.12:9866, bytes: 2027, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741880_1056, duration(ns): 7450223
2025-03-26 02:24:16,211 INFO terminating
2025-03-26 02:24:16,211 INFO terminating
2025-03-26 02:24:16,212 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/tf_idf_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/bisecting_k_means_example.py._COPYING_
2025-03-26 02:24:16,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741881_1057 src: /172.20.1.10:41306 dest: /172.20.1.12:9866
2025-03-26 02:24:16,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741881_1057 src: /172.20.1.12:46630 dest: /172.20.1.13:9866
2025-03-26 02:24:16,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741881_1057 src: /172.20.1.13:52514 dest: /172.20.1.11:9866
2025-03-26 02:24:16,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52514, dest: /172.20.1.11:9866, bytes: 1512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741881_1057, duration(ns): 2188372
2025-03-26 02:24:16,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741881_1057, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41306, dest: /172.20.1.12:9866, bytes: 1512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741881_1057, duration(ns): 3308581
2025-03-26 02:24:16,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46630, dest: /172.20.1.13:9866, bytes: 1512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741881_1057, duration(ns): 2967367
2025-03-26 02:24:16,225 INFO terminating
2025-03-26 02:24:16,227 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/bisecting_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,227 INFO terminating
2025-03-26 02:24:16,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,235 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/logistic_regression.py._COPYING_
2025-03-26 02:24:16,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741882_1058 src: /172.20.1.10:41316 dest: /172.20.1.12:9866
2025-03-26 02:24:16,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741882_1058 src: /172.20.1.12:45362 dest: /172.20.1.11:9866
2025-03-26 02:24:16,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741882_1058 src: /172.20.1.11:60860 dest: /172.20.1.13:9866
2025-03-26 02:24:16,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60860, dest: /172.20.1.13:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741882_1058, duration(ns): 3621897
2025-03-26 02:24:16,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741882_1058, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41316, dest: /172.20.1.12:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741882_1058, duration(ns): 4703424
2025-03-26 02:24:16,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45362, dest: /172.20.1.11:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741882_1058, duration(ns): 3945879
2025-03-26 02:24:16,244 INFO terminating
2025-03-26 02:24:16,244 INFO terminating
2025-03-26 02:24:16,246 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/logistic_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/naive_bayes_example.py._COPYING_
2025-03-26 02:24:16,256 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,256 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741883_1059 src: /172.20.1.10:44198 dest: /172.20.1.13:9866
2025-03-26 02:24:16,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741883_1059 src: /172.20.1.13:52516 dest: /172.20.1.11:9866
2025-03-26 02:24:16,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741883_1059 src: /172.20.1.11:56652 dest: /172.20.1.12:9866
2025-03-26 02:24:16,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56652, dest: /172.20.1.12:9866, bytes: 2246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741883_1059, duration(ns): 3655062
2025-03-26 02:24:16,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741883_1059, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44198, dest: /172.20.1.13:9866, bytes: 2246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741883_1059, duration(ns): 3118262
2025-03-26 02:24:16,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52516, dest: /172.20.1.11:9866, bytes: 2246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741883_1059, duration(ns): 2325215
2025-03-26 02:24:16,266 INFO terminating
2025-03-26 02:24:16,266 INFO terminating
2025-03-26 02:24:16,267 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/naive_bayes_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/streaming_k_means_example.py._COPYING_
2025-03-26 02:24:16,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741884_1060 src: /172.20.1.10:47592 dest: /172.20.1.11:9866
2025-03-26 02:24:16,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741884_1060 src: /172.20.1.11:56656 dest: /172.20.1.12:9866
2025-03-26 02:24:16,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741884_1060 src: /172.20.1.12:46644 dest: /172.20.1.13:9866
2025-03-26 02:24:16,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56656, dest: /172.20.1.12:9866, bytes: 2530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741884_1060, duration(ns): 4726197
2025-03-26 02:24:16,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46644, dest: /172.20.1.13:9866, bytes: 2530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741884_1060, duration(ns): 4941676
2025-03-26 02:24:16,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741884_1060, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,288 INFO terminating
2025-03-26 02:24:16,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47592, dest: /172.20.1.11:9866, bytes: 2530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741884_1060, duration(ns): 5171610
2025-03-26 02:24:16,289 INFO terminating
2025-03-26 02:24:16,290 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/streaming_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,295 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py._COPYING_
2025-03-26 02:24:16,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741885_1061 src: /172.20.1.10:44206 dest: /172.20.1.13:9866
2025-03-26 02:24:16,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741885_1061 src: /172.20.1.13:52518 dest: /172.20.1.11:9866
2025-03-26 02:24:16,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741885_1061 src: /172.20.1.11:56672 dest: /172.20.1.12:9866
2025-03-26 02:24:16,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56672, dest: /172.20.1.12:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741885_1061, duration(ns): 1846752
2025-03-26 02:24:16,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741885_1061, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44206, dest: /172.20.1.13:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741885_1061, duration(ns): 2975854
2025-03-26 02:24:16,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52518, dest: /172.20.1.11:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741885_1061, duration(ns): 2621159
2025-03-26 02:24:16,303 INFO terminating
2025-03-26 02:24:16,303 INFO terminating
2025-03-26 02:24:16,304 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,316 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/decision_tree_classification_example.py._COPYING_
2025-03-26 02:24:16,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741886_1062 src: /172.20.1.10:41332 dest: /172.20.1.12:9866
2025-03-26 02:24:16,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741886_1062 src: /172.20.1.11:60872 dest: /172.20.1.13:9866
2025-03-26 02:24:16,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741886_1062 src: /172.20.1.12:45378 dest: /172.20.1.11:9866
2025-03-26 02:24:16,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60872, dest: /172.20.1.13:9866, bytes: 2333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741886_1062, duration(ns): 1764370
2025-03-26 02:24:16,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45378, dest: /172.20.1.11:9866, bytes: 2333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741886_1062, duration(ns): 2486738
2025-03-26 02:24:16,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741886_1062, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,323 INFO terminating
2025-03-26 02:24:16,324 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/decision_tree_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41332, dest: /172.20.1.12:9866, bytes: 2333, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741886_1062, duration(ns): 2994292
2025-03-26 02:24:16,324 INFO terminating
2025-03-26 02:24:16,332 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/word2vec.py._COPYING_
2025-03-26 02:24:16,332 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,332 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741887_1063 src: /172.20.1.10:41334 dest: /172.20.1.12:9866
2025-03-26 02:24:16,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741887_1063 src: /172.20.1.11:60876 dest: /172.20.1.13:9866
2025-03-26 02:24:16,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741887_1063 src: /172.20.1.12:45386 dest: /172.20.1.11:9866
2025-03-26 02:24:16,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60876, dest: /172.20.1.13:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741887_1063, duration(ns): 2146456
2025-03-26 02:24:16,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41334, dest: /172.20.1.12:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741887_1063, duration(ns): 3040257
2025-03-26 02:24:16,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45386, dest: /172.20.1.11:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741887_1063, duration(ns): 2723407
2025-03-26 02:24:16,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741887_1063, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,339 INFO terminating
2025-03-26 02:24:16,340 INFO terminating
2025-03-26 02:24:16,341 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/word2vec.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,345 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/isotonic_regression_example.py._COPYING_
2025-03-26 02:24:16,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741888_1064 src: /172.20.1.10:41336 dest: /172.20.1.12:9866
2025-03-26 02:24:16,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741888_1064 src: /172.20.1.12:45400 dest: /172.20.1.11:9866
2025-03-26 02:24:16,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741888_1064 src: /172.20.1.11:60882 dest: /172.20.1.13:9866
2025-03-26 02:24:16,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60882, dest: /172.20.1.13:9866, bytes: 2341, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741888_1064, duration(ns): 1625864
2025-03-26 02:24:16,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741888_1064, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45400, dest: /172.20.1.11:9866, bytes: 2341, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741888_1064, duration(ns): 2329235
2025-03-26 02:24:16,357 INFO terminating
2025-03-26 02:24:16,358 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/isotonic_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41336, dest: /172.20.1.12:9866, bytes: 2341, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741888_1064, duration(ns): 3177157
2025-03-26 02:24:16,358 INFO terminating
2025-03-26 02:24:16,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/pca_rowmatrix_example.py._COPYING_
2025-03-26 02:24:16,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741889_1065 src: /172.20.1.10:44214 dest: /172.20.1.13:9866
2025-03-26 02:24:16,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741889_1065 src: /172.20.1.13:52532 dest: /172.20.1.11:9866
2025-03-26 02:24:16,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741889_1065 src: /172.20.1.11:56686 dest: /172.20.1.12:9866
2025-03-26 02:24:16,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56686, dest: /172.20.1.12:9866, bytes: 1712, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741889_1065, duration(ns): 1512320
2025-03-26 02:24:16,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44214, dest: /172.20.1.13:9866, bytes: 1712, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741889_1065, duration(ns): 2203145
2025-03-26 02:24:16,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52532, dest: /172.20.1.11:9866, bytes: 1712, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741889_1065, duration(ns): 1905107
2025-03-26 02:24:16,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741889_1065, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,376 INFO terminating
2025-03-26 02:24:16,376 INFO terminating
2025-03-26 02:24:16,377 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/pca_rowmatrix_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,382 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/kmeans.py._COPYING_
2025-03-26 02:24:16,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741890_1066 src: /172.20.1.10:47602 dest: /172.20.1.11:9866
2025-03-26 02:24:16,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741890_1066 src: /172.20.1.11:56698 dest: /172.20.1.12:9866
2025-03-26 02:24:16,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741890_1066 src: /172.20.1.12:46658 dest: /172.20.1.13:9866
2025-03-26 02:24:16,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46658, dest: /172.20.1.13:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741890_1066, duration(ns): 3178835
2025-03-26 02:24:16,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741890_1066, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56698, dest: /172.20.1.12:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741890_1066, duration(ns): 3862563
2025-03-26 02:24:16,391 INFO terminating
2025-03-26 02:24:16,392 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/kmeans.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47602, dest: /172.20.1.11:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741890_1066, duration(ns): 4470992
2025-03-26 02:24:16,392 INFO terminating
2025-03-26 02:24:16,398 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/power_iteration_clustering_example.py._COPYING_
2025-03-26 02:24:16,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741891_1067 src: /172.20.1.10:44228 dest: /172.20.1.13:9866
2025-03-26 02:24:16,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741891_1067 src: /172.20.1.13:47138 dest: /172.20.1.12:9866
2025-03-26 02:24:16,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741891_1067 src: /172.20.1.12:45410 dest: /172.20.1.11:9866
2025-03-26 02:24:16,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45410, dest: /172.20.1.11:9866, bytes: 1753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741891_1067, duration(ns): 1506998
2025-03-26 02:24:16,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47138, dest: /172.20.1.12:9866, bytes: 1753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741891_1067, duration(ns): 2340771
2025-03-26 02:24:16,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741891_1067, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,405 INFO terminating
2025-03-26 02:24:16,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44228, dest: /172.20.1.13:9866, bytes: 1753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741891_1067, duration(ns): 3019248
2025-03-26 02:24:16,406 INFO terminating
2025-03-26 02:24:16,407 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/power_iteration_clustering_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,413 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/gradient_boosting_regression_example.py._COPYING_
2025-03-26 02:24:16,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741892_1068 src: /172.20.1.10:44242 dest: /172.20.1.13:9866
2025-03-26 02:24:16,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741892_1068 src: /172.20.1.13:52536 dest: /172.20.1.11:9866
2025-03-26 02:24:16,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741892_1068 src: /172.20.1.11:56708 dest: /172.20.1.12:9866
2025-03-26 02:24:16,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56708, dest: /172.20.1.12:9866, bytes: 2404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741892_1068, duration(ns): 1829489
2025-03-26 02:24:16,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52536, dest: /172.20.1.11:9866, bytes: 2404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741892_1068, duration(ns): 2279323
2025-03-26 02:24:16,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741892_1068, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,421 INFO terminating
2025-03-26 02:24:16,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44242, dest: /172.20.1.13:9866, bytes: 2404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741892_1068, duration(ns): 2742740
2025-03-26 02:24:16,422 INFO terminating
2025-03-26 02:24:16,423 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gradient_boosting_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/hypothesis_testing_example.py._COPYING_
2025-03-26 02:24:16,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741893_1069 src: /172.20.1.10:44250 dest: /172.20.1.13:9866
2025-03-26 02:24:16,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741893_1069 src: /172.20.1.13:47146 dest: /172.20.1.12:9866
2025-03-26 02:24:16,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741893_1069 src: /172.20.1.12:45418 dest: /172.20.1.11:9866
2025-03-26 02:24:16,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45418, dest: /172.20.1.11:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741893_1069, duration(ns): 1604946
2025-03-26 02:24:16,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741893_1069, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44250, dest: /172.20.1.13:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741893_1069, duration(ns): 2477189
2025-03-26 02:24:16,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47146, dest: /172.20.1.12:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741893_1069, duration(ns): 1996517
2025-03-26 02:24:16,435 INFO terminating
2025-03-26 02:24:16,435 INFO terminating
2025-03-26 02:24:16,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/hypothesis_testing_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,446 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/__init__.py._COPYING_
2025-03-26 02:24:16,446 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,446 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741894_1070 src: /172.20.1.10:47608 dest: /172.20.1.11:9866
2025-03-26 02:24:16,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741894_1070 src: /172.20.1.11:60898 dest: /172.20.1.13:9866
2025-03-26 02:24:16,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741894_1070 src: /172.20.1.13:47150 dest: /172.20.1.12:9866
2025-03-26 02:24:16,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47150, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741894_1070, duration(ns): 1819266
2025-03-26 02:24:16,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741894_1070, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47608, dest: /172.20.1.11:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741894_1070, duration(ns): 2477981
2025-03-26 02:24:16,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60898, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741894_1070, duration(ns): 2110615
2025-03-26 02:24:16,453 INFO terminating
2025-03-26 02:24:16,453 INFO terminating
2025-03-26 02:24:16,455 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,462 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py._COPYING_
2025-03-26 02:24:16,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741895_1071 src: /172.20.1.10:44256 dest: /172.20.1.13:9866
2025-03-26 02:24:16,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741895_1071 src: /172.20.1.13:52540 dest: /172.20.1.11:9866
2025-03-26 02:24:16,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741895_1071 src: /172.20.1.11:56712 dest: /172.20.1.12:9866
2025-03-26 02:24:16,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56712, dest: /172.20.1.12:9866, bytes: 2150, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741895_1071, duration(ns): 1708841
2025-03-26 02:24:16,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741895_1071, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52540, dest: /172.20.1.11:9866, bytes: 2150, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741895_1071, duration(ns): 2353244
2025-03-26 02:24:16,470 INFO terminating
2025-03-26 02:24:16,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44256, dest: /172.20.1.13:9866, bytes: 2150, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741895_1071, duration(ns): 3090544
2025-03-26 02:24:16,471 INFO terminating
2025-03-26 02:24:16,472 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/summary_statistics_example.py._COPYING_
2025-03-26 02:24:16,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741896_1072 src: /172.20.1.10:47614 dest: /172.20.1.11:9866
2025-03-26 02:24:16,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741896_1072 src: /172.20.1.11:56720 dest: /172.20.1.12:9866
2025-03-26 02:24:16,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741896_1072 src: /172.20.1.12:46672 dest: /172.20.1.13:9866
2025-03-26 02:24:16,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56720, dest: /172.20.1.12:9866, bytes: 1511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741896_1072, duration(ns): 1777630
2025-03-26 02:24:16,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46672, dest: /172.20.1.13:9866, bytes: 1511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741896_1072, duration(ns): 1427858
2025-03-26 02:24:16,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741896_1072, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,482 INFO terminating
2025-03-26 02:24:16,483 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/summary_statistics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47614, dest: /172.20.1.11:9866, bytes: 1511, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741896_1072, duration(ns): 2216535
2025-03-26 02:24:16,483 INFO terminating
2025-03-26 02:24:16,488 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/decision_tree_regression_example.py._COPYING_
2025-03-26 02:24:16,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741897_1073 src: /172.20.1.10:44272 dest: /172.20.1.13:9866
2025-03-26 02:24:16,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741897_1073 src: /172.20.1.13:52546 dest: /172.20.1.11:9866
2025-03-26 02:24:16,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741897_1073 src: /172.20.1.11:56732 dest: /172.20.1.12:9866
2025-03-26 02:24:16,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56732, dest: /172.20.1.12:9866, bytes: 2328, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741897_1073, duration(ns): 1345012
2025-03-26 02:24:16,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741897_1073, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52546, dest: /172.20.1.11:9866, bytes: 2328, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741897_1073, duration(ns): 1730553
2025-03-26 02:24:16,494 INFO terminating
2025-03-26 02:24:16,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44272, dest: /172.20.1.13:9866, bytes: 2328, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741897_1073, duration(ns): 2542339
2025-03-26 02:24:16,495 INFO terminating
2025-03-26 02:24:16,496 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/decision_tree_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,502 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/word2vec_example.py._COPYING_
2025-03-26 02:24:16,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741898_1074 src: /172.20.1.10:44288 dest: /172.20.1.13:9866
2025-03-26 02:24:16,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741898_1074 src: /172.20.1.13:52562 dest: /172.20.1.11:9866
2025-03-26 02:24:16,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741898_1074 src: /172.20.1.11:56736 dest: /172.20.1.12:9866
2025-03-26 02:24:16,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56736, dest: /172.20.1.12:9866, bytes: 1326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741898_1074, duration(ns): 5759255
2025-03-26 02:24:16,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52562, dest: /172.20.1.11:9866, bytes: 1326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741898_1074, duration(ns): 6211633
2025-03-26 02:24:16,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741898_1074, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,512 INFO terminating
2025-03-26 02:24:16,513 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/word2vec_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44288, dest: /172.20.1.13:9866, bytes: 1326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741898_1074, duration(ns): 6622924
2025-03-26 02:24:16,513 INFO terminating
2025-03-26 02:24:16,520 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/fpgrowth_example.py._COPYING_
2025-03-26 02:24:16,520 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,520 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741899_1075 src: /172.20.1.10:41344 dest: /172.20.1.12:9866
2025-03-26 02:24:16,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741899_1075 src: /172.20.1.12:46682 dest: /172.20.1.13:9866
2025-03-26 02:24:16,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741899_1075 src: /172.20.1.13:52564 dest: /172.20.1.11:9866
2025-03-26 02:24:16,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46682, dest: /172.20.1.13:9866, bytes: 1280, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741899_1075, duration(ns): 2465070
2025-03-26 02:24:16,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52564, dest: /172.20.1.11:9866, bytes: 1280, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741899_1075, duration(ns): 2091532
2025-03-26 02:24:16,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741899_1075, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,527 INFO terminating
2025-03-26 02:24:16,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41344, dest: /172.20.1.12:9866, bytes: 1280, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741899_1075, duration(ns): 2925592
2025-03-26 02:24:16,528 INFO terminating
2025-03-26 02:24:16,529 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/fpgrowth_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,534 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/correlations_example.py._COPYING_
2025-03-26 02:24:16,534 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,534 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741900_1076 src: /172.20.1.10:47620 dest: /172.20.1.11:9866
2025-03-26 02:24:16,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741900_1076 src: /172.20.1.11:56738 dest: /172.20.1.12:9866
2025-03-26 02:24:16,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741900_1076 src: /172.20.1.12:46694 dest: /172.20.1.13:9866
2025-03-26 02:24:16,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46694, dest: /172.20.1.13:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741900_1076, duration(ns): 2254248
2025-03-26 02:24:16,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741900_1076, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56738, dest: /172.20.1.12:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741900_1076, duration(ns): 2817077
2025-03-26 02:24:16,542 INFO terminating
2025-03-26 02:24:16,543 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/correlations_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47620, dest: /172.20.1.11:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741900_1076, duration(ns): 3246961
2025-03-26 02:24:16,543 INFO terminating
2025-03-26 02:24:16,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,550 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/binary_classification_metrics_example.py._COPYING_
2025-03-26 02:24:16,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741901_1077 src: /172.20.1.10:41356 dest: /172.20.1.12:9866
2025-03-26 02:24:16,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741901_1077 src: /172.20.1.12:46700 dest: /172.20.1.13:9866
2025-03-26 02:24:16,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741901_1077 src: /172.20.1.13:52572 dest: /172.20.1.11:9866
2025-03-26 02:24:16,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52572, dest: /172.20.1.11:9866, bytes: 2083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741901_1077, duration(ns): 1734081
2025-03-26 02:24:16,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741901_1077, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41356, dest: /172.20.1.12:9866, bytes: 2083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741901_1077, duration(ns): 2438877
2025-03-26 02:24:16,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46700, dest: /172.20.1.13:9866, bytes: 2083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741901_1077, duration(ns): 2059993
2025-03-26 02:24:16,557 INFO terminating
2025-03-26 02:24:16,557 INFO terminating
2025-03-26 02:24:16,559 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/binary_classification_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/multi_label_metrics_example.py._COPYING_
2025-03-26 02:24:16,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741902_1078 src: /172.20.1.10:47632 dest: /172.20.1.11:9866
2025-03-26 02:24:16,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741902_1078 src: /172.20.1.11:60906 dest: /172.20.1.13:9866
2025-03-26 02:24:16,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741902_1078 src: /172.20.1.13:47152 dest: /172.20.1.12:9866
2025-03-26 02:24:16,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60906, dest: /172.20.1.13:9866, bytes: 2277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741902_1078, duration(ns): 1947928
2025-03-26 02:24:16,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47152, dest: /172.20.1.12:9866, bytes: 2277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741902_1078, duration(ns): 1670301
2025-03-26 02:24:16,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741902_1078, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,579 INFO terminating
2025-03-26 02:24:16,580 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/multi_label_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47632, dest: /172.20.1.11:9866, bytes: 2277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741902_1078, duration(ns): 2330057
2025-03-26 02:24:16,580 INFO terminating
2025-03-26 02:24:16,589 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,590 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py._COPYING_
2025-03-26 02:24:16,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741903_1079 src: /172.20.1.10:47646 dest: /172.20.1.11:9866
2025-03-26 02:24:16,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741903_1079 src: /172.20.1.11:56750 dest: /172.20.1.12:9866
2025-03-26 02:24:16,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741903_1079 src: /172.20.1.12:46710 dest: /172.20.1.13:9866
2025-03-26 02:24:16,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56750, dest: /172.20.1.12:9866, bytes: 1619, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741903_1079, duration(ns): 2079210
2025-03-26 02:24:16,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46710, dest: /172.20.1.13:9866, bytes: 1619, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741903_1079, duration(ns): 1710095
2025-03-26 02:24:16,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741903_1079, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,596 INFO terminating
2025-03-26 02:24:16,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47646, dest: /172.20.1.11:9866, bytes: 1619, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741903_1079, duration(ns): 2373651
2025-03-26 02:24:16,597 INFO terminating
2025-03-26 02:24:16,598 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,603 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/gradient_boosting_classification_example.py._COPYING_
2025-03-26 02:24:16,603 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,603 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741904_1080 src: /172.20.1.10:44296 dest: /172.20.1.13:9866
2025-03-26 02:24:16,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741904_1080 src: /172.20.1.13:47156 dest: /172.20.1.12:9866
2025-03-26 02:24:16,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741904_1080 src: /172.20.1.12:45430 dest: /172.20.1.11:9866
2025-03-26 02:24:16,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45430, dest: /172.20.1.11:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741904_1080, duration(ns): 1664842
2025-03-26 02:24:16,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47156, dest: /172.20.1.12:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741904_1080, duration(ns): 1882509
2025-03-26 02:24:16,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741904_1080, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,610 INFO terminating
2025-03-26 02:24:16,611 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gradient_boosting_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44296, dest: /172.20.1.13:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741904_1080, duration(ns): 2314694
2025-03-26 02:24:16,611 INFO terminating
2025-03-26 02:24:16,623 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/correlations.py._COPYING_
2025-03-26 02:24:16,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741905_1081 src: /172.20.1.10:41372 dest: /172.20.1.12:9866
2025-03-26 02:24:16,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741905_1081 src: /172.20.1.12:45432 dest: /172.20.1.11:9866
2025-03-26 02:24:16,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741905_1081 src: /172.20.1.11:60912 dest: /172.20.1.13:9866
2025-03-26 02:24:16,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60912, dest: /172.20.1.13:9866, bytes: 2049, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741905_1081, duration(ns): 1785430
2025-03-26 02:24:16,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45432, dest: /172.20.1.11:9866, bytes: 2049, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741905_1081, duration(ns): 2185075
2025-03-26 02:24:16,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741905_1081, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41372, dest: /172.20.1.12:9866, bytes: 2049, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741905_1081, duration(ns): 2554133
2025-03-26 02:24:16,633 INFO terminating
2025-03-26 02:24:16,633 INFO terminating
2025-03-26 02:24:16,634 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/correlations.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/gaussian_mixture_example.py._COPYING_
2025-03-26 02:24:16,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,638 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741906_1082 src: /172.20.1.10:44312 dest: /172.20.1.13:9866
2025-03-26 02:24:16,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741906_1082 src: /172.20.1.13:52576 dest: /172.20.1.11:9866
2025-03-26 02:24:16,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741906_1082 src: /172.20.1.11:56756 dest: /172.20.1.12:9866
2025-03-26 02:24:16,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56756, dest: /172.20.1.12:9866, bytes: 1839, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741906_1082, duration(ns): 1735328
2025-03-26 02:24:16,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52576, dest: /172.20.1.11:9866, bytes: 1839, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741906_1082, duration(ns): 2384629
2025-03-26 02:24:16,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741906_1082, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,645 INFO terminating
2025-03-26 02:24:16,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44312, dest: /172.20.1.13:9866, bytes: 1839, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741906_1082, duration(ns): 2743959
2025-03-26 02:24:16,646 INFO terminating
2025-03-26 02:24:16,647 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/gaussian_mixture_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/k_means_example.py._COPYING_
2025-03-26 02:24:16,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741907_1083 src: /172.20.1.10:41388 dest: /172.20.1.12:9866
2025-03-26 02:24:16,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741907_1083 src: /172.20.1.12:46720 dest: /172.20.1.13:9866
2025-03-26 02:24:16,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741907_1083 src: /172.20.1.13:52580 dest: /172.20.1.11:9866
2025-03-26 02:24:16,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52580, dest: /172.20.1.11:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741907_1083, duration(ns): 1643455
2025-03-26 02:24:16,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741907_1083, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46720, dest: /172.20.1.13:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741907_1083, duration(ns): 2012036
2025-03-26 02:24:16,660 INFO terminating
2025-03-26 02:24:16,661 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41388, dest: /172.20.1.12:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741907_1083, duration(ns): 2638227
2025-03-26 02:24:16,661 INFO terminating
2025-03-26 02:24:16,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/ranking_metrics_example.py._COPYING_
2025-03-26 02:24:16,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741908_1084 src: /172.20.1.10:44318 dest: /172.20.1.13:9866
2025-03-26 02:24:16,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741908_1084 src: /172.20.1.13:47158 dest: /172.20.1.12:9866
2025-03-26 02:24:16,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741908_1084 src: /172.20.1.12:45438 dest: /172.20.1.11:9866
2025-03-26 02:24:16,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45438, dest: /172.20.1.11:9866, bytes: 2181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741908_1084, duration(ns): 1647242
2025-03-26 02:24:16,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44318, dest: /172.20.1.13:9866, bytes: 2181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741908_1084, duration(ns): 2343797
2025-03-26 02:24:16,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47158, dest: /172.20.1.12:9866, bytes: 2181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741908_1084, duration(ns): 1971987
2025-03-26 02:24:16,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741908_1084, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,680 INFO terminating
2025-03-26 02:24:16,681 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/ranking_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,681 INFO terminating
2025-03-26 02:24:16,686 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,686 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,687 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/multi_class_metrics_example.py._COPYING_
2025-03-26 02:24:16,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741909_1085 src: /172.20.1.10:44324 dest: /172.20.1.13:9866
2025-03-26 02:24:16,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741909_1085 src: /172.20.1.13:47172 dest: /172.20.1.12:9866
2025-03-26 02:24:16,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741909_1085 src: /172.20.1.12:45454 dest: /172.20.1.11:9866
2025-03-26 02:24:16,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45454, dest: /172.20.1.11:9866, bytes: 2836, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741909_1085, duration(ns): 1939558
2025-03-26 02:24:16,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741909_1085, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44324, dest: /172.20.1.13:9866, bytes: 2836, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741909_1085, duration(ns): 2964062
2025-03-26 02:24:16,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47172, dest: /172.20.1.12:9866, bytes: 2836, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741909_1085, duration(ns): 2263241
2025-03-26 02:24:16,694 INFO terminating
2025-03-26 02:24:16,694 INFO terminating
2025-03-26 02:24:16,695 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/multi_class_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,700 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/linear_regression_with_sgd_example.py._COPYING_
2025-03-26 02:24:16,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741910_1086 src: /172.20.1.10:47660 dest: /172.20.1.11:9866
2025-03-26 02:24:16,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741910_1086 src: /172.20.1.11:56770 dest: /172.20.1.12:9866
2025-03-26 02:24:16,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741910_1086 src: /172.20.1.12:46726 dest: /172.20.1.13:9866
2025-03-26 02:24:16,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46726, dest: /172.20.1.13:9866, bytes: 2013, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741910_1086, duration(ns): 1573511
2025-03-26 02:24:16,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741910_1086, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56770, dest: /172.20.1.12:9866, bytes: 2013, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741910_1086, duration(ns): 1998625
2025-03-26 02:24:16,708 INFO terminating
2025-03-26 02:24:16,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47660, dest: /172.20.1.11:9866, bytes: 2013, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741910_1086, duration(ns): 2520170
2025-03-26 02:24:16,709 INFO terminating
2025-03-26 02:24:16,710 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/linear_regression_with_sgd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/standard_scaler_example.py._COPYING_
2025-03-26 02:24:16,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741911_1087 src: /172.20.1.10:44326 dest: /172.20.1.13:9866
2025-03-26 02:24:16,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741911_1087 src: /172.20.1.13:52594 dest: /172.20.1.11:9866
2025-03-26 02:24:16,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741911_1087 src: /172.20.1.11:56772 dest: /172.20.1.12:9866
2025-03-26 02:24:16,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56772, dest: /172.20.1.12:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741911_1087, duration(ns): 1729484
2025-03-26 02:24:16,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44326, dest: /172.20.1.13:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741911_1087, duration(ns): 2724520
2025-03-26 02:24:16,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52594, dest: /172.20.1.11:9866, bytes: 1789, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741911_1087, duration(ns): 2373029
2025-03-26 02:24:16,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741911_1087, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,728 INFO terminating
2025-03-26 02:24:16,729 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/standard_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,729 INFO terminating
2025-03-26 02:24:16,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/kernel_density_estimation_example.py._COPYING_
2025-03-26 02:24:16,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741912_1088 src: /172.20.1.10:44340 dest: /172.20.1.13:9866
2025-03-26 02:24:16,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741912_1088 src: /172.20.1.13:52596 dest: /172.20.1.11:9866
2025-03-26 02:24:16,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741912_1088 src: /172.20.1.11:56788 dest: /172.20.1.12:9866
2025-03-26 02:24:16,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56788, dest: /172.20.1.12:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741912_1088, duration(ns): 1446280
2025-03-26 02:24:16,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52596, dest: /172.20.1.11:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741912_1088, duration(ns): 1803566
2025-03-26 02:24:16,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741912_1088, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,740 INFO terminating
2025-03-26 02:24:16,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44340, dest: /172.20.1.13:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741912_1088, duration(ns): 2254213
2025-03-26 02:24:16,741 INFO terminating
2025-03-26 02:24:16,742 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/kernel_density_estimation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,749 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/regression_metrics_example.py._COPYING_
2025-03-26 02:24:16,749 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,749 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741913_1089 src: /172.20.1.10:41400 dest: /172.20.1.12:9866
2025-03-26 02:24:16,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741913_1089 src: /172.20.1.11:60920 dest: /172.20.1.13:9866
2025-03-26 02:24:16,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741913_1089 src: /172.20.1.12:45462 dest: /172.20.1.11:9866
2025-03-26 02:24:16,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60920, dest: /172.20.1.13:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741913_1089, duration(ns): 2299038
2025-03-26 02:24:16,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45462, dest: /172.20.1.11:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741913_1089, duration(ns): 2645576
2025-03-26 02:24:16,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741913_1089, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,756 INFO terminating
2025-03-26 02:24:16,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41400, dest: /172.20.1.12:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741913_1089, duration(ns): 3144290
2025-03-26 02:24:16,757 INFO terminating
2025-03-26 02:24:16,758 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/regression_metrics_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,762 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/mllib/svm_with_sgd_example.py._COPYING_
2025-03-26 02:24:16,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741914_1090 src: /172.20.1.10:44346 dest: /172.20.1.13:9866
2025-03-26 02:24:16,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741914_1090 src: /172.20.1.13:47176 dest: /172.20.1.12:9866
2025-03-26 02:24:16,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741914_1090 src: /172.20.1.12:45478 dest: /172.20.1.11:9866
2025-03-26 02:24:16,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45478, dest: /172.20.1.11:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741914_1090, duration(ns): 1242940
2025-03-26 02:24:16,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47176, dest: /172.20.1.12:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741914_1090, duration(ns): 1560025
2025-03-26 02:24:16,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741914_1090, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44346, dest: /172.20.1.13:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741914_1090, duration(ns): 2000285
2025-03-26 02:24:16,768 INFO terminating
2025-03-26 02:24:16,768 INFO terminating
2025-03-26 02:24:16,769 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/svm_with_sgd_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/mllib/normalizer_example.py._COPYING_
2025-03-26 02:24:16,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741915_1091 src: /172.20.1.10:47674 dest: /172.20.1.11:9866
2025-03-26 02:24:16,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741915_1091 src: /172.20.1.11:56796 dest: /172.20.1.12:9866
2025-03-26 02:24:16,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741915_1091 src: /172.20.1.12:46740 dest: /172.20.1.13:9866
2025-03-26 02:24:16,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46740, dest: /172.20.1.13:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741915_1091, duration(ns): 1446786
2025-03-26 02:24:16,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741915_1091, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47674, dest: /172.20.1.11:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741915_1091, duration(ns): 2472112
2025-03-26 02:24:16,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56796, dest: /172.20.1.12:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741915_1091, duration(ns): 1941911
2025-03-26 02:24:16,788 INFO terminating
2025-03-26 02:24:16,788 INFO terminating
2025-03-26 02:24:16,789 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/normalizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,793 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/random_rdd_generation.py._COPYING_
2025-03-26 02:24:16,794 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741916_1092 src: /172.20.1.10:44348 dest: /172.20.1.13:9866
2025-03-26 02:24:16,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741916_1092 src: /172.20.1.13:52608 dest: /172.20.1.11:9866
2025-03-26 02:24:16,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741916_1092 src: /172.20.1.11:56806 dest: /172.20.1.12:9866
2025-03-26 02:24:16,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56806, dest: /172.20.1.12:9866, bytes: 1905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741916_1092, duration(ns): 1206539
2025-03-26 02:24:16,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52608, dest: /172.20.1.11:9866, bytes: 1905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741916_1092, duration(ns): 1554439
2025-03-26 02:24:16,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741916_1092, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,799 INFO terminating
2025-03-26 02:24:16,800 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/random_rdd_generation.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44348, dest: /172.20.1.13:9866, bytes: 1905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741916_1092, duration(ns): 1993982
2025-03-26 02:24:16,800 INFO terminating
2025-03-26 02:24:16,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/sampled_rdds.py._COPYING_
2025-03-26 02:24:16,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741917_1093 src: /172.20.1.10:44352 dest: /172.20.1.13:9866
2025-03-26 02:24:16,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741917_1093 src: /172.20.1.13:52610 dest: /172.20.1.11:9866
2025-03-26 02:24:16,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741917_1093 src: /172.20.1.11:56814 dest: /172.20.1.12:9866
2025-03-26 02:24:16,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56814, dest: /172.20.1.12:9866, bytes: 3185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741917_1093, duration(ns): 1087493
2025-03-26 02:24:16,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52610, dest: /172.20.1.11:9866, bytes: 3185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741917_1093, duration(ns): 1403512
2025-03-26 02:24:16,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741917_1093, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,810 INFO terminating
2025-03-26 02:24:16,811 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/sampled_rdds.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44352, dest: /172.20.1.13:9866, bytes: 3185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741917_1093, duration(ns): 1829498
2025-03-26 02:24:16,811 INFO terminating
2025-03-26 02:24:16,816 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/mllib/elementwise_product_example.py._COPYING_
2025-03-26 02:24:16,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741918_1094 src: /172.20.1.10:44366 dest: /172.20.1.13:9866
2025-03-26 02:24:16,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741918_1094 src: /172.20.1.11:56828 dest: /172.20.1.12:9866
2025-03-26 02:24:16,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741918_1094 src: /172.20.1.13:52612 dest: /172.20.1.11:9866
2025-03-26 02:24:16,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56828, dest: /172.20.1.12:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741918_1094, duration(ns): 940956
2025-03-26 02:24:16,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52612, dest: /172.20.1.11:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741918_1094, duration(ns): 1256004
2025-03-26 02:24:16,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741918_1094, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44366, dest: /172.20.1.13:9866, bytes: 1717, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741918_1094, duration(ns): 1705662
2025-03-26 02:24:16,823 INFO terminating
2025-03-26 02:24:16,823 INFO terminating
2025-03-26 02:24:16,825 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/mllib/elementwise_product_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,832 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/__init__.py._COPYING_
2025-03-26 02:24:16,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741919_1095 src: /172.20.1.10:44382 dest: /172.20.1.13:9866
2025-03-26 02:24:16,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741919_1095 src: /172.20.1.13:47192 dest: /172.20.1.12:9866
2025-03-26 02:24:16,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741919_1095 src: /172.20.1.12:45486 dest: /172.20.1.11:9866
2025-03-26 02:24:16,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45486, dest: /172.20.1.11:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741919_1095, duration(ns): 1199307
2025-03-26 02:24:16,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47192, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741919_1095, duration(ns): 1503637
2025-03-26 02:24:16,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741919_1095, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44382, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741919_1095, duration(ns): 1842633
2025-03-26 02:24:16,839 INFO terminating
2025-03-26 02:24:16,839 INFO terminating
2025-03-26 02:24:16,840 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,845 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/pagerank.py._COPYING_
2025-03-26 02:24:16,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741920_1096 src: /172.20.1.10:47690 dest: /172.20.1.11:9866
2025-03-26 02:24:16,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741920_1096 src: /172.20.1.11:56838 dest: /172.20.1.12:9866
2025-03-26 02:24:16,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741920_1096 src: /172.20.1.12:46750 dest: /172.20.1.13:9866
2025-03-26 02:24:16,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46750, dest: /172.20.1.13:9866, bytes: 3339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741920_1096, duration(ns): 1239270
2025-03-26 02:24:16,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741920_1096, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:56838, dest: /172.20.1.12:9866, bytes: 3339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741920_1096, duration(ns): 1879931
2025-03-26 02:24:16,852 INFO terminating
2025-03-26 02:24:16,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47690, dest: /172.20.1.11:9866, bytes: 3339, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741920_1096, duration(ns): 2265117
2025-03-26 02:24:16,853 INFO terminating
2025-03-26 02:24:16,854 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/pagerank.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/fm_regressor_example.py._COPYING_
2025-03-26 02:24:16,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741921_1097 src: /172.20.1.10:44396 dest: /172.20.1.13:9866
2025-03-26 02:24:16,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741921_1097 src: /172.20.1.13:47206 dest: /172.20.1.12:9866
2025-03-26 02:24:16,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741921_1097 src: /172.20.1.12:45496 dest: /172.20.1.11:9866
2025-03-26 02:24:16,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45496, dest: /172.20.1.11:9866, bytes: 2559, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741921_1097, duration(ns): 1457882
2025-03-26 02:24:16,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47206, dest: /172.20.1.12:9866, bytes: 2559, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741921_1097, duration(ns): 1734813
2025-03-26 02:24:16,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741921_1097, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,877 INFO terminating
2025-03-26 02:24:16,878 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fm_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44396, dest: /172.20.1.13:9866, bytes: 2559, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741921_1097, duration(ns): 2160456
2025-03-26 02:24:16,878 INFO terminating
2025-03-26 02:24:16,883 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/string_indexer_example.py._COPYING_
2025-03-26 02:24:16,883 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,883 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741922_1098 src: /172.20.1.10:47706 dest: /172.20.1.11:9866
2025-03-26 02:24:16,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741922_1098 src: /172.20.1.11:60932 dest: /172.20.1.13:9866
2025-03-26 02:24:16,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741922_1098 src: /172.20.1.13:47208 dest: /172.20.1.12:9866
2025-03-26 02:24:16,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60932, dest: /172.20.1.13:9866, bytes: 1363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741922_1098, duration(ns): 1407865
2025-03-26 02:24:16,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47208, dest: /172.20.1.12:9866, bytes: 1363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741922_1098, duration(ns): 1162915
2025-03-26 02:24:16,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741922_1098, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,889 INFO terminating
2025-03-26 02:24:16,890 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/string_indexer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47706, dest: /172.20.1.11:9866, bytes: 1363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741922_1098, duration(ns): 1689880
2025-03-26 02:24:16,890 INFO terminating
2025-03-26 02:24:16,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/vector_assembler_example.py._COPYING_
2025-03-26 02:24:16,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741923_1099 src: /172.20.1.10:44408 dest: /172.20.1.13:9866
2025-03-26 02:24:16,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741923_1099 src: /172.20.1.13:47216 dest: /172.20.1.12:9866
2025-03-26 02:24:16,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741923_1099 src: /172.20.1.12:45506 dest: /172.20.1.11:9866
2025-03-26 02:24:16,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:45506, dest: /172.20.1.11:9866, bytes: 1610, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741923_1099, duration(ns): 1031867
2025-03-26 02:24:16,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47216, dest: /172.20.1.12:9866, bytes: 1610, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741923_1099, duration(ns): 1335317
2025-03-26 02:24:16,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741923_1099, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,901 INFO terminating
2025-03-26 02:24:16,902 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_assembler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44408, dest: /172.20.1.13:9866, bytes: 1610, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741923_1099, duration(ns): 1699933
2025-03-26 02:24:16,902 INFO terminating
2025-03-26 02:24:16,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/robust_scaler_example.py._COPYING_
2025-03-26 02:24:16,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741924_1100 src: /172.20.1.10:47716 dest: /172.20.1.11:9866
2025-03-26 02:24:16,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741924_1100 src: /172.20.1.11:60936 dest: /172.20.1.13:9866
2025-03-26 02:24:16,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741924_1100 src: /172.20.1.13:47220 dest: /172.20.1.12:9866
2025-03-26 02:24:16,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:47220, dest: /172.20.1.12:9866, bytes: 1600, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741924_1100, duration(ns): 1547592
2025-03-26 02:24:16,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:47716, dest: /172.20.1.11:9866, bytes: 1600, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741924_1100, duration(ns): 2145871
2025-03-26 02:24:16,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:60936, dest: /172.20.1.13:9866, bytes: 1600, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741924_1100, duration(ns): 1844689
2025-03-26 02:24:16,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741924_1100, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,913 INFO terminating
2025-03-26 02:24:16,914 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/robust_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:16,914 INFO terminating
2025-03-26 02:24:16,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_
2025-03-26 02:24:16,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:16,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741925_1101 src: /172.20.1.10:41404 dest: /172.20.1.12:9866
2025-03-26 02:24:16,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741925_1101 src: /172.20.1.12:46752 dest: /172.20.1.13:9866
2025-03-26 02:24:16,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741925_1101 src: /172.20.1.13:52618 dest: /172.20.1.11:9866
2025-03-26 02:24:16,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:52618, dest: /172.20.1.11:9866, bytes: 2653, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741925_1101, duration(ns): 1252744
2025-03-26 02:24:16,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741925_1101, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:16,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:41404, dest: /172.20.1.12:9866, bytes: 2653, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741925_1101, duration(ns): 2635880
2025-03-26 02:24:16,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:46752, dest: /172.20.1.13:9866, bytes: 2653, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741925_1101, duration(ns): 2078586
2025-03-26 02:24:16,927 INFO terminating
2025-03-26 02:24:16,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741925_1101 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_
2025-03-26 02:24:16,928 INFO terminating
2025-03-26 02:24:17,329 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/random_forest_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/vector_indexer_example.py._COPYING_
2025-03-26 02:24:17,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741926_1102 src: /172.20.1.10:43940 dest: /172.20.1.12:9866
2025-03-26 02:24:17,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741926_1102 src: /172.20.1.12:54804 dest: /172.20.1.13:9866
2025-03-26 02:24:17,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741926_1102 src: /172.20.1.13:56734 dest: /172.20.1.11:9866
2025-03-26 02:24:17,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56734, dest: /172.20.1.11:9866, bytes: 1646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741926_1102, duration(ns): 1962683
2025-03-26 02:24:17,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741926_1102, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54804, dest: /172.20.1.13:9866, bytes: 1646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741926_1102, duration(ns): 2831481
2025-03-26 02:24:17,346 INFO terminating
2025-03-26 02:24:17,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:43940, dest: /172.20.1.12:9866, bytes: 1646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741926_1102, duration(ns): 3363256
2025-03-26 02:24:17,347 INFO terminating
2025-03-26 02:24:17,348 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_indexer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,354 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/variance_threshold_selector_example.py._COPYING_
2025-03-26 02:24:17,354 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,354 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741927_1103 src: /172.20.1.10:43948 dest: /172.20.1.12:9866
2025-03-26 02:24:17,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741927_1103 src: /172.20.1.12:54404 dest: /172.20.1.11:9866
2025-03-26 02:24:17,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741927_1103 src: /172.20.1.11:34442 dest: /172.20.1.13:9866
2025-03-26 02:24:17,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34442, dest: /172.20.1.13:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741927_1103, duration(ns): 1966334
2025-03-26 02:24:17,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741927_1103, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54404, dest: /172.20.1.11:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741927_1103, duration(ns): 2885347
2025-03-26 02:24:17,362 INFO terminating
2025-03-26 02:24:17,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:43948, dest: /172.20.1.12:9866, bytes: 1989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741927_1103, duration(ns): 3419001
2025-03-26 02:24:17,363 INFO terminating
2025-03-26 02:24:17,364 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/variance_threshold_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/feature_hasher_example.py._COPYING_
2025-03-26 02:24:17,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741928_1104 src: /172.20.1.10:43960 dest: /172.20.1.12:9866
2025-03-26 02:24:17,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741928_1104 src: /172.20.1.12:54812 dest: /172.20.1.13:9866
2025-03-26 02:24:17,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741928_1104 src: /172.20.1.13:56736 dest: /172.20.1.11:9866
2025-03-26 02:24:17,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56736, dest: /172.20.1.11:9866, bytes: 1521, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741928_1104, duration(ns): 1985619
2025-03-26 02:24:17,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741928_1104, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54812, dest: /172.20.1.13:9866, bytes: 1521, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741928_1104, duration(ns): 2570801
2025-03-26 02:24:17,377 INFO terminating
2025-03-26 02:24:17,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:43960, dest: /172.20.1.12:9866, bytes: 1521, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741928_1104, duration(ns): 2708980
2025-03-26 02:24:17,378 INFO terminating
2025-03-26 02:24:17,379 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/feature_hasher_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,385 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_
2025-03-26 02:24:17,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741929_1105 src: /172.20.1.10:57236 dest: /172.20.1.11:9866
2025-03-26 02:24:17,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741929_1105 src: /172.20.1.11:47916 dest: /172.20.1.12:9866
2025-03-26 02:24:17,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741929_1105 src: /172.20.1.12:54822 dest: /172.20.1.13:9866
2025-03-26 02:24:17,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:47916, dest: /172.20.1.12:9866, bytes: 1934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741929_1105, duration(ns): 1732506
2025-03-26 02:24:17,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54822, dest: /172.20.1.13:9866, bytes: 1934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741929_1105, duration(ns): 1451062
2025-03-26 02:24:17,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741929_1105, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,392 INFO terminating
2025-03-26 02:24:17,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57236, dest: /172.20.1.11:9866, bytes: 1934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741929_1105, duration(ns): 2183875
2025-03-26 02:24:17,393 INFO terminating
2025-03-26 02:24:17,394 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/linear_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,400 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,401 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/tf_idf_example.py._COPYING_
2025-03-26 02:24:17,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741930_1106 src: /172.20.1.10:43970 dest: /172.20.1.12:9866
2025-03-26 02:24:17,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741930_1106 src: /172.20.1.12:54410 dest: /172.20.1.11:9866
2025-03-26 02:24:17,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741930_1106 src: /172.20.1.11:34446 dest: /172.20.1.13:9866
2025-03-26 02:24:17,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34446, dest: /172.20.1.13:9866, bytes: 1863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741930_1106, duration(ns): 1803683
2025-03-26 02:24:17,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741930_1106, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54410, dest: /172.20.1.11:9866, bytes: 1863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741930_1106, duration(ns): 2236474
2025-03-26 02:24:17,409 INFO terminating
2025-03-26 02:24:17,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:43970, dest: /172.20.1.12:9866, bytes: 1863, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741930_1106, duration(ns): 2875679
2025-03-26 02:24:17,410 INFO terminating
2025-03-26 02:24:17,412 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/tf_idf_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,419 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/stopwords_remover_example.py._COPYING_
2025-03-26 02:24:17,419 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,419 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741931_1107 src: /172.20.1.10:50826 dest: /172.20.1.13:9866
2025-03-26 02:24:17,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741931_1107 src: /172.20.1.13:56742 dest: /172.20.1.11:9866
2025-03-26 02:24:17,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741931_1107 src: /172.20.1.11:47928 dest: /172.20.1.12:9866
2025-03-26 02:24:17,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:47928, dest: /172.20.1.12:9866, bytes: 1395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741931_1107, duration(ns): 1475899
2025-03-26 02:24:17,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56742, dest: /172.20.1.11:9866, bytes: 1395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741931_1107, duration(ns): 1773779
2025-03-26 02:24:17,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741931_1107, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,426 INFO terminating
2025-03-26 02:24:17,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50826, dest: /172.20.1.13:9866, bytes: 1395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741931_1107, duration(ns): 2401720
2025-03-26 02:24:17,428 INFO terminating
2025-03-26 02:24:17,429 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/stopwords_remover_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/cross_validator.py._COPYING_
2025-03-26 02:24:17,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741932_1108 src: /172.20.1.10:57250 dest: /172.20.1.11:9866
2025-03-26 02:24:17,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741932_1108 src: /172.20.1.11:47944 dest: /172.20.1.12:9866
2025-03-26 02:24:17,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741932_1108 src: /172.20.1.12:54838 dest: /172.20.1.13:9866
2025-03-26 02:24:17,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:47944, dest: /172.20.1.12:9866, bytes: 3904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741932_1108, duration(ns): 2425642
2025-03-26 02:24:17,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54838, dest: /172.20.1.13:9866, bytes: 3904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741932_1108, duration(ns): 1984917
2025-03-26 02:24:17,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741932_1108, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,445 INFO terminating
2025-03-26 02:24:17,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57250, dest: /172.20.1.11:9866, bytes: 3904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741932_1108, duration(ns): 2794531
2025-03-26 02:24:17,446 INFO terminating
2025-03-26 02:24:17,447 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/cross_validator.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,455 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py._COPYING_
2025-03-26 02:24:17,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741933_1109 src: /172.20.1.10:57262 dest: /172.20.1.11:9866
2025-03-26 02:24:17,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741933_1109 src: /172.20.1.11:47950 dest: /172.20.1.12:9866
2025-03-26 02:24:17,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741933_1109 src: /172.20.1.12:54842 dest: /172.20.1.13:9866
2025-03-26 02:24:17,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54842, dest: /172.20.1.13:9866, bytes: 2950, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741933_1109, duration(ns): 2004169
2025-03-26 02:24:17,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:47950, dest: /172.20.1.12:9866, bytes: 2950, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741933_1109, duration(ns): 2434234
2025-03-26 02:24:17,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741933_1109, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,464 INFO terminating
2025-03-26 02:24:17,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57262, dest: /172.20.1.11:9866, bytes: 2950, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741933_1109, duration(ns): 3002378
2025-03-26 02:24:17,465 INFO terminating
2025-03-26 02:24:17,466 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,473 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/bisecting_k_means_example.py._COPYING_
2025-03-26 02:24:17,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741934_1110 src: /172.20.1.10:50838 dest: /172.20.1.13:9866
2025-03-26 02:24:17,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741934_1110 src: /172.20.1.13:56758 dest: /172.20.1.11:9866
2025-03-26 02:24:17,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741934_1110 src: /172.20.1.11:47962 dest: /172.20.1.12:9866
2025-03-26 02:24:17,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:47962, dest: /172.20.1.12:9866, bytes: 1953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741934_1110, duration(ns): 2254037
2025-03-26 02:24:17,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741934_1110, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56758, dest: /172.20.1.11:9866, bytes: 1953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741934_1110, duration(ns): 3691969
2025-03-26 02:24:17,483 INFO terminating
2025-03-26 02:24:17,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50838, dest: /172.20.1.13:9866, bytes: 1953, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741934_1110, duration(ns): 4397624
2025-03-26 02:24:17,484 INFO terminating
2025-03-26 02:24:17,485 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bisecting_k_means_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,494 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/correlation_example.py._COPYING_
2025-03-26 02:24:17,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741935_1111 src: /172.20.1.10:50844 dest: /172.20.1.13:9866
2025-03-26 02:24:17,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741935_1111 src: /172.20.1.13:56766 dest: /172.20.1.11:9866
2025-03-26 02:24:17,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741935_1111 src: /172.20.1.11:47974 dest: /172.20.1.12:9866
2025-03-26 02:24:17,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:47974, dest: /172.20.1.12:9866, bytes: 1885, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741935_1111, duration(ns): 1893573
2025-03-26 02:24:17,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56766, dest: /172.20.1.11:9866, bytes: 1885, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741935_1111, duration(ns): 3460082
2025-03-26 02:24:17,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741935_1111, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,502 INFO terminating
2025-03-26 02:24:17,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50844, dest: /172.20.1.13:9866, bytes: 1885, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741935_1111, duration(ns): 4194777
2025-03-26 02:24:17,503 INFO terminating
2025-03-26 02:24:17,504 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/correlation_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/kmeans_example.py._COPYING_
2025-03-26 02:24:17,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741936_1112 src: /172.20.1.10:43980 dest: /172.20.1.12:9866
2025-03-26 02:24:17,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741936_1112 src: /172.20.1.12:54856 dest: /172.20.1.13:9866
2025-03-26 02:24:17,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741936_1112 src: /172.20.1.13:56768 dest: /172.20.1.11:9866
2025-03-26 02:24:17,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56768, dest: /172.20.1.11:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741936_1112, duration(ns): 1762754
2025-03-26 02:24:17,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741936_1112, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:43980, dest: /172.20.1.12:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741936_1112, duration(ns): 2804537
2025-03-26 02:24:17,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54856, dest: /172.20.1.13:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741936_1112, duration(ns): 2233636
2025-03-26 02:24:17,519 INFO terminating
2025-03-26 02:24:17,520 INFO terminating
2025-03-26 02:24:17,521 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/kmeans_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,528 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py._COPYING_
2025-03-26 02:24:17,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741937_1113 src: /172.20.1.10:43984 dest: /172.20.1.12:9866
2025-03-26 02:24:17,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741937_1113 src: /172.20.1.12:54868 dest: /172.20.1.13:9866
2025-03-26 02:24:17,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741937_1113 src: /172.20.1.13:56780 dest: /172.20.1.11:9866
2025-03-26 02:24:17,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54868, dest: /172.20.1.13:9866, bytes: 2654, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741937_1113, duration(ns): 2491323
2025-03-26 02:24:17,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56780, dest: /172.20.1.11:9866, bytes: 2654, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741937_1113, duration(ns): 2194572
2025-03-26 02:24:17,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741937_1113, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,538 INFO terminating
2025-03-26 02:24:17,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:43984, dest: /172.20.1.12:9866, bytes: 2654, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741937_1113, duration(ns): 2965281
2025-03-26 02:24:17,539 INFO terminating
2025-03-26 02:24:17,541 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/naive_bayes_example.py._COPYING_
2025-03-26 02:24:17,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741938_1114 src: /172.20.1.10:43998 dest: /172.20.1.12:9866
2025-03-26 02:24:17,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741938_1114 src: /172.20.1.12:54412 dest: /172.20.1.11:9866
2025-03-26 02:24:17,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741938_1114 src: /172.20.1.11:34462 dest: /172.20.1.13:9866
2025-03-26 02:24:17,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34462, dest: /172.20.1.13:9866, bytes: 1978, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741938_1114, duration(ns): 3564458
2025-03-26 02:24:17,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54412, dest: /172.20.1.11:9866, bytes: 1978, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741938_1114, duration(ns): 4292053
2025-03-26 02:24:17,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741938_1114, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,564 INFO terminating
2025-03-26 02:24:17,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:43998, dest: /172.20.1.12:9866, bytes: 1978, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741938_1114, duration(ns): 5227990
2025-03-26 02:24:17,565 INFO terminating
2025-03-26 02:24:17,567 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/naive_bayes_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/count_vectorizer_example.py._COPYING_
2025-03-26 02:24:17,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741939_1115 src: /172.20.1.10:57272 dest: /172.20.1.11:9866
2025-03-26 02:24:17,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741939_1115 src: /172.20.1.11:34476 dest: /172.20.1.13:9866
2025-03-26 02:24:17,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741939_1115 src: /172.20.1.13:37950 dest: /172.20.1.12:9866
2025-03-26 02:24:17,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:37950, dest: /172.20.1.12:9866, bytes: 1509, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741939_1115, duration(ns): 2828217
2025-03-26 02:24:17,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34476, dest: /172.20.1.13:9866, bytes: 1509, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741939_1115, duration(ns): 3432977
2025-03-26 02:24:17,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741939_1115, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,585 INFO terminating
2025-03-26 02:24:17,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57272, dest: /172.20.1.11:9866, bytes: 1509, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741939_1115, duration(ns): 3842525
2025-03-26 02:24:17,586 INFO terminating
2025-03-26 02:24:17,587 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/count_vectorizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/decision_tree_classification_example.py._COPYING_
2025-03-26 02:24:17,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741940_1116 src: /172.20.1.10:44008 dest: /172.20.1.12:9866
2025-03-26 02:24:17,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741940_1116 src: /172.20.1.12:54872 dest: /172.20.1.13:9866
2025-03-26 02:24:17,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741940_1116 src: /172.20.1.13:56782 dest: /172.20.1.11:9866
2025-03-26 02:24:17,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56782, dest: /172.20.1.11:9866, bytes: 2964, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741940_1116, duration(ns): 2271148
2025-03-26 02:24:17,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741940_1116, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54872, dest: /172.20.1.13:9866, bytes: 2964, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741940_1116, duration(ns): 2661179
2025-03-26 02:24:17,614 INFO terminating
2025-03-26 02:24:17,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44008, dest: /172.20.1.12:9866, bytes: 2964, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741940_1116, duration(ns): 3818263
2025-03-26 02:24:17,615 INFO terminating
2025-03-26 02:24:17,616 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/decision_tree_classification_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/isotonic_regression_example.py._COPYING_
2025-03-26 02:24:17,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741941_1117 src: /172.20.1.10:44020 dest: /172.20.1.12:9866
2025-03-26 02:24:17,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741941_1117 src: /172.20.1.12:54422 dest: /172.20.1.11:9866
2025-03-26 02:24:17,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741941_1117 src: /172.20.1.11:34482 dest: /172.20.1.13:9866
2025-03-26 02:24:17,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34482, dest: /172.20.1.13:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741941_1117, duration(ns): 1068808
2025-03-26 02:24:17,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741941_1117, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54422, dest: /172.20.1.11:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741941_1117, duration(ns): 1515628
2025-03-26 02:24:17,631 INFO terminating
2025-03-26 02:24:17,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44020, dest: /172.20.1.12:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741941_1117, duration(ns): 2338843
2025-03-26 02:24:17,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/isotonic_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,633 INFO terminating
2025-03-26 02:24:17,639 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/sql_transformer.py._COPYING_
2025-03-26 02:24:17,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741942_1118 src: /172.20.1.10:57282 dest: /172.20.1.11:9866
2025-03-26 02:24:17,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741942_1118 src: /172.20.1.11:47988 dest: /172.20.1.12:9866
2025-03-26 02:24:17,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741942_1118 src: /172.20.1.12:54888 dest: /172.20.1.13:9866
2025-03-26 02:24:17,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54888, dest: /172.20.1.13:9866, bytes: 1343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741942_1118, duration(ns): 1329696
2025-03-26 02:24:17,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741942_1118, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57282, dest: /172.20.1.11:9866, bytes: 1343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741942_1118, duration(ns): 2724777
2025-03-26 02:24:17,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:47988, dest: /172.20.1.12:9866, bytes: 1343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741942_1118, duration(ns): 1651208
2025-03-26 02:24:17,647 INFO terminating
2025-03-26 02:24:17,647 INFO terminating
2025-03-26 02:24:17,648 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/sql_transformer.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,656 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/polynomial_expansion_example.py._COPYING_
2025-03-26 02:24:17,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741943_1119 src: /172.20.1.10:44032 dest: /172.20.1.12:9866
2025-03-26 02:24:17,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741943_1119 src: /172.20.1.12:54900 dest: /172.20.1.13:9866
2025-03-26 02:24:17,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741943_1119 src: /172.20.1.13:56798 dest: /172.20.1.11:9866
2025-03-26 02:24:17,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56798, dest: /172.20.1.11:9866, bytes: 1483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741943_1119, duration(ns): 1486461
2025-03-26 02:24:17,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741943_1119, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54900, dest: /172.20.1.13:9866, bytes: 1483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741943_1119, duration(ns): 1919516
2025-03-26 02:24:17,665 INFO terminating
2025-03-26 02:24:17,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44032, dest: /172.20.1.12:9866, bytes: 1483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741943_1119, duration(ns): 3004570
2025-03-26 02:24:17,666 INFO terminating
2025-03-26 02:24:17,667 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/polynomial_expansion_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,673 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/bucketizer_example.py._COPYING_
2025-03-26 02:24:17,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741944_1120 src: /172.20.1.10:50848 dest: /172.20.1.13:9866
2025-03-26 02:24:17,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741944_1120 src: /172.20.1.13:56812 dest: /172.20.1.11:9866
2025-03-26 02:24:17,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741944_1120 src: /172.20.1.11:47994 dest: /172.20.1.12:9866
2025-03-26 02:24:17,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:47994, dest: /172.20.1.12:9866, bytes: 1580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741944_1120, duration(ns): 1383314
2025-03-26 02:24:17,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741944_1120, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56812, dest: /172.20.1.11:9866, bytes: 1580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741944_1120, duration(ns): 1697582
2025-03-26 02:24:17,683 INFO terminating
2025-03-26 02:24:17,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50848, dest: /172.20.1.13:9866, bytes: 1580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741944_1120, duration(ns): 2274505
2025-03-26 02:24:17,684 INFO terminating
2025-03-26 02:24:17,685 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bucketizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,690 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/univariate_feature_selector_example.py._COPYING_
2025-03-26 02:24:17,690 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,690 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741945_1121 src: /172.20.1.10:50852 dest: /172.20.1.13:9866
2025-03-26 02:24:17,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741945_1121 src: /172.20.1.13:37956 dest: /172.20.1.12:9866
2025-03-26 02:24:17,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741945_1121 src: /172.20.1.12:54432 dest: /172.20.1.11:9866
2025-03-26 02:24:17,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54432, dest: /172.20.1.11:9866, bytes: 2243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741945_1121, duration(ns): 2508953
2025-03-26 02:24:17,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:37956, dest: /172.20.1.12:9866, bytes: 2243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741945_1121, duration(ns): 3243797
2025-03-26 02:24:17,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741945_1121, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,699 INFO terminating
2025-03-26 02:24:17,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50852, dest: /172.20.1.13:9866, bytes: 2243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741945_1121, duration(ns): 3956890
2025-03-26 02:24:17,700 INFO terminating
2025-03-26 02:24:17,701 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/univariate_feature_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,707 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/power_iteration_clustering_example.py._COPYING_
2025-03-26 02:24:17,707 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,707 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741946_1122 src: /172.20.1.10:44042 dest: /172.20.1.12:9866
2025-03-26 02:24:17,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741946_1122 src: /172.20.1.12:54902 dest: /172.20.1.13:9866
2025-03-26 02:24:17,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741946_1122 src: /172.20.1.13:56824 dest: /172.20.1.11:9866
2025-03-26 02:24:17,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54902, dest: /172.20.1.13:9866, bytes: 1604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741946_1122, duration(ns): 1682895
2025-03-26 02:24:17,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56824, dest: /172.20.1.11:9866, bytes: 1604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741946_1122, duration(ns): 1448734
2025-03-26 02:24:17,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741946_1122, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44042, dest: /172.20.1.12:9866, bytes: 1604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741946_1122, duration(ns): 2210140
2025-03-26 02:24:17,717 INFO terminating
2025-03-26 02:24:17,717 INFO terminating
2025-03-26 02:24:17,718 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/power_iteration_clustering_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/als_example.py._COPYING_
2025-03-26 02:24:17,724 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,724 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741947_1123 src: /172.20.1.10:57292 dest: /172.20.1.11:9866
2025-03-26 02:24:17,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741947_1123 src: /172.20.1.11:47996 dest: /172.20.1.12:9866
2025-03-26 02:24:17,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741947_1123 src: /172.20.1.12:54906 dest: /172.20.1.13:9866
2025-03-26 02:24:17,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54906, dest: /172.20.1.13:9866, bytes: 2936, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741947_1123, duration(ns): 1498606
2025-03-26 02:24:17,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741947_1123, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:47996, dest: /172.20.1.12:9866, bytes: 2936, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741947_1123, duration(ns): 1826226
2025-03-26 02:24:17,731 INFO terminating
2025-03-26 02:24:17,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/als_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57292, dest: /172.20.1.11:9866, bytes: 2936, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741947_1123, duration(ns): 2352323
2025-03-26 02:24:17,732 INFO terminating
2025-03-26 02:24:17,737 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/logistic_regression_summary_example.py._COPYING_
2025-03-26 02:24:17,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741948_1124 src: /172.20.1.10:44056 dest: /172.20.1.12:9866
2025-03-26 02:24:17,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741948_1124 src: /172.20.1.12:54442 dest: /172.20.1.11:9866
2025-03-26 02:24:17,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741948_1124 src: /172.20.1.11:34492 dest: /172.20.1.13:9866
2025-03-26 02:24:17,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34492, dest: /172.20.1.13:9866, bytes: 2402, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741948_1124, duration(ns): 3471530
2025-03-26 02:24:17,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741948_1124, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54442, dest: /172.20.1.11:9866, bytes: 2402, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741948_1124, duration(ns): 3954686
2025-03-26 02:24:17,750 INFO terminating
2025-03-26 02:24:17,751 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/logistic_regression_summary_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44056, dest: /172.20.1.12:9866, bytes: 2402, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741948_1124, duration(ns): 2769567
2025-03-26 02:24:17,751 INFO terminating
2025-03-26 02:24:17,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/summarizer_example.py._COPYING_
2025-03-26 02:24:17,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741949_1125 src: /172.20.1.10:57298 dest: /172.20.1.11:9866
2025-03-26 02:24:17,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741949_1125 src: /172.20.1.11:48008 dest: /172.20.1.12:9866
2025-03-26 02:24:17,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741949_1125 src: /172.20.1.12:54908 dest: /172.20.1.13:9866
2025-03-26 02:24:17,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54908, dest: /172.20.1.13:9866, bytes: 2121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741949_1125, duration(ns): 1420436
2025-03-26 02:24:17,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741949_1125, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48008, dest: /172.20.1.12:9866, bytes: 2121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741949_1125, duration(ns): 2345138
2025-03-26 02:24:17,775 INFO terminating
2025-03-26 02:24:17,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57298, dest: /172.20.1.11:9866, bytes: 2121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741949_1125, duration(ns): 2819996
2025-03-26 02:24:17,776 INFO terminating
2025-03-26 02:24:17,777 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/summarizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,782 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/vector_slicer_example.py._COPYING_
2025-03-26 02:24:17,782 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,782 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741950_1126 src: /172.20.1.10:57308 dest: /172.20.1.11:9866
2025-03-26 02:24:17,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741950_1126 src: /172.20.1.11:34498 dest: /172.20.1.13:9866
2025-03-26 02:24:17,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741950_1126 src: /172.20.1.13:37960 dest: /172.20.1.12:9866
2025-03-26 02:24:17,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:37960, dest: /172.20.1.12:9866, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741950_1126, duration(ns): 1896187
2025-03-26 02:24:17,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741950_1126, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34498, dest: /172.20.1.13:9866, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741950_1126, duration(ns): 2144913
2025-03-26 02:24:17,790 INFO terminating
2025-03-26 02:24:17,791 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_slicer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57308, dest: /172.20.1.11:9866, bytes: 1496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741950_1126, duration(ns): 2665864
2025-03-26 02:24:17,791 INFO terminating
2025-03-26 02:24:17,797 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,797 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,798 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/imputer_example.py._COPYING_
2025-03-26 02:24:17,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741951_1127 src: /172.20.1.10:57324 dest: /172.20.1.11:9866
2025-03-26 02:24:17,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741951_1127 src: /172.20.1.11:48020 dest: /172.20.1.12:9866
2025-03-26 02:24:17,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741951_1127 src: /172.20.1.12:54924 dest: /172.20.1.13:9866
2025-03-26 02:24:17,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48020, dest: /172.20.1.12:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741951_1127, duration(ns): 1624435
2025-03-26 02:24:17,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54924, dest: /172.20.1.13:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741951_1127, duration(ns): 1340042
2025-03-26 02:24:17,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741951_1127, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57324, dest: /172.20.1.11:9866, bytes: 1513, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741951_1127, duration(ns): 2266060
2025-03-26 02:24:17,806 INFO terminating
2025-03-26 02:24:17,806 INFO terminating
2025-03-26 02:24:17,809 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/imputer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/onehot_encoder_example.py._COPYING_
2025-03-26 02:24:17,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741952_1128 src: /172.20.1.10:50858 dest: /172.20.1.13:9866
2025-03-26 02:24:17,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741952_1128 src: /172.20.1.13:37974 dest: /172.20.1.12:9866
2025-03-26 02:24:17,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741952_1128 src: /172.20.1.12:54446 dest: /172.20.1.11:9866
2025-03-26 02:24:17,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54446, dest: /172.20.1.11:9866, bytes: 1599, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741952_1128, duration(ns): 1868637
2025-03-26 02:24:17,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741952_1128, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:37974, dest: /172.20.1.12:9866, bytes: 1599, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741952_1128, duration(ns): 3166155
2025-03-26 02:24:17,825 INFO terminating
2025-03-26 02:24:17,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50858, dest: /172.20.1.13:9866, bytes: 1599, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741952_1128, duration(ns): 3833388
2025-03-26 02:24:17,826 INFO terminating
2025-03-26 02:24:17,830 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/onehot_encoder_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,836 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/linearsvc.py._COPYING_
2025-03-26 02:24:17,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741953_1129 src: /172.20.1.10:44060 dest: /172.20.1.12:9866
2025-03-26 02:24:17,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741953_1129 src: /172.20.1.12:54450 dest: /172.20.1.11:9866
2025-03-26 02:24:17,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741953_1129 src: /172.20.1.11:34512 dest: /172.20.1.13:9866
2025-03-26 02:24:17,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34512, dest: /172.20.1.13:9866, bytes: 1477, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741953_1129, duration(ns): 1094491
2025-03-26 02:24:17,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741953_1129, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44060, dest: /172.20.1.12:9866, bytes: 1477, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741953_1129, duration(ns): 2085681
2025-03-26 02:24:17,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54450, dest: /172.20.1.11:9866, bytes: 1477, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741953_1129, duration(ns): 1597634
2025-03-26 02:24:17,843 INFO terminating
2025-03-26 02:24:17,843 INFO terminating
2025-03-26 02:24:17,846 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/linearsvc.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,856 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_
2025-03-26 02:24:17,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741954_1130 src: /172.20.1.10:44074 dest: /172.20.1.12:9866
2025-03-26 02:24:17,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741954_1130 src: /172.20.1.12:54934 dest: /172.20.1.13:9866
2025-03-26 02:24:17,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741954_1130 src: /172.20.1.13:56838 dest: /172.20.1.11:9866
2025-03-26 02:24:17,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56838, dest: /172.20.1.11:9866, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741954_1130, duration(ns): 1623133
2025-03-26 02:24:17,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741954_1130, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44074, dest: /172.20.1.12:9866, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741954_1130, duration(ns): 2405863
2025-03-26 02:24:17,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54934, dest: /172.20.1.13:9866, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741954_1130, duration(ns): 1922292
2025-03-26 02:24:17,862 INFO terminating
2025-03-26 02:24:17,862 INFO terminating
2025-03-26 02:24:17,863 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/vector_size_hint_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,868 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/fm_classifier_example.py._COPYING_
2025-03-26 02:24:17,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741955_1131 src: /172.20.1.10:57338 dest: /172.20.1.11:9866
2025-03-26 02:24:17,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741955_1131 src: /172.20.1.11:48024 dest: /172.20.1.12:9866
2025-03-26 02:24:17,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741955_1131 src: /172.20.1.12:54950 dest: /172.20.1.13:9866
2025-03-26 02:24:17,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48024, dest: /172.20.1.12:9866, bytes: 2855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741955_1131, duration(ns): 1920194
2025-03-26 02:24:17,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54950, dest: /172.20.1.13:9866, bytes: 2855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741955_1131, duration(ns): 1622727
2025-03-26 02:24:17,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741955_1131, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,874 INFO terminating
2025-03-26 02:24:17,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57338, dest: /172.20.1.11:9866, bytes: 2855, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741955_1131, duration(ns): 2374316
2025-03-26 02:24:17,875 INFO terminating
2025-03-26 02:24:17,876 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fm_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/decision_tree_regression_example.py._COPYING_
2025-03-26 02:24:17,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741956_1132 src: /172.20.1.10:57348 dest: /172.20.1.11:9866
2025-03-26 02:24:17,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741956_1132 src: /172.20.1.11:34524 dest: /172.20.1.13:9866
2025-03-26 02:24:17,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741956_1132 src: /172.20.1.13:37984 dest: /172.20.1.12:9866
2025-03-26 02:24:17,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34524, dest: /172.20.1.13:9866, bytes: 2661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741956_1132, duration(ns): 2036552
2025-03-26 02:24:17,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:37984, dest: /172.20.1.12:9866, bytes: 2661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741956_1132, duration(ns): 1630057
2025-03-26 02:24:17,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741956_1132, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,888 INFO terminating
2025-03-26 02:24:17,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57348, dest: /172.20.1.11:9866, bytes: 2661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741956_1132, duration(ns): 2524698
2025-03-26 02:24:17,889 INFO terminating
2025-03-26 02:24:17,890 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/decision_tree_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/word2vec_example.py._COPYING_
2025-03-26 02:24:17,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741957_1133 src: /172.20.1.10:44080 dest: /172.20.1.12:9866
2025-03-26 02:24:17,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741957_1133 src: /172.20.1.12:54966 dest: /172.20.1.13:9866
2025-03-26 02:24:17,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741957_1133 src: /172.20.1.13:56854 dest: /172.20.1.11:9866
2025-03-26 02:24:17,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54966, dest: /172.20.1.13:9866, bytes: 1737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741957_1133, duration(ns): 1948217
2025-03-26 02:24:17,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56854, dest: /172.20.1.11:9866, bytes: 1737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741957_1133, duration(ns): 1585238
2025-03-26 02:24:17,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741957_1133, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44080, dest: /172.20.1.12:9866, bytes: 1737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741957_1133, duration(ns): 2479338
2025-03-26 02:24:17,905 INFO terminating
2025-03-26 02:24:17,905 INFO terminating
2025-03-26 02:24:17,906 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/word2vec_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/fpgrowth_example.py._COPYING_
2025-03-26 02:24:17,911 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,911 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741958_1134 src: /172.20.1.10:44094 dest: /172.20.1.12:9866
2025-03-26 02:24:17,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741958_1134 src: /172.20.1.12:54978 dest: /172.20.1.13:9866
2025-03-26 02:24:17,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741958_1134 src: /172.20.1.13:56860 dest: /172.20.1.11:9866
2025-03-26 02:24:17,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56860, dest: /172.20.1.11:9866, bytes: 1733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741958_1134, duration(ns): 1649331
2025-03-26 02:24:17,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741958_1134, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54978, dest: /172.20.1.13:9866, bytes: 1733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741958_1134, duration(ns): 1992191
2025-03-26 02:24:17,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44094, dest: /172.20.1.12:9866, bytes: 1733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741958_1134, duration(ns): 2980181
2025-03-26 02:24:17,919 INFO terminating
2025-03-26 02:24:17,919 INFO terminating
2025-03-26 02:24:17,920 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/fpgrowth_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,926 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/pipeline_example.py._COPYING_
2025-03-26 02:24:17,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741959_1135 src: /172.20.1.10:44110 dest: /172.20.1.12:9866
2025-03-26 02:24:17,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741959_1135 src: /172.20.1.12:54452 dest: /172.20.1.11:9866
2025-03-26 02:24:17,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741959_1135 src: /172.20.1.11:34534 dest: /172.20.1.13:9866
2025-03-26 02:24:17,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34534, dest: /172.20.1.13:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741959_1135, duration(ns): 1592617
2025-03-26 02:24:17,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54452, dest: /172.20.1.11:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741959_1135, duration(ns): 2074352
2025-03-26 02:24:17,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741959_1135, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44110, dest: /172.20.1.12:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741959_1135, duration(ns): 2990535
2025-03-26 02:24:17,933 INFO terminating
2025-03-26 02:24:17,933 INFO terminating
2025-03-26 02:24:17,935 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/pipeline_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,940 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/logistic_regression_with_elastic_net.py._COPYING_
2025-03-26 02:24:17,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741960_1136 src: /172.20.1.10:50862 dest: /172.20.1.13:9866
2025-03-26 02:24:17,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741960_1136 src: /172.20.1.13:56868 dest: /172.20.1.11:9866
2025-03-26 02:24:17,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741960_1136 src: /172.20.1.11:48026 dest: /172.20.1.12:9866
2025-03-26 02:24:17,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48026, dest: /172.20.1.12:9866, bytes: 1990, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741960_1136, duration(ns): 1158634
2025-03-26 02:24:17,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56868, dest: /172.20.1.11:9866, bytes: 1990, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741960_1136, duration(ns): 1386625
2025-03-26 02:24:17,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741960_1136, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,946 INFO terminating
2025-03-26 02:24:17,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50862, dest: /172.20.1.13:9866, bytes: 1990, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741960_1136, duration(ns): 1879449
2025-03-26 02:24:17,947 INFO terminating
2025-03-26 02:24:17,948 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/logistic_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,952 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/train_validation_split.py._COPYING_
2025-03-26 02:24:17,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741961_1137 src: /172.20.1.10:50876 dest: /172.20.1.13:9866
2025-03-26 02:24:17,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741961_1137 src: /172.20.1.13:37994 dest: /172.20.1.12:9866
2025-03-26 02:24:17,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741961_1137 src: /172.20.1.12:54454 dest: /172.20.1.11:9866
2025-03-26 02:24:17,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54454, dest: /172.20.1.11:9866, bytes: 2841, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741961_1137, duration(ns): 1442778
2025-03-26 02:24:17,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741961_1137, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50876, dest: /172.20.1.13:9866, bytes: 2841, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741961_1137, duration(ns): 2256310
2025-03-26 02:24:17,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:37994, dest: /172.20.1.12:9866, bytes: 2841, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741961_1137, duration(ns): 1865695
2025-03-26 02:24:17,960 INFO terminating
2025-03-26 02:24:17,960 INFO terminating
2025-03-26 02:24:17,963 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/train_validation_split.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/interaction_example.py._COPYING_
2025-03-26 02:24:17,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741962_1138 src: /172.20.1.10:57352 dest: /172.20.1.11:9866
2025-03-26 02:24:17,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741962_1138 src: /172.20.1.11:48032 dest: /172.20.1.12:9866
2025-03-26 02:24:17,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741962_1138 src: /172.20.1.12:54984 dest: /172.20.1.13:9866
2025-03-26 02:24:17,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48032, dest: /172.20.1.12:9866, bytes: 1868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741962_1138, duration(ns): 1738610
2025-03-26 02:24:17,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54984, dest: /172.20.1.13:9866, bytes: 1868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741962_1138, duration(ns): 1458288
2025-03-26 02:24:17,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741962_1138, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,975 INFO terminating
2025-03-26 02:24:17,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57352, dest: /172.20.1.11:9866, bytes: 1868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741962_1138, duration(ns): 2199110
2025-03-26 02:24:17,976 INFO terminating
2025-03-26 02:24:17,977 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/interaction_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/random_forest_classifier_example.py._COPYING_
2025-03-26 02:24:17,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741963_1139 src: /172.20.1.10:50882 dest: /172.20.1.13:9866
2025-03-26 02:24:17,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741963_1139 src: /172.20.1.13:38006 dest: /172.20.1.12:9866
2025-03-26 02:24:17,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741963_1139 src: /172.20.1.12:54460 dest: /172.20.1.11:9866
2025-03-26 02:24:17,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54460, dest: /172.20.1.11:9866, bytes: 3195, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741963_1139, duration(ns): 1124221
2025-03-26 02:24:17,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38006, dest: /172.20.1.12:9866, bytes: 3195, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741963_1139, duration(ns): 1448857
2025-03-26 02:24:17,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741963_1139, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:17,988 INFO terminating
2025-03-26 02:24:17,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50882, dest: /172.20.1.13:9866, bytes: 3195, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741963_1139, duration(ns): 1856146
2025-03-26 02:24:17,989 INFO terminating
2025-03-26 02:24:17,990 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/random_forest_classifier_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:17,994 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,994 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:17,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/quantile_discretizer_example.py._COPYING_
2025-03-26 02:24:17,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741964_1140 src: /172.20.1.10:50894 dest: /172.20.1.13:9866
2025-03-26 02:24:17,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741964_1140 src: /172.20.1.13:56880 dest: /172.20.1.11:9866
2025-03-26 02:24:17,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741964_1140 src: /172.20.1.11:48036 dest: /172.20.1.12:9866
2025-03-26 02:24:18,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48036, dest: /172.20.1.12:9866, bytes: 1668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741964_1140, duration(ns): 1449518
2025-03-26 02:24:18,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56880, dest: /172.20.1.11:9866, bytes: 1668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741964_1140, duration(ns): 1803740
2025-03-26 02:24:18,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741964_1140, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,001 INFO terminating
2025-03-26 02:24:18,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50894, dest: /172.20.1.13:9866, bytes: 1668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741964_1140, duration(ns): 2240797
2025-03-26 02:24:18,002 INFO terminating
2025-03-26 02:24:18,003 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/quantile_discretizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/aft_survival_regression.py._COPYING_
2025-03-26 02:24:18,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741965_1141 src: /172.20.1.10:50902 dest: /172.20.1.13:9866
2025-03-26 02:24:18,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741965_1141 src: /172.20.1.13:56882 dest: /172.20.1.11:9866
2025-03-26 02:24:18,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741965_1141 src: /172.20.1.11:48044 dest: /172.20.1.12:9866
2025-03-26 02:24:18,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48044, dest: /172.20.1.12:9866, bytes: 2112, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741965_1141, duration(ns): 1359869
2025-03-26 02:24:18,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56882, dest: /172.20.1.11:9866, bytes: 2112, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741965_1141, duration(ns): 1678361
2025-03-26 02:24:18,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741965_1141, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,015 INFO terminating
2025-03-26 02:24:18,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50902, dest: /172.20.1.13:9866, bytes: 2112, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741965_1141, duration(ns): 2027742
2025-03-26 02:24:18,016 INFO terminating
2025-03-26 02:24:18,017 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/aft_survival_regression.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,022 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/estimator_transformer_param_example.py._COPYING_
2025-03-26 02:24:18,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741966_1142 src: /172.20.1.10:57360 dest: /172.20.1.11:9866
2025-03-26 02:24:18,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741966_1142 src: /172.20.1.11:34538 dest: /172.20.1.13:9866
2025-03-26 02:24:18,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741966_1142 src: /172.20.1.13:38014 dest: /172.20.1.12:9866
2025-03-26 02:24:18,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38014, dest: /172.20.1.12:9866, bytes: 3951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741966_1142, duration(ns): 1578387
2025-03-26 02:24:18,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741966_1142, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34538, dest: /172.20.1.13:9866, bytes: 3951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741966_1142, duration(ns): 2008651
2025-03-26 02:24:18,029 INFO terminating
2025-03-26 02:24:18,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57360, dest: /172.20.1.11:9866, bytes: 3951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741966_1142, duration(ns): 2422366
2025-03-26 02:24:18,030 INFO terminating
2025-03-26 02:24:18,031 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/estimator_transformer_param_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,039 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/__init__,py._COPYING_
2025-03-26 02:24:18,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741967_1143 src: /172.20.1.10:50910 dest: /172.20.1.13:9866
2025-03-26 02:24:18,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741967_1143 src: /172.20.1.13:38026 dest: /172.20.1.12:9866
2025-03-26 02:24:18,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741967_1143 src: /172.20.1.12:54476 dest: /172.20.1.11:9866
2025-03-26 02:24:18,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54476, dest: /172.20.1.11:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741967_1143, duration(ns): 1439350
2025-03-26 02:24:18,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741967_1143, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50910, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741967_1143, duration(ns): 2668343
2025-03-26 02:24:18,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38026, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741967_1143, duration(ns): 2194109
2025-03-26 02:24:18,046 INFO terminating
2025-03-26 02:24:18,046 INFO terminating
2025-03-26 02:24:18,047 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/__init__,py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/chi_square_test_example.py._COPYING_
2025-03-26 02:24:18,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741968_1144 src: /172.20.1.10:50926 dest: /172.20.1.13:9866
2025-03-26 02:24:18,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741968_1144 src: /172.20.1.13:56888 dest: /172.20.1.11:9866
2025-03-26 02:24:18,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741968_1144 src: /172.20.1.11:48058 dest: /172.20.1.12:9866
2025-03-26 02:24:18,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48058, dest: /172.20.1.12:9866, bytes: 1869, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741968_1144, duration(ns): 1446419
2025-03-26 02:24:18,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56888, dest: /172.20.1.11:9866, bytes: 1869, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741968_1144, duration(ns): 2239600
2025-03-26 02:24:18,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741968_1144, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,059 INFO terminating
2025-03-26 02:24:18,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50926, dest: /172.20.1.13:9866, bytes: 1869, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741968_1144, duration(ns): 2701149
2025-03-26 02:24:18,060 INFO terminating
2025-03-26 02:24:18,061 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/chi_square_test_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/multilayer_perceptron_classification.py._COPYING_
2025-03-26 02:24:18,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741969_1145 src: /172.20.1.10:50938 dest: /172.20.1.13:9866
2025-03-26 02:24:18,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741969_1145 src: /172.20.1.13:38034 dest: /172.20.1.12:9866
2025-03-26 02:24:18,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741969_1145 src: /172.20.1.12:54492 dest: /172.20.1.11:9866
2025-03-26 02:24:18,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54492, dest: /172.20.1.11:9866, bytes: 2133, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741969_1145, duration(ns): 1631291
2025-03-26 02:24:18,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741969_1145, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38034, dest: /172.20.1.12:9866, bytes: 2133, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741969_1145, duration(ns): 2624901
2025-03-26 02:24:18,074 INFO terminating
2025-03-26 02:24:18,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50938, dest: /172.20.1.13:9866, bytes: 2133, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741969_1145, duration(ns): 3163492
2025-03-26 02:24:18,075 INFO terminating
2025-03-26 02:24:18,078 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/multilayer_perceptron_classification.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/dataframe_example.py._COPYING_
2025-03-26 02:24:18,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741970_1146 src: /172.20.1.10:44120 dest: /172.20.1.12:9866
2025-03-26 02:24:18,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741970_1146 src: /172.20.1.12:54496 dest: /172.20.1.11:9866
2025-03-26 02:24:18,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741970_1146 src: /172.20.1.11:34542 dest: /172.20.1.13:9866
2025-03-26 02:24:18,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34542, dest: /172.20.1.13:9866, bytes: 2663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741970_1146, duration(ns): 1921419
2025-03-26 02:24:18,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741970_1146, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44120, dest: /172.20.1.12:9866, bytes: 2663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741970_1146, duration(ns): 2929051
2025-03-26 02:24:18,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54496, dest: /172.20.1.11:9866, bytes: 2663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741970_1146, duration(ns): 2388764
2025-03-26 02:24:18,093 INFO terminating
2025-03-26 02:24:18,093 INFO terminating
2025-03-26 02:24:18,094 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/dataframe_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/prefixspan_example.py._COPYING_
2025-03-26 02:24:18,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741971_1147 src: /172.20.1.10:44126 dest: /172.20.1.12:9866
2025-03-26 02:24:18,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741971_1147 src: /172.20.1.12:54990 dest: /172.20.1.13:9866
2025-03-26 02:24:18,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741971_1147 src: /172.20.1.13:56904 dest: /172.20.1.11:9866
2025-03-26 02:24:18,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56904, dest: /172.20.1.11:9866, bytes: 1685, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741971_1147, duration(ns): 1984917
2025-03-26 02:24:18,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54990, dest: /172.20.1.13:9866, bytes: 1685, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741971_1147, duration(ns): 2309723
2025-03-26 02:24:18,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741971_1147, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,110 INFO terminating
2025-03-26 02:24:18,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44126, dest: /172.20.1.12:9866, bytes: 1685, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741971_1147, duration(ns): 2826155
2025-03-26 02:24:18,111 INFO terminating
2025-03-26 02:24:18,112 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/prefixspan_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,119 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/index_to_string_example.py._COPYING_
2025-03-26 02:24:18,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741972_1148 src: /172.20.1.10:44136 dest: /172.20.1.12:9866
2025-03-26 02:24:18,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741972_1148 src: /172.20.1.12:55002 dest: /172.20.1.13:9866
2025-03-26 02:24:18,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741972_1148 src: /172.20.1.13:56920 dest: /172.20.1.11:9866
2025-03-26 02:24:18,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55002, dest: /172.20.1.13:9866, bytes: 1975, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741972_1148, duration(ns): 2070676
2025-03-26 02:24:18,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56920, dest: /172.20.1.11:9866, bytes: 1975, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741972_1148, duration(ns): 1761304
2025-03-26 02:24:18,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741972_1148, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,126 INFO terminating
2025-03-26 02:24:18,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44136, dest: /172.20.1.12:9866, bytes: 1975, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741972_1148, duration(ns): 2647606
2025-03-26 02:24:18,127 INFO terminating
2025-03-26 02:24:18,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/index_to_string_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,133 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/one_vs_rest_example.py._COPYING_
2025-03-26 02:24:18,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741973_1149 src: /172.20.1.10:57372 dest: /172.20.1.11:9866
2025-03-26 02:24:18,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741973_1149 src: /172.20.1.11:48074 dest: /172.20.1.12:9866
2025-03-26 02:24:18,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741973_1149 src: /172.20.1.12:55006 dest: /172.20.1.13:9866
2025-03-26 02:24:18,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48074, dest: /172.20.1.12:9866, bytes: 2197, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741973_1149, duration(ns): 2086164
2025-03-26 02:24:18,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55006, dest: /172.20.1.13:9866, bytes: 2197, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741973_1149, duration(ns): 1794388
2025-03-26 02:24:18,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741973_1149, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57372, dest: /172.20.1.11:9866, bytes: 2197, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741973_1149, duration(ns): 2502585
2025-03-26 02:24:18,142 INFO terminating
2025-03-26 02:24:18,142 INFO terminating
2025-03-26 02:24:18,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/one_vs_rest_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,157 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/chisq_selector_example.py._COPYING_
2025-03-26 02:24:18,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741974_1150 src: /172.20.1.10:50950 dest: /172.20.1.13:9866
2025-03-26 02:24:18,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741974_1150 src: /172.20.1.13:38042 dest: /172.20.1.12:9866
2025-03-26 02:24:18,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741974_1150 src: /172.20.1.12:54498 dest: /172.20.1.11:9866
2025-03-26 02:24:18,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54498, dest: /172.20.1.11:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741974_1150, duration(ns): 1950306
2025-03-26 02:24:18,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38042, dest: /172.20.1.12:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741974_1150, duration(ns): 2282757
2025-03-26 02:24:18,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741974_1150, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50950, dest: /172.20.1.13:9866, bytes: 1677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741974_1150, duration(ns): 2755667
2025-03-26 02:24:18,165 INFO terminating
2025-03-26 02:24:18,165 INFO terminating
2025-03-26 02:24:18,166 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/chisq_selector_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,171 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/gaussian_mixture_example.py._COPYING_
2025-03-26 02:24:18,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741975_1151 src: /172.20.1.10:44150 dest: /172.20.1.12:9866
2025-03-26 02:24:18,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741975_1151 src: /172.20.1.12:55022 dest: /172.20.1.13:9866
2025-03-26 02:24:18,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741975_1151 src: /172.20.1.13:56926 dest: /172.20.1.11:9866
2025-03-26 02:24:18,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56926, dest: /172.20.1.11:9866, bytes: 1530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741975_1151, duration(ns): 3108592
2025-03-26 02:24:18,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741975_1151, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44150, dest: /172.20.1.12:9866, bytes: 1530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741975_1151, duration(ns): 4094189
2025-03-26 02:24:18,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55022, dest: /172.20.1.13:9866, bytes: 1530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741975_1151, duration(ns): 3355725
2025-03-26 02:24:18,180 INFO terminating
2025-03-26 02:24:18,180 INFO terminating
2025-03-26 02:24:18,181 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/gaussian_mixture_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/pca_example.py._COPYING_
2025-03-26 02:24:18,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741976_1152 src: /172.20.1.10:50966 dest: /172.20.1.13:9866
2025-03-26 02:24:18,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741976_1152 src: /172.20.1.13:38052 dest: /172.20.1.12:9866
2025-03-26 02:24:18,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741976_1152 src: /172.20.1.12:54504 dest: /172.20.1.11:9866
2025-03-26 02:24:18,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54504, dest: /172.20.1.11:9866, bytes: 1510, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741976_1152, duration(ns): 1703846
2025-03-26 02:24:18,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38052, dest: /172.20.1.12:9866, bytes: 1510, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741976_1152, duration(ns): 2010627
2025-03-26 02:24:18,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741976_1152, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,192 INFO terminating
2025-03-26 02:24:18,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50966, dest: /172.20.1.13:9866, bytes: 1510, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741976_1152, duration(ns): 2470235
2025-03-26 02:24:18,193 INFO terminating
2025-03-26 02:24:18,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/pca_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,199 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1153, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/generalized_linear_regression_example.py._COPYING_
2025-03-26 02:24:18,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741977_1153 src: /172.20.1.10:44154 dest: /172.20.1.12:9866
2025-03-26 02:24:18,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741977_1153 src: /172.20.1.12:55034 dest: /172.20.1.13:9866
2025-03-26 02:24:18,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741977_1153 src: /172.20.1.13:56934 dest: /172.20.1.11:9866
2025-03-26 02:24:18,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55034, dest: /172.20.1.13:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741977_1153, duration(ns): 2565674
2025-03-26 02:24:18,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56934, dest: /172.20.1.11:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741977_1153, duration(ns): 2302697
2025-03-26 02:24:18,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741977_1153, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,206 INFO terminating
2025-03-26 02:24:18,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44154, dest: /172.20.1.12:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741977_1153, duration(ns): 3119797
2025-03-26 02:24:18,207 INFO terminating
2025-03-26 02:24:18,208 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/generalized_linear_regression_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1154, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/lda_example.py._COPYING_
2025-03-26 02:24:18,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741978_1154 src: /172.20.1.10:57378 dest: /172.20.1.11:9866
2025-03-26 02:24:18,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741978_1154 src: /172.20.1.11:48090 dest: /172.20.1.12:9866
2025-03-26 02:24:18,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741978_1154 src: /172.20.1.12:55044 dest: /172.20.1.13:9866
2025-03-26 02:24:18,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55044, dest: /172.20.1.13:9866, bytes: 1859, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741978_1154, duration(ns): 1492253
2025-03-26 02:24:18,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741978_1154, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48090, dest: /172.20.1.12:9866, bytes: 1859, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741978_1154, duration(ns): 1871035
2025-03-26 02:24:18,223 INFO terminating
2025-03-26 02:24:18,224 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/lda_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57378, dest: /172.20.1.11:9866, bytes: 1859, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741978_1154, duration(ns): 2481722
2025-03-26 02:24:18,224 INFO terminating
2025-03-26 02:24:18,232 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1155, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/min_max_scaler_example.py._COPYING_
2025-03-26 02:24:18,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741979_1155 src: /172.20.1.10:44166 dest: /172.20.1.12:9866
2025-03-26 02:24:18,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741979_1155 src: /172.20.1.12:55048 dest: /172.20.1.13:9866
2025-03-26 02:24:18,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741979_1155 src: /172.20.1.13:56936 dest: /172.20.1.11:9866
2025-03-26 02:24:18,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55048, dest: /172.20.1.13:9866, bytes: 1759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741979_1155, duration(ns): 2795807
2025-03-26 02:24:18,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56936, dest: /172.20.1.11:9866, bytes: 1759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741979_1155, duration(ns): 2499863
2025-03-26 02:24:18,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741979_1155, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44166, dest: /172.20.1.12:9866, bytes: 1759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741979_1155, duration(ns): 3255941
2025-03-26 02:24:18,241 INFO terminating
2025-03-26 02:24:18,241 INFO terminating
2025-03-26 02:24:18,244 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/min_max_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1156, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_
2025-03-26 02:24:18,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741980_1156 src: /172.20.1.10:44174 dest: /172.20.1.12:9866
2025-03-26 02:24:18,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741980_1156 src: /172.20.1.12:55054 dest: /172.20.1.13:9866
2025-03-26 02:24:18,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741980_1156 src: /172.20.1.13:56950 dest: /172.20.1.11:9866
2025-03-26 02:24:18,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55054, dest: /172.20.1.13:9866, bytes: 3199, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741980_1156, duration(ns): 2349274
2025-03-26 02:24:18,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56950, dest: /172.20.1.11:9866, bytes: 3199, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741980_1156, duration(ns): 1714435
2025-03-26 02:24:18,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741980_1156, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,256 INFO terminating
2025-03-26 02:24:18,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44174, dest: /172.20.1.12:9866, bytes: 3199, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741980_1156, duration(ns): 2786900
2025-03-26 02:24:18,257 INFO terminating
2025-03-26 02:24:18,258 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,263 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1157, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/standard_scaler_example.py._COPYING_
2025-03-26 02:24:18,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741981_1157 src: /172.20.1.10:44178 dest: /172.20.1.12:9866
2025-03-26 02:24:18,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741981_1157 src: /172.20.1.12:54510 dest: /172.20.1.11:9866
2025-03-26 02:24:18,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741981_1157 src: /172.20.1.11:34550 dest: /172.20.1.13:9866
2025-03-26 02:24:18,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34550, dest: /172.20.1.13:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741981_1157, duration(ns): 2161563
2025-03-26 02:24:18,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741981_1157, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54510, dest: /172.20.1.11:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741981_1157, duration(ns): 2504685
2025-03-26 02:24:18,270 INFO terminating
2025-03-26 02:24:18,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44178, dest: /172.20.1.12:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741981_1157, duration(ns): 3435197
2025-03-26 02:24:18,271 INFO terminating
2025-03-26 02:24:18,273 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/standard_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,281 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1158, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/tokenizer_example.py._COPYING_
2025-03-26 02:24:18,281 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,281 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741982_1158 src: /172.20.1.10:44190 dest: /172.20.1.12:9866
2025-03-26 02:24:18,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741982_1158 src: /172.20.1.12:54520 dest: /172.20.1.11:9866
2025-03-26 02:24:18,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741982_1158 src: /172.20.1.11:34562 dest: /172.20.1.13:9866
2025-03-26 02:24:18,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34562, dest: /172.20.1.13:9866, bytes: 2044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741982_1158, duration(ns): 1580312
2025-03-26 02:24:18,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741982_1158, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44190, dest: /172.20.1.12:9866, bytes: 2044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741982_1158, duration(ns): 2386392
2025-03-26 02:24:18,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54520, dest: /172.20.1.11:9866, bytes: 2044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741982_1158, duration(ns): 1914379
2025-03-26 02:24:18,288 INFO terminating
2025-03-26 02:24:18,288 INFO terminating
2025-03-26 02:24:18,289 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/tokenizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,294 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1159, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/rformula_example.py._COPYING_
2025-03-26 02:24:18,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741983_1159 src: /172.20.1.10:44194 dest: /172.20.1.12:9866
2025-03-26 02:24:18,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741983_1159 src: /172.20.1.12:55058 dest: /172.20.1.13:9866
2025-03-26 02:24:18,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741983_1159 src: /172.20.1.13:56962 dest: /172.20.1.11:9866
2025-03-26 02:24:18,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56962, dest: /172.20.1.11:9866, bytes: 1481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741983_1159, duration(ns): 1515944
2025-03-26 02:24:18,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741983_1159, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44194, dest: /172.20.1.12:9866, bytes: 1481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741983_1159, duration(ns): 2340223
2025-03-26 02:24:18,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55058, dest: /172.20.1.13:9866, bytes: 1481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741983_1159, duration(ns): 1861690
2025-03-26 02:24:18,300 INFO terminating
2025-03-26 02:24:18,300 INFO terminating
2025-03-26 02:24:18,301 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/rformula_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,307 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1160, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/normalizer_example.py._COPYING_
2025-03-26 02:24:18,307 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,307 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741984_1160 src: /172.20.1.10:50978 dest: /172.20.1.13:9866
2025-03-26 02:24:18,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741984_1160 src: /172.20.1.12:54524 dest: /172.20.1.11:9866
2025-03-26 02:24:18,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741984_1160 src: /172.20.1.13:38056 dest: /172.20.1.12:9866
2025-03-26 02:24:18,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54524, dest: /172.20.1.11:9866, bytes: 1768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741984_1160, duration(ns): 1519303
2025-03-26 02:24:18,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741984_1160, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38056, dest: /172.20.1.12:9866, bytes: 1768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741984_1160, duration(ns): 2861246
2025-03-26 02:24:18,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50978, dest: /172.20.1.13:9866, bytes: 1768, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741984_1160, duration(ns): 3756867
2025-03-26 02:24:18,315 INFO terminating
2025-03-26 02:24:18,315 INFO terminating
2025-03-26 02:24:18,316 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/normalizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1161, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/n_gram_example.py._COPYING_
2025-03-26 02:24:18,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741985_1161 src: /172.20.1.10:44200 dest: /172.20.1.12:9866
2025-03-26 02:24:18,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741985_1161 src: /172.20.1.12:55070 dest: /172.20.1.13:9866
2025-03-26 02:24:18,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741985_1161 src: /172.20.1.13:56968 dest: /172.20.1.11:9866
2025-03-26 02:24:18,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55070, dest: /172.20.1.13:9866, bytes: 1506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741985_1161, duration(ns): 1904080
2025-03-26 02:24:18,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56968, dest: /172.20.1.11:9866, bytes: 1506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741985_1161, duration(ns): 1625181
2025-03-26 02:24:18,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741985_1161, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44200, dest: /172.20.1.12:9866, bytes: 1506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741985_1161, duration(ns): 2333439
2025-03-26 02:24:18,340 INFO terminating
2025-03-26 02:24:18,340 INFO terminating
2025-03-26 02:24:18,341 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/n_gram_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1162, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/dct_example.py._COPYING_
2025-03-26 02:24:18,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741986_1162 src: /172.20.1.10:57386 dest: /172.20.1.11:9866
2025-03-26 02:24:18,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741986_1162 src: /172.20.1.11:48100 dest: /172.20.1.12:9866
2025-03-26 02:24:18,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741986_1162 src: /172.20.1.12:55078 dest: /172.20.1.13:9866
2025-03-26 02:24:18,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48100, dest: /172.20.1.12:9866, bytes: 1470, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741986_1162, duration(ns): 2115732
2025-03-26 02:24:18,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55078, dest: /172.20.1.13:9866, bytes: 1470, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741986_1162, duration(ns): 1676486
2025-03-26 02:24:18,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741986_1162, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57386, dest: /172.20.1.11:9866, bytes: 1470, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741986_1162, duration(ns): 2633095
2025-03-26 02:24:18,353 INFO terminating
2025-03-26 02:24:18,353 INFO terminating
2025-03-26 02:24:18,354 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/dct_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1163, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/min_hash_lsh_example.py._COPYING_
2025-03-26 02:24:18,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741987_1163 src: /172.20.1.10:57402 dest: /172.20.1.11:9866
2025-03-26 02:24:18,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741987_1163 src: /172.20.1.11:48112 dest: /172.20.1.12:9866
2025-03-26 02:24:18,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741987_1163 src: /172.20.1.12:55088 dest: /172.20.1.13:9866
2025-03-26 02:24:18,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55088, dest: /172.20.1.13:9866, bytes: 3183, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741987_1163, duration(ns): 1403053
2025-03-26 02:24:18,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741987_1163, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57402, dest: /172.20.1.11:9866, bytes: 3183, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741987_1163, duration(ns): 2011847
2025-03-26 02:24:18,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48112, dest: /172.20.1.12:9866, bytes: 3183, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741987_1163, duration(ns): 1696736
2025-03-26 02:24:18,366 INFO terminating
2025-03-26 02:24:18,366 INFO terminating
2025-03-26 02:24:18,367 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/min_hash_lsh_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,373 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1164, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py._COPYING_
2025-03-26 02:24:18,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741988_1164 src: /172.20.1.10:50988 dest: /172.20.1.13:9866
2025-03-26 02:24:18,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741988_1164 src: /172.20.1.13:56974 dest: /172.20.1.11:9866
2025-03-26 02:24:18,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741988_1164 src: /172.20.1.11:48124 dest: /172.20.1.12:9866
2025-03-26 02:24:18,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48124, dest: /172.20.1.12:9866, bytes: 3128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741988_1164, duration(ns): 1988246
2025-03-26 02:24:18,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741988_1164, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50988, dest: /172.20.1.13:9866, bytes: 3128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741988_1164, duration(ns): 2819990
2025-03-26 02:24:18,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56974, dest: /172.20.1.11:9866, bytes: 3128, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741988_1164, duration(ns): 2347610
2025-03-26 02:24:18,381 INFO terminating
2025-03-26 02:24:18,381 INFO terminating
2025-03-26 02:24:18,382 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1165, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/ml/binarizer_example.py._COPYING_
2025-03-26 02:24:18,387 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,387 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741989_1165 src: /172.20.1.10:57416 dest: /172.20.1.11:9866
2025-03-26 02:24:18,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741989_1165 src: /172.20.1.11:34568 dest: /172.20.1.13:9866
2025-03-26 02:24:18,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741989_1165 src: /172.20.1.13:38064 dest: /172.20.1.12:9866
2025-03-26 02:24:18,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34568, dest: /172.20.1.13:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741989_1165, duration(ns): 1832122
2025-03-26 02:24:18,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38064, dest: /172.20.1.12:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741989_1165, duration(ns): 1431297
2025-03-26 02:24:18,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741989_1165, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,394 INFO terminating
2025-03-26 02:24:18,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57416, dest: /172.20.1.11:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741989_1165, duration(ns): 2274678
2025-03-26 02:24:18,395 INFO terminating
2025-03-26 02:24:18,397 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/binarizer_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1166, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/ml/elementwise_product_example.py._COPYING_
2025-03-26 02:24:18,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741990_1166 src: /172.20.1.10:57422 dest: /172.20.1.11:9866
2025-03-26 02:24:18,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741990_1166 src: /172.20.1.11:48126 dest: /172.20.1.12:9866
2025-03-26 02:24:18,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741990_1166 src: /172.20.1.12:55090 dest: /172.20.1.13:9866
2025-03-26 02:24:18,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55090, dest: /172.20.1.13:9866, bytes: 1593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741990_1166, duration(ns): 3692442
2025-03-26 02:24:18,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741990_1166, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48126, dest: /172.20.1.12:9866, bytes: 1593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741990_1166, duration(ns): 4185626
2025-03-26 02:24:18,415 INFO terminating
2025-03-26 02:24:18,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57422, dest: /172.20.1.11:9866, bytes: 1593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741990_1166, duration(ns): 4762695
2025-03-26 02:24:18,416 INFO terminating
2025-03-26 02:24:18,417 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/elementwise_product_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1167, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/ml/max_abs_scaler_example.py._COPYING_
2025-03-26 02:24:18,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741991_1167 src: /172.20.1.10:44210 dest: /172.20.1.12:9866
2025-03-26 02:24:18,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741991_1167 src: /172.20.1.12:55096 dest: /172.20.1.13:9866
2025-03-26 02:24:18,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741991_1167 src: /172.20.1.13:56990 dest: /172.20.1.11:9866
2025-03-26 02:24:18,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55096, dest: /172.20.1.13:9866, bytes: 1673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741991_1167, duration(ns): 1966825
2025-03-26 02:24:18,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:56990, dest: /172.20.1.11:9866, bytes: 1673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741991_1167, duration(ns): 1674092
2025-03-26 02:24:18,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741991_1167, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44210, dest: /172.20.1.12:9866, bytes: 1673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741991_1167, duration(ns): 2344929
2025-03-26 02:24:18,429 INFO terminating
2025-03-26 02:24:18,429 INFO terminating
2025-03-26 02:24:18,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/ml/max_abs_scaler_example.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1168, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/als.py._COPYING_
2025-03-26 02:24:18,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741992_1168 src: /172.20.1.10:50992 dest: /172.20.1.13:9866
2025-03-26 02:24:18,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741992_1168 src: /172.20.1.13:38078 dest: /172.20.1.12:9866
2025-03-26 02:24:18,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741992_1168 src: /172.20.1.12:54530 dest: /172.20.1.11:9866
2025-03-26 02:24:18,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54530, dest: /172.20.1.11:9866, bytes: 3329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741992_1168, duration(ns): 1275415
2025-03-26 02:24:18,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38078, dest: /172.20.1.12:9866, bytes: 3329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741992_1168, duration(ns): 1503672
2025-03-26 02:24:18,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741992_1168, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,442 INFO terminating
2025-03-26 02:24:18,443 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/als.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50992, dest: /172.20.1.13:9866, bytes: 3329, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741992_1168, duration(ns): 1933233
2025-03-26 02:24:18,443 INFO terminating
2025-03-26 02:24:18,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1169, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/sql/hive.py._COPYING_
2025-03-26 02:24:18,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741993_1169 src: /172.20.1.10:44212 dest: /172.20.1.12:9866
2025-03-26 02:24:18,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741993_1169 src: /172.20.1.12:55102 dest: /172.20.1.13:9866
2025-03-26 02:24:18,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741993_1169 src: /172.20.1.13:57002 dest: /172.20.1.11:9866
2025-03-26 02:24:18,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55102, dest: /172.20.1.13:9866, bytes: 3260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741993_1169, duration(ns): 1880016
2025-03-26 02:24:18,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57002, dest: /172.20.1.11:9866, bytes: 3260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741993_1169, duration(ns): 1534325
2025-03-26 02:24:18,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741993_1169, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,457 INFO terminating
2025-03-26 02:24:18,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44212, dest: /172.20.1.12:9866, bytes: 3260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741993_1169, duration(ns): 2366730
2025-03-26 02:24:18,458 INFO terminating
2025-03-26 02:24:18,459 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/hive.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1170, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/sql/__init__.py._COPYING_
2025-03-26 02:24:18,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741994_1170 src: /172.20.1.10:44226 dest: /172.20.1.12:9866
2025-03-26 02:24:18,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741994_1170 src: /172.20.1.12:54546 dest: /172.20.1.11:9866
2025-03-26 02:24:18,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741994_1170 src: /172.20.1.11:34584 dest: /172.20.1.13:9866
2025-03-26 02:24:18,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34584, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741994_1170, duration(ns): 1440999
2025-03-26 02:24:18,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741994_1170, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54546, dest: /172.20.1.11:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741994_1170, duration(ns): 1895418
2025-03-26 02:24:18,472 INFO terminating
2025-03-26 02:24:18,473 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44226, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741994_1170, duration(ns): 2674982
2025-03-26 02:24:18,473 INFO terminating
2025-03-26 02:24:18,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1171, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/sql/datasource.py._COPYING_
2025-03-26 02:24:18,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741995_1171 src: /172.20.1.10:57432 dest: /172.20.1.11:9866
2025-03-26 02:24:18,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741995_1171 src: /172.20.1.11:34600 dest: /172.20.1.13:9866
2025-03-26 02:24:18,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741995_1171 src: /172.20.1.13:38094 dest: /172.20.1.12:9866
2025-03-26 02:24:18,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38094, dest: /172.20.1.12:9866, bytes: 15038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741995_1171, duration(ns): 1189485
2025-03-26 02:24:18,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741995_1171, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57432, dest: /172.20.1.11:9866, bytes: 15038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741995_1171, duration(ns): 2101602
2025-03-26 02:24:18,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34600, dest: /172.20.1.13:9866, bytes: 15038, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741995_1171, duration(ns): 1606015
2025-03-26 02:24:18,488 INFO terminating
2025-03-26 02:24:18,488 INFO terminating
2025-03-26 02:24:18,491 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/datasource.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,495 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1172, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/sql/basic.py._COPYING_
2025-03-26 02:24:18,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741996_1172 src: /172.20.1.10:44228 dest: /172.20.1.12:9866
2025-03-26 02:24:18,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741996_1172 src: /172.20.1.12:55104 dest: /172.20.1.13:9866
2025-03-26 02:24:18,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741996_1172 src: /172.20.1.13:57014 dest: /172.20.1.11:9866
2025-03-26 02:24:18,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57014, dest: /172.20.1.11:9866, bytes: 6331, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741996_1172, duration(ns): 1576352
2025-03-26 02:24:18,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741996_1172, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44228, dest: /172.20.1.12:9866, bytes: 6331, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741996_1172, duration(ns): 2196107
2025-03-26 02:24:18,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55104, dest: /172.20.1.13:9866, bytes: 6331, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741996_1172, duration(ns): 1843158
2025-03-26 02:24:18,502 INFO terminating
2025-03-26 02:24:18,502 INFO terminating
2025-03-26 02:24:18,504 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/basic.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,512 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1173, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/sql/arrow.py._COPYING_
2025-03-26 02:24:18,512 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,512 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741997_1173 src: /172.20.1.10:44230 dest: /172.20.1.12:9866
2025-03-26 02:24:18,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741997_1173 src: /172.20.1.12:55114 dest: /172.20.1.13:9866
2025-03-26 02:24:18,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741997_1173 src: /172.20.1.13:57024 dest: /172.20.1.11:9866
2025-03-26 02:24:18,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55114, dest: /172.20.1.13:9866, bytes: 9733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741997_1173, duration(ns): 1617212
2025-03-26 02:24:18,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57024, dest: /172.20.1.11:9866, bytes: 9733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741997_1173, duration(ns): 1270977
2025-03-26 02:24:18,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741997_1173, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44230, dest: /172.20.1.12:9866, bytes: 9733, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741997_1173, duration(ns): 1975308
2025-03-26 02:24:18,519 INFO terminating
2025-03-26 02:24:18,519 INFO terminating
2025-03-26 02:24:18,520 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/arrow.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,527 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1174, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/sql/streaming/structured_sessionization.py._COPYING_
2025-03-26 02:24:18,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741998_1174 src: /172.20.1.10:57448 dest: /172.20.1.11:9866
2025-03-26 02:24:18,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741998_1174 src: /172.20.1.11:48138 dest: /172.20.1.12:9866
2025-03-26 02:24:18,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741998_1174 src: /172.20.1.12:55120 dest: /172.20.1.13:9866
2025-03-26 02:24:18,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48138, dest: /172.20.1.12:9866, bytes: 3213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741998_1174, duration(ns): 1983214
2025-03-26 02:24:18,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55120, dest: /172.20.1.13:9866, bytes: 3213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741998_1174, duration(ns): 1705517
2025-03-26 02:24:18,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741998_1174, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,533 INFO terminating
2025-03-26 02:24:18,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57448, dest: /172.20.1.11:9866, bytes: 3213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741998_1174, duration(ns): 2346755
2025-03-26 02:24:18,534 INFO terminating
2025-03-26 02:24:18,535 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_sessionization.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1175, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py._COPYING_
2025-03-26 02:24:18,539 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,539 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741999_1175 src: /172.20.1.10:50996 dest: /172.20.1.13:9866
2025-03-26 02:24:18,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741999_1175 src: /172.20.1.13:38110 dest: /172.20.1.12:9866
2025-03-26 02:24:18,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073741999_1175 src: /172.20.1.12:54552 dest: /172.20.1.11:9866
2025-03-26 02:24:18,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54552, dest: /172.20.1.11:9866, bytes: 3172, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741999_1175, duration(ns): 1372625
2025-03-26 02:24:18,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38110, dest: /172.20.1.12:9866, bytes: 3172, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741999_1175, duration(ns): 1650930
2025-03-26 02:24:18,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073741999_1175, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,545 INFO terminating
2025-03-26 02:24:18,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50996, dest: /172.20.1.13:9866, bytes: 3172, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073741999_1175, duration(ns): 2027282
2025-03-26 02:24:18,546 INFO terminating
2025-03-26 02:24:18,547 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,551 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1176, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/sql/streaming/__init__,py._COPYING_
2025-03-26 02:24:18,551 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,551 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742000_1176 src: /172.20.1.10:51000 dest: /172.20.1.13:9866
2025-03-26 02:24:18,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742000_1176 src: /172.20.1.13:38122 dest: /172.20.1.12:9866
2025-03-26 02:24:18,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742000_1176 src: /172.20.1.12:54558 dest: /172.20.1.11:9866
2025-03-26 02:24:18,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54558, dest: /172.20.1.11:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742000_1176, duration(ns): 1025463
2025-03-26 02:24:18,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38122, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742000_1176, duration(ns): 1300472
2025-03-26 02:24:18,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742000_1176, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,556 INFO terminating
2025-03-26 02:24:18,557 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/__init__,py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51000, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742000_1176, duration(ns): 1705087
2025-03-26 02:24:18,557 INFO terminating
2025-03-26 02:24:18,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1177, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount.py._COPYING_
2025-03-26 02:24:18,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742001_1177 src: /172.20.1.10:44234 dest: /172.20.1.12:9866
2025-03-26 02:24:18,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742001_1177 src: /172.20.1.12:54560 dest: /172.20.1.11:9866
2025-03-26 02:24:18,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742001_1177 src: /172.20.1.11:34602 dest: /172.20.1.13:9866
2025-03-26 02:24:18,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34602, dest: /172.20.1.13:9866, bytes: 2500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742001_1177, duration(ns): 1071545
2025-03-26 02:24:18,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54560, dest: /172.20.1.11:9866, bytes: 2500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742001_1177, duration(ns): 1426136
2025-03-26 02:24:18,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742001_1177, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,567 INFO terminating
2025-03-26 02:24:18,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44234, dest: /172.20.1.12:9866, bytes: 2500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742001_1177, duration(ns): 1878438
2025-03-26 02:24:18,568 INFO terminating
2025-03-26 02:24:18,569 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1178, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py._COPYING_
2025-03-26 02:24:18,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742002_1178 src: /172.20.1.10:51012 dest: /172.20.1.13:9866
2025-03-26 02:24:18,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742002_1178 src: /172.20.1.11:48142 dest: /172.20.1.12:9866
2025-03-26 02:24:18,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742002_1178 src: /172.20.1.13:57040 dest: /172.20.1.11:9866
2025-03-26 02:24:18,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48142, dest: /172.20.1.12:9866, bytes: 4047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742002_1178, duration(ns): 1895518
2025-03-26 02:24:18,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57040, dest: /172.20.1.11:9866, bytes: 4047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742002_1178, duration(ns): 2868881
2025-03-26 02:24:18,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742002_1178, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,581 INFO terminating
2025-03-26 02:24:18,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51012, dest: /172.20.1.13:9866, bytes: 4047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742002_1178, duration(ns): 3670364
2025-03-26 02:24:18,582 INFO terminating
2025-03-26 02:24:18,584 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,599 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1179, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/streaming/queue_stream.py._COPYING_
2025-03-26 02:24:18,599 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742003_1179 src: /172.20.1.10:57452 dest: /172.20.1.11:9866
2025-03-26 02:24:18,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742003_1179 src: /172.20.1.11:48150 dest: /172.20.1.12:9866
2025-03-26 02:24:18,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742003_1179 src: /172.20.1.12:55136 dest: /172.20.1.13:9866
2025-03-26 02:24:18,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57452, dest: /172.20.1.11:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742003_1179, duration(ns): 2013594
2025-03-26 02:24:18,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48150, dest: /172.20.1.12:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742003_1179, duration(ns): 1725171
2025-03-26 02:24:18,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55136, dest: /172.20.1.13:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742003_1179, duration(ns): 1488060
2025-03-26 02:24:18,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742003_1179, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,605 INFO terminating
2025-03-26 02:24:18,606 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/queue_stream.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,606 INFO terminating
2025-03-26 02:24:18,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1180, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/streaming/network_wordcount.py._COPYING_
2025-03-26 02:24:18,611 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,611 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742004_1180 src: /172.20.1.10:51014 dest: /172.20.1.13:9866
2025-03-26 02:24:18,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742004_1180 src: /172.20.1.13:57048 dest: /172.20.1.11:9866
2025-03-26 02:24:18,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742004_1180 src: /172.20.1.11:48154 dest: /172.20.1.12:9866
2025-03-26 02:24:18,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48154, dest: /172.20.1.12:9866, bytes: 1883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742004_1180, duration(ns): 1306049
2025-03-26 02:24:18,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742004_1180, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51014, dest: /172.20.1.13:9866, bytes: 1883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742004_1180, duration(ns): 2688192
2025-03-26 02:24:18,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57048, dest: /172.20.1.11:9866, bytes: 1883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742004_1180, duration(ns): 1578796
2025-03-26 02:24:18,618 INFO terminating
2025-03-26 02:24:18,619 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,619 INFO terminating
2025-03-26 02:24:18,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1181, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/python/streaming/__init__.py._COPYING_
2025-03-26 02:24:18,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,624 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742005_1181 src: /172.20.1.10:57468 dest: /172.20.1.11:9866
2025-03-26 02:24:18,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742005_1181 src: /172.20.1.11:48162 dest: /172.20.1.12:9866
2025-03-26 02:24:18,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742005_1181 src: /172.20.1.12:55140 dest: /172.20.1.13:9866
2025-03-26 02:24:18,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55140, dest: /172.20.1.13:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742005_1181, duration(ns): 1183435
2025-03-26 02:24:18,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742005_1181, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48162, dest: /172.20.1.12:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742005_1181, duration(ns): 1912238
2025-03-26 02:24:18,633 INFO terminating
2025-03-26 02:24:18,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57468, dest: /172.20.1.11:9866, bytes: 784, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742005_1181, duration(ns): 2929666
2025-03-26 02:24:18,634 INFO terminating
2025-03-26 02:24:18,635 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/__init__.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1182, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/streaming/sql_network_wordcount.py._COPYING_
2025-03-26 02:24:18,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742006_1182 src: /172.20.1.10:44236 dest: /172.20.1.12:9866
2025-03-26 02:24:18,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742006_1182 src: /172.20.1.12:55146 dest: /172.20.1.13:9866
2025-03-26 02:24:18,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742006_1182 src: /172.20.1.13:57058 dest: /172.20.1.11:9866
2025-03-26 02:24:18,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57058, dest: /172.20.1.11:9866, bytes: 3297, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742006_1182, duration(ns): 1262596
2025-03-26 02:24:18,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742006_1182, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44236, dest: /172.20.1.12:9866, bytes: 3297, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742006_1182, duration(ns): 1927459
2025-03-26 02:24:18,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55146, dest: /172.20.1.13:9866, bytes: 3297, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742006_1182, duration(ns): 1562738
2025-03-26 02:24:18,646 INFO terminating
2025-03-26 02:24:18,646 INFO terminating
2025-03-26 02:24:18,647 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/sql_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,652 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1183, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/python/streaming/hdfs_wordcount.py._COPYING_
2025-03-26 02:24:18,653 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742007_1183 src: /172.20.1.10:51022 dest: /172.20.1.13:9866
2025-03-26 02:24:18,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742007_1183 src: /172.20.1.13:38132 dest: /172.20.1.12:9866
2025-03-26 02:24:18,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742007_1183 src: /172.20.1.12:54566 dest: /172.20.1.11:9866
2025-03-26 02:24:18,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54566, dest: /172.20.1.11:9866, bytes: 1832, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742007_1183, duration(ns): 904328
2025-03-26 02:24:18,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51022, dest: /172.20.1.13:9866, bytes: 1832, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742007_1183, duration(ns): 1440625
2025-03-26 02:24:18,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38132, dest: /172.20.1.12:9866, bytes: 1832, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742007_1183, duration(ns): 1077716
2025-03-26 02:24:18,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742007_1183, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,658 INFO terminating
2025-03-26 02:24:18,659 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/hdfs_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,659 INFO terminating
2025-03-26 02:24:18,663 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1184, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/streaming/network_wordjoinsentiments.py._COPYING_
2025-03-26 02:24:18,663 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,663 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742008_1184 src: /172.20.1.10:51026 dest: /172.20.1.13:9866
2025-03-26 02:24:18,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742008_1184 src: /172.20.1.13:57060 dest: /172.20.1.11:9866
2025-03-26 02:24:18,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742008_1184 src: /172.20.1.11:48170 dest: /172.20.1.12:9866
2025-03-26 02:24:18,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48170, dest: /172.20.1.12:9866, bytes: 3393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742008_1184, duration(ns): 1261345
2025-03-26 02:24:18,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57060, dest: /172.20.1.11:9866, bytes: 3393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742008_1184, duration(ns): 1477920
2025-03-26 02:24:18,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742008_1184, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,669 INFO terminating
2025-03-26 02:24:18,670 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/network_wordjoinsentiments.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51026, dest: /172.20.1.13:9866, bytes: 3393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742008_1184, duration(ns): 1818141
2025-03-26 02:24:18,670 INFO terminating
2025-03-26 02:24:18,677 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1185, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_
2025-03-26 02:24:18,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742009_1185 src: /172.20.1.10:51030 dest: /172.20.1.13:9866
2025-03-26 02:24:18,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742009_1185 src: /172.20.1.13:57062 dest: /172.20.1.11:9866
2025-03-26 02:24:18,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742009_1185 src: /172.20.1.11:48172 dest: /172.20.1.12:9866
2025-03-26 02:24:18,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48172, dest: /172.20.1.12:9866, bytes: 2310, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742009_1185, duration(ns): 1582202
2025-03-26 02:24:18,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57062, dest: /172.20.1.11:9866, bytes: 2310, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742009_1185, duration(ns): 2500199
2025-03-26 02:24:18,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742009_1185, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51030, dest: /172.20.1.13:9866, bytes: 2310, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742009_1185, duration(ns): 2985841
2025-03-26 02:24:18,685 INFO terminating
2025-03-26 02:24:18,685 INFO terminating
2025-03-26 02:24:18,686 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/stateful_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,691 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1186, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/python/streaming/recoverable_network_wordcount.py._COPYING_
2025-03-26 02:24:18,691 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,691 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742010_1186 src: /172.20.1.10:51036 dest: /172.20.1.13:9866
2025-03-26 02:24:18,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742010_1186 src: /172.20.1.13:57078 dest: /172.20.1.11:9866
2025-03-26 02:24:18,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742010_1186 src: /172.20.1.11:48176 dest: /172.20.1.12:9866
2025-03-26 02:24:18,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48176, dest: /172.20.1.12:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742010_1186, duration(ns): 1408870
2025-03-26 02:24:18,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742010_1186, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51036, dest: /172.20.1.13:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742010_1186, duration(ns): 2489463
2025-03-26 02:24:18,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57078, dest: /172.20.1.11:9866, bytes: 4763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742010_1186, duration(ns): 2121280
2025-03-26 02:24:18,698 INFO terminating
2025-03-26 02:24:18,699 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/python/streaming/recoverable_network_wordcount.py._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,699 INFO terminating
2025-03-26 02:24:18,710 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1187, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/data-manipulation.R._COPYING_
2025-03-26 02:24:18,710 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,710 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742011_1187 src: /172.20.1.10:44240 dest: /172.20.1.12:9866
2025-03-26 02:24:18,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742011_1187 src: /172.20.1.12:55162 dest: /172.20.1.13:9866
2025-03-26 02:24:18,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742011_1187 src: /172.20.1.13:57090 dest: /172.20.1.11:9866
2025-03-26 02:24:18,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55162, dest: /172.20.1.13:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742011_1187, duration(ns): 1767192
2025-03-26 02:24:18,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57090, dest: /172.20.1.11:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742011_1187, duration(ns): 1381018
2025-03-26 02:24:18,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742011_1187, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,717 INFO terminating
2025-03-26 02:24:18,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44240, dest: /172.20.1.12:9866, bytes: 3369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742011_1187, duration(ns): 2170907
2025-03-26 02:24:18,718 INFO terminating
2025-03-26 02:24:18,719 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/data-manipulation.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1188, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/RSparkSQLExample.R._COPYING_
2025-03-26 02:24:18,724 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,724 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742012_1188 src: /172.20.1.10:57476 dest: /172.20.1.11:9866
2025-03-26 02:24:18,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742012_1188 src: /172.20.1.11:34604 dest: /172.20.1.13:9866
2025-03-26 02:24:18,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742012_1188 src: /172.20.1.13:38138 dest: /172.20.1.12:9866
2025-03-26 02:24:18,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34604, dest: /172.20.1.13:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742012_1188, duration(ns): 1518859
2025-03-26 02:24:18,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38138, dest: /172.20.1.12:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742012_1188, duration(ns): 1209963
2025-03-26 02:24:18,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742012_1188, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,730 INFO terminating
2025-03-26 02:24:18,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57476, dest: /172.20.1.11:9866, bytes: 8917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742012_1188, duration(ns): 2043115
2025-03-26 02:24:18,731 INFO terminating
2025-03-26 02:24:18,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/RSparkSQLExample.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,741 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1189, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/als.R._COPYING_
2025-03-26 02:24:18,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742013_1189 src: /172.20.1.10:44254 dest: /172.20.1.12:9866
2025-03-26 02:24:18,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742013_1189 src: /172.20.1.12:55174 dest: /172.20.1.13:9866
2025-03-26 02:24:18,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742013_1189 src: /172.20.1.13:57100 dest: /172.20.1.11:9866
2025-03-26 02:24:18,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57100, dest: /172.20.1.11:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742013_1189, duration(ns): 1045279
2025-03-26 02:24:18,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742013_1189, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44254, dest: /172.20.1.12:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742013_1189, duration(ns): 2478749
2025-03-26 02:24:18,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55174, dest: /172.20.1.13:9866, bytes: 1585, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742013_1189, duration(ns): 1738117
2025-03-26 02:24:18,748 INFO terminating
2025-03-26 02:24:18,749 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/als.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,749 INFO terminating
2025-03-26 02:24:18,754 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1190, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/ml.R._COPYING_
2025-03-26 02:24:18,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742014_1190 src: /172.20.1.10:51038 dest: /172.20.1.13:9866
2025-03-26 02:24:18,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742014_1190 src: /172.20.1.13:38154 dest: /172.20.1.12:9866
2025-03-26 02:24:18,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742014_1190 src: /172.20.1.12:54582 dest: /172.20.1.11:9866
2025-03-26 02:24:18,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54582, dest: /172.20.1.11:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742014_1190, duration(ns): 4021478
2025-03-26 02:24:18,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742014_1190, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51038, dest: /172.20.1.13:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742014_1190, duration(ns): 5142689
2025-03-26 02:24:18,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38154, dest: /172.20.1.12:9866, bytes: 2345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742014_1190, duration(ns): 4436629
2025-03-26 02:24:18,764 INFO terminating
2025-03-26 02:24:18,765 INFO terminating
2025-03-26 02:24:18,770 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/ml.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1191, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/prefixSpan.R._COPYING_
2025-03-26 02:24:18,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742015_1191 src: /172.20.1.10:51054 dest: /172.20.1.13:9866
2025-03-26 02:24:18,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742015_1191 src: /172.20.1.13:38168 dest: /172.20.1.12:9866
2025-03-26 02:24:18,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742015_1191 src: /172.20.1.12:54594 dest: /172.20.1.11:9866
2025-03-26 02:24:18,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54594, dest: /172.20.1.11:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742015_1191, duration(ns): 1832688
2025-03-26 02:24:18,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742015_1191, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51054, dest: /172.20.1.13:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742015_1191, duration(ns): 2699927
2025-03-26 02:24:18,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38168, dest: /172.20.1.12:9866, bytes: 1623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742015_1191, duration(ns): 2221630
2025-03-26 02:24:18,786 INFO terminating
2025-03-26 02:24:18,787 INFO terminating
2025-03-26 02:24:18,788 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/prefixSpan.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,795 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1192, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_
2025-03-26 02:24:18,795 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,795 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742016_1192 src: /172.20.1.10:51060 dest: /172.20.1.13:9866
2025-03-26 02:24:18,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742016_1192 src: /172.20.1.13:38180 dest: /172.20.1.12:9866
2025-03-26 02:24:18,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742016_1192 src: /172.20.1.12:54608 dest: /172.20.1.11:9866
2025-03-26 02:24:18,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54608, dest: /172.20.1.11:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742016_1192, duration(ns): 1389703
2025-03-26 02:24:18,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742016_1192, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38180, dest: /172.20.1.12:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742016_1192, duration(ns): 1871943
2025-03-26 02:24:18,807 INFO terminating
2025-03-26 02:24:18,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51060, dest: /172.20.1.13:9866, bytes: 1523, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742016_1192, duration(ns): 2736350
2025-03-26 02:24:18,808 INFO terminating
2025-03-26 02:24:18,809 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/powerIterationClustering.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,817 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1193, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/lm_with_elastic_net.R._COPYING_
2025-03-26 02:24:18,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742017_1193 src: /172.20.1.10:44258 dest: /172.20.1.12:9866
2025-03-26 02:24:18,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742017_1193 src: /172.20.1.12:54614 dest: /172.20.1.11:9866
2025-03-26 02:24:18,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742017_1193 src: /172.20.1.11:34616 dest: /172.20.1.13:9866
2025-03-26 02:24:18,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34616, dest: /172.20.1.13:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742017_1193, duration(ns): 1380868
2025-03-26 02:24:18,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742017_1193, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54614, dest: /172.20.1.11:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742017_1193, duration(ns): 1606453
2025-03-26 02:24:18,824 INFO terminating
2025-03-26 02:24:18,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44258, dest: /172.20.1.12:9866, bytes: 1410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742017_1193, duration(ns): 2530199
2025-03-26 02:24:18,825 INFO terminating
2025-03-26 02:24:18,831 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/lm_with_elastic_net.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,836 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1194, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/naiveBayes.R._COPYING_
2025-03-26 02:24:18,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742018_1194 src: /172.20.1.10:51064 dest: /172.20.1.13:9866
2025-03-26 02:24:18,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742018_1194 src: /172.20.1.13:38190 dest: /172.20.1.12:9866
2025-03-26 02:24:18,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742018_1194 src: /172.20.1.12:54622 dest: /172.20.1.11:9866
2025-03-26 02:24:18,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54622, dest: /172.20.1.11:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742018_1194, duration(ns): 1218768
2025-03-26 02:24:18,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742018_1194, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51064, dest: /172.20.1.13:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742018_1194, duration(ns): 1807313
2025-03-26 02:24:18,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38190, dest: /172.20.1.12:9866, bytes: 1434, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742018_1194, duration(ns): 1445238
2025-03-26 02:24:18,842 INFO terminating
2025-03-26 02:24:18,842 INFO terminating
2025-03-26 02:24:18,843 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/naiveBayes.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,848 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1195, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/decisionTree.R._COPYING_
2025-03-26 02:24:18,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742019_1195 src: /172.20.1.10:51066 dest: /172.20.1.13:9866
2025-03-26 02:24:18,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742019_1195 src: /172.20.1.11:48190 dest: /172.20.1.12:9866
2025-03-26 02:24:18,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742019_1195 src: /172.20.1.13:57104 dest: /172.20.1.11:9866
2025-03-26 02:24:18,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48190, dest: /172.20.1.12:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742019_1195, duration(ns): 1062885
2025-03-26 02:24:18,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57104, dest: /172.20.1.11:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742019_1195, duration(ns): 1267944
2025-03-26 02:24:18,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742019_1195, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51066, dest: /172.20.1.13:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742019_1195, duration(ns): 1717091
2025-03-26 02:24:18,854 INFO terminating
2025-03-26 02:24:18,854 INFO terminating
2025-03-26 02:24:18,855 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/decisionTree.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,862 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1196, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/lda.R._COPYING_
2025-03-26 02:24:18,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742020_1196 src: /172.20.1.10:57484 dest: /172.20.1.11:9866
2025-03-26 02:24:18,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742020_1196 src: /172.20.1.11:34626 dest: /172.20.1.13:9866
2025-03-26 02:24:18,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742020_1196 src: /172.20.1.13:38200 dest: /172.20.1.12:9866
2025-03-26 02:24:18,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34626, dest: /172.20.1.13:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742020_1196, duration(ns): 1852505
2025-03-26 02:24:18,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38200, dest: /172.20.1.12:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742020_1196, duration(ns): 1530708
2025-03-26 02:24:18,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742020_1196, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,871 INFO terminating
2025-03-26 02:24:18,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57484, dest: /172.20.1.11:9866, bytes: 1555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742020_1196, duration(ns): 2271057
2025-03-26 02:24:18,872 INFO terminating
2025-03-26 02:24:18,874 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/lda.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,884 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1197, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/survreg.R._COPYING_
2025-03-26 02:24:18,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,884 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742021_1197 src: /172.20.1.10:44274 dest: /172.20.1.12:9866
2025-03-26 02:24:18,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742021_1197 src: /172.20.1.12:54636 dest: /172.20.1.11:9866
2025-03-26 02:24:18,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742021_1197 src: /172.20.1.11:34640 dest: /172.20.1.13:9866
2025-03-26 02:24:18,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34640, dest: /172.20.1.13:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742021_1197, duration(ns): 1404008
2025-03-26 02:24:18,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54636, dest: /172.20.1.11:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742021_1197, duration(ns): 1597902
2025-03-26 02:24:18,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742021_1197, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44274, dest: /172.20.1.12:9866, bytes: 1508, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742021_1197, duration(ns): 2266822
2025-03-26 02:24:18,891 INFO terminating
2025-03-26 02:24:18,891 INFO terminating
2025-03-26 02:24:18,892 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/survreg.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1198, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/svmLinear.R._COPYING_
2025-03-26 02:24:18,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742022_1198 src: /172.20.1.10:44276 dest: /172.20.1.12:9866
2025-03-26 02:24:18,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742022_1198 src: /172.20.1.12:55184 dest: /172.20.1.13:9866
2025-03-26 02:24:18,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742022_1198 src: /172.20.1.13:57116 dest: /172.20.1.11:9866
2025-03-26 02:24:18,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55184, dest: /172.20.1.13:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742022_1198, duration(ns): 3416814
2025-03-26 02:24:18,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57116, dest: /172.20.1.11:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742022_1198, duration(ns): 3079093
2025-03-26 02:24:18,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742022_1198, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,906 INFO terminating
2025-03-26 02:24:18,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/svmLinear.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44276, dest: /172.20.1.12:9866, bytes: 1352, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742022_1198, duration(ns): 4432774
2025-03-26 02:24:18,907 INFO terminating
2025-03-26 02:24:18,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1199, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/isoreg.R._COPYING_
2025-03-26 02:24:18,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742023_1199 src: /172.20.1.10:57496 dest: /172.20.1.11:9866
2025-03-26 02:24:18,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742023_1199 src: /172.20.1.11:34650 dest: /172.20.1.13:9866
2025-03-26 02:24:18,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742023_1199 src: /172.20.1.13:38208 dest: /172.20.1.12:9866
2025-03-26 02:24:18,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38208, dest: /172.20.1.12:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742023_1199, duration(ns): 1387541
2025-03-26 02:24:18,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742023_1199, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57496, dest: /172.20.1.11:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742023_1199, duration(ns): 2247424
2025-03-26 02:24:18,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34650, dest: /172.20.1.13:9866, bytes: 1417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742023_1199, duration(ns): 1775941
2025-03-26 02:24:18,920 INFO terminating
2025-03-26 02:24:18,920 INFO terminating
2025-03-26 02:24:18,921 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/isoreg.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,926 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742024_1200, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/bisectingKmeans.R._COPYING_
2025-03-26 02:24:18,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742024_1200 src: /172.20.1.10:57512 dest: /172.20.1.11:9866
2025-03-26 02:24:18,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742024_1200 src: /172.20.1.11:34654 dest: /172.20.1.13:9866
2025-03-26 02:24:18,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742024_1200 src: /172.20.1.13:38212 dest: /172.20.1.12:9866
2025-03-26 02:24:18,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34654, dest: /172.20.1.13:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742024_1200, duration(ns): 1771102
2025-03-26 02:24:18,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38212, dest: /172.20.1.12:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742024_1200, duration(ns): 1417593
2025-03-26 02:24:18,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742024_1200, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57512, dest: /172.20.1.11:9866, bytes: 1501, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742024_1200, duration(ns): 2152297
2025-03-26 02:24:18,933 INFO terminating
2025-03-26 02:24:18,933 INFO terminating
2025-03-26 02:24:18,934 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/bisectingKmeans.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,938 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742025_1201, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/mlp.R._COPYING_
2025-03-26 02:24:18,938 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,938 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742025_1201 src: /172.20.1.10:57518 dest: /172.20.1.11:9866
2025-03-26 02:24:18,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742025_1201 src: /172.20.1.11:34660 dest: /172.20.1.13:9866
2025-03-26 02:24:18,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742025_1201 src: /172.20.1.13:38218 dest: /172.20.1.12:9866
2025-03-26 02:24:18,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34660, dest: /172.20.1.13:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742025_1201, duration(ns): 1718483
2025-03-26 02:24:18,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38218, dest: /172.20.1.12:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742025_1201, duration(ns): 1411680
2025-03-26 02:24:18,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742025_1201, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57518, dest: /172.20.1.11:9866, bytes: 1651, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742025_1201, duration(ns): 2234930
2025-03-26 02:24:18,945 INFO terminating
2025-03-26 02:24:18,945 INFO terminating
2025-03-26 02:24:18,946 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/mlp.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,953 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742026_1202, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/fpm.R._COPYING_
2025-03-26 02:24:18,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742026_1202 src: /172.20.1.10:57528 dest: /172.20.1.11:9866
2025-03-26 02:24:18,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742026_1202 src: /172.20.1.11:48204 dest: /172.20.1.12:9866
2025-03-26 02:24:18,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742026_1202 src: /172.20.1.12:55198 dest: /172.20.1.13:9866
2025-03-26 02:24:18,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55198, dest: /172.20.1.13:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742026_1202, duration(ns): 1087068
2025-03-26 02:24:18,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742026_1202, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57528, dest: /172.20.1.11:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742026_1202, duration(ns): 2058670
2025-03-26 02:24:18,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48204, dest: /172.20.1.12:9866, bytes: 1486, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742026_1202, duration(ns): 1469417
2025-03-26 02:24:18,959 INFO terminating
2025-03-26 02:24:18,960 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fpm.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,960 INFO terminating
2025-03-26 02:24:18,964 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,964 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742027_1203, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/r/ml/glm.R._COPYING_
2025-03-26 02:24:18,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742027_1203 src: /172.20.1.10:44286 dest: /172.20.1.12:9866
2025-03-26 02:24:18,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742027_1203 src: /172.20.1.12:54644 dest: /172.20.1.11:9866
2025-03-26 02:24:18,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742027_1203 src: /172.20.1.11:34662 dest: /172.20.1.13:9866
2025-03-26 02:24:18,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34662, dest: /172.20.1.13:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742027_1203, duration(ns): 1250977
2025-03-26 02:24:18,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54644, dest: /172.20.1.11:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742027_1203, duration(ns): 1610366
2025-03-26 02:24:18,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742027_1203, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44286, dest: /172.20.1.12:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742027_1203, duration(ns): 2073453
2025-03-26 02:24:18,971 INFO terminating
2025-03-26 02:24:18,971 INFO terminating
2025-03-26 02:24:18,972 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/glm.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,976 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742028_1204, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/randomForest.R._COPYING_
2025-03-26 02:24:18,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742028_1204 src: /172.20.1.10:51082 dest: /172.20.1.13:9866
2025-03-26 02:24:18,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742028_1204 src: /172.20.1.13:38234 dest: /172.20.1.12:9866
2025-03-26 02:24:18,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742028_1204 src: /172.20.1.12:54656 dest: /172.20.1.11:9866
2025-03-26 02:24:18,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54656, dest: /172.20.1.11:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742028_1204, duration(ns): 1234168
2025-03-26 02:24:18,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38234, dest: /172.20.1.12:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742028_1204, duration(ns): 1476505
2025-03-26 02:24:18,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742028_1204, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,982 INFO terminating
2025-03-26 02:24:18,983 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/randomForest.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:18,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51082, dest: /172.20.1.13:9866, bytes: 1977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742028_1204, duration(ns): 1915040
2025-03-26 02:24:18,983 INFO terminating
2025-03-26 02:24:18,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742029_1205, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/gaussianMixture.R._COPYING_
2025-03-26 02:24:18,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:18,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742029_1205 src: /172.20.1.10:51098 dest: /172.20.1.13:9866
2025-03-26 02:24:18,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742029_1205 src: /172.20.1.13:57124 dest: /172.20.1.11:9866
2025-03-26 02:24:18,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742029_1205 src: /172.20.1.11:48218 dest: /172.20.1.12:9866
2025-03-26 02:24:18,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48218, dest: /172.20.1.12:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742029_1205, duration(ns): 1493208
2025-03-26 02:24:18,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742029_1205, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:18,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51098, dest: /172.20.1.13:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742029_1205, duration(ns): 2172022
2025-03-26 02:24:18,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57124, dest: /172.20.1.11:9866, bytes: 1423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742029_1205, duration(ns): 1817511
2025-03-26 02:24:18,996 INFO terminating
2025-03-26 02:24:18,996 INFO terminating
2025-03-26 02:24:18,997 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/gaussianMixture.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,002 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742030_1206, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/fmClassifier.R._COPYING_
2025-03-26 02:24:19,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742030_1206 src: /172.20.1.10:44288 dest: /172.20.1.12:9866
2025-03-26 02:24:19,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742030_1206 src: /172.20.1.12:55208 dest: /172.20.1.13:9866
2025-03-26 02:24:19,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742030_1206 src: /172.20.1.13:57130 dest: /172.20.1.11:9866
2025-03-26 02:24:19,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57130, dest: /172.20.1.11:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742030_1206, duration(ns): 1321352
2025-03-26 02:24:19,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742030_1206, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44288, dest: /172.20.1.12:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742030_1206, duration(ns): 2074565
2025-03-26 02:24:19,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55208, dest: /172.20.1.13:9866, bytes: 1375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742030_1206, duration(ns): 1693035
2025-03-26 02:24:19,008 INFO terminating
2025-03-26 02:24:19,009 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fmClassifier.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,009 INFO terminating
2025-03-26 02:24:19,015 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742031_1207, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/gbt.R._COPYING_
2025-03-26 02:24:19,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742031_1207 src: /172.20.1.10:51102 dest: /172.20.1.13:9866
2025-03-26 02:24:19,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742031_1207 src: /172.20.1.13:38238 dest: /172.20.1.12:9866
2025-03-26 02:24:19,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742031_1207 src: /172.20.1.12:54670 dest: /172.20.1.11:9866
2025-03-26 02:24:19,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54670, dest: /172.20.1.11:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742031_1207, duration(ns): 1978739
2025-03-26 02:24:19,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742031_1207, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51102, dest: /172.20.1.13:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742031_1207, duration(ns): 2594608
2025-03-26 02:24:19,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38238, dest: /172.20.1.12:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742031_1207, duration(ns): 2222783
2025-03-26 02:24:19,022 INFO terminating
2025-03-26 02:24:19,023 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/gbt.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,023 INFO terminating
2025-03-26 02:24:19,028 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742032_1208, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/fmRegressor.R._COPYING_
2025-03-26 02:24:19,028 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,028 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,028 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,028 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:19,028 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:19,028 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:19,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742032_1208 src: /172.20.1.10:57544 dest: /172.20.1.11:9866
2025-03-26 02:24:19,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742032_1208 src: /172.20.1.11:48220 dest: /172.20.1.12:9866
2025-03-26 02:24:19,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48220, dest: /172.20.1.12:9866, bytes: 1458, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742032_1208, duration(ns): 1000361
2025-03-26 02:24:19,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57544, dest: /172.20.1.11:9866, bytes: 1458, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742032_1208, duration(ns): 1202875
2025-03-26 02:24:19,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742032_1208, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,033 INFO terminating
2025-03-26 02:24:19,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/fmRegressor.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742033_1209, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/ml/kmeans.R._COPYING_
2025-03-26 02:24:19,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,038 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:19,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:19,038 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:19,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742033_1209 src: /172.20.1.10:44296 dest: /172.20.1.12:9866
2025-03-26 02:24:19,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742033_1209 src: /172.20.1.12:54674 dest: /172.20.1.11:9866
2025-03-26 02:24:19,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44296, dest: /172.20.1.12:9866, bytes: 1558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742033_1209, duration(ns): 896346
2025-03-26 02:24:19,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54674, dest: /172.20.1.11:9866, bytes: 1558, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742033_1209, duration(ns): 524890
2025-03-26 02:24:19,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742033_1209, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,043 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/kmeans.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,043 INFO terminating
2025-03-26 02:24:19,048 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742034_1210, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/kstest.R._COPYING_
2025-03-26 02:24:19,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,048 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:19,048 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:19,048 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:19,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742034_1210 src: /172.20.1.10:57552 dest: /172.20.1.11:9866
2025-03-26 02:24:19,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742034_1210 src: /172.20.1.11:48224 dest: /172.20.1.12:9866
2025-03-26 02:24:19,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48224, dest: /172.20.1.12:9866, bytes: 1345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742034_1210, duration(ns): 941446
2025-03-26 02:24:19,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742034_1210, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57552, dest: /172.20.1.11:9866, bytes: 1345, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742034_1210, duration(ns): 1142294
2025-03-26 02:24:19,053 INFO terminating
2025-03-26 02:24:19,054 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/kstest.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742035_1211, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/ml/logit.R._COPYING_
2025-03-26 02:24:19,058 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:19,058 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:19,058 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:19,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742035_1211 src: /172.20.1.10:57558 dest: /172.20.1.11:9866
2025-03-26 02:24:19,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742035_1211 src: /172.20.1.11:48230 dest: /172.20.1.12:9866
2025-03-26 02:24:19,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48230, dest: /172.20.1.12:9866, bytes: 1980, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742035_1211, duration(ns): 596028
2025-03-26 02:24:19,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57558, dest: /172.20.1.11:9866, bytes: 1980, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742035_1211, duration(ns): 1221501
2025-03-26 02:24:19,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742035_1211, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,062 INFO terminating
2025-03-26 02:24:19,063 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/ml/logit.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742036_1212, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/r/dataframe.R._COPYING_
2025-03-26 02:24:19,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,069 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:19,069 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:19,069 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:19,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742036_1212 src: /172.20.1.10:57560 dest: /172.20.1.11:9866
2025-03-26 02:24:19,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742036_1212 src: /172.20.1.11:48240 dest: /172.20.1.12:9866
2025-03-26 02:24:19,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48240, dest: /172.20.1.12:9866, bytes: 1930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742036_1212, duration(ns): 529695
2025-03-26 02:24:19,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742036_1212, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,074 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/dataframe.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57560, dest: /172.20.1.11:9866, bytes: 1930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742036_1212, duration(ns): 740450
2025-03-26 02:24:19,074 INFO terminating
2025-03-26 02:24:19,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742037_1213, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/r/streaming/structured_network_wordcount.R._COPYING_
2025-03-26 02:24:19,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,080 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:19,080 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:19,080 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:19,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742037_1213 src: /172.20.1.10:44302 dest: /172.20.1.12:9866
2025-03-26 02:24:19,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742037_1213 src: /172.20.1.12:54680 dest: /172.20.1.11:9866
2025-03-26 02:24:19,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44302, dest: /172.20.1.12:9866, bytes: 2084, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742037_1213, duration(ns): 969819
2025-03-26 02:24:19,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54680, dest: /172.20.1.11:9866, bytes: 2084, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742037_1213, duration(ns): 785788
2025-03-26 02:24:19,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742037_1213, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,084 INFO terminating
2025-03-26 02:24:19,085 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/r/streaming/structured_network_wordcount.R._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742038_1214, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/resources/kv1.txt._COPYING_
2025-03-26 02:24:19,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742038_1214 src: /172.20.1.10:57562 dest: /172.20.1.11:9866
2025-03-26 02:24:19,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742038_1214 src: /172.20.1.11:48248 dest: /172.20.1.12:9866
2025-03-26 02:24:19,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742038_1214 src: /172.20.1.12:55212 dest: /172.20.1.13:9866
2025-03-26 02:24:19,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48248, dest: /172.20.1.12:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742038_1214, duration(ns): 1271444
2025-03-26 02:24:19,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55212, dest: /172.20.1.13:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742038_1214, duration(ns): 999748
2025-03-26 02:24:19,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742038_1214, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57562, dest: /172.20.1.11:9866, bytes: 5812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742038_1214, duration(ns): 1631248
2025-03-26 02:24:19,097 INFO terminating
2025-03-26 02:24:19,098 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/kv1.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,098 INFO terminating
2025-03-26 02:24:19,104 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,104 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742039_1215, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/resources/dir1/file1.parquet._COPYING_
2025-03-26 02:24:19,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742039_1215 src: /172.20.1.10:44308 dest: /172.20.1.12:9866
2025-03-26 02:24:19,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742039_1215 src: /172.20.1.12:55228 dest: /172.20.1.13:9866
2025-03-26 02:24:19,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742039_1215 src: /172.20.1.13:57136 dest: /172.20.1.11:9866
2025-03-26 02:24:19,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55228, dest: /172.20.1.13:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742039_1215, duration(ns): 1370010
2025-03-26 02:24:19,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57136, dest: /172.20.1.11:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742039_1215, duration(ns): 1181709
2025-03-26 02:24:19,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742039_1215, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,110 INFO terminating
2025-03-26 02:24:19,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44308, dest: /172.20.1.12:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742039_1215, duration(ns): 1803574
2025-03-26 02:24:19,111 INFO terminating
2025-03-26 02:24:19,118 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/file1.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742040_1216, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/resources/dir1/file3.json._COPYING_
2025-03-26 02:24:19,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742040_1216 src: /172.20.1.10:44314 dest: /172.20.1.12:9866
2025-03-26 02:24:19,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742040_1216 src: /172.20.1.12:55242 dest: /172.20.1.13:9866
2025-03-26 02:24:19,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742040_1216 src: /172.20.1.13:57140 dest: /172.20.1.11:9866
2025-03-26 02:24:19,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57140, dest: /172.20.1.11:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742040_1216, duration(ns): 1437639
2025-03-26 02:24:19,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742040_1216, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44314, dest: /172.20.1.12:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742040_1216, duration(ns): 2054760
2025-03-26 02:24:19,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55242, dest: /172.20.1.13:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742040_1216, duration(ns): 1733971
2025-03-26 02:24:19,130 INFO terminating
2025-03-26 02:24:19,130 INFO terminating
2025-03-26 02:24:19,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/file3.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742041_1217, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/resources/dir1/dir2/file2.parquet._COPYING_
2025-03-26 02:24:19,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742041_1217 src: /172.20.1.10:57574 dest: /172.20.1.11:9866
2025-03-26 02:24:19,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742041_1217 src: /172.20.1.11:48254 dest: /172.20.1.12:9866
2025-03-26 02:24:19,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742041_1217 src: /172.20.1.12:55258 dest: /172.20.1.13:9866
2025-03-26 02:24:19,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48254, dest: /172.20.1.12:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742041_1217, duration(ns): 3558254
2025-03-26 02:24:19,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55258, dest: /172.20.1.13:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742041_1217, duration(ns): 3132317
2025-03-26 02:24:19,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742041_1217, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,147 INFO terminating
2025-03-26 02:24:19,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57574, dest: /172.20.1.11:9866, bytes: 520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742041_1217, duration(ns): 4089936
2025-03-26 02:24:19,148 INFO terminating
2025-03-26 02:24:19,149 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/dir1/dir2/file2.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742042_1218, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/resources/user.avsc._COPYING_
2025-03-26 02:24:19,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742042_1218 src: /172.20.1.10:51106 dest: /172.20.1.13:9866
2025-03-26 02:24:19,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742042_1218 src: /172.20.1.13:57146 dest: /172.20.1.11:9866
2025-03-26 02:24:19,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742042_1218 src: /172.20.1.11:48268 dest: /172.20.1.12:9866
2025-03-26 02:24:19,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48268, dest: /172.20.1.12:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742042_1218, duration(ns): 1133953
2025-03-26 02:24:19,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742042_1218, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57146, dest: /172.20.1.11:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742042_1218, duration(ns): 1412297
2025-03-26 02:24:19,159 INFO terminating
2025-03-26 02:24:19,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51106, dest: /172.20.1.13:9866, bytes: 185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742042_1218, duration(ns): 1913867
2025-03-26 02:24:19,160 INFO terminating
2025-03-26 02:24:19,170 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/user.avsc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742043_1219, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/resources/people.csv._COPYING_
2025-03-26 02:24:19,176 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,176 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742043_1219 src: /172.20.1.10:44326 dest: /172.20.1.12:9866
2025-03-26 02:24:19,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742043_1219 src: /172.20.1.12:54694 dest: /172.20.1.11:9866
2025-03-26 02:24:19,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742043_1219 src: /172.20.1.11:34668 dest: /172.20.1.13:9866
2025-03-26 02:24:19,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34668, dest: /172.20.1.13:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742043_1219, duration(ns): 1671343
2025-03-26 02:24:19,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54694, dest: /172.20.1.11:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742043_1219, duration(ns): 1974666
2025-03-26 02:24:19,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742043_1219, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,183 INFO terminating
2025-03-26 02:24:19,184 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44326, dest: /172.20.1.12:9866, bytes: 49, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742043_1219, duration(ns): 2528423
2025-03-26 02:24:19,184 INFO terminating
2025-03-26 02:24:19,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,190 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742044_1220, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/resources/full_user.avsc._COPYING_
2025-03-26 02:24:19,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742044_1220 src: /172.20.1.10:44332 dest: /172.20.1.12:9866
2025-03-26 02:24:19,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742044_1220 src: /172.20.1.12:55264 dest: /172.20.1.13:9866
2025-03-26 02:24:19,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742044_1220 src: /172.20.1.13:57156 dest: /172.20.1.11:9866
2025-03-26 02:24:19,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55264, dest: /172.20.1.13:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742044_1220, duration(ns): 1882089
2025-03-26 02:24:19,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57156, dest: /172.20.1.11:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742044_1220, duration(ns): 1637220
2025-03-26 02:24:19,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742044_1220, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,198 INFO terminating
2025-03-26 02:24:19,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44332, dest: /172.20.1.12:9866, bytes: 240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742044_1220, duration(ns): 2289167
2025-03-26 02:24:19,199 INFO terminating
2025-03-26 02:24:19,200 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/full_user.avsc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,205 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742045_1221, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/resources/users.avro._COPYING_
2025-03-26 02:24:19,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742045_1221 src: /172.20.1.10:51108 dest: /172.20.1.13:9866
2025-03-26 02:24:19,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742045_1221 src: /172.20.1.13:57166 dest: /172.20.1.11:9866
2025-03-26 02:24:19,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742045_1221 src: /172.20.1.11:48284 dest: /172.20.1.12:9866
2025-03-26 02:24:19,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48284, dest: /172.20.1.12:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742045_1221, duration(ns): 1009828
2025-03-26 02:24:19,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57166, dest: /172.20.1.11:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742045_1221, duration(ns): 1649993
2025-03-26 02:24:19,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742045_1221, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,211 INFO terminating
2025-03-26 02:24:19,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51108, dest: /172.20.1.13:9866, bytes: 334, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742045_1221, duration(ns): 2335963
2025-03-26 02:24:19,212 INFO terminating
2025-03-26 02:24:19,213 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.avro._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742046_1222, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider._COPYING_
2025-03-26 02:24:19,220 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,220 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742046_1222 src: /172.20.1.10:57590 dest: /172.20.1.11:9866
2025-03-26 02:24:19,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742046_1222 src: /172.20.1.11:48290 dest: /172.20.1.12:9866
2025-03-26 02:24:19,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742046_1222 src: /172.20.1.12:55278 dest: /172.20.1.13:9866
2025-03-26 02:24:19,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55278, dest: /172.20.1.13:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742046_1222, duration(ns): 1254302
2025-03-26 02:24:19,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742046_1222, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48290, dest: /172.20.1.12:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742046_1222, duration(ns): 1518783
2025-03-26 02:24:19,226 INFO terminating
2025-03-26 02:24:19,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57590, dest: /172.20.1.11:9866, bytes: 850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742046_1222, duration(ns): 1973350
2025-03-26 02:24:19,227 INFO terminating
2025-03-26 02:24:19,228 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,232 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742047_1223, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider._COPYING_
2025-03-26 02:24:19,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742047_1223 src: /172.20.1.10:57602 dest: /172.20.1.11:9866
2025-03-26 02:24:19,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742047_1223 src: /172.20.1.11:48302 dest: /172.20.1.12:9866
2025-03-26 02:24:19,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742047_1223 src: /172.20.1.12:55286 dest: /172.20.1.13:9866
2025-03-26 02:24:19,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55286, dest: /172.20.1.13:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742047_1223, duration(ns): 1213426
2025-03-26 02:24:19,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742047_1223, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57602, dest: /172.20.1.11:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742047_1223, duration(ns): 1907577
2025-03-26 02:24:19,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48302, dest: /172.20.1.12:9866, bytes: 849, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742047_1223, duration(ns): 1495620
2025-03-26 02:24:19,238 INFO terminating
2025-03-26 02:24:19,239 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,239 INFO terminating
2025-03-26 02:24:19,244 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742048_1224, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/resources/users.parquet._COPYING_
2025-03-26 02:24:19,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742048_1224 src: /172.20.1.10:51118 dest: /172.20.1.13:9866
2025-03-26 02:24:19,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742048_1224 src: /172.20.1.13:57180 dest: /172.20.1.11:9866
2025-03-26 02:24:19,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742048_1224 src: /172.20.1.11:48308 dest: /172.20.1.12:9866
2025-03-26 02:24:19,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48308, dest: /172.20.1.12:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742048_1224, duration(ns): 1223137
2025-03-26 02:24:19,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742048_1224, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51118, dest: /172.20.1.13:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742048_1224, duration(ns): 2670558
2025-03-26 02:24:19,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57180, dest: /172.20.1.11:9866, bytes: 615, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742048_1224, duration(ns): 1906507
2025-03-26 02:24:19,251 INFO terminating
2025-03-26 02:24:19,251 INFO terminating
2025-03-26 02:24:19,252 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.parquet._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742049_1225, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/resources/users.orc._COPYING_
2025-03-26 02:24:19,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,257 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742049_1225 src: /172.20.1.10:44336 dest: /172.20.1.12:9866
2025-03-26 02:24:19,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742049_1225 src: /172.20.1.12:54708 dest: /172.20.1.11:9866
2025-03-26 02:24:19,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742049_1225 src: /172.20.1.11:34680 dest: /172.20.1.13:9866
2025-03-26 02:24:19,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34680, dest: /172.20.1.13:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742049_1225, duration(ns): 1586350
2025-03-26 02:24:19,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742049_1225, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54708, dest: /172.20.1.11:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742049_1225, duration(ns): 1921514
2025-03-26 02:24:19,265 INFO terminating
2025-03-26 02:24:19,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44336, dest: /172.20.1.12:9866, bytes: 547, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742049_1225, duration(ns): 2882258
2025-03-26 02:24:19,266 INFO terminating
2025-03-26 02:24:19,267 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/users.orc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742050_1226, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/resources/people.txt._COPYING_
2025-03-26 02:24:19,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742050_1226 src: /172.20.1.10:51122 dest: /172.20.1.13:9866
2025-03-26 02:24:19,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742050_1226 src: /172.20.1.13:38240 dest: /172.20.1.12:9866
2025-03-26 02:24:19,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742050_1226 src: /172.20.1.12:54716 dest: /172.20.1.11:9866
2025-03-26 02:24:19,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54716, dest: /172.20.1.11:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742050_1226, duration(ns): 1181272
2025-03-26 02:24:19,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38240, dest: /172.20.1.12:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742050_1226, duration(ns): 1396632
2025-03-26 02:24:19,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742050_1226, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,277 INFO terminating
2025-03-26 02:24:19,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51122, dest: /172.20.1.13:9866, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742050_1226, duration(ns): 1635051
2025-03-26 02:24:19,278 INFO terminating
2025-03-26 02:24:19,279 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,284 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742051_1227, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/resources/people.json._COPYING_
2025-03-26 02:24:19,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742051_1227 src: /172.20.1.10:44338 dest: /172.20.1.12:9866
2025-03-26 02:24:19,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742051_1227 src: /172.20.1.11:34692 dest: /172.20.1.13:9866
2025-03-26 02:24:19,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742051_1227 src: /172.20.1.12:54720 dest: /172.20.1.11:9866
2025-03-26 02:24:19,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34692, dest: /172.20.1.13:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742051_1227, duration(ns): 1150070
2025-03-26 02:24:19,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742051_1227, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54720, dest: /172.20.1.11:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742051_1227, duration(ns): 1452917
2025-03-26 02:24:19,290 INFO terminating
2025-03-26 02:24:19,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44338, dest: /172.20.1.12:9866, bytes: 73, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742051_1227, duration(ns): 2435368
2025-03-26 02:24:19,291 INFO terminating
2025-03-26 02:24:19,292 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/people.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742052_1228, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/resources/employees.json._COPYING_
2025-03-26 02:24:19,297 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742052_1228 src: /172.20.1.10:57608 dest: /172.20.1.11:9866
2025-03-26 02:24:19,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742052_1228 src: /172.20.1.11:48324 dest: /172.20.1.12:9866
2025-03-26 02:24:19,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742052_1228 src: /172.20.1.12:55300 dest: /172.20.1.13:9866
2025-03-26 02:24:19,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48324, dest: /172.20.1.12:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742052_1228, duration(ns): 1221841
2025-03-26 02:24:19,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55300, dest: /172.20.1.13:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742052_1228, duration(ns): 939806
2025-03-26 02:24:19,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742052_1228, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,302 INFO terminating
2025-03-26 02:24:19,303 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/resources/employees.json._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57608, dest: /172.20.1.11:9866, bytes: 130, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742052_1228, duration(ns): 1609215
2025-03-26 02:24:19,303 INFO terminating
2025-03-26 02:24:19,319 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742053_1229, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala._COPYING_
2025-03-26 02:24:19,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742053_1229 src: /172.20.1.10:44346 dest: /172.20.1.12:9866
2025-03-26 02:24:19,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742053_1229 src: /172.20.1.12:55316 dest: /172.20.1.13:9866
2025-03-26 02:24:19,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742053_1229 src: /172.20.1.13:57192 dest: /172.20.1.11:9866
2025-03-26 02:24:19,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55316, dest: /172.20.1.13:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742053_1229, duration(ns): 2387003
2025-03-26 02:24:19,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57192, dest: /172.20.1.11:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742053_1229, duration(ns): 1428053
2025-03-26 02:24:19,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742053_1229, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,326 INFO terminating
2025-03-26 02:24:19,327 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44346, dest: /172.20.1.12:9866, bytes: 3427, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742053_1229, duration(ns): 2709587
2025-03-26 02:24:19,327 INFO terminating
2025-03-26 02:24:19,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742054_1230, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala._COPYING_
2025-03-26 02:24:19,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742054_1230 src: /172.20.1.10:57620 dest: /172.20.1.11:9866
2025-03-26 02:24:19,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742054_1230 src: /172.20.1.11:48328 dest: /172.20.1.12:9866
2025-03-26 02:24:19,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742054_1230 src: /172.20.1.12:55324 dest: /172.20.1.13:9866
2025-03-26 02:24:19,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55324, dest: /172.20.1.13:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742054_1230, duration(ns): 1479353
2025-03-26 02:24:19,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742054_1230, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48328, dest: /172.20.1.12:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742054_1230, duration(ns): 2409975
2025-03-26 02:24:19,343 INFO terminating
2025-03-26 02:24:19,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57620, dest: /172.20.1.11:9866, bytes: 2461, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742054_1230, duration(ns): 2845457
2025-03-26 02:24:19,344 INFO terminating
2025-03-26 02:24:19,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,350 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742055_1231, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_
2025-03-26 02:24:19,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742055_1231 src: /172.20.1.10:51130 dest: /172.20.1.13:9866
2025-03-26 02:24:19,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742055_1231 src: /172.20.1.13:57204 dest: /172.20.1.11:9866
2025-03-26 02:24:19,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742055_1231 src: /172.20.1.11:48342 dest: /172.20.1.12:9866
2025-03-26 02:24:19,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48342, dest: /172.20.1.12:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742055_1231, duration(ns): 1608245
2025-03-26 02:24:19,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57204, dest: /172.20.1.11:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742055_1231, duration(ns): 2003997
2025-03-26 02:24:19,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742055_1231, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51130, dest: /172.20.1.13:9866, bytes: 2897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742055_1231, duration(ns): 2599399
2025-03-26 02:24:19,358 INFO terminating
2025-03-26 02:24:19,358 INFO terminating
2025-03-26 02:24:19,359 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742056_1232, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala._COPYING_
2025-03-26 02:24:19,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742056_1232 src: /172.20.1.10:44350 dest: /172.20.1.12:9866
2025-03-26 02:24:19,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742056_1232 src: /172.20.1.12:55326 dest: /172.20.1.13:9866
2025-03-26 02:24:19,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742056_1232 src: /172.20.1.13:57214 dest: /172.20.1.11:9866
2025-03-26 02:24:19,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57214, dest: /172.20.1.11:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742056_1232, duration(ns): 1102031
2025-03-26 02:24:19,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742056_1232, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55326, dest: /172.20.1.13:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742056_1232, duration(ns): 1471449
2025-03-26 02:24:19,371 INFO terminating
2025-03-26 02:24:19,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44350, dest: /172.20.1.12:9866, bytes: 1959, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742056_1232, duration(ns): 2091889
2025-03-26 02:24:19,372 INFO terminating
2025-03-26 02:24:19,373 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,377 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742057_1233, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala._COPYING_
2025-03-26 02:24:19,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742057_1233 src: /172.20.1.10:44358 dest: /172.20.1.12:9866
2025-03-26 02:24:19,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742057_1233 src: /172.20.1.12:55340 dest: /172.20.1.13:9866
2025-03-26 02:24:19,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742057_1233 src: /172.20.1.13:57226 dest: /172.20.1.11:9866
2025-03-26 02:24:19,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57226, dest: /172.20.1.11:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742057_1233, duration(ns): 1459242
2025-03-26 02:24:19,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742057_1233, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44358, dest: /172.20.1.12:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742057_1233, duration(ns): 2478291
2025-03-26 02:24:19,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55340, dest: /172.20.1.13:9866, bytes: 2691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742057_1233, duration(ns): 1838424
2025-03-26 02:24:19,384 INFO terminating
2025-03-26 02:24:19,384 INFO terminating
2025-03-26 02:24:19,385 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742058_1234, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala._COPYING_
2025-03-26 02:24:19,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742058_1234 src: /172.20.1.10:51142 dest: /172.20.1.13:9866
2025-03-26 02:24:19,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742058_1234 src: /172.20.1.13:38250 dest: /172.20.1.12:9866
2025-03-26 02:24:19,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742058_1234 src: /172.20.1.12:54726 dest: /172.20.1.11:9866
2025-03-26 02:24:19,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54726, dest: /172.20.1.11:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742058_1234, duration(ns): 2039268
2025-03-26 02:24:19,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38250, dest: /172.20.1.12:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742058_1234, duration(ns): 2666199
2025-03-26 02:24:19,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742058_1234, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,399 INFO terminating
2025-03-26 02:24:19,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51142, dest: /172.20.1.13:9866, bytes: 5192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742058_1234, duration(ns): 3415895
2025-03-26 02:24:19,402 INFO terminating
2025-03-26 02:24:19,403 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,408 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742059_1235, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala._COPYING_
2025-03-26 02:24:19,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742059_1235 src: /172.20.1.10:44366 dest: /172.20.1.12:9866
2025-03-26 02:24:19,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742059_1235 src: /172.20.1.12:55352 dest: /172.20.1.13:9866
2025-03-26 02:24:19,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742059_1235 src: /172.20.1.13:57228 dest: /172.20.1.11:9866
2025-03-26 02:24:19,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55352, dest: /172.20.1.13:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742059_1235, duration(ns): 1768535
2025-03-26 02:24:19,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57228, dest: /172.20.1.11:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742059_1235, duration(ns): 1379534
2025-03-26 02:24:19,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742059_1235, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,415 INFO terminating
2025-03-26 02:24:19,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44366, dest: /172.20.1.12:9866, bytes: 2694, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742059_1235, duration(ns): 2283542
2025-03-26 02:24:19,417 INFO terminating
2025-03-26 02:24:19,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742060_1236, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala._COPYING_
2025-03-26 02:24:19,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742060_1236 src: /172.20.1.10:44372 dest: /172.20.1.12:9866
2025-03-26 02:24:19,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742060_1236 src: /172.20.1.12:54736 dest: /172.20.1.11:9866
2025-03-26 02:24:19,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742060_1236 src: /172.20.1.11:34706 dest: /172.20.1.13:9866
2025-03-26 02:24:19,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34706, dest: /172.20.1.13:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742060_1236, duration(ns): 1494070
2025-03-26 02:24:19,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54736, dest: /172.20.1.11:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742060_1236, duration(ns): 1931644
2025-03-26 02:24:19,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742060_1236, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,431 INFO terminating
2025-03-26 02:24:19,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44372, dest: /172.20.1.12:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742060_1236, duration(ns): 2424107
2025-03-26 02:24:19,432 INFO terminating
2025-03-26 02:24:19,433 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,440 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742061_1237, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala._COPYING_
2025-03-26 02:24:19,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742061_1237 src: /172.20.1.10:51152 dest: /172.20.1.13:9866
2025-03-26 02:24:19,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742061_1237 src: /172.20.1.13:38252 dest: /172.20.1.12:9866
2025-03-26 02:24:19,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742061_1237 src: /172.20.1.12:54750 dest: /172.20.1.11:9866
2025-03-26 02:24:19,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54750, dest: /172.20.1.11:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742061_1237, duration(ns): 1195462
2025-03-26 02:24:19,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742061_1237, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38252, dest: /172.20.1.12:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742061_1237, duration(ns): 1624352
2025-03-26 02:24:19,447 INFO terminating
2025-03-26 02:24:19,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51152, dest: /172.20.1.13:9866, bytes: 1995, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742061_1237, duration(ns): 2146805
2025-03-26 02:24:19,448 INFO terminating
2025-03-26 02:24:19,449 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,457 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742062_1238, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala._COPYING_
2025-03-26 02:24:19,457 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,457 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742062_1238 src: /172.20.1.10:57634 dest: /172.20.1.11:9866
2025-03-26 02:24:19,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742062_1238 src: /172.20.1.11:34722 dest: /172.20.1.13:9866
2025-03-26 02:24:19,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742062_1238 src: /172.20.1.13:38268 dest: /172.20.1.12:9866
2025-03-26 02:24:19,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34722, dest: /172.20.1.13:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742062_1238, duration(ns): 1964877
2025-03-26 02:24:19,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38268, dest: /172.20.1.12:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742062_1238, duration(ns): 1576652
2025-03-26 02:24:19,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742062_1238, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57634, dest: /172.20.1.11:9866, bytes: 6074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742062_1238, duration(ns): 2755262
2025-03-26 02:24:19,465 INFO terminating
2025-03-26 02:24:19,465 INFO terminating
2025-03-26 02:24:19,467 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,473 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742063_1239, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala._COPYING_
2025-03-26 02:24:19,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742063_1239 src: /172.20.1.10:51164 dest: /172.20.1.13:9866
2025-03-26 02:24:19,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742063_1239 src: /172.20.1.13:38270 dest: /172.20.1.12:9866
2025-03-26 02:24:19,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742063_1239 src: /172.20.1.12:54764 dest: /172.20.1.11:9866
2025-03-26 02:24:19,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54764, dest: /172.20.1.11:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742063_1239, duration(ns): 1242989
2025-03-26 02:24:19,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38270, dest: /172.20.1.12:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742063_1239, duration(ns): 1530788
2025-03-26 02:24:19,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742063_1239, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,479 INFO terminating
2025-03-26 02:24:19,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51164, dest: /172.20.1.13:9866, bytes: 3246, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742063_1239, duration(ns): 2058871
2025-03-26 02:24:19,480 INFO terminating
2025-03-26 02:24:19,481 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742064_1240, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala._COPYING_
2025-03-26 02:24:19,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742064_1240 src: /172.20.1.10:57638 dest: /172.20.1.11:9866
2025-03-26 02:24:19,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742064_1240 src: /172.20.1.11:34728 dest: /172.20.1.13:9866
2025-03-26 02:24:19,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742064_1240 src: /172.20.1.13:38282 dest: /172.20.1.12:9866
2025-03-26 02:24:19,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38282, dest: /172.20.1.12:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742064_1240, duration(ns): 1500183
2025-03-26 02:24:19,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742064_1240, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57638, dest: /172.20.1.11:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742064_1240, duration(ns): 2146218
2025-03-26 02:24:19,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34728, dest: /172.20.1.13:9866, bytes: 1982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742064_1240, duration(ns): 1916783
2025-03-26 02:24:19,493 INFO terminating
2025-03-26 02:24:19,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,494 INFO terminating
2025-03-26 02:24:19,500 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742065_1241, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala._COPYING_
2025-03-26 02:24:19,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742065_1241 src: /172.20.1.10:44376 dest: /172.20.1.12:9866
2025-03-26 02:24:19,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742065_1241 src: /172.20.1.12:54768 dest: /172.20.1.11:9866
2025-03-26 02:24:19,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742065_1241 src: /172.20.1.11:34740 dest: /172.20.1.13:9866
2025-03-26 02:24:19,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34740, dest: /172.20.1.13:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742065_1241, duration(ns): 1426536
2025-03-26 02:24:19,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54768, dest: /172.20.1.11:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742065_1241, duration(ns): 2033109
2025-03-26 02:24:19,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742065_1241, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44376, dest: /172.20.1.12:9866, bytes: 3135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742065_1241, duration(ns): 2582234
2025-03-26 02:24:19,508 INFO terminating
2025-03-26 02:24:19,508 INFO terminating
2025-03-26 02:24:19,509 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,517 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742066_1242, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala._COPYING_
2025-03-26 02:24:19,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742066_1242 src: /172.20.1.10:44382 dest: /172.20.1.12:9866
2025-03-26 02:24:19,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742066_1242 src: /172.20.1.12:55360 dest: /172.20.1.13:9866
2025-03-26 02:24:19,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742066_1242 src: /172.20.1.13:57236 dest: /172.20.1.11:9866
2025-03-26 02:24:19,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57236, dest: /172.20.1.11:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742066_1242, duration(ns): 1781817
2025-03-26 02:24:19,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55360, dest: /172.20.1.13:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742066_1242, duration(ns): 2838087
2025-03-26 02:24:19,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742066_1242, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,526 INFO terminating
2025-03-26 02:24:19,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44382, dest: /172.20.1.12:9866, bytes: 1181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742066_1242, duration(ns): 3389635
2025-03-26 02:24:19,527 INFO terminating
2025-03-26 02:24:19,528 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,538 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742067_1243, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala._COPYING_
2025-03-26 02:24:19,538 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,538 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742067_1243 src: /172.20.1.10:51172 dest: /172.20.1.13:9866
2025-03-26 02:24:19,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742067_1243 src: /172.20.1.13:38288 dest: /172.20.1.12:9866
2025-03-26 02:24:19,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742067_1243 src: /172.20.1.12:54780 dest: /172.20.1.11:9866
2025-03-26 02:24:19,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54780, dest: /172.20.1.11:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742067_1243, duration(ns): 1953828
2025-03-26 02:24:19,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38288, dest: /172.20.1.12:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742067_1243, duration(ns): 2368797
2025-03-26 02:24:19,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742067_1243, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,545 INFO terminating
2025-03-26 02:24:19,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51172, dest: /172.20.1.13:9866, bytes: 1415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742067_1243, duration(ns): 2842138
2025-03-26 02:24:19,546 INFO terminating
2025-03-26 02:24:19,547 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,552 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742068_1244, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala._COPYING_
2025-03-26 02:24:19,552 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,552 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742068_1244 src: /172.20.1.10:44392 dest: /172.20.1.12:9866
2025-03-26 02:24:19,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742068_1244 src: /172.20.1.12:55366 dest: /172.20.1.13:9866
2025-03-26 02:24:19,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742068_1244 src: /172.20.1.13:57250 dest: /172.20.1.11:9866
2025-03-26 02:24:19,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55366, dest: /172.20.1.13:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742068_1244, duration(ns): 1547940
2025-03-26 02:24:19,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57250, dest: /172.20.1.11:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742068_1244, duration(ns): 1181735
2025-03-26 02:24:19,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742068_1244, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,558 INFO terminating
2025-03-26 02:24:19,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44392, dest: /172.20.1.12:9866, bytes: 1482, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742068_1244, duration(ns): 2128065
2025-03-26 02:24:19,560 INFO terminating
2025-03-26 02:24:19,561 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,568 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742069_1245, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala._COPYING_
2025-03-26 02:24:19,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742069_1245 src: /172.20.1.10:57646 dest: /172.20.1.11:9866
2025-03-26 02:24:19,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742069_1245 src: /172.20.1.11:48352 dest: /172.20.1.12:9866
2025-03-26 02:24:19,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742069_1245 src: /172.20.1.12:55370 dest: /172.20.1.13:9866
2025-03-26 02:24:19,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55370, dest: /172.20.1.13:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742069_1245, duration(ns): 1621048
2025-03-26 02:24:19,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742069_1245, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48352, dest: /172.20.1.12:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742069_1245, duration(ns): 2039505
2025-03-26 02:24:19,576 INFO terminating
2025-03-26 02:24:19,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57646, dest: /172.20.1.11:9866, bytes: 1397, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742069_1245, duration(ns): 2791539
2025-03-26 02:24:19,577 INFO terminating
2025-03-26 02:24:19,587 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742070_1246, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala._COPYING_
2025-03-26 02:24:19,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,607 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742070_1246 src: /172.20.1.10:51180 dest: /172.20.1.13:9866
2025-03-26 02:24:19,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742070_1246 src: /172.20.1.13:57264 dest: /172.20.1.11:9866
2025-03-26 02:24:19,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742070_1246 src: /172.20.1.11:48366 dest: /172.20.1.12:9866
2025-03-26 02:24:19,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48366, dest: /172.20.1.12:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742070_1246, duration(ns): 1544409
2025-03-26 02:24:19,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742070_1246, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57264, dest: /172.20.1.11:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742070_1246, duration(ns): 2120144
2025-03-26 02:24:19,619 INFO terminating
2025-03-26 02:24:19,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51180, dest: /172.20.1.13:9866, bytes: 1412, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742070_1246, duration(ns): 2754924
2025-03-26 02:24:19,620 INFO terminating
2025-03-26 02:24:19,621 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742071_1247, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala._COPYING_
2025-03-26 02:24:19,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,629 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742071_1247 src: /172.20.1.10:57656 dest: /172.20.1.11:9866
2025-03-26 02:24:19,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742071_1247 src: /172.20.1.11:48372 dest: /172.20.1.12:9866
2025-03-26 02:24:19,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742071_1247 src: /172.20.1.12:55378 dest: /172.20.1.13:9866
2025-03-26 02:24:19,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55378, dest: /172.20.1.13:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742071_1247, duration(ns): 2120509
2025-03-26 02:24:19,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742071_1247, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48372, dest: /172.20.1.12:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742071_1247, duration(ns): 2521642
2025-03-26 02:24:19,637 INFO terminating
2025-03-26 02:24:19,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57656, dest: /172.20.1.11:9866, bytes: 2502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742071_1247, duration(ns): 3507159
2025-03-26 02:24:19,638 INFO terminating
2025-03-26 02:24:19,639 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,645 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742072_1248, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala._COPYING_
2025-03-26 02:24:19,645 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,645 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742072_1248 src: /172.20.1.10:51196 dest: /172.20.1.13:9866
2025-03-26 02:24:19,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742072_1248 src: /172.20.1.13:38302 dest: /172.20.1.12:9866
2025-03-26 02:24:19,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742072_1248 src: /172.20.1.12:54790 dest: /172.20.1.11:9866
2025-03-26 02:24:19,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54790, dest: /172.20.1.11:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742072_1248, duration(ns): 1915358
2025-03-26 02:24:19,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38302, dest: /172.20.1.12:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742072_1248, duration(ns): 2356069
2025-03-26 02:24:19,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742072_1248, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,653 INFO terminating
2025-03-26 02:24:19,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51196, dest: /172.20.1.13:9866, bytes: 4848, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742072_1248, duration(ns): 2790733
2025-03-26 02:24:19,656 INFO terminating
2025-03-26 02:24:19,657 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742073_1249, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala._COPYING_
2025-03-26 02:24:19,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742073_1249 src: /172.20.1.10:51210 dest: /172.20.1.13:9866
2025-03-26 02:24:19,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742073_1249 src: /172.20.1.13:38308 dest: /172.20.1.12:9866
2025-03-26 02:24:19,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742073_1249 src: /172.20.1.12:54792 dest: /172.20.1.11:9866
2025-03-26 02:24:19,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54792, dest: /172.20.1.11:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742073_1249, duration(ns): 1625067
2025-03-26 02:24:19,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38308, dest: /172.20.1.12:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742073_1249, duration(ns): 1977465
2025-03-26 02:24:19,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742073_1249, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,675 INFO terminating
2025-03-26 02:24:19,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51210, dest: /172.20.1.13:9866, bytes: 2753, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742073_1249, duration(ns): 2277550
2025-03-26 02:24:19,676 INFO terminating
2025-03-26 02:24:19,680 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742074_1250, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala._COPYING_
2025-03-26 02:24:19,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742074_1250 src: /172.20.1.10:51226 dest: /172.20.1.13:9866
2025-03-26 02:24:19,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742074_1250 src: /172.20.1.13:38310 dest: /172.20.1.12:9866
2025-03-26 02:24:19,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742074_1250 src: /172.20.1.12:54802 dest: /172.20.1.11:9866
2025-03-26 02:24:19,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54802, dest: /172.20.1.11:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742074_1250, duration(ns): 1228029
2025-03-26 02:24:19,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742074_1250, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51226, dest: /172.20.1.13:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742074_1250, duration(ns): 2494158
2025-03-26 02:24:19,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38310, dest: /172.20.1.12:9866, bytes: 2554, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742074_1250, duration(ns): 1993762
2025-03-26 02:24:19,693 INFO terminating
2025-03-26 02:24:19,693 INFO terminating
2025-03-26 02:24:19,695 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,702 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742075_1251, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala._COPYING_
2025-03-26 02:24:19,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,702 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742075_1251 src: /172.20.1.10:51238 dest: /172.20.1.13:9866
2025-03-26 02:24:19,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742075_1251 src: /172.20.1.13:38320 dest: /172.20.1.12:9866
2025-03-26 02:24:19,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742075_1251 src: /172.20.1.12:54814 dest: /172.20.1.11:9866
2025-03-26 02:24:19,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54814, dest: /172.20.1.11:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742075_1251, duration(ns): 2854607
2025-03-26 02:24:19,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742075_1251, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51238, dest: /172.20.1.13:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742075_1251, duration(ns): 4200095
2025-03-26 02:24:19,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38320, dest: /172.20.1.12:9866, bytes: 1550, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742075_1251, duration(ns): 3500439
2025-03-26 02:24:19,711 INFO terminating
2025-03-26 02:24:19,712 INFO terminating
2025-03-26 02:24:19,713 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742076_1252, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala._COPYING_
2025-03-26 02:24:19,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742076_1252 src: /172.20.1.10:51250 dest: /172.20.1.13:9866
2025-03-26 02:24:19,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742076_1252 src: /172.20.1.13:38332 dest: /172.20.1.12:9866
2025-03-26 02:24:19,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742076_1252 src: /172.20.1.12:54824 dest: /172.20.1.11:9866
2025-03-26 02:24:19,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54824, dest: /172.20.1.11:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742076_1252, duration(ns): 1631795
2025-03-26 02:24:19,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742076_1252, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38332, dest: /172.20.1.12:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742076_1252, duration(ns): 2784131
2025-03-26 02:24:19,731 INFO terminating
2025-03-26 02:24:19,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51250, dest: /172.20.1.13:9866, bytes: 2001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742076_1252, duration(ns): 3564942
2025-03-26 02:24:19,732 INFO terminating
2025-03-26 02:24:19,733 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742077_1253, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala._COPYING_
2025-03-26 02:24:19,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742077_1253 src: /172.20.1.10:57672 dest: /172.20.1.11:9866
2025-03-26 02:24:19,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742077_1253 src: /172.20.1.11:34754 dest: /172.20.1.13:9866
2025-03-26 02:24:19,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742077_1253 src: /172.20.1.13:38344 dest: /172.20.1.12:9866
2025-03-26 02:24:19,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38344, dest: /172.20.1.12:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742077_1253, duration(ns): 1629354
2025-03-26 02:24:19,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742077_1253, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57672, dest: /172.20.1.11:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742077_1253, duration(ns): 3296958
2025-03-26 02:24:19,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34754, dest: /172.20.1.13:9866, bytes: 2194, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742077_1253, duration(ns): 2645630
2025-03-26 02:24:19,764 INFO terminating
2025-03-26 02:24:19,764 INFO terminating
2025-03-26 02:24:19,766 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742078_1254, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala._COPYING_
2025-03-26 02:24:19,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742078_1254 src: /172.20.1.10:57682 dest: /172.20.1.11:9866
2025-03-26 02:24:19,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742078_1254 src: /172.20.1.11:48382 dest: /172.20.1.12:9866
2025-03-26 02:24:19,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742078_1254 src: /172.20.1.12:55388 dest: /172.20.1.13:9866
2025-03-26 02:24:19,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48382, dest: /172.20.1.12:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742078_1254, duration(ns): 1454815
2025-03-26 02:24:19,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55388, dest: /172.20.1.13:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742078_1254, duration(ns): 1136487
2025-03-26 02:24:19,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742078_1254, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57682, dest: /172.20.1.11:9866, bytes: 1876, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742078_1254, duration(ns): 1887833
2025-03-26 02:24:19,780 INFO terminating
2025-03-26 02:24:19,781 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,781 INFO terminating
2025-03-26 02:24:19,792 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742079_1255, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala._COPYING_
2025-03-26 02:24:19,793 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742079_1255 src: /172.20.1.10:44404 dest: /172.20.1.12:9866
2025-03-26 02:24:19,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742079_1255 src: /172.20.1.12:55402 dest: /172.20.1.13:9866
2025-03-26 02:24:19,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742079_1255 src: /172.20.1.13:57268 dest: /172.20.1.11:9866
2025-03-26 02:24:19,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55402, dest: /172.20.1.13:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742079_1255, duration(ns): 1422023
2025-03-26 02:24:19,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57268, dest: /172.20.1.11:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742079_1255, duration(ns): 1067141
2025-03-26 02:24:19,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742079_1255, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,799 INFO terminating
2025-03-26 02:24:19,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44404, dest: /172.20.1.12:9866, bytes: 2921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742079_1255, duration(ns): 1875017
2025-03-26 02:24:19,800 INFO terminating
2025-03-26 02:24:19,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,815 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742080_1256, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala._COPYING_
2025-03-26 02:24:19,815 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,815 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742080_1256 src: /172.20.1.10:44414 dest: /172.20.1.12:9866
2025-03-26 02:24:19,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742080_1256 src: /172.20.1.12:54826 dest: /172.20.1.11:9866
2025-03-26 02:24:19,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742080_1256 src: /172.20.1.11:34768 dest: /172.20.1.13:9866
2025-03-26 02:24:19,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34768, dest: /172.20.1.13:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742080_1256, duration(ns): 1248464
2025-03-26 02:24:19,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742080_1256, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54826, dest: /172.20.1.11:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742080_1256, duration(ns): 1555372
2025-03-26 02:24:19,826 INFO terminating
2025-03-26 02:24:19,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44414, dest: /172.20.1.12:9866, bytes: 3420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742080_1256, duration(ns): 2448722
2025-03-26 02:24:19,827 INFO terminating
2025-03-26 02:24:19,831 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,838 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,838 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,839 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742081_1257, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala._COPYING_
2025-03-26 02:24:19,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742081_1257 src: /172.20.1.10:51256 dest: /172.20.1.13:9866
2025-03-26 02:24:19,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742081_1257 src: /172.20.1.13:38360 dest: /172.20.1.12:9866
2025-03-26 02:24:19,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742081_1257 src: /172.20.1.12:54830 dest: /172.20.1.11:9866
2025-03-26 02:24:19,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54830, dest: /172.20.1.11:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742081_1257, duration(ns): 1204871
2025-03-26 02:24:19,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38360, dest: /172.20.1.12:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742081_1257, duration(ns): 1698033
2025-03-26 02:24:19,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742081_1257, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,845 INFO terminating
2025-03-26 02:24:19,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51256, dest: /172.20.1.13:9866, bytes: 1997, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742081_1257, duration(ns): 2322141
2025-03-26 02:24:19,846 INFO terminating
2025-03-26 02:24:19,847 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,853 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742082_1258, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 02:24:19,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742082_1258 src: /172.20.1.10:51264 dest: /172.20.1.13:9866
2025-03-26 02:24:19,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742082_1258 src: /172.20.1.13:38364 dest: /172.20.1.12:9866
2025-03-26 02:24:19,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742082_1258 src: /172.20.1.12:54846 dest: /172.20.1.11:9866
2025-03-26 02:24:19,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54846, dest: /172.20.1.11:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742082_1258, duration(ns): 1495858
2025-03-26 02:24:19,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38364, dest: /172.20.1.12:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742082_1258, duration(ns): 1725106
2025-03-26 02:24:19,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742082_1258, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,860 INFO terminating
2025-03-26 02:24:19,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51264, dest: /172.20.1.13:9866, bytes: 5316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742082_1258, duration(ns): 1974636
2025-03-26 02:24:19,861 INFO terminating
2025-03-26 02:24:19,862 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742083_1259, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala._COPYING_
2025-03-26 02:24:19,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742083_1259 src: /172.20.1.10:51278 dest: /172.20.1.13:9866
2025-03-26 02:24:19,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742083_1259 src: /172.20.1.11:48386 dest: /172.20.1.12:9866
2025-03-26 02:24:19,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742083_1259 src: /172.20.1.13:57276 dest: /172.20.1.11:9866
2025-03-26 02:24:19,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48386, dest: /172.20.1.12:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742083_1259, duration(ns): 1310807
2025-03-26 02:24:19,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57276, dest: /172.20.1.11:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742083_1259, duration(ns): 1674977
2025-03-26 02:24:19,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742083_1259, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,877 INFO terminating
2025-03-26 02:24:19,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51278, dest: /172.20.1.13:9866, bytes: 2825, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742083_1259, duration(ns): 2260824
2025-03-26 02:24:19,878 INFO terminating
2025-03-26 02:24:19,879 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,887 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742084_1260, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala._COPYING_
2025-03-26 02:24:19,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742084_1260 src: /172.20.1.10:44428 dest: /172.20.1.12:9866
2025-03-26 02:24:19,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742084_1260 src: /172.20.1.12:55410 dest: /172.20.1.13:9866
2025-03-26 02:24:19,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742084_1260 src: /172.20.1.13:57292 dest: /172.20.1.11:9866
2025-03-26 02:24:19,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57292, dest: /172.20.1.11:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742084_1260, duration(ns): 1325319
2025-03-26 02:24:19,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742084_1260, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44428, dest: /172.20.1.12:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742084_1260, duration(ns): 3278709
2025-03-26 02:24:19,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55410, dest: /172.20.1.13:9866, bytes: 2417, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742084_1260, duration(ns): 2360226
2025-03-26 02:24:19,896 INFO terminating
2025-03-26 02:24:19,896 INFO terminating
2025-03-26 02:24:19,897 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,903 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742085_1261, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala._COPYING_
2025-03-26 02:24:19,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742085_1261 src: /172.20.1.10:44438 dest: /172.20.1.12:9866
2025-03-26 02:24:19,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742085_1261 src: /172.20.1.12:55422 dest: /172.20.1.13:9866
2025-03-26 02:24:19,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742085_1261 src: /172.20.1.13:57298 dest: /172.20.1.11:9866
2025-03-26 02:24:19,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57298, dest: /172.20.1.11:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742085_1261, duration(ns): 1275745
2025-03-26 02:24:19,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742085_1261, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44438, dest: /172.20.1.12:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742085_1261, duration(ns): 5308941
2025-03-26 02:24:19,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55422, dest: /172.20.1.13:9866, bytes: 1773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742085_1261, duration(ns): 1554171
2025-03-26 02:24:19,913 INFO terminating
2025-03-26 02:24:19,914 INFO terminating
2025-03-26 02:24:19,915 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742086_1262, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala._COPYING_
2025-03-26 02:24:19,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742086_1262 src: /172.20.1.10:57694 dest: /172.20.1.11:9866
2025-03-26 02:24:19,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742086_1262 src: /172.20.1.11:34772 dest: /172.20.1.13:9866
2025-03-26 02:24:19,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742086_1262 src: /172.20.1.13:38368 dest: /172.20.1.12:9866
2025-03-26 02:24:19,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38368, dest: /172.20.1.12:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742086_1262, duration(ns): 1413742
2025-03-26 02:24:19,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742086_1262, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34772, dest: /172.20.1.13:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742086_1262, duration(ns): 1726187
2025-03-26 02:24:19,930 INFO terminating
2025-03-26 02:24:19,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57694, dest: /172.20.1.11:9866, bytes: 3137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742086_1262, duration(ns): 3154047
2025-03-26 02:24:19,931 INFO terminating
2025-03-26 02:24:19,932 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742087_1263, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala._COPYING_
2025-03-26 02:24:19,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742087_1263 src: /172.20.1.10:51282 dest: /172.20.1.13:9866
2025-03-26 02:24:19,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742087_1263 src: /172.20.1.13:38378 dest: /172.20.1.12:9866
2025-03-26 02:24:19,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742087_1263 src: /172.20.1.12:54856 dest: /172.20.1.11:9866
2025-03-26 02:24:19,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54856, dest: /172.20.1.11:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742087_1263, duration(ns): 1383534
2025-03-26 02:24:19,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742087_1263, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51282, dest: /172.20.1.13:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742087_1263, duration(ns): 2215794
2025-03-26 02:24:19,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38378, dest: /172.20.1.12:9866, bytes: 5584, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742087_1263, duration(ns): 1767107
2025-03-26 02:24:19,955 INFO terminating
2025-03-26 02:24:19,955 INFO terminating
2025-03-26 02:24:19,956 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742088_1264, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala._COPYING_
2025-03-26 02:24:19,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742088_1264 src: /172.20.1.10:57700 dest: /172.20.1.11:9866
2025-03-26 02:24:19,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742088_1264 src: /172.20.1.11:34774 dest: /172.20.1.13:9866
2025-03-26 02:24:19,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742088_1264 src: /172.20.1.13:38394 dest: /172.20.1.12:9866
2025-03-26 02:24:19,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34774, dest: /172.20.1.13:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742088_1264, duration(ns): 1877005
2025-03-26 02:24:19,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38394, dest: /172.20.1.12:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742088_1264, duration(ns): 1605112
2025-03-26 02:24:19,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742088_1264, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:19,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57700, dest: /172.20.1.11:9866, bytes: 4982, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742088_1264, duration(ns): 2196259
2025-03-26 02:24:19,970 INFO terminating
2025-03-26 02:24:19,970 INFO terminating
2025-03-26 02:24:19,971 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:19,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742089_1265, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala._COPYING_
2025-03-26 02:24:19,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:19,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742089_1265 src: /172.20.1.10:57708 dest: /172.20.1.11:9866
2025-03-26 02:24:19,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742089_1265 src: /172.20.1.11:34778 dest: /172.20.1.13:9866
2025-03-26 02:24:19,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742089_1265 src: /172.20.1.13:38398 dest: /172.20.1.12:9866
2025-03-26 02:24:20,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34778, dest: /172.20.1.13:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742089_1265, duration(ns): 14527847
2025-03-26 02:24:20,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38398, dest: /172.20.1.12:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742089_1265, duration(ns): 14051694
2025-03-26 02:24:20,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742089_1265, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,013 INFO terminating
2025-03-26 02:24:20,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57708, dest: /172.20.1.11:9866, bytes: 2894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742089_1265, duration(ns): 14913464
2025-03-26 02:24:20,014 INFO terminating
2025-03-26 02:24:20,015 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,027 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,027 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,028 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742090_1266, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala._COPYING_
2025-03-26 02:24:20,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742090_1266 src: /172.20.1.10:57714 dest: /172.20.1.11:9866
2025-03-26 02:24:20,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742090_1266 src: /172.20.1.11:48398 dest: /172.20.1.12:9866
2025-03-26 02:24:20,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742090_1266 src: /172.20.1.12:55430 dest: /172.20.1.13:9866
2025-03-26 02:24:20,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55430, dest: /172.20.1.13:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742090_1266, duration(ns): 1089504
2025-03-26 02:24:20,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742090_1266, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48398, dest: /172.20.1.12:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742090_1266, duration(ns): 1776231
2025-03-26 02:24:20,034 INFO terminating
2025-03-26 02:24:20,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57714, dest: /172.20.1.11:9866, bytes: 2686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742090_1266, duration(ns): 2292012
2025-03-26 02:24:20,035 INFO terminating
2025-03-26 02:24:20,036 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,042 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,042 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,043 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742091_1267, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala._COPYING_
2025-03-26 02:24:20,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742091_1267 src: /172.20.1.10:44444 dest: /172.20.1.12:9866
2025-03-26 02:24:20,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742091_1267 src: /172.20.1.12:54868 dest: /172.20.1.11:9866
2025-03-26 02:24:20,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742091_1267 src: /172.20.1.11:34790 dest: /172.20.1.13:9866
2025-03-26 02:24:20,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34790, dest: /172.20.1.13:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742091_1267, duration(ns): 3303888
2025-03-26 02:24:20,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54868, dest: /172.20.1.11:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742091_1267, duration(ns): 3695867
2025-03-26 02:24:20,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742091_1267, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,056 INFO terminating
2025-03-26 02:24:20,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44444, dest: /172.20.1.12:9866, bytes: 14560, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742091_1267, duration(ns): 4143840
2025-03-26 02:24:20,057 INFO terminating
2025-03-26 02:24:20,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742092_1268, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala._COPYING_
2025-03-26 02:24:20,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742092_1268 src: /172.20.1.10:44460 dest: /172.20.1.12:9866
2025-03-26 02:24:20,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742092_1268 src: /172.20.1.12:55444 dest: /172.20.1.13:9866
2025-03-26 02:24:20,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742092_1268 src: /172.20.1.13:57300 dest: /172.20.1.11:9866
2025-03-26 02:24:20,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57300, dest: /172.20.1.11:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742092_1268, duration(ns): 997861
2025-03-26 02:24:20,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742092_1268, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44460, dest: /172.20.1.12:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742092_1268, duration(ns): 1634868
2025-03-26 02:24:20,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55444, dest: /172.20.1.13:9866, bytes: 1929, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742092_1268, duration(ns): 1321580
2025-03-26 02:24:20,071 INFO terminating
2025-03-26 02:24:20,071 INFO terminating
2025-03-26 02:24:20,072 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,077 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742093_1269, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala._COPYING_
2025-03-26 02:24:20,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742093_1269 src: /172.20.1.10:57726 dest: /172.20.1.11:9866
2025-03-26 02:24:20,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742093_1269 src: /172.20.1.11:34798 dest: /172.20.1.13:9866
2025-03-26 02:24:20,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742093_1269 src: /172.20.1.13:38404 dest: /172.20.1.12:9866
2025-03-26 02:24:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34798, dest: /172.20.1.13:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742093_1269, duration(ns): 1386258
2025-03-26 02:24:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38404, dest: /172.20.1.12:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742093_1269, duration(ns): 1068749
2025-03-26 02:24:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742093_1269, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,083 INFO terminating
2025-03-26 02:24:20,084 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57726, dest: /172.20.1.11:9866, bytes: 2354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742093_1269, duration(ns): 1766771
2025-03-26 02:24:20,084 INFO terminating
2025-03-26 02:24:20,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,090 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742094_1270, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala._COPYING_
2025-03-26 02:24:20,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742094_1270 src: /172.20.1.10:51292 dest: /172.20.1.13:9866
2025-03-26 02:24:20,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742094_1270 src: /172.20.1.13:38408 dest: /172.20.1.12:9866
2025-03-26 02:24:20,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742094_1270 src: /172.20.1.12:54870 dest: /172.20.1.11:9866
2025-03-26 02:24:20,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54870, dest: /172.20.1.11:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742094_1270, duration(ns): 1112756
2025-03-26 02:24:20,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51292, dest: /172.20.1.13:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742094_1270, duration(ns): 1682276
2025-03-26 02:24:20,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38408, dest: /172.20.1.12:9866, bytes: 1775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742094_1270, duration(ns): 1256825
2025-03-26 02:24:20,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742094_1270, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,096 INFO terminating
2025-03-26 02:24:20,097 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,097 INFO terminating
2025-03-26 02:24:20,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742095_1271, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala._COPYING_
2025-03-26 02:24:20,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742095_1271 src: /172.20.1.10:57740 dest: /172.20.1.11:9866
2025-03-26 02:24:20,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742095_1271 src: /172.20.1.11:34814 dest: /172.20.1.13:9866
2025-03-26 02:24:20,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742095_1271 src: /172.20.1.13:38422 dest: /172.20.1.12:9866
2025-03-26 02:24:20,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38422, dest: /172.20.1.12:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742095_1271, duration(ns): 1099733
2025-03-26 02:24:20,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742095_1271, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34814, dest: /172.20.1.13:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742095_1271, duration(ns): 1577061
2025-03-26 02:24:20,111 INFO terminating
2025-03-26 02:24:20,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57740, dest: /172.20.1.11:9866, bytes: 2051, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742095_1271, duration(ns): 2232278
2025-03-26 02:24:20,112 INFO terminating
2025-03-26 02:24:20,113 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,119 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742096_1272, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala._COPYING_
2025-03-26 02:24:20,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742096_1272 src: /172.20.1.10:57748 dest: /172.20.1.11:9866
2025-03-26 02:24:20,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742096_1272 src: /172.20.1.11:48410 dest: /172.20.1.12:9866
2025-03-26 02:24:20,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742096_1272 src: /172.20.1.12:55450 dest: /172.20.1.13:9866
2025-03-26 02:24:20,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48410, dest: /172.20.1.12:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742096_1272, duration(ns): 1828844
2025-03-26 02:24:20,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55450, dest: /172.20.1.13:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742096_1272, duration(ns): 1432268
2025-03-26 02:24:20,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742096_1272, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57748, dest: /172.20.1.11:9866, bytes: 1956, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742096_1272, duration(ns): 2392327
2025-03-26 02:24:20,127 INFO terminating
2025-03-26 02:24:20,127 INFO terminating
2025-03-26 02:24:20,129 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742097_1273, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala._COPYING_
2025-03-26 02:24:20,136 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742097_1273 src: /172.20.1.10:57750 dest: /172.20.1.11:9866
2025-03-26 02:24:20,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742097_1273 src: /172.20.1.11:34826 dest: /172.20.1.13:9866
2025-03-26 02:24:20,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742097_1273 src: /172.20.1.13:38424 dest: /172.20.1.12:9866
2025-03-26 02:24:20,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34826, dest: /172.20.1.13:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742097_1273, duration(ns): 1537774
2025-03-26 02:24:20,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38424, dest: /172.20.1.12:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742097_1273, duration(ns): 1323501
2025-03-26 02:24:20,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742097_1273, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57750, dest: /172.20.1.11:9866, bytes: 6344, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742097_1273, duration(ns): 2115458
2025-03-26 02:24:20,142 INFO terminating
2025-03-26 02:24:20,142 INFO terminating
2025-03-26 02:24:20,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742098_1274, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala._COPYING_
2025-03-26 02:24:20,147 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,147 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742098_1274 src: /172.20.1.10:44468 dest: /172.20.1.12:9866
2025-03-26 02:24:20,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742098_1274 src: /172.20.1.12:54874 dest: /172.20.1.11:9866
2025-03-26 02:24:20,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742098_1274 src: /172.20.1.11:34838 dest: /172.20.1.13:9866
2025-03-26 02:24:20,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34838, dest: /172.20.1.13:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742098_1274, duration(ns): 1220149
2025-03-26 02:24:20,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54874, dest: /172.20.1.11:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742098_1274, duration(ns): 1439196
2025-03-26 02:24:20,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742098_1274, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,152 INFO terminating
2025-03-26 02:24:20,153 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44468, dest: /172.20.1.12:9866, bytes: 4372, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742098_1274, duration(ns): 1719515
2025-03-26 02:24:20,153 INFO terminating
2025-03-26 02:24:20,158 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742099_1275, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala._COPYING_
2025-03-26 02:24:20,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742099_1275 src: /172.20.1.10:51300 dest: /172.20.1.13:9866
2025-03-26 02:24:20,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742099_1275 src: /172.20.1.13:38440 dest: /172.20.1.12:9866
2025-03-26 02:24:20,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742099_1275 src: /172.20.1.12:54890 dest: /172.20.1.11:9866
2025-03-26 02:24:20,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54890, dest: /172.20.1.11:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742099_1275, duration(ns): 1496444
2025-03-26 02:24:20,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742099_1275, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51300, dest: /172.20.1.13:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742099_1275, duration(ns): 2138188
2025-03-26 02:24:20,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38440, dest: /172.20.1.12:9866, bytes: 2681, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742099_1275, duration(ns): 1778637
2025-03-26 02:24:20,164 INFO terminating
2025-03-26 02:24:20,165 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,165 INFO terminating
2025-03-26 02:24:20,173 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742100_1276, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala._COPYING_
2025-03-26 02:24:20,173 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,173 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742100_1276 src: /172.20.1.10:51302 dest: /172.20.1.13:9866
2025-03-26 02:24:20,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742100_1276 src: /172.20.1.13:57302 dest: /172.20.1.11:9866
2025-03-26 02:24:20,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742100_1276 src: /172.20.1.11:48414 dest: /172.20.1.12:9866
2025-03-26 02:24:20,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51302, dest: /172.20.1.13:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742100_1276, duration(ns): 1552921
2025-03-26 02:24:20,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48414, dest: /172.20.1.12:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742100_1276, duration(ns): 1044716
2025-03-26 02:24:20,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57302, dest: /172.20.1.11:9866, bytes: 2205, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742100_1276, duration(ns): 1203349
2025-03-26 02:24:20,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742100_1276, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,178 INFO terminating
2025-03-26 02:24:20,179 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,179 INFO terminating
2025-03-26 02:24:20,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742101_1277, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala._COPYING_
2025-03-26 02:24:20,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742101_1277 src: /172.20.1.10:57756 dest: /172.20.1.11:9866
2025-03-26 02:24:20,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742101_1277 src: /172.20.1.11:34844 dest: /172.20.1.13:9866
2025-03-26 02:24:20,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742101_1277 src: /172.20.1.13:38448 dest: /172.20.1.12:9866
2025-03-26 02:24:20,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38448, dest: /172.20.1.12:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742101_1277, duration(ns): 1236172
2025-03-26 02:24:20,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742101_1277, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57756, dest: /172.20.1.11:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742101_1277, duration(ns): 1792803
2025-03-26 02:24:20,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34844, dest: /172.20.1.13:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742101_1277, duration(ns): 1460477
2025-03-26 02:24:20,190 INFO terminating
2025-03-26 02:24:20,190 INFO terminating
2025-03-26 02:24:20,191 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742102_1278, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala._COPYING_
2025-03-26 02:24:20,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742102_1278 src: /172.20.1.10:57766 dest: /172.20.1.11:9866
2025-03-26 02:24:20,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742102_1278 src: /172.20.1.11:48430 dest: /172.20.1.12:9866
2025-03-26 02:24:20,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742102_1278 src: /172.20.1.12:55462 dest: /172.20.1.13:9866
2025-03-26 02:24:20,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48430, dest: /172.20.1.12:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742102_1278, duration(ns): 1254246
2025-03-26 02:24:20,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55462, dest: /172.20.1.13:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742102_1278, duration(ns): 1046038
2025-03-26 02:24:20,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742102_1278, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,202 INFO terminating
2025-03-26 02:24:20,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57766, dest: /172.20.1.11:9866, bytes: 3212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742102_1278, duration(ns): 1588654
2025-03-26 02:24:20,203 INFO terminating
2025-03-26 02:24:20,204 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,208 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742103_1279, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala._COPYING_
2025-03-26 02:24:20,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742103_1279 src: /172.20.1.10:57770 dest: /172.20.1.11:9866
2025-03-26 02:24:20,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742103_1279 src: /172.20.1.11:34860 dest: /172.20.1.13:9866
2025-03-26 02:24:20,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742103_1279 src: /172.20.1.13:38454 dest: /172.20.1.12:9866
2025-03-26 02:24:20,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38454, dest: /172.20.1.12:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742103_1279, duration(ns): 1072759
2025-03-26 02:24:20,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742103_1279, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57770, dest: /172.20.1.11:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742103_1279, duration(ns): 1555730
2025-03-26 02:24:20,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34860, dest: /172.20.1.13:9866, bytes: 2359, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742103_1279, duration(ns): 1275620
2025-03-26 02:24:20,214 INFO terminating
2025-03-26 02:24:20,214 INFO terminating
2025-03-26 02:24:20,219 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,225 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742104_1280, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala._COPYING_
2025-03-26 02:24:20,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742104_1280 src: /172.20.1.10:51310 dest: /172.20.1.13:9866
2025-03-26 02:24:20,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742104_1280 src: /172.20.1.13:57304 dest: /172.20.1.11:9866
2025-03-26 02:24:20,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742104_1280 src: /172.20.1.11:48434 dest: /172.20.1.12:9866
2025-03-26 02:24:20,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48434, dest: /172.20.1.12:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742104_1280, duration(ns): 1952242
2025-03-26 02:24:20,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742104_1280, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51310, dest: /172.20.1.13:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742104_1280, duration(ns): 2489722
2025-03-26 02:24:20,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57304, dest: /172.20.1.11:9866, bytes: 3001, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742104_1280, duration(ns): 2141654
2025-03-26 02:24:20,233 INFO terminating
2025-03-26 02:24:20,233 INFO terminating
2025-03-26 02:24:20,234 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,244 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742105_1281, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala._COPYING_
2025-03-26 02:24:20,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742105_1281 src: /172.20.1.10:57776 dest: /172.20.1.11:9866
2025-03-26 02:24:20,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742105_1281 src: /172.20.1.11:48440 dest: /172.20.1.12:9866
2025-03-26 02:24:20,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742105_1281 src: /172.20.1.12:55472 dest: /172.20.1.13:9866
2025-03-26 02:24:20,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48440, dest: /172.20.1.12:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742105_1281, duration(ns): 7545728
2025-03-26 02:24:20,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55472, dest: /172.20.1.13:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742105_1281, duration(ns): 7139157
2025-03-26 02:24:20,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742105_1281, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,256 INFO terminating
2025-03-26 02:24:20,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57776, dest: /172.20.1.11:9866, bytes: 7324, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742105_1281, duration(ns): 7860221
2025-03-26 02:24:20,257 INFO terminating
2025-03-26 02:24:20,260 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,265 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742106_1282, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala._COPYING_
2025-03-26 02:24:20,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742106_1282 src: /172.20.1.10:51318 dest: /172.20.1.13:9866
2025-03-26 02:24:20,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742106_1282 src: /172.20.1.13:57310 dest: /172.20.1.11:9866
2025-03-26 02:24:20,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742106_1282 src: /172.20.1.11:48450 dest: /172.20.1.12:9866
2025-03-26 02:24:20,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48450, dest: /172.20.1.12:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742106_1282, duration(ns): 1290189
2025-03-26 02:24:20,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57310, dest: /172.20.1.11:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742106_1282, duration(ns): 1549090
2025-03-26 02:24:20,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742106_1282, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,270 INFO terminating
2025-03-26 02:24:20,271 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51318, dest: /172.20.1.13:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742106_1282, duration(ns): 1850504
2025-03-26 02:24:20,271 INFO terminating
2025-03-26 02:24:20,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742107_1283, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala._COPYING_
2025-03-26 02:24:20,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742107_1283 src: /172.20.1.10:57792 dest: /172.20.1.11:9866
2025-03-26 02:24:20,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742107_1283 src: /172.20.1.11:48452 dest: /172.20.1.12:9866
2025-03-26 02:24:20,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742107_1283 src: /172.20.1.12:55478 dest: /172.20.1.13:9866
2025-03-26 02:24:20,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55478, dest: /172.20.1.13:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742107_1283, duration(ns): 6486067
2025-03-26 02:24:20,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57792, dest: /172.20.1.11:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742107_1283, duration(ns): 6731227
2025-03-26 02:24:20,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48452, dest: /172.20.1.12:9866, bytes: 2396, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742107_1283, duration(ns): 6677422
2025-03-26 02:24:20,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742107_1283, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,288 INFO terminating
2025-03-26 02:24:20,289 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,289 INFO terminating
2025-03-26 02:24:20,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742108_1284, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala._COPYING_
2025-03-26 02:24:20,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742108_1284 src: /172.20.1.10:51320 dest: /172.20.1.13:9866
2025-03-26 02:24:20,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742108_1284 src: /172.20.1.11:48454 dest: /172.20.1.12:9866
2025-03-26 02:24:20,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742108_1284 src: /172.20.1.13:57324 dest: /172.20.1.11:9866
2025-03-26 02:24:20,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48454, dest: /172.20.1.12:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742108_1284, duration(ns): 1021149
2025-03-26 02:24:20,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742108_1284, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51320, dest: /172.20.1.13:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742108_1284, duration(ns): 1947797
2025-03-26 02:24:20,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57324, dest: /172.20.1.11:9866, bytes: 2374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742108_1284, duration(ns): 1465870
2025-03-26 02:24:20,299 INFO terminating
2025-03-26 02:24:20,299 INFO terminating
2025-03-26 02:24:20,300 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,305 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742109_1285, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala._COPYING_
2025-03-26 02:24:20,305 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,305 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742109_1285 src: /172.20.1.10:57800 dest: /172.20.1.11:9866
2025-03-26 02:24:20,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742109_1285 src: /172.20.1.11:34862 dest: /172.20.1.13:9866
2025-03-26 02:24:20,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742109_1285 src: /172.20.1.13:38468 dest: /172.20.1.12:9866
2025-03-26 02:24:20,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34862, dest: /172.20.1.13:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742109_1285, duration(ns): 1307516
2025-03-26 02:24:20,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38468, dest: /172.20.1.12:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742109_1285, duration(ns): 1023573
2025-03-26 02:24:20,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742109_1285, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,311 INFO terminating
2025-03-26 02:24:20,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57800, dest: /172.20.1.11:9866, bytes: 2059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742109_1285, duration(ns): 1718016
2025-03-26 02:24:20,312 INFO terminating
2025-03-26 02:24:20,313 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,317 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742110_1286, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala._COPYING_
2025-03-26 02:24:20,317 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,317 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742110_1286 src: /172.20.1.10:57802 dest: /172.20.1.11:9866
2025-03-26 02:24:20,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742110_1286 src: /172.20.1.11:48458 dest: /172.20.1.12:9866
2025-03-26 02:24:20,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742110_1286 src: /172.20.1.12:55482 dest: /172.20.1.13:9866
2025-03-26 02:24:20,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48458, dest: /172.20.1.12:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742110_1286, duration(ns): 1367595
2025-03-26 02:24:20,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55482, dest: /172.20.1.13:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742110_1286, duration(ns): 1173737
2025-03-26 02:24:20,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742110_1286, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,322 INFO terminating
2025-03-26 02:24:20,323 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57802, dest: /172.20.1.11:9866, bytes: 2091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742110_1286, duration(ns): 1691377
2025-03-26 02:24:20,323 INFO terminating
2025-03-26 02:24:20,328 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742111_1287, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala._COPYING_
2025-03-26 02:24:20,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742111_1287 src: /172.20.1.10:51326 dest: /172.20.1.13:9866
2025-03-26 02:24:20,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742111_1287 src: /172.20.1.13:57334 dest: /172.20.1.11:9866
2025-03-26 02:24:20,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742111_1287 src: /172.20.1.11:48462 dest: /172.20.1.12:9866
2025-03-26 02:24:20,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48462, dest: /172.20.1.12:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742111_1287, duration(ns): 1265335
2025-03-26 02:24:20,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57334, dest: /172.20.1.11:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742111_1287, duration(ns): 1511781
2025-03-26 02:24:20,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742111_1287, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,333 INFO terminating
2025-03-26 02:24:20,334 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51326, dest: /172.20.1.13:9866, bytes: 3119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742111_1287, duration(ns): 1774868
2025-03-26 02:24:20,334 INFO terminating
2025-03-26 02:24:20,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742112_1288, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala._COPYING_
2025-03-26 02:24:20,338 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,338 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742112_1288 src: /172.20.1.10:51340 dest: /172.20.1.13:9866
2025-03-26 02:24:20,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742112_1288 src: /172.20.1.13:57350 dest: /172.20.1.11:9866
2025-03-26 02:24:20,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742112_1288 src: /172.20.1.11:48478 dest: /172.20.1.12:9866
2025-03-26 02:24:20,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48478, dest: /172.20.1.12:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742112_1288, duration(ns): 1261250
2025-03-26 02:24:20,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57350, dest: /172.20.1.11:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742112_1288, duration(ns): 1502504
2025-03-26 02:24:20,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742112_1288, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,343 INFO terminating
2025-03-26 02:24:20,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51340, dest: /172.20.1.13:9866, bytes: 3617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742112_1288, duration(ns): 1854310
2025-03-26 02:24:20,344 INFO terminating
2025-03-26 02:24:20,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,350 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742113_1289, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala._COPYING_
2025-03-26 02:24:20,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742113_1289 src: /172.20.1.10:57808 dest: /172.20.1.11:9866
2025-03-26 02:24:20,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742113_1289 src: /172.20.1.11:34876 dest: /172.20.1.13:9866
2025-03-26 02:24:20,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742113_1289 src: /172.20.1.13:38476 dest: /172.20.1.12:9866
2025-03-26 02:24:20,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38476, dest: /172.20.1.12:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742113_1289, duration(ns): 857147
2025-03-26 02:24:20,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742113_1289, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57808, dest: /172.20.1.11:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742113_1289, duration(ns): 2154261
2025-03-26 02:24:20,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34876, dest: /172.20.1.13:9866, bytes: 2074, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742113_1289, duration(ns): 1052722
2025-03-26 02:24:20,355 INFO terminating
2025-03-26 02:24:20,355 INFO terminating
2025-03-26 02:24:20,356 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742114_1290, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala._COPYING_
2025-03-26 02:24:20,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742114_1290 src: /172.20.1.10:51354 dest: /172.20.1.13:9866
2025-03-26 02:24:20,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742114_1290 src: /172.20.1.13:38490 dest: /172.20.1.12:9866
2025-03-26 02:24:20,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742114_1290 src: /172.20.1.12:54892 dest: /172.20.1.11:9866
2025-03-26 02:24:20,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54892, dest: /172.20.1.11:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742114_1290, duration(ns): 799111
2025-03-26 02:24:20,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742114_1290, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51354, dest: /172.20.1.13:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742114_1290, duration(ns): 1294179
2025-03-26 02:24:20,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38490, dest: /172.20.1.12:9866, bytes: 9570, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742114_1290, duration(ns): 976635
2025-03-26 02:24:20,365 INFO terminating
2025-03-26 02:24:20,365 INFO terminating
2025-03-26 02:24:20,366 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,369 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742115_1291, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala._COPYING_
2025-03-26 02:24:20,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742115_1291 src: /172.20.1.10:51368 dest: /172.20.1.13:9866
2025-03-26 02:24:20,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742115_1291 src: /172.20.1.13:57356 dest: /172.20.1.11:9866
2025-03-26 02:24:20,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742115_1291 src: /172.20.1.11:48490 dest: /172.20.1.12:9866
2025-03-26 02:24:20,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48490, dest: /172.20.1.12:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742115_1291, duration(ns): 616666
2025-03-26 02:24:20,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57356, dest: /172.20.1.11:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742115_1291, duration(ns): 1264347
2025-03-26 02:24:20,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742115_1291, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51368, dest: /172.20.1.13:9866, bytes: 1981, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742115_1291, duration(ns): 2122828
2025-03-26 02:24:20,375 INFO terminating
2025-03-26 02:24:20,375 INFO terminating
2025-03-26 02:24:20,376 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,380 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742116_1292, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala._COPYING_
2025-03-26 02:24:20,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742116_1292 src: /172.20.1.10:51370 dest: /172.20.1.13:9866
2025-03-26 02:24:20,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742116_1292 src: /172.20.1.13:38502 dest: /172.20.1.12:9866
2025-03-26 02:24:20,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742116_1292 src: /172.20.1.12:54908 dest: /172.20.1.11:9866
2025-03-26 02:24:20,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54908, dest: /172.20.1.11:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742116_1292, duration(ns): 650850
2025-03-26 02:24:20,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38502, dest: /172.20.1.12:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742116_1292, duration(ns): 876137
2025-03-26 02:24:20,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742116_1292, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,385 INFO terminating
2025-03-26 02:24:20,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51370, dest: /172.20.1.13:9866, bytes: 2673, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742116_1292, duration(ns): 1146926
2025-03-26 02:24:20,386 INFO terminating
2025-03-26 02:24:20,387 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,398 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742117_1293, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala._COPYING_
2025-03-26 02:24:20,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742117_1293 src: /172.20.1.10:51386 dest: /172.20.1.13:9866
2025-03-26 02:24:20,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742117_1293 src: /172.20.1.13:57364 dest: /172.20.1.11:9866
2025-03-26 02:24:20,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742117_1293 src: /172.20.1.11:48502 dest: /172.20.1.12:9866
2025-03-26 02:24:20,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48502, dest: /172.20.1.12:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742117_1293, duration(ns): 3081869
2025-03-26 02:24:20,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742117_1293, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51386, dest: /172.20.1.13:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742117_1293, duration(ns): 3868350
2025-03-26 02:24:20,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57364, dest: /172.20.1.11:9866, bytes: 3292, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742117_1293, duration(ns): 3551587
2025-03-26 02:24:20,408 INFO terminating
2025-03-26 02:24:20,408 INFO terminating
2025-03-26 02:24:20,409 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,416 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742118_1294, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala._COPYING_
2025-03-26 02:24:20,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742118_1294 src: /172.20.1.10:57812 dest: /172.20.1.11:9866
2025-03-26 02:24:20,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742118_1294 src: /172.20.1.11:48514 dest: /172.20.1.12:9866
2025-03-26 02:24:20,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742118_1294 src: /172.20.1.12:55498 dest: /172.20.1.13:9866
2025-03-26 02:24:20,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48514, dest: /172.20.1.12:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742118_1294, duration(ns): 1531741
2025-03-26 02:24:20,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55498, dest: /172.20.1.13:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742118_1294, duration(ns): 1292456
2025-03-26 02:24:20,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742118_1294, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,421 INFO terminating
2025-03-26 02:24:20,422 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57812, dest: /172.20.1.11:9866, bytes: 2387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742118_1294, duration(ns): 2114226
2025-03-26 02:24:20,422 INFO terminating
2025-03-26 02:24:20,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742119_1295, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala._COPYING_
2025-03-26 02:24:20,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742119_1295 src: /172.20.1.10:51394 dest: /172.20.1.13:9866
2025-03-26 02:24:20,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742119_1295 src: /172.20.1.13:57374 dest: /172.20.1.11:9866
2025-03-26 02:24:20,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742119_1295 src: /172.20.1.11:48528 dest: /172.20.1.12:9866
2025-03-26 02:24:20,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48528, dest: /172.20.1.12:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742119_1295, duration(ns): 1209378
2025-03-26 02:24:20,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57374, dest: /172.20.1.11:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742119_1295, duration(ns): 1514123
2025-03-26 02:24:20,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742119_1295, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,436 INFO terminating
2025-03-26 02:24:20,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51394, dest: /172.20.1.13:9866, bytes: 3668, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742119_1295, duration(ns): 2247809
2025-03-26 02:24:20,437 INFO terminating
2025-03-26 02:24:20,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742120_1296, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala._COPYING_
2025-03-26 02:24:20,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742120_1296 src: /172.20.1.10:44476 dest: /172.20.1.12:9866
2025-03-26 02:24:20,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742120_1296 src: /172.20.1.12:55510 dest: /172.20.1.13:9866
2025-03-26 02:24:20,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742120_1296 src: /172.20.1.13:57388 dest: /172.20.1.11:9866
2025-03-26 02:24:20,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44476, dest: /172.20.1.12:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742120_1296, duration(ns): 1472379
2025-03-26 02:24:20,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55510, dest: /172.20.1.13:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742120_1296, duration(ns): 1314204
2025-03-26 02:24:20,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57388, dest: /172.20.1.11:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742120_1296, duration(ns): 1002153
2025-03-26 02:24:20,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742120_1296, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,449 INFO terminating
2025-03-26 02:24:20,449 INFO terminating
2025-03-26 02:24:20,450 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742121_1297, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala._COPYING_
2025-03-26 02:24:20,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742121_1297 src: /172.20.1.10:44490 dest: /172.20.1.12:9866
2025-03-26 02:24:20,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742121_1297 src: /172.20.1.12:54920 dest: /172.20.1.11:9866
2025-03-26 02:24:20,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742121_1297 src: /172.20.1.11:34884 dest: /172.20.1.13:9866
2025-03-26 02:24:20,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34884, dest: /172.20.1.13:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742121_1297, duration(ns): 6578078
2025-03-26 02:24:20,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742121_1297, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44490, dest: /172.20.1.12:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742121_1297, duration(ns): 7427562
2025-03-26 02:24:20,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54920, dest: /172.20.1.11:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742121_1297, duration(ns): 6812570
2025-03-26 02:24:20,464 INFO terminating
2025-03-26 02:24:20,464 INFO terminating
2025-03-26 02:24:20,465 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,468 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742122_1298, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala._COPYING_
2025-03-26 02:24:20,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742122_1298 src: /172.20.1.10:44498 dest: /172.20.1.12:9866
2025-03-26 02:24:20,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742122_1298 src: /172.20.1.12:54924 dest: /172.20.1.11:9866
2025-03-26 02:24:20,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742122_1298 src: /172.20.1.11:34888 dest: /172.20.1.13:9866
2025-03-26 02:24:20,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34888, dest: /172.20.1.13:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742122_1298, duration(ns): 1902557
2025-03-26 02:24:20,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742122_1298, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44498, dest: /172.20.1.12:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742122_1298, duration(ns): 2773849
2025-03-26 02:24:20,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54924, dest: /172.20.1.11:9866, bytes: 2043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742122_1298, duration(ns): 2100303
2025-03-26 02:24:20,474 INFO terminating
2025-03-26 02:24:20,474 INFO terminating
2025-03-26 02:24:20,475 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742123_1299, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala._COPYING_
2025-03-26 02:24:20,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742123_1299 src: /172.20.1.10:44506 dest: /172.20.1.12:9866
2025-03-26 02:24:20,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742123_1299 src: /172.20.1.12:55522 dest: /172.20.1.13:9866
2025-03-26 02:24:20,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742123_1299 src: /172.20.1.13:57392 dest: /172.20.1.11:9866
2025-03-26 02:24:20,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44506, dest: /172.20.1.12:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742123_1299, duration(ns): 1448724
2025-03-26 02:24:20,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55522, dest: /172.20.1.13:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742123_1299, duration(ns): 1231036
2025-03-26 02:24:20,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57392, dest: /172.20.1.11:9866, bytes: 2945, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742123_1299, duration(ns): 1051086
2025-03-26 02:24:20,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742123_1299, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,485 INFO terminating
2025-03-26 02:24:20,486 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,486 INFO terminating
2025-03-26 02:24:20,490 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742124_1300, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala._COPYING_
2025-03-26 02:24:20,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742124_1300 src: /172.20.1.10:44516 dest: /172.20.1.12:9866
2025-03-26 02:24:20,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742124_1300 src: /172.20.1.12:55524 dest: /172.20.1.13:9866
2025-03-26 02:24:20,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742124_1300 src: /172.20.1.13:57408 dest: /172.20.1.11:9866
2025-03-26 02:24:20,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57408, dest: /172.20.1.11:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742124_1300, duration(ns): 762175
2025-03-26 02:24:20,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742124_1300, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44516, dest: /172.20.1.12:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742124_1300, duration(ns): 1330848
2025-03-26 02:24:20,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55524, dest: /172.20.1.13:9866, bytes: 1932, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742124_1300, duration(ns): 1057120
2025-03-26 02:24:20,495 INFO terminating
2025-03-26 02:24:20,495 INFO terminating
2025-03-26 02:24:20,496 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,500 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742125_1301, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala._COPYING_
2025-03-26 02:24:20,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742125_1301 src: /172.20.1.10:57826 dest: /172.20.1.11:9866
2025-03-26 02:24:20,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742125_1301 src: /172.20.1.11:48540 dest: /172.20.1.12:9866
2025-03-26 02:24:20,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742125_1301 src: /172.20.1.12:55530 dest: /172.20.1.13:9866
2025-03-26 02:24:20,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57826, dest: /172.20.1.11:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742125_1301, duration(ns): 1504417
2025-03-26 02:24:20,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48540, dest: /172.20.1.12:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742125_1301, duration(ns): 1263668
2025-03-26 02:24:20,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55530, dest: /172.20.1.13:9866, bytes: 2812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742125_1301, duration(ns): 1025387
2025-03-26 02:24:20,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742125_1301, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,504 INFO terminating
2025-03-26 02:24:20,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,505 INFO terminating
2025-03-26 02:24:20,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742126_1302, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala._COPYING_
2025-03-26 02:24:20,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742126_1302 src: /172.20.1.10:57840 dest: /172.20.1.11:9866
2025-03-26 02:24:20,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742126_1302 src: /172.20.1.11:34892 dest: /172.20.1.13:9866
2025-03-26 02:24:20,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742126_1302 src: /172.20.1.13:38518 dest: /172.20.1.12:9866
2025-03-26 02:24:20,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34892, dest: /172.20.1.13:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742126_1302, duration(ns): 2350755
2025-03-26 02:24:20,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38518, dest: /172.20.1.12:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742126_1302, duration(ns): 825645
2025-03-26 02:24:20,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742126_1302, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,514 INFO terminating
2025-03-26 02:24:20,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57840, dest: /172.20.1.11:9866, bytes: 2076, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742126_1302, duration(ns): 2580123
2025-03-26 02:24:20,515 INFO terminating
2025-03-26 02:24:20,516 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,519 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742127_1303, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala._COPYING_
2025-03-26 02:24:20,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742127_1303 src: /172.20.1.10:57844 dest: /172.20.1.11:9866
2025-03-26 02:24:20,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742127_1303 src: /172.20.1.11:48546 dest: /172.20.1.12:9866
2025-03-26 02:24:20,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742127_1303 src: /172.20.1.12:55542 dest: /172.20.1.13:9866
2025-03-26 02:24:20,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55542, dest: /172.20.1.13:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742127_1303, duration(ns): 869546
2025-03-26 02:24:20,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742127_1303, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,524 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57844, dest: /172.20.1.11:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742127_1303, duration(ns): 1291132
2025-03-26 02:24:20,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48546, dest: /172.20.1.12:9866, bytes: 1871, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742127_1303, duration(ns): 1087430
2025-03-26 02:24:20,524 INFO terminating
2025-03-26 02:24:20,524 INFO terminating
2025-03-26 02:24:20,527 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742128_1304, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_
2025-03-26 02:24:20,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742128_1304 src: /172.20.1.10:57854 dest: /172.20.1.11:9866
2025-03-26 02:24:20,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742128_1304 src: /172.20.1.11:34906 dest: /172.20.1.13:9866
2025-03-26 02:24:20,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742128_1304 src: /172.20.1.13:38522 dest: /172.20.1.12:9866
2025-03-26 02:24:20,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38522, dest: /172.20.1.12:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742128_1304, duration(ns): 886356
2025-03-26 02:24:20,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742128_1304, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57854, dest: /172.20.1.11:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742128_1304, duration(ns): 1297467
2025-03-26 02:24:20,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34906, dest: /172.20.1.13:9866, bytes: 1731, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742128_1304, duration(ns): 1122905
2025-03-26 02:24:20,532 INFO terminating
2025-03-26 02:24:20,532 INFO terminating
2025-03-26 02:24:20,533 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,535 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,536 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742129_1305, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala._COPYING_
2025-03-26 02:24:20,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742129_1305 src: /172.20.1.10:57862 dest: /172.20.1.11:9866
2025-03-26 02:24:20,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742129_1305 src: /172.20.1.11:34918 dest: /172.20.1.13:9866
2025-03-26 02:24:20,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742129_1305 src: /172.20.1.13:38538 dest: /172.20.1.12:9866
2025-03-26 02:24:20,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57862, dest: /172.20.1.11:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742129_1305, duration(ns): 1367855
2025-03-26 02:24:20,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34918, dest: /172.20.1.13:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742129_1305, duration(ns): 1192054
2025-03-26 02:24:20,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38538, dest: /172.20.1.12:9866, bytes: 3592, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742129_1305, duration(ns): 965218
2025-03-26 02:24:20,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742129_1305, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,540 INFO terminating
2025-03-26 02:24:20,540 INFO terminating
2025-03-26 02:24:20,541 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,544 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742130_1306, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala._COPYING_
2025-03-26 02:24:20,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742130_1306 src: /172.20.1.10:51406 dest: /172.20.1.13:9866
2025-03-26 02:24:20,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742130_1306 src: /172.20.1.11:48550 dest: /172.20.1.12:9866
2025-03-26 02:24:20,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742130_1306 src: /172.20.1.13:57418 dest: /172.20.1.11:9866
2025-03-26 02:24:20,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48550, dest: /172.20.1.12:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742130_1306, duration(ns): 572020
2025-03-26 02:24:20,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57418, dest: /172.20.1.11:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742130_1306, duration(ns): 1040183
2025-03-26 02:24:20,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742130_1306, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,549 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51406, dest: /172.20.1.13:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742130_1306, duration(ns): 1827310
2025-03-26 02:24:20,549 INFO terminating
2025-03-26 02:24:20,549 INFO terminating
2025-03-26 02:24:20,553 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742131_1307, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala._COPYING_
2025-03-26 02:24:20,553 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,553 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742131_1307 src: /172.20.1.10:57868 dest: /172.20.1.11:9866
2025-03-26 02:24:20,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742131_1307 src: /172.20.1.11:34926 dest: /172.20.1.13:9866
2025-03-26 02:24:20,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742131_1307 src: /172.20.1.13:38554 dest: /172.20.1.12:9866
2025-03-26 02:24:20,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38554, dest: /172.20.1.12:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742131_1307, duration(ns): 647777
2025-03-26 02:24:20,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742131_1307, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,558 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57868, dest: /172.20.1.11:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742131_1307, duration(ns): 1086283
2025-03-26 02:24:20,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34926, dest: /172.20.1.13:9866, bytes: 2247, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742131_1307, duration(ns): 795878
2025-03-26 02:24:20,558 INFO terminating
2025-03-26 02:24:20,558 INFO terminating
2025-03-26 02:24:20,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742132_1308, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala._COPYING_
2025-03-26 02:24:20,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742132_1308 src: /172.20.1.10:57878 dest: /172.20.1.11:9866
2025-03-26 02:24:20,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742132_1308 src: /172.20.1.11:34932 dest: /172.20.1.13:9866
2025-03-26 02:24:20,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742132_1308 src: /172.20.1.13:38564 dest: /172.20.1.12:9866
2025-03-26 02:24:20,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38564, dest: /172.20.1.12:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742132_1308, duration(ns): 565474
2025-03-26 02:24:20,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742132_1308, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57878, dest: /172.20.1.11:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742132_1308, duration(ns): 1011442
2025-03-26 02:24:20,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34932, dest: /172.20.1.13:9866, bytes: 2527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742132_1308, duration(ns): 742859
2025-03-26 02:24:20,566 INFO terminating
2025-03-26 02:24:20,566 INFO terminating
2025-03-26 02:24:20,567 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742133_1309, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala._COPYING_
2025-03-26 02:24:20,571 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,571 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742133_1309 src: /172.20.1.10:51414 dest: /172.20.1.13:9866
2025-03-26 02:24:20,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742133_1309 src: /172.20.1.13:57424 dest: /172.20.1.11:9866
2025-03-26 02:24:20,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742133_1309 src: /172.20.1.11:48558 dest: /172.20.1.12:9866
2025-03-26 02:24:20,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51414, dest: /172.20.1.13:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742133_1309, duration(ns): 1147673
2025-03-26 02:24:20,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48558, dest: /172.20.1.12:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742133_1309, duration(ns): 650303
2025-03-26 02:24:20,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57424, dest: /172.20.1.11:9866, bytes: 3870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742133_1309, duration(ns): 859725
2025-03-26 02:24:20,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742133_1309, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,575 INFO terminating
2025-03-26 02:24:20,575 INFO terminating
2025-03-26 02:24:20,576 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,579 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742134_1310, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala._COPYING_
2025-03-26 02:24:20,580 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742134_1310 src: /172.20.1.10:51424 dest: /172.20.1.13:9866
2025-03-26 02:24:20,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742134_1310 src: /172.20.1.13:38572 dest: /172.20.1.12:9866
2025-03-26 02:24:20,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742134_1310 src: /172.20.1.12:54930 dest: /172.20.1.11:9866
2025-03-26 02:24:20,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54930, dest: /172.20.1.11:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742134_1310, duration(ns): 7336162
2025-03-26 02:24:20,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51424, dest: /172.20.1.13:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742134_1310, duration(ns): 8091881
2025-03-26 02:24:20,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38572, dest: /172.20.1.12:9866, bytes: 2104, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742134_1310, duration(ns): 7601412
2025-03-26 02:24:20,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742134_1310, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,591 INFO terminating
2025-03-26 02:24:20,592 INFO terminating
2025-03-26 02:24:20,594 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742135_1311, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala._COPYING_
2025-03-26 02:24:20,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742135_1311 src: /172.20.1.10:44532 dest: /172.20.1.12:9866
2025-03-26 02:24:20,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742135_1311 src: /172.20.1.12:55556 dest: /172.20.1.13:9866
2025-03-26 02:24:20,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742135_1311 src: /172.20.1.13:57438 dest: /172.20.1.11:9866
2025-03-26 02:24:20,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55556, dest: /172.20.1.13:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742135_1311, duration(ns): 1050233
2025-03-26 02:24:20,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57438, dest: /172.20.1.11:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742135_1311, duration(ns): 814148
2025-03-26 02:24:20,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742135_1311, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,603 INFO terminating
2025-03-26 02:24:20,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44532, dest: /172.20.1.12:9866, bytes: 1806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742135_1311, duration(ns): 1333523
2025-03-26 02:24:20,604 INFO terminating
2025-03-26 02:24:20,605 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742136_1312, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala._COPYING_
2025-03-26 02:24:20,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742136_1312 src: /172.20.1.10:57882 dest: /172.20.1.11:9866
2025-03-26 02:24:20,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742136_1312 src: /172.20.1.11:48566 dest: /172.20.1.12:9866
2025-03-26 02:24:20,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742136_1312 src: /172.20.1.12:55564 dest: /172.20.1.13:9866
2025-03-26 02:24:20,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48566, dest: /172.20.1.12:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742136_1312, duration(ns): 1682557
2025-03-26 02:24:20,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55564, dest: /172.20.1.13:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742136_1312, duration(ns): 1186851
2025-03-26 02:24:20,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742136_1312, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,614 INFO terminating
2025-03-26 02:24:20,615 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57882, dest: /172.20.1.11:9866, bytes: 2496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742136_1312, duration(ns): 1871506
2025-03-26 02:24:20,615 INFO terminating
2025-03-26 02:24:20,619 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742137_1313, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala._COPYING_
2025-03-26 02:24:20,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,619 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742137_1313 src: /172.20.1.10:44542 dest: /172.20.1.12:9866
2025-03-26 02:24:20,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742137_1313 src: /172.20.1.12:54934 dest: /172.20.1.11:9866
2025-03-26 02:24:20,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742137_1313 src: /172.20.1.11:34938 dest: /172.20.1.13:9866
2025-03-26 02:24:20,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34938, dest: /172.20.1.13:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742137_1313, duration(ns): 1088935
2025-03-26 02:24:20,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742137_1313, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54934, dest: /172.20.1.11:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742137_1313, duration(ns): 1309253
2025-03-26 02:24:20,625 INFO terminating
2025-03-26 02:24:20,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44542, dest: /172.20.1.12:9866, bytes: 2015, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742137_1313, duration(ns): 2084852
2025-03-26 02:24:20,626 INFO terminating
2025-03-26 02:24:20,627 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,631 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742138_1314, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_
2025-03-26 02:24:20,631 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,631 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742138_1314 src: /172.20.1.10:57892 dest: /172.20.1.11:9866
2025-03-26 02:24:20,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742138_1314 src: /172.20.1.11:34942 dest: /172.20.1.13:9866
2025-03-26 02:24:20,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742138_1314 src: /172.20.1.13:38578 dest: /172.20.1.12:9866
2025-03-26 02:24:20,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34942, dest: /172.20.1.13:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742138_1314, duration(ns): 1296909
2025-03-26 02:24:20,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38578, dest: /172.20.1.12:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742138_1314, duration(ns): 1015708
2025-03-26 02:24:20,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742138_1314, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,636 INFO terminating
2025-03-26 02:24:20,637 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57892, dest: /172.20.1.11:9866, bytes: 2806, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742138_1314, duration(ns): 1507251
2025-03-26 02:24:20,637 INFO terminating
2025-03-26 02:24:20,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742139_1315, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala._COPYING_
2025-03-26 02:24:20,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742139_1315 src: /172.20.1.10:44546 dest: /172.20.1.12:9866
2025-03-26 02:24:20,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742139_1315 src: /172.20.1.12:55570 dest: /172.20.1.13:9866
2025-03-26 02:24:20,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742139_1315 src: /172.20.1.13:57448 dest: /172.20.1.11:9866
2025-03-26 02:24:20,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55570, dest: /172.20.1.13:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742139_1315, duration(ns): 1444415
2025-03-26 02:24:20,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57448, dest: /172.20.1.11:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742139_1315, duration(ns): 908049
2025-03-26 02:24:20,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742139_1315, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,654 INFO terminating
2025-03-26 02:24:20,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44546, dest: /172.20.1.12:9866, bytes: 2009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742139_1315, duration(ns): 1710996
2025-03-26 02:24:20,655 INFO terminating
2025-03-26 02:24:20,656 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742140_1316, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala._COPYING_
2025-03-26 02:24:20,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742140_1316 src: /172.20.1.10:57902 dest: /172.20.1.11:9866
2025-03-26 02:24:20,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742140_1316 src: /172.20.1.11:34950 dest: /172.20.1.13:9866
2025-03-26 02:24:20,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742140_1316 src: /172.20.1.13:38580 dest: /172.20.1.12:9866
2025-03-26 02:24:20,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57902, dest: /172.20.1.11:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742140_1316, duration(ns): 1387975
2025-03-26 02:24:20,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34950, dest: /172.20.1.13:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742140_1316, duration(ns): 1176858
2025-03-26 02:24:20,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38580, dest: /172.20.1.12:9866, bytes: 2466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742140_1316, duration(ns): 883920
2025-03-26 02:24:20,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742140_1316, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,672 INFO terminating
2025-03-26 02:24:20,672 INFO terminating
2025-03-26 02:24:20,673 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,677 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742141_1317, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala._COPYING_
2025-03-26 02:24:20,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742141_1317 src: /172.20.1.10:44550 dest: /172.20.1.12:9866
2025-03-26 02:24:20,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742141_1317 src: /172.20.1.12:54948 dest: /172.20.1.11:9866
2025-03-26 02:24:20,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742141_1317 src: /172.20.1.11:34962 dest: /172.20.1.13:9866
2025-03-26 02:24:20,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34962, dest: /172.20.1.13:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742141_1317, duration(ns): 750175
2025-03-26 02:24:20,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54948, dest: /172.20.1.11:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742141_1317, duration(ns): 943781
2025-03-26 02:24:20,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742141_1317, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,682 INFO terminating
2025-03-26 02:24:20,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44550, dest: /172.20.1.12:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742141_1317, duration(ns): 1672522
2025-03-26 02:24:20,683 INFO terminating
2025-03-26 02:24:20,684 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,688 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742142_1318, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala._COPYING_
2025-03-26 02:24:20,688 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,688 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742142_1318 src: /172.20.1.10:44558 dest: /172.20.1.12:9866
2025-03-26 02:24:20,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742142_1318 src: /172.20.1.12:55582 dest: /172.20.1.13:9866
2025-03-26 02:24:20,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742142_1318 src: /172.20.1.13:57460 dest: /172.20.1.11:9866
2025-03-26 02:24:20,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57460, dest: /172.20.1.11:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742142_1318, duration(ns): 1051222
2025-03-26 02:24:20,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742142_1318, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55582, dest: /172.20.1.13:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742142_1318, duration(ns): 1387388
2025-03-26 02:24:20,695 INFO terminating
2025-03-26 02:24:20,696 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44558, dest: /172.20.1.12:9866, bytes: 1586, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742142_1318, duration(ns): 2146183
2025-03-26 02:24:20,696 INFO terminating
2025-03-26 02:24:20,700 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742143_1319, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala._COPYING_
2025-03-26 02:24:20,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742143_1319 src: /172.20.1.10:44566 dest: /172.20.1.12:9866
2025-03-26 02:24:20,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742143_1319 src: /172.20.1.12:55586 dest: /172.20.1.13:9866
2025-03-26 02:24:20,704 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742143_1319 src: /172.20.1.13:57462 dest: /172.20.1.11:9866
2025-03-26 02:24:20,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57462, dest: /172.20.1.11:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742143_1319, duration(ns): 1154746
2025-03-26 02:24:20,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742143_1319, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55586, dest: /172.20.1.13:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742143_1319, duration(ns): 1889508
2025-03-26 02:24:20,708 INFO terminating
2025-03-26 02:24:20,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44566, dest: /172.20.1.12:9866, bytes: 3395, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742143_1319, duration(ns): 2847275
2025-03-26 02:24:20,709 INFO terminating
2025-03-26 02:24:20,710 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,714 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742144_1320, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_
2025-03-26 02:24:20,714 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,714 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742144_1320 src: /172.20.1.10:44568 dest: /172.20.1.12:9866
2025-03-26 02:24:20,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742144_1320 src: /172.20.1.12:54950 dest: /172.20.1.11:9866
2025-03-26 02:24:20,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742144_1320 src: /172.20.1.11:34976 dest: /172.20.1.13:9866
2025-03-26 02:24:20,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34976, dest: /172.20.1.13:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742144_1320, duration(ns): 1096163
2025-03-26 02:24:20,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742144_1320, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54950, dest: /172.20.1.11:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742144_1320, duration(ns): 2003326
2025-03-26 02:24:20,734 INFO terminating
2025-03-26 02:24:20,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44568, dest: /172.20.1.12:9866, bytes: 1691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742144_1320, duration(ns): 13904667
2025-03-26 02:24:20,744 INFO terminating
2025-03-26 02:24:20,745 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1321, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala._COPYING_
2025-03-26 02:24:20,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742145_1321 src: /172.20.1.10:51438 dest: /172.20.1.13:9866
2025-03-26 02:24:20,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742145_1321 src: /172.20.1.13:38594 dest: /172.20.1.12:9866
2025-03-26 02:24:20,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742145_1321 src: /172.20.1.12:54956 dest: /172.20.1.11:9866
2025-03-26 02:24:20,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54956, dest: /172.20.1.11:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742145_1321, duration(ns): 1295829
2025-03-26 02:24:20,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742145_1321, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38594, dest: /172.20.1.12:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742145_1321, duration(ns): 2337411
2025-03-26 02:24:20,763 INFO terminating
2025-03-26 02:24:20,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51438, dest: /172.20.1.13:9866, bytes: 2719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742145_1321, duration(ns): 3944868
2025-03-26 02:24:20,764 INFO terminating
2025-03-26 02:24:20,765 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,770 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1322, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala._COPYING_
2025-03-26 02:24:20,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742146_1322 src: /172.20.1.10:51450 dest: /172.20.1.13:9866
2025-03-26 02:24:20,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742146_1322 src: /172.20.1.13:57472 dest: /172.20.1.11:9866
2025-03-26 02:24:20,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742146_1322 src: /172.20.1.11:48578 dest: /172.20.1.12:9866
2025-03-26 02:24:20,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48578, dest: /172.20.1.12:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742146_1322, duration(ns): 1030272
2025-03-26 02:24:20,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57472, dest: /172.20.1.11:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742146_1322, duration(ns): 1826829
2025-03-26 02:24:20,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742146_1322, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51450, dest: /172.20.1.13:9866, bytes: 1850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742146_1322, duration(ns): 2589341
2025-03-26 02:24:20,779 INFO terminating
2025-03-26 02:24:20,780 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,780 INFO terminating
2025-03-26 02:24:20,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1323, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala._COPYING_
2025-03-26 02:24:20,784 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,784 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742147_1323 src: /172.20.1.10:57918 dest: /172.20.1.11:9866
2025-03-26 02:24:20,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742147_1323 src: /172.20.1.11:48590 dest: /172.20.1.12:9866
2025-03-26 02:24:20,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742147_1323 src: /172.20.1.12:55594 dest: /172.20.1.13:9866
2025-03-26 02:24:20,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55594, dest: /172.20.1.13:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742147_1323, duration(ns): 1308841
2025-03-26 02:24:20,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742147_1323, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48590, dest: /172.20.1.12:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742147_1323, duration(ns): 1674414
2025-03-26 02:24:20,793 INFO terminating
2025-03-26 02:24:20,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57918, dest: /172.20.1.11:9866, bytes: 1763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742147_1323, duration(ns): 2722213
2025-03-26 02:24:20,794 INFO terminating
2025-03-26 02:24:20,795 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1324, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala._COPYING_
2025-03-26 02:24:20,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742148_1324 src: /172.20.1.10:51466 dest: /172.20.1.13:9866
2025-03-26 02:24:20,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742148_1324 src: /172.20.1.13:57488 dest: /172.20.1.11:9866
2025-03-26 02:24:20,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742148_1324 src: /172.20.1.11:48596 dest: /172.20.1.12:9866
2025-03-26 02:24:20,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48596, dest: /172.20.1.12:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742148_1324, duration(ns): 4311235
2025-03-26 02:24:20,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742148_1324, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57488, dest: /172.20.1.11:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742148_1324, duration(ns): 5208499
2025-03-26 02:24:20,822 INFO terminating
2025-03-26 02:24:20,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51466, dest: /172.20.1.13:9866, bytes: 2561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742148_1324, duration(ns): 3397611
2025-03-26 02:24:20,823 INFO terminating
2025-03-26 02:24:20,824 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1325, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala._COPYING_
2025-03-26 02:24:20,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742149_1325 src: /172.20.1.10:57924 dest: /172.20.1.11:9866
2025-03-26 02:24:20,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742149_1325 src: /172.20.1.11:48612 dest: /172.20.1.12:9866
2025-03-26 02:24:20,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742149_1325 src: /172.20.1.12:55602 dest: /172.20.1.13:9866
2025-03-26 02:24:20,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55602, dest: /172.20.1.13:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742149_1325, duration(ns): 1555513
2025-03-26 02:24:20,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742149_1325, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48612, dest: /172.20.1.12:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742149_1325, duration(ns): 1961436
2025-03-26 02:24:20,841 INFO terminating
2025-03-26 02:24:20,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57924, dest: /172.20.1.11:9866, bytes: 7295, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742149_1325, duration(ns): 3160250
2025-03-26 02:24:20,842 INFO terminating
2025-03-26 02:24:20,843 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1326, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala._COPYING_
2025-03-26 02:24:20,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742150_1326 src: /172.20.1.10:57930 dest: /172.20.1.11:9866
2025-03-26 02:24:20,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742150_1326 src: /172.20.1.11:34978 dest: /172.20.1.13:9866
2025-03-26 02:24:20,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742150_1326 src: /172.20.1.13:38606 dest: /172.20.1.12:9866
2025-03-26 02:24:20,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38606, dest: /172.20.1.12:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742150_1326, duration(ns): 1916875
2025-03-26 02:24:20,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742150_1326, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34978, dest: /172.20.1.13:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742150_1326, duration(ns): 3177018
2025-03-26 02:24:20,874 INFO terminating
2025-03-26 02:24:20,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57930, dest: /172.20.1.11:9866, bytes: 4620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742150_1326, duration(ns): 12307619
2025-03-26 02:24:20,876 INFO terminating
2025-03-26 02:24:20,877 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1327, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala._COPYING_
2025-03-26 02:24:20,882 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,882 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742151_1327 src: /172.20.1.10:57946 dest: /172.20.1.11:9866
2025-03-26 02:24:20,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742151_1327 src: /172.20.1.11:34984 dest: /172.20.1.13:9866
2025-03-26 02:24:20,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742151_1327 src: /172.20.1.13:38614 dest: /172.20.1.12:9866
2025-03-26 02:24:20,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34984, dest: /172.20.1.13:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742151_1327, duration(ns): 1255693
2025-03-26 02:24:20,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38614, dest: /172.20.1.12:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742151_1327, duration(ns): 955375
2025-03-26 02:24:20,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742151_1327, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,888 INFO terminating
2025-03-26 02:24:20,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57946, dest: /172.20.1.11:9866, bytes: 3086, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742151_1327, duration(ns): 1693218
2025-03-26 02:24:20,890 INFO terminating
2025-03-26 02:24:20,891 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,896 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1328, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala._COPYING_
2025-03-26 02:24:20,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742152_1328 src: /172.20.1.10:51482 dest: /172.20.1.13:9866
2025-03-26 02:24:20,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742152_1328 src: /172.20.1.12:54964 dest: /172.20.1.11:9866
2025-03-26 02:24:20,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742152_1328 src: /172.20.1.13:38624 dest: /172.20.1.12:9866
2025-03-26 02:24:20,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54964, dest: /172.20.1.11:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742152_1328, duration(ns): 912791
2025-03-26 02:24:20,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38624, dest: /172.20.1.12:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742152_1328, duration(ns): 1549532
2025-03-26 02:24:20,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742152_1328, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,902 INFO terminating
2025-03-26 02:24:20,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51482, dest: /172.20.1.13:9866, bytes: 1798, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742152_1328, duration(ns): 1958313
2025-03-26 02:24:20,903 INFO terminating
2025-03-26 02:24:20,904 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1329, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala._COPYING_
2025-03-26 02:24:20,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742153_1329 src: /172.20.1.10:44580 dest: /172.20.1.12:9866
2025-03-26 02:24:20,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742153_1329 src: /172.20.1.12:55614 dest: /172.20.1.13:9866
2025-03-26 02:24:20,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742153_1329 src: /172.20.1.13:57500 dest: /172.20.1.11:9866
2025-03-26 02:24:20,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55614, dest: /172.20.1.13:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742153_1329, duration(ns): 1608067
2025-03-26 02:24:20,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57500, dest: /172.20.1.11:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742153_1329, duration(ns): 873515
2025-03-26 02:24:20,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742153_1329, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,914 INFO terminating
2025-03-26 02:24:20,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44580, dest: /172.20.1.12:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742153_1329, duration(ns): 1941389
2025-03-26 02:24:20,915 INFO terminating
2025-03-26 02:24:20,916 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1330, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala._COPYING_
2025-03-26 02:24:20,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742154_1330 src: /172.20.1.10:51490 dest: /172.20.1.13:9866
2025-03-26 02:24:20,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742154_1330 src: /172.20.1.13:38632 dest: /172.20.1.12:9866
2025-03-26 02:24:20,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742154_1330 src: /172.20.1.12:54978 dest: /172.20.1.11:9866
2025-03-26 02:24:20,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54978, dest: /172.20.1.11:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742154_1330, duration(ns): 1015178
2025-03-26 02:24:20,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742154_1330, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38632, dest: /172.20.1.12:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742154_1330, duration(ns): 1316608
2025-03-26 02:24:20,926 INFO terminating
2025-03-26 02:24:20,927 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51490, dest: /172.20.1.13:9866, bytes: 1897, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742154_1330, duration(ns): 1645896
2025-03-26 02:24:20,927 INFO terminating
2025-03-26 02:24:20,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1331, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:24:20,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742155_1331 src: /172.20.1.10:57956 dest: /172.20.1.11:9866
2025-03-26 02:24:20,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742155_1331 src: /172.20.1.11:34994 dest: /172.20.1.13:9866
2025-03-26 02:24:20,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742155_1331 src: /172.20.1.13:38636 dest: /172.20.1.12:9866
2025-03-26 02:24:20,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:34994, dest: /172.20.1.13:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742155_1331, duration(ns): 993238
2025-03-26 02:24:20,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38636, dest: /172.20.1.12:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742155_1331, duration(ns): 787644
2025-03-26 02:24:20,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742155_1331, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,942 INFO terminating
2025-03-26 02:24:20,943 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57956, dest: /172.20.1.11:9866, bytes: 2244, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742155_1331, duration(ns): 1331161
2025-03-26 02:24:20,943 INFO terminating
2025-03-26 02:24:20,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,947 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,948 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1332, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala._COPYING_
2025-03-26 02:24:20,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742156_1332 src: /172.20.1.10:51496 dest: /172.20.1.13:9866
2025-03-26 02:24:20,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742156_1332 src: /172.20.1.13:38642 dest: /172.20.1.12:9866
2025-03-26 02:24:20,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742156_1332 src: /172.20.1.12:54992 dest: /172.20.1.11:9866
2025-03-26 02:24:20,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:54992, dest: /172.20.1.11:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742156_1332, duration(ns): 760266
2025-03-26 02:24:20,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742156_1332, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38642, dest: /172.20.1.12:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742156_1332, duration(ns): 1370074
2025-03-26 02:24:20,955 INFO terminating
2025-03-26 02:24:20,957 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51496, dest: /172.20.1.13:9866, bytes: 2265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742156_1332, duration(ns): 2023814
2025-03-26 02:24:20,957 INFO terminating
2025-03-26 02:24:20,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1333, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala._COPYING_
2025-03-26 02:24:20,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742157_1333 src: /172.20.1.10:51504 dest: /172.20.1.13:9866
2025-03-26 02:24:20,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742157_1333 src: /172.20.1.12:55000 dest: /172.20.1.11:9866
2025-03-26 02:24:20,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742157_1333 src: /172.20.1.13:38658 dest: /172.20.1.12:9866
2025-03-26 02:24:20,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55000, dest: /172.20.1.11:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742157_1333, duration(ns): 985876
2025-03-26 02:24:20,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38658, dest: /172.20.1.12:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742157_1333, duration(ns): 1247008
2025-03-26 02:24:20,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742157_1333, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,967 INFO terminating
2025-03-26 02:24:20,968 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51504, dest: /172.20.1.13:9866, bytes: 1632, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742157_1333, duration(ns): 1473173
2025-03-26 02:24:20,968 INFO terminating
2025-03-26 02:24:20,972 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1334, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala._COPYING_
2025-03-26 02:24:20,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742158_1334 src: /172.20.1.10:57972 dest: /172.20.1.11:9866
2025-03-26 02:24:20,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742158_1334 src: /172.20.1.11:48622 dest: /172.20.1.12:9866
2025-03-26 02:24:20,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742158_1334 src: /172.20.1.12:55628 dest: /172.20.1.13:9866
2025-03-26 02:24:20,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48622, dest: /172.20.1.12:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742158_1334, duration(ns): 1575150
2025-03-26 02:24:20,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55628, dest: /172.20.1.13:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742158_1334, duration(ns): 988540
2025-03-26 02:24:20,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742158_1334, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,977 INFO terminating
2025-03-26 02:24:20,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57972, dest: /172.20.1.11:9866, bytes: 5518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742158_1334, duration(ns): 1775162
2025-03-26 02:24:20,978 INFO terminating
2025-03-26 02:24:20,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1335, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala._COPYING_
2025-03-26 02:24:20,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742159_1335 src: /172.20.1.10:51514 dest: /172.20.1.13:9866
2025-03-26 02:24:20,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742159_1335 src: /172.20.1.13:57516 dest: /172.20.1.11:9866
2025-03-26 02:24:20,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742159_1335 src: /172.20.1.11:48632 dest: /172.20.1.12:9866
2025-03-26 02:24:20,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48632, dest: /172.20.1.12:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742159_1335, duration(ns): 670268
2025-03-26 02:24:20,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57516, dest: /172.20.1.11:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742159_1335, duration(ns): 785889
2025-03-26 02:24:20,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742159_1335, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,986 INFO terminating
2025-03-26 02:24:20,987 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51514, dest: /172.20.1.13:9866, bytes: 2545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742159_1335, duration(ns): 1066333
2025-03-26 02:24:20,987 INFO terminating
2025-03-26 02:24:20,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1336, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala._COPYING_
2025-03-26 02:24:20,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:20,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742160_1336 src: /172.20.1.10:57974 dest: /172.20.1.11:9866
2025-03-26 02:24:20,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742160_1336 src: /172.20.1.11:48634 dest: /172.20.1.12:9866
2025-03-26 02:24:20,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742160_1336 src: /172.20.1.12:55638 dest: /172.20.1.13:9866
2025-03-26 02:24:20,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55638, dest: /172.20.1.13:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742160_1336, duration(ns): 763442
2025-03-26 02:24:20,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742160_1336, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:20,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48634, dest: /172.20.1.12:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742160_1336, duration(ns): 1354207
2025-03-26 02:24:20,997 INFO terminating
2025-03-26 02:24:20,998 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:20,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57974, dest: /172.20.1.11:9866, bytes: 4168, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742160_1336, duration(ns): 1813737
2025-03-26 02:24:20,998 INFO terminating
2025-03-26 02:24:21,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1337, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala._COPYING_
2025-03-26 02:24:21,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742161_1337 src: /172.20.1.10:51516 dest: /172.20.1.13:9866
2025-03-26 02:24:21,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742161_1337 src: /172.20.1.13:38662 dest: /172.20.1.12:9866
2025-03-26 02:24:21,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742161_1337 src: /172.20.1.12:55006 dest: /172.20.1.11:9866
2025-03-26 02:24:21,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55006, dest: /172.20.1.11:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742161_1337, duration(ns): 1047394
2025-03-26 02:24:21,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742161_1337, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51516, dest: /172.20.1.13:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742161_1337, duration(ns): 1619954
2025-03-26 02:24:21,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38662, dest: /172.20.1.12:9866, bytes: 14023, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742161_1337, duration(ns): 1334305
2025-03-26 02:24:21,016 INFO terminating
2025-03-26 02:24:21,016 INFO terminating
2025-03-26 02:24:21,017 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1338, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala._COPYING_
2025-03-26 02:24:21,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742162_1338 src: /172.20.1.10:51524 dest: /172.20.1.13:9866
2025-03-26 02:24:21,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742162_1338 src: /172.20.1.13:38676 dest: /172.20.1.12:9866
2025-03-26 02:24:21,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742162_1338 src: /172.20.1.12:55016 dest: /172.20.1.11:9866
2025-03-26 02:24:21,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55016, dest: /172.20.1.11:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742162_1338, duration(ns): 761279
2025-03-26 02:24:21,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742162_1338, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51524, dest: /172.20.1.13:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742162_1338, duration(ns): 1448172
2025-03-26 02:24:21,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38676, dest: /172.20.1.12:9866, bytes: 1678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742162_1338, duration(ns): 930095
2025-03-26 02:24:21,026 INFO terminating
2025-03-26 02:24:21,027 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,027 INFO terminating
2025-03-26 02:24:21,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1339, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala._COPYING_
2025-03-26 02:24:21,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742163_1339 src: /172.20.1.10:51536 dest: /172.20.1.13:9866
2025-03-26 02:24:21,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742163_1339 src: /172.20.1.13:38686 dest: /172.20.1.12:9866
2025-03-26 02:24:21,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742163_1339 src: /172.20.1.12:55024 dest: /172.20.1.11:9866
2025-03-26 02:24:21,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51536, dest: /172.20.1.13:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742163_1339, duration(ns): 1492033
2025-03-26 02:24:21,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55024, dest: /172.20.1.11:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742163_1339, duration(ns): 921667
2025-03-26 02:24:21,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38686, dest: /172.20.1.12:9866, bytes: 2282, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742163_1339, duration(ns): 1097876
2025-03-26 02:24:21,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742163_1339, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,036 INFO terminating
2025-03-26 02:24:21,036 INFO terminating
2025-03-26 02:24:21,037 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,041 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1340, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala._COPYING_
2025-03-26 02:24:21,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742164_1340 src: /172.20.1.10:51544 dest: /172.20.1.13:9866
2025-03-26 02:24:21,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742164_1340 src: /172.20.1.13:38690 dest: /172.20.1.12:9866
2025-03-26 02:24:21,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742164_1340 src: /172.20.1.12:55028 dest: /172.20.1.11:9866
2025-03-26 02:24:21,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55028, dest: /172.20.1.11:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742164_1340, duration(ns): 757579
2025-03-26 02:24:21,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742164_1340, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51544, dest: /172.20.1.13:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742164_1340, duration(ns): 1448146
2025-03-26 02:24:21,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38690, dest: /172.20.1.12:9866, bytes: 1783, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742164_1340, duration(ns): 897721
2025-03-26 02:24:21,046 INFO terminating
2025-03-26 02:24:21,046 INFO terminating
2025-03-26 02:24:21,047 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,050 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,051 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1341, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala._COPYING_
2025-03-26 02:24:21,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742165_1341 src: /172.20.1.10:44582 dest: /172.20.1.12:9866
2025-03-26 02:24:21,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742165_1341 src: /172.20.1.12:55030 dest: /172.20.1.11:9866
2025-03-26 02:24:21,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742165_1341 src: /172.20.1.11:35010 dest: /172.20.1.13:9866
2025-03-26 02:24:21,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44582, dest: /172.20.1.12:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742165_1341, duration(ns): 1318681
2025-03-26 02:24:21,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35010, dest: /172.20.1.13:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742165_1341, duration(ns): 870118
2025-03-26 02:24:21,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55030, dest: /172.20.1.11:9866, bytes: 1870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742165_1341, duration(ns): 1084962
2025-03-26 02:24:21,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742165_1341, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,055 INFO terminating
2025-03-26 02:24:21,055 INFO terminating
2025-03-26 02:24:21,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1342, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala._COPYING_
2025-03-26 02:24:21,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742166_1342 src: /172.20.1.10:44594 dest: /172.20.1.12:9866
2025-03-26 02:24:21,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742166_1342 src: /172.20.1.12:55032 dest: /172.20.1.11:9866
2025-03-26 02:24:21,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742166_1342 src: /172.20.1.11:35016 dest: /172.20.1.13:9866
2025-03-26 02:24:21,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35016, dest: /172.20.1.13:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742166_1342, duration(ns): 3645287
2025-03-26 02:24:21,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742166_1342, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55032, dest: /172.20.1.11:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742166_1342, duration(ns): 4243630
2025-03-26 02:24:21,072 INFO terminating
2025-03-26 02:24:21,073 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44594, dest: /172.20.1.12:9866, bytes: 2102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742166_1342, duration(ns): 4663926
2025-03-26 02:24:21,073 INFO terminating
2025-03-26 02:24:21,077 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1343, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala._COPYING_
2025-03-26 02:24:21,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742167_1343 src: /172.20.1.10:44610 dest: /172.20.1.12:9866
2025-03-26 02:24:21,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742167_1343 src: /172.20.1.12:55648 dest: /172.20.1.13:9866
2025-03-26 02:24:21,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742167_1343 src: /172.20.1.13:57532 dest: /172.20.1.11:9866
2025-03-26 02:24:21,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55648, dest: /172.20.1.13:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742167_1343, duration(ns): 896102
2025-03-26 02:24:21,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57532, dest: /172.20.1.11:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742167_1343, duration(ns): 683830
2025-03-26 02:24:21,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742167_1343, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,082 INFO terminating
2025-03-26 02:24:21,083 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44610, dest: /172.20.1.12:9866, bytes: 3703, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742167_1343, duration(ns): 1200624
2025-03-26 02:24:21,083 INFO terminating
2025-03-26 02:24:21,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1344, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala._COPYING_
2025-03-26 02:24:21,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742168_1344 src: /172.20.1.10:57986 dest: /172.20.1.11:9866
2025-03-26 02:24:21,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742168_1344 src: /172.20.1.11:48646 dest: /172.20.1.12:9866
2025-03-26 02:24:21,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742168_1344 src: /172.20.1.12:55658 dest: /172.20.1.13:9866
2025-03-26 02:24:21,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55658, dest: /172.20.1.13:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742168_1344, duration(ns): 767477
2025-03-26 02:24:21,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742168_1344, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48646, dest: /172.20.1.12:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742168_1344, duration(ns): 1002455
2025-03-26 02:24:21,094 INFO terminating
2025-03-26 02:24:21,095 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57986, dest: /172.20.1.11:9866, bytes: 10364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742168_1344, duration(ns): 1785587
2025-03-26 02:24:21,095 INFO terminating
2025-03-26 02:24:21,100 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1345, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala._COPYING_
2025-03-26 02:24:21,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742169_1345 src: /172.20.1.10:57990 dest: /172.20.1.11:9866
2025-03-26 02:24:21,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742169_1345 src: /172.20.1.11:35030 dest: /172.20.1.13:9866
2025-03-26 02:24:21,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742169_1345 src: /172.20.1.13:38698 dest: /172.20.1.12:9866
2025-03-26 02:24:21,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35030, dest: /172.20.1.13:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742169_1345, duration(ns): 2031486
2025-03-26 02:24:21,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38698, dest: /172.20.1.12:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742169_1345, duration(ns): 1437688
2025-03-26 02:24:21,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742169_1345, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,106 INFO terminating
2025-03-26 02:24:21,107 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57990, dest: /172.20.1.11:9866, bytes: 1716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742169_1345, duration(ns): 2326523
2025-03-26 02:24:21,107 INFO terminating
2025-03-26 02:24:21,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1346, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala._COPYING_
2025-03-26 02:24:21,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742170_1346 src: /172.20.1.10:57996 dest: /172.20.1.11:9866
2025-03-26 02:24:21,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742170_1346 src: /172.20.1.11:35040 dest: /172.20.1.13:9866
2025-03-26 02:24:21,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742170_1346 src: /172.20.1.13:38700 dest: /172.20.1.12:9866
2025-03-26 02:24:21,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35040, dest: /172.20.1.13:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742170_1346, duration(ns): 1681653
2025-03-26 02:24:21,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38700, dest: /172.20.1.12:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742170_1346, duration(ns): 1135139
2025-03-26 02:24:21,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742170_1346, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,117 INFO terminating
2025-03-26 02:24:21,118 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:57996, dest: /172.20.1.11:9866, bytes: 3448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742170_1346, duration(ns): 1936718
2025-03-26 02:24:21,118 INFO terminating
2025-03-26 02:24:21,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1347, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala._COPYING_
2025-03-26 02:24:21,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742171_1347 src: /172.20.1.10:44626 dest: /172.20.1.12:9866
2025-03-26 02:24:21,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742171_1347 src: /172.20.1.12:55034 dest: /172.20.1.11:9866
2025-03-26 02:24:21,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742171_1347 src: /172.20.1.11:35048 dest: /172.20.1.13:9866
2025-03-26 02:24:21,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35048, dest: /172.20.1.13:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742171_1347, duration(ns): 1134137
2025-03-26 02:24:21,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55034, dest: /172.20.1.11:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742171_1347, duration(ns): 1301376
2025-03-26 02:24:21,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742171_1347, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,128 INFO terminating
2025-03-26 02:24:21,129 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44626, dest: /172.20.1.12:9866, bytes: 3691, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742171_1347, duration(ns): 1534247
2025-03-26 02:24:21,129 INFO terminating
2025-03-26 02:24:21,135 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1348, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala._COPYING_
2025-03-26 02:24:21,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742172_1348 src: /172.20.1.10:44630 dest: /172.20.1.12:9866
2025-03-26 02:24:21,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742172_1348 src: /172.20.1.12:55670 dest: /172.20.1.13:9866
2025-03-26 02:24:21,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742172_1348 src: /172.20.1.13:57546 dest: /172.20.1.11:9866
2025-03-26 02:24:21,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57546, dest: /172.20.1.11:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742172_1348, duration(ns): 2581911
2025-03-26 02:24:21,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742172_1348, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44630, dest: /172.20.1.12:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742172_1348, duration(ns): 3088964
2025-03-26 02:24:21,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55670, dest: /172.20.1.13:9866, bytes: 1758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742172_1348, duration(ns): 2792008
2025-03-26 02:24:21,142 INFO terminating
2025-03-26 02:24:21,142 INFO terminating
2025-03-26 02:24:21,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742173_1349, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala._COPYING_
2025-03-26 02:24:21,147 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,147 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742173_1349 src: /172.20.1.10:58000 dest: /172.20.1.11:9866
2025-03-26 02:24:21,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742173_1349 src: /172.20.1.11:35064 dest: /172.20.1.13:9866
2025-03-26 02:24:21,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742173_1349 src: /172.20.1.13:38712 dest: /172.20.1.12:9866
2025-03-26 02:24:21,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38712, dest: /172.20.1.12:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742173_1349, duration(ns): 988423
2025-03-26 02:24:21,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742173_1349, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58000, dest: /172.20.1.11:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742173_1349, duration(ns): 2312859
2025-03-26 02:24:21,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35064, dest: /172.20.1.13:9866, bytes: 1658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742173_1349, duration(ns): 1565147
2025-03-26 02:24:21,153 INFO terminating
2025-03-26 02:24:21,153 INFO terminating
2025-03-26 02:24:21,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,160 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742174_1350, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala._COPYING_
2025-03-26 02:24:21,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742174_1350 src: /172.20.1.10:58010 dest: /172.20.1.11:9866
2025-03-26 02:24:21,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742174_1350 src: /172.20.1.11:35080 dest: /172.20.1.13:9866
2025-03-26 02:24:21,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742174_1350 src: /172.20.1.13:38718 dest: /172.20.1.12:9866
2025-03-26 02:24:21,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38718, dest: /172.20.1.12:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742174_1350, duration(ns): 811909
2025-03-26 02:24:21,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742174_1350, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35080, dest: /172.20.1.13:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742174_1350, duration(ns): 1369087
2025-03-26 02:24:21,166 INFO terminating
2025-03-26 02:24:21,167 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58010, dest: /172.20.1.11:9866, bytes: 3110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742174_1350, duration(ns): 2047056
2025-03-26 02:24:21,167 INFO terminating
2025-03-26 02:24:21,171 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742175_1351, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala._COPYING_
2025-03-26 02:24:21,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742175_1351 src: /172.20.1.10:58016 dest: /172.20.1.11:9866
2025-03-26 02:24:21,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742175_1351 src: /172.20.1.11:48660 dest: /172.20.1.12:9866
2025-03-26 02:24:21,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742175_1351 src: /172.20.1.12:55676 dest: /172.20.1.13:9866
2025-03-26 02:24:21,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48660, dest: /172.20.1.12:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742175_1351, duration(ns): 1378149
2025-03-26 02:24:21,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55676, dest: /172.20.1.13:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742175_1351, duration(ns): 830839
2025-03-26 02:24:21,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742175_1351, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,176 INFO terminating
2025-03-26 02:24:21,177 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58016, dest: /172.20.1.11:9866, bytes: 1917, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742175_1351, duration(ns): 1990484
2025-03-26 02:24:21,177 INFO terminating
2025-03-26 02:24:21,181 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742176_1352, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala._COPYING_
2025-03-26 02:24:21,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742176_1352 src: /172.20.1.10:58020 dest: /172.20.1.11:9866
2025-03-26 02:24:21,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742176_1352 src: /172.20.1.11:35084 dest: /172.20.1.13:9866
2025-03-26 02:24:21,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742176_1352 src: /172.20.1.13:38732 dest: /172.20.1.12:9866
2025-03-26 02:24:21,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38732, dest: /172.20.1.12:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742176_1352, duration(ns): 651159
2025-03-26 02:24:21,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742176_1352, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58020, dest: /172.20.1.11:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742176_1352, duration(ns): 1983147
2025-03-26 02:24:21,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35084, dest: /172.20.1.13:9866, bytes: 4235, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742176_1352, duration(ns): 1375544
2025-03-26 02:24:21,186 INFO terminating
2025-03-26 02:24:21,187 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,187 INFO terminating
2025-03-26 02:24:21,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742177_1353, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala._COPYING_
2025-03-26 02:24:21,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,194 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742177_1353 src: /172.20.1.10:58030 dest: /172.20.1.11:9866
2025-03-26 02:24:21,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742177_1353 src: /172.20.1.11:48666 dest: /172.20.1.12:9866
2025-03-26 02:24:21,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742177_1353 src: /172.20.1.12:55690 dest: /172.20.1.13:9866
2025-03-26 02:24:21,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55690, dest: /172.20.1.13:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742177_1353, duration(ns): 734893
2025-03-26 02:24:21,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742177_1353, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58030, dest: /172.20.1.11:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742177_1353, duration(ns): 1951230
2025-03-26 02:24:21,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48666, dest: /172.20.1.12:9866, bytes: 1797, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742177_1353, duration(ns): 1305580
2025-03-26 02:24:21,201 INFO terminating
2025-03-26 02:24:21,201 INFO terminating
2025-03-26 02:24:21,202 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742178_1354, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala._COPYING_
2025-03-26 02:24:21,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742178_1354 src: /172.20.1.10:58042 dest: /172.20.1.11:9866
2025-03-26 02:24:21,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742178_1354 src: /172.20.1.11:35094 dest: /172.20.1.13:9866
2025-03-26 02:24:21,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742178_1354 src: /172.20.1.13:38740 dest: /172.20.1.12:9866
2025-03-26 02:24:21,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38740, dest: /172.20.1.12:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742178_1354, duration(ns): 4502701
2025-03-26 02:24:21,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742178_1354, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35094, dest: /172.20.1.13:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742178_1354, duration(ns): 6726608
2025-03-26 02:24:21,217 INFO terminating
2025-03-26 02:24:21,220 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58042, dest: /172.20.1.11:9866, bytes: 3337, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742178_1354, duration(ns): 7689553
2025-03-26 02:24:21,220 INFO terminating
2025-03-26 02:24:21,224 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742179_1355, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala._COPYING_
2025-03-26 02:24:21,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742179_1355 src: /172.20.1.10:58048 dest: /172.20.1.11:9866
2025-03-26 02:24:21,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742179_1355 src: /172.20.1.11:48676 dest: /172.20.1.12:9866
2025-03-26 02:24:21,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742179_1355 src: /172.20.1.12:55700 dest: /172.20.1.13:9866
2025-03-26 02:24:21,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55700, dest: /172.20.1.13:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742179_1355, duration(ns): 1961635
2025-03-26 02:24:21,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742179_1355, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48676, dest: /172.20.1.12:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742179_1355, duration(ns): 2678418
2025-03-26 02:24:21,231 INFO terminating
2025-03-26 02:24:21,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58048, dest: /172.20.1.11:9866, bytes: 1516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742179_1355, duration(ns): 3450735
2025-03-26 02:24:21,232 INFO terminating
2025-03-26 02:24:21,233 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,236 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742180_1356, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala._COPYING_
2025-03-26 02:24:21,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742180_1356 src: /172.20.1.10:51546 dest: /172.20.1.13:9866
2025-03-26 02:24:21,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742180_1356 src: /172.20.1.13:57562 dest: /172.20.1.11:9866
2025-03-26 02:24:21,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742180_1356 src: /172.20.1.11:48678 dest: /172.20.1.12:9866
2025-03-26 02:24:21,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48678, dest: /172.20.1.12:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742180_1356, duration(ns): 2336371
2025-03-26 02:24:21,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57562, dest: /172.20.1.11:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742180_1356, duration(ns): 2948304
2025-03-26 02:24:21,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742180_1356, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,243 INFO terminating
2025-03-26 02:24:21,244 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51546, dest: /172.20.1.13:9866, bytes: 2475, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742180_1356, duration(ns): 3266321
2025-03-26 02:24:21,244 INFO terminating
2025-03-26 02:24:21,248 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742181_1357, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala._COPYING_
2025-03-26 02:24:21,248 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,248 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742181_1357 src: /172.20.1.10:51552 dest: /172.20.1.13:9866
2025-03-26 02:24:21,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742181_1357 src: /172.20.1.12:55042 dest: /172.20.1.11:9866
2025-03-26 02:24:21,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742181_1357 src: /172.20.1.13:38756 dest: /172.20.1.12:9866
2025-03-26 02:24:21,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55042, dest: /172.20.1.11:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742181_1357, duration(ns): 654285
2025-03-26 02:24:21,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38756, dest: /172.20.1.12:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742181_1357, duration(ns): 1130219
2025-03-26 02:24:21,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742181_1357, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51552, dest: /172.20.1.13:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742181_1357, duration(ns): 1725499
2025-03-26 02:24:21,254 INFO terminating
2025-03-26 02:24:21,254 INFO terminating
2025-03-26 02:24:21,255 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,258 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742182_1358, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala._COPYING_
2025-03-26 02:24:21,258 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,258 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742182_1358 src: /172.20.1.10:51560 dest: /172.20.1.13:9866
2025-03-26 02:24:21,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742182_1358 src: /172.20.1.13:38770 dest: /172.20.1.12:9866
2025-03-26 02:24:21,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742182_1358 src: /172.20.1.12:55052 dest: /172.20.1.11:9866
2025-03-26 02:24:21,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55052, dest: /172.20.1.11:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742182_1358, duration(ns): 1351474
2025-03-26 02:24:21,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742182_1358, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51560, dest: /172.20.1.13:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742182_1358, duration(ns): 2514685
2025-03-26 02:24:21,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38770, dest: /172.20.1.12:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742182_1358, duration(ns): 1900931
2025-03-26 02:24:21,266 INFO terminating
2025-03-26 02:24:21,266 INFO terminating
2025-03-26 02:24:21,267 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742183_1359, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala._COPYING_
2025-03-26 02:24:21,270 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,270 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742183_1359 src: /172.20.1.10:51566 dest: /172.20.1.13:9866
2025-03-26 02:24:21,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742183_1359 src: /172.20.1.13:57564 dest: /172.20.1.11:9866
2025-03-26 02:24:21,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742183_1359 src: /172.20.1.11:48682 dest: /172.20.1.12:9866
2025-03-26 02:24:21,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48682, dest: /172.20.1.12:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742183_1359, duration(ns): 2614053
2025-03-26 02:24:21,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742183_1359, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57564, dest: /172.20.1.11:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742183_1359, duration(ns): 3364881
2025-03-26 02:24:21,277 INFO terminating
2025-03-26 02:24:21,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51566, dest: /172.20.1.13:9866, bytes: 1955, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742183_1359, duration(ns): 4433393
2025-03-26 02:24:21,278 INFO terminating
2025-03-26 02:24:21,281 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,285 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742184_1360, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala._COPYING_
2025-03-26 02:24:21,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742184_1360 src: /172.20.1.10:51582 dest: /172.20.1.13:9866
2025-03-26 02:24:21,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742184_1360 src: /172.20.1.13:57578 dest: /172.20.1.11:9866
2025-03-26 02:24:21,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742184_1360 src: /172.20.1.11:48696 dest: /172.20.1.12:9866
2025-03-26 02:24:21,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48696, dest: /172.20.1.12:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742184_1360, duration(ns): 718764
2025-03-26 02:24:21,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57578, dest: /172.20.1.11:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742184_1360, duration(ns): 1308977
2025-03-26 02:24:21,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742184_1360, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,302 INFO terminating
2025-03-26 02:24:21,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51582, dest: /172.20.1.13:9866, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742184_1360, duration(ns): 1973389
2025-03-26 02:24:21,303 INFO terminating
2025-03-26 02:24:21,304 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742185_1361, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala._COPYING_
2025-03-26 02:24:21,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742185_1361 src: /172.20.1.10:51596 dest: /172.20.1.13:9866
2025-03-26 02:24:21,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742185_1361 src: /172.20.1.13:38776 dest: /172.20.1.12:9866
2025-03-26 02:24:21,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742185_1361 src: /172.20.1.12:55060 dest: /172.20.1.11:9866
2025-03-26 02:24:21,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55060, dest: /172.20.1.11:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742185_1361, duration(ns): 678826
2025-03-26 02:24:21,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742185_1361, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51596, dest: /172.20.1.13:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742185_1361, duration(ns): 1832722
2025-03-26 02:24:21,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38776, dest: /172.20.1.12:9866, bytes: 3097, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742185_1361, duration(ns): 1237335
2025-03-26 02:24:21,314 INFO terminating
2025-03-26 02:24:21,315 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,315 INFO terminating
2025-03-26 02:24:21,322 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742186_1362, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala._COPYING_
2025-03-26 02:24:21,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742186_1362 src: /172.20.1.10:51602 dest: /172.20.1.13:9866
2025-03-26 02:24:21,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742186_1362 src: /172.20.1.13:57584 dest: /172.20.1.11:9866
2025-03-26 02:24:21,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742186_1362 src: /172.20.1.11:48708 dest: /172.20.1.12:9866
2025-03-26 02:24:21,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48708, dest: /172.20.1.12:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742186_1362, duration(ns): 756666
2025-03-26 02:24:21,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742186_1362, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57584, dest: /172.20.1.11:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742186_1362, duration(ns): 2476353
2025-03-26 02:24:21,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51602, dest: /172.20.1.13:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742186_1362, duration(ns): 4308270
2025-03-26 02:24:21,331 INFO terminating
2025-03-26 02:24:21,331 INFO terminating
2025-03-26 02:24:21,332 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742187_1363, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_
2025-03-26 02:24:21,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742187_1363 src: /172.20.1.10:51618 dest: /172.20.1.13:9866
2025-03-26 02:24:21,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742187_1363 src: /172.20.1.13:57586 dest: /172.20.1.11:9866
2025-03-26 02:24:21,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742187_1363 src: /172.20.1.11:48716 dest: /172.20.1.12:9866
2025-03-26 02:24:21,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48716, dest: /172.20.1.12:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742187_1363, duration(ns): 562247
2025-03-26 02:24:21,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742187_1363, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57586, dest: /172.20.1.11:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742187_1363, duration(ns): 2756633
2025-03-26 02:24:21,345 INFO terminating
2025-03-26 02:24:21,346 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51618, dest: /172.20.1.13:9866, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742187_1363, duration(ns): 4972616
2025-03-26 02:24:21,346 INFO terminating
2025-03-26 02:24:21,350 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742188_1364, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala._COPYING_
2025-03-26 02:24:21,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742188_1364 src: /172.20.1.10:51626 dest: /172.20.1.13:9866
2025-03-26 02:24:21,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742188_1364 src: /172.20.1.13:38792 dest: /172.20.1.12:9866
2025-03-26 02:24:21,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742188_1364 src: /172.20.1.12:55066 dest: /172.20.1.11:9866
2025-03-26 02:24:21,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55066, dest: /172.20.1.11:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742188_1364, duration(ns): 623443
2025-03-26 02:24:21,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742188_1364, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51626, dest: /172.20.1.13:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742188_1364, duration(ns): 3756227
2025-03-26 02:24:21,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38792, dest: /172.20.1.12:9866, bytes: 2161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742188_1364, duration(ns): 1949792
2025-03-26 02:24:21,359 INFO terminating
2025-03-26 02:24:21,360 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,360 INFO terminating
2025-03-26 02:24:21,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742189_1365, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala._COPYING_
2025-03-26 02:24:21,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742189_1365 src: /172.20.1.10:58056 dest: /172.20.1.11:9866
2025-03-26 02:24:21,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742189_1365 src: /172.20.1.11:48728 dest: /172.20.1.12:9866
2025-03-26 02:24:21,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742189_1365 src: /172.20.1.12:55708 dest: /172.20.1.13:9866
2025-03-26 02:24:21,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55708, dest: /172.20.1.13:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742189_1365, duration(ns): 693969
2025-03-26 02:24:21,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742189_1365, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48728, dest: /172.20.1.12:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742189_1365, duration(ns): 1211365
2025-03-26 02:24:21,369 INFO terminating
2025-03-26 02:24:21,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58056, dest: /172.20.1.11:9866, bytes: 1879, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742189_1365, duration(ns): 2234537
2025-03-26 02:24:21,371 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,371 INFO terminating
2025-03-26 02:24:21,374 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742190_1366, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala._COPYING_
2025-03-26 02:24:21,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742190_1366 src: /172.20.1.10:58068 dest: /172.20.1.11:9866
2025-03-26 02:24:21,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742190_1366 src: /172.20.1.11:35102 dest: /172.20.1.13:9866
2025-03-26 02:24:21,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742190_1366 src: /172.20.1.13:38798 dest: /172.20.1.12:9866
2025-03-26 02:24:21,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38798, dest: /172.20.1.12:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742190_1366, duration(ns): 633416
2025-03-26 02:24:21,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742190_1366, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35102, dest: /172.20.1.13:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742190_1366, duration(ns): 8328406
2025-03-26 02:24:21,387 INFO terminating
2025-03-26 02:24:21,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58068, dest: /172.20.1.11:9866, bytes: 1567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742190_1366, duration(ns): 9311460
2025-03-26 02:24:21,395 INFO terminating
2025-03-26 02:24:21,396 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,399 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742191_1367, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala._COPYING_
2025-03-26 02:24:21,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742191_1367 src: /172.20.1.10:58078 dest: /172.20.1.11:9866
2025-03-26 02:24:21,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742191_1367 src: /172.20.1.11:48740 dest: /172.20.1.12:9866
2025-03-26 02:24:21,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742191_1367 src: /172.20.1.12:55710 dest: /172.20.1.13:9866
2025-03-26 02:24:21,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55710, dest: /172.20.1.13:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742191_1367, duration(ns): 668674
2025-03-26 02:24:21,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742191_1367, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48740, dest: /172.20.1.12:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742191_1367, duration(ns): 2438914
2025-03-26 02:24:21,407 INFO terminating
2025-03-26 02:24:21,410 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58078, dest: /172.20.1.11:9866, bytes: 6378, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742191_1367, duration(ns): 4283414
2025-03-26 02:24:21,410 INFO terminating
2025-03-26 02:24:21,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,415 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742192_1368, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala._COPYING_
2025-03-26 02:24:21,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742192_1368 src: /172.20.1.10:58090 dest: /172.20.1.11:9866
2025-03-26 02:24:21,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742192_1368 src: /172.20.1.11:35112 dest: /172.20.1.13:9866
2025-03-26 02:24:21,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742192_1368 src: /172.20.1.13:38810 dest: /172.20.1.12:9866
2025-03-26 02:24:21,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38810, dest: /172.20.1.12:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742192_1368, duration(ns): 622092
2025-03-26 02:24:21,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742192_1368, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35112, dest: /172.20.1.13:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742192_1368, duration(ns): 2526967
2025-03-26 02:24:21,422 INFO terminating
2025-03-26 02:24:21,427 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58090, dest: /172.20.1.11:9866, bytes: 3699, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742192_1368, duration(ns): 3179625
2025-03-26 02:24:21,427 INFO terminating
2025-03-26 02:24:21,430 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742193_1369, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala._COPYING_
2025-03-26 02:24:21,430 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,430 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742193_1369 src: /172.20.1.10:58106 dest: /172.20.1.11:9866
2025-03-26 02:24:21,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742193_1369 src: /172.20.1.11:35124 dest: /172.20.1.13:9866
2025-03-26 02:24:21,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742193_1369 src: /172.20.1.13:38826 dest: /172.20.1.12:9866
2025-03-26 02:24:21,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38826, dest: /172.20.1.12:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742193_1369, duration(ns): 636450
2025-03-26 02:24:21,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742193_1369, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35124, dest: /172.20.1.13:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742193_1369, duration(ns): 3466516
2025-03-26 02:24:21,440 INFO terminating
2025-03-26 02:24:21,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58106, dest: /172.20.1.11:9866, bytes: 2875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742193_1369, duration(ns): 6405138
2025-03-26 02:24:21,444 INFO terminating
2025-03-26 02:24:21,445 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742194_1370, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala._COPYING_
2025-03-26 02:24:21,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742194_1370 src: /172.20.1.10:44636 dest: /172.20.1.12:9866
2025-03-26 02:24:21,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742194_1370 src: /172.20.1.12:55722 dest: /172.20.1.13:9866
2025-03-26 02:24:21,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742194_1370 src: /172.20.1.13:57596 dest: /172.20.1.11:9866
2025-03-26 02:24:21,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57596, dest: /172.20.1.11:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742194_1370, duration(ns): 2557048
2025-03-26 02:24:21,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742194_1370, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55722, dest: /172.20.1.13:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742194_1370, duration(ns): 5118239
2025-03-26 02:24:21,461 INFO terminating
2025-03-26 02:24:21,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44636, dest: /172.20.1.12:9866, bytes: 2214, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742194_1370, duration(ns): 6565315
2025-03-26 02:24:21,465 INFO terminating
2025-03-26 02:24:21,466 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742195_1371, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala._COPYING_
2025-03-26 02:24:21,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742195_1371 src: /172.20.1.10:44650 dest: /172.20.1.12:9866
2025-03-26 02:24:21,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742195_1371 src: /172.20.1.12:55068 dest: /172.20.1.11:9866
2025-03-26 02:24:21,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742195_1371 src: /172.20.1.11:35140 dest: /172.20.1.13:9866
2025-03-26 02:24:21,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35140, dest: /172.20.1.13:9866, bytes: 1721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742195_1371, duration(ns): 839320
2025-03-26 02:24:21,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742195_1371, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55068, dest: /172.20.1.11:9866, bytes: 1721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742195_1371, duration(ns): 8807759
2025-03-26 02:24:21,484 INFO terminating
2025-03-26 02:24:21,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44650, dest: /172.20.1.12:9866, bytes: 1721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742195_1371, duration(ns): 9584413
2025-03-26 02:24:21,485 INFO terminating
2025-03-26 02:24:21,486 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,489 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742196_1372, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala._COPYING_
2025-03-26 02:24:21,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742196_1372 src: /172.20.1.10:51634 dest: /172.20.1.13:9866
2025-03-26 02:24:21,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742196_1372 src: /172.20.1.13:38840 dest: /172.20.1.12:9866
2025-03-26 02:24:21,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742196_1372 src: /172.20.1.12:55078 dest: /172.20.1.11:9866
2025-03-26 02:24:21,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55078, dest: /172.20.1.11:9866, bytes: 2906, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742196_1372, duration(ns): 1067104
2025-03-26 02:24:21,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742196_1372, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38840, dest: /172.20.1.12:9866, bytes: 2906, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742196_1372, duration(ns): 2259502
2025-03-26 02:24:21,502 INFO terminating
2025-03-26 02:24:21,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51634, dest: /172.20.1.13:9866, bytes: 2906, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742196_1372, duration(ns): 3031551
2025-03-26 02:24:21,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,505 INFO terminating
2025-03-26 02:24:21,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742197_1373, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala._COPYING_
2025-03-26 02:24:21,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742197_1373 src: /172.20.1.10:44652 dest: /172.20.1.12:9866
2025-03-26 02:24:21,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742197_1373 src: /172.20.1.12:55734 dest: /172.20.1.13:9866
2025-03-26 02:24:21,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742197_1373 src: /172.20.1.13:57604 dest: /172.20.1.11:9866
2025-03-26 02:24:21,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57604, dest: /172.20.1.11:9866, bytes: 2064, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742197_1373, duration(ns): 859324
2025-03-26 02:24:21,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742197_1373, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55734, dest: /172.20.1.13:9866, bytes: 2064, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742197_1373, duration(ns): 1429889
2025-03-26 02:24:21,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44652, dest: /172.20.1.12:9866, bytes: 2064, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742197_1373, duration(ns): 3488297
2025-03-26 02:24:21,522 INFO terminating
2025-03-26 02:24:21,522 INFO terminating
2025-03-26 02:24:21,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,533 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,534 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742198_1374, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala._COPYING_
2025-03-26 02:24:21,534 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742198_1374 src: /172.20.1.10:58122 dest: /172.20.1.11:9866
2025-03-26 02:24:21,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742198_1374 src: /172.20.1.11:48754 dest: /172.20.1.12:9866
2025-03-26 02:24:21,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742198_1374 src: /172.20.1.12:55738 dest: /172.20.1.13:9866
2025-03-26 02:24:21,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55738, dest: /172.20.1.13:9866, bytes: 1918, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742198_1374, duration(ns): 2170991
2025-03-26 02:24:21,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742198_1374, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48754, dest: /172.20.1.12:9866, bytes: 1918, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742198_1374, duration(ns): 3445966
2025-03-26 02:24:21,546 INFO terminating
2025-03-26 02:24:21,547 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58122, dest: /172.20.1.11:9866, bytes: 1918, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742198_1374, duration(ns): 5189447
2025-03-26 02:24:21,547 INFO terminating
2025-03-26 02:24:21,550 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742199_1375, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala._COPYING_
2025-03-26 02:24:21,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742199_1375 src: /172.20.1.10:58128 dest: /172.20.1.11:9866
2025-03-26 02:24:21,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742199_1375 src: /172.20.1.11:35146 dest: /172.20.1.13:9866
2025-03-26 02:24:21,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742199_1375 src: /172.20.1.13:38852 dest: /172.20.1.12:9866
2025-03-26 02:24:21,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38852, dest: /172.20.1.12:9866, bytes: 1695, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742199_1375, duration(ns): 771828
2025-03-26 02:24:21,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742199_1375, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35146, dest: /172.20.1.13:9866, bytes: 1695, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742199_1375, duration(ns): 966913
2025-03-26 02:24:21,559 INFO terminating
2025-03-26 02:24:21,560 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58128, dest: /172.20.1.11:9866, bytes: 1695, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742199_1375, duration(ns): 4419262
2025-03-26 02:24:21,560 INFO terminating
2025-03-26 02:24:21,564 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742200_1376, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala._COPYING_
2025-03-26 02:24:21,564 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,564 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742200_1376 src: /172.20.1.10:44658 dest: /172.20.1.12:9866
2025-03-26 02:24:21,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742200_1376 src: /172.20.1.12:55086 dest: /172.20.1.11:9866
2025-03-26 02:24:21,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742200_1376 src: /172.20.1.11:35158 dest: /172.20.1.13:9866
2025-03-26 02:24:21,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35158, dest: /172.20.1.13:9866, bytes: 1851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742200_1376, duration(ns): 775361
2025-03-26 02:24:21,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55086, dest: /172.20.1.11:9866, bytes: 1851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742200_1376, duration(ns): 2297244
2025-03-26 02:24:21,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742200_1376, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,571 INFO terminating
2025-03-26 02:24:21,572 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44658, dest: /172.20.1.12:9866, bytes: 1851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742200_1376, duration(ns): 3033397
2025-03-26 02:24:21,572 INFO terminating
2025-03-26 02:24:21,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742201_1377, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala._COPYING_
2025-03-26 02:24:21,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,576 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742201_1377 src: /172.20.1.10:58132 dest: /172.20.1.11:9866
2025-03-26 02:24:21,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742201_1377 src: /172.20.1.11:48758 dest: /172.20.1.12:9866
2025-03-26 02:24:21,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742201_1377 src: /172.20.1.12:55746 dest: /172.20.1.13:9866
2025-03-26 02:24:21,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48758, dest: /172.20.1.12:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742201_1377, duration(ns): 1231788
2025-03-26 02:24:21,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55746, dest: /172.20.1.13:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742201_1377, duration(ns): 704732
2025-03-26 02:24:21,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742201_1377, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,581 INFO terminating
2025-03-26 02:24:21,583 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58132, dest: /172.20.1.11:9866, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742201_1377, duration(ns): 1988501
2025-03-26 02:24:21,583 INFO terminating
2025-03-26 02:24:21,587 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742202_1378, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala._COPYING_
2025-03-26 02:24:21,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,587 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742202_1378 src: /172.20.1.10:51636 dest: /172.20.1.13:9866
2025-03-26 02:24:21,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742202_1378 src: /172.20.1.13:38864 dest: /172.20.1.12:9866
2025-03-26 02:24:21,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742202_1378 src: /172.20.1.12:55096 dest: /172.20.1.11:9866
2025-03-26 02:24:21,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55096, dest: /172.20.1.11:9866, bytes: 1822, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742202_1378, duration(ns): 2028402
2025-03-26 02:24:21,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38864, dest: /172.20.1.12:9866, bytes: 1822, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742202_1378, duration(ns): 2533144
2025-03-26 02:24:21,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742202_1378, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,593 INFO terminating
2025-03-26 02:24:21,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51636, dest: /172.20.1.13:9866, bytes: 1822, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742202_1378, duration(ns): 1638675
2025-03-26 02:24:21,594 INFO terminating
2025-03-26 02:24:21,595 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742203_1379, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala._COPYING_
2025-03-26 02:24:21,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742203_1379 src: /172.20.1.10:58140 dest: /172.20.1.11:9866
2025-03-26 02:24:21,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742203_1379 src: /172.20.1.11:48774 dest: /172.20.1.12:9866
2025-03-26 02:24:21,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742203_1379 src: /172.20.1.12:55750 dest: /172.20.1.13:9866
2025-03-26 02:24:21,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55750, dest: /172.20.1.13:9866, bytes: 2248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742203_1379, duration(ns): 1002991
2025-03-26 02:24:21,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742203_1379, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48774, dest: /172.20.1.12:9866, bytes: 2248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742203_1379, duration(ns): 2063107
2025-03-26 02:24:21,605 INFO terminating
2025-03-26 02:24:21,606 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58140, dest: /172.20.1.11:9866, bytes: 2248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742203_1379, duration(ns): 2378289
2025-03-26 02:24:21,606 INFO terminating
2025-03-26 02:24:21,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,610 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742204_1380, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala._COPYING_
2025-03-26 02:24:21,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742204_1380 src: /172.20.1.10:44674 dest: /172.20.1.12:9866
2025-03-26 02:24:21,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742204_1380 src: /172.20.1.12:55106 dest: /172.20.1.11:9866
2025-03-26 02:24:21,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742204_1380 src: /172.20.1.11:35174 dest: /172.20.1.13:9866
2025-03-26 02:24:21,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35174, dest: /172.20.1.13:9866, bytes: 3245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742204_1380, duration(ns): 892785
2025-03-26 02:24:21,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742204_1380, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55106, dest: /172.20.1.11:9866, bytes: 3245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742204_1380, duration(ns): 1535862
2025-03-26 02:24:21,618 INFO terminating
2025-03-26 02:24:21,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44674, dest: /172.20.1.12:9866, bytes: 3245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742204_1380, duration(ns): 2454859
2025-03-26 02:24:21,619 INFO terminating
2025-03-26 02:24:21,620 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,630 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742205_1381, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:24:21,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742205_1381 src: /172.20.1.10:58154 dest: /172.20.1.11:9866
2025-03-26 02:24:21,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742205_1381 src: /172.20.1.11:48788 dest: /172.20.1.12:9866
2025-03-26 02:24:21,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742205_1381 src: /172.20.1.12:55758 dest: /172.20.1.13:9866
2025-03-26 02:24:21,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48788, dest: /172.20.1.12:9866, bytes: 3465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742205_1381, duration(ns): 2014849
2025-03-26 02:24:21,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55758, dest: /172.20.1.13:9866, bytes: 3465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742205_1381, duration(ns): 1265977
2025-03-26 02:24:21,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742205_1381, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,637 INFO terminating
2025-03-26 02:24:21,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58154, dest: /172.20.1.11:9866, bytes: 3465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742205_1381, duration(ns): 2353014
2025-03-26 02:24:21,638 INFO terminating
2025-03-26 02:24:21,639 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742206_1382, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala._COPYING_
2025-03-26 02:24:21,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742206_1382 src: /172.20.1.10:51642 dest: /172.20.1.13:9866
2025-03-26 02:24:21,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742206_1382 src: /172.20.1.13:57608 dest: /172.20.1.11:9866
2025-03-26 02:24:21,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742206_1382 src: /172.20.1.11:48794 dest: /172.20.1.12:9866
2025-03-26 02:24:21,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48794, dest: /172.20.1.12:9866, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742206_1382, duration(ns): 1233350
2025-03-26 02:24:21,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742206_1382, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57608, dest: /172.20.1.11:9866, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742206_1382, duration(ns): 1424718
2025-03-26 02:24:21,653 INFO terminating
2025-03-26 02:24:21,654 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51642, dest: /172.20.1.13:9866, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742206_1382, duration(ns): 1765207
2025-03-26 02:24:21,654 INFO terminating
2025-03-26 02:24:21,660 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,660 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742207_1383, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala._COPYING_
2025-03-26 02:24:21,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742207_1383 src: /172.20.1.10:58168 dest: /172.20.1.11:9866
2025-03-26 02:24:21,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742207_1383 src: /172.20.1.11:35186 dest: /172.20.1.13:9866
2025-03-26 02:24:21,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742207_1383 src: /172.20.1.13:38870 dest: /172.20.1.12:9866
2025-03-26 02:24:21,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38870, dest: /172.20.1.12:9866, bytes: 3111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742207_1383, duration(ns): 1254263
2025-03-26 02:24:21,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742207_1383, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35186, dest: /172.20.1.13:9866, bytes: 3111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742207_1383, duration(ns): 1506486
2025-03-26 02:24:21,672 INFO terminating
2025-03-26 02:24:21,673 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58168, dest: /172.20.1.11:9866, bytes: 3111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742207_1383, duration(ns): 2388585
2025-03-26 02:24:21,673 INFO terminating
2025-03-26 02:24:21,680 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742208_1384, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala._COPYING_
2025-03-26 02:24:21,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742208_1384 src: /172.20.1.10:51658 dest: /172.20.1.13:9866
2025-03-26 02:24:21,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742208_1384 src: /172.20.1.13:57620 dest: /172.20.1.11:9866
2025-03-26 02:24:21,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742208_1384 src: /172.20.1.11:48800 dest: /172.20.1.12:9866
2025-03-26 02:24:21,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48800, dest: /172.20.1.12:9866, bytes: 2167, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742208_1384, duration(ns): 15798092
2025-03-26 02:24:21,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742208_1384, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57620, dest: /172.20.1.11:9866, bytes: 2167, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742208_1384, duration(ns): 7123558
2025-03-26 02:24:21,735 INFO terminating
2025-03-26 02:24:21,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51658, dest: /172.20.1.13:9866, bytes: 2167, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742208_1384, duration(ns): 16765249
2025-03-26 02:24:21,736 INFO terminating
2025-03-26 02:24:21,737 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,741 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742209_1385, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala._COPYING_
2025-03-26 02:24:21,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742209_1385 src: /172.20.1.10:58170 dest: /172.20.1.11:9866
2025-03-26 02:24:21,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742209_1385 src: /172.20.1.11:35202 dest: /172.20.1.13:9866
2025-03-26 02:24:21,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742209_1385 src: /172.20.1.13:38884 dest: /172.20.1.12:9866
2025-03-26 02:24:21,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38884, dest: /172.20.1.12:9866, bytes: 2408, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742209_1385, duration(ns): 893687
2025-03-26 02:24:21,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742209_1385, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35202, dest: /172.20.1.13:9866, bytes: 2408, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742209_1385, duration(ns): 1378414
2025-03-26 02:24:21,750 INFO terminating
2025-03-26 02:24:21,751 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58170, dest: /172.20.1.11:9866, bytes: 2408, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742209_1385, duration(ns): 1626244
2025-03-26 02:24:21,751 INFO terminating
2025-03-26 02:24:21,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,757 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742210_1386, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala._COPYING_
2025-03-26 02:24:21,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742210_1386 src: /172.20.1.10:58178 dest: /172.20.1.11:9866
2025-03-26 02:24:21,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742210_1386 src: /172.20.1.11:35204 dest: /172.20.1.13:9866
2025-03-26 02:24:21,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742210_1386 src: /172.20.1.13:38892 dest: /172.20.1.12:9866
2025-03-26 02:24:21,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35204, dest: /172.20.1.13:9866, bytes: 2005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742210_1386, duration(ns): 932564
2025-03-26 02:24:21,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38892, dest: /172.20.1.12:9866, bytes: 2005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742210_1386, duration(ns): 645954
2025-03-26 02:24:21,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742210_1386, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,762 INFO terminating
2025-03-26 02:24:21,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58178, dest: /172.20.1.11:9866, bytes: 2005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742210_1386, duration(ns): 1175296
2025-03-26 02:24:21,763 INFO terminating
2025-03-26 02:24:21,764 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742211_1387, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala._COPYING_
2025-03-26 02:24:21,768 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,768 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742211_1387 src: /172.20.1.10:58194 dest: /172.20.1.11:9866
2025-03-26 02:24:21,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742211_1387 src: /172.20.1.11:35218 dest: /172.20.1.13:9866
2025-03-26 02:24:21,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742211_1387 src: /172.20.1.13:38906 dest: /172.20.1.12:9866
2025-03-26 02:24:21,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35218, dest: /172.20.1.13:9866, bytes: 3423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742211_1387, duration(ns): 858422
2025-03-26 02:24:21,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38906, dest: /172.20.1.12:9866, bytes: 3423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742211_1387, duration(ns): 670324
2025-03-26 02:24:21,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742211_1387, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,772 INFO terminating
2025-03-26 02:24:21,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58194, dest: /172.20.1.11:9866, bytes: 3423, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742211_1387, duration(ns): 1093332
2025-03-26 02:24:21,773 INFO terminating
2025-03-26 02:24:21,779 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742212_1388, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala._COPYING_
2025-03-26 02:24:21,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742212_1388 src: /172.20.1.10:44688 dest: /172.20.1.12:9866
2025-03-26 02:24:21,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742212_1388 src: /172.20.1.12:55120 dest: /172.20.1.11:9866
2025-03-26 02:24:21,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742212_1388 src: /172.20.1.11:35234 dest: /172.20.1.13:9866
2025-03-26 02:24:21,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35234, dest: /172.20.1.13:9866, bytes: 9724, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742212_1388, duration(ns): 834196
2025-03-26 02:24:21,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742212_1388, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44688, dest: /172.20.1.12:9866, bytes: 9724, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742212_1388, duration(ns): 1866792
2025-03-26 02:24:21,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55120, dest: /172.20.1.11:9866, bytes: 9724, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742212_1388, duration(ns): 1043299
2025-03-26 02:24:21,787 INFO terminating
2025-03-26 02:24:21,787 INFO terminating
2025-03-26 02:24:21,788 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742213_1389, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala._COPYING_
2025-03-26 02:24:21,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742213_1389 src: /172.20.1.10:51660 dest: /172.20.1.13:9866
2025-03-26 02:24:21,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742213_1389 src: /172.20.1.13:57632 dest: /172.20.1.11:9866
2025-03-26 02:24:21,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742213_1389 src: /172.20.1.11:48812 dest: /172.20.1.12:9866
2025-03-26 02:24:21,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48812, dest: /172.20.1.12:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742213_1389, duration(ns): 804576
2025-03-26 02:24:21,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742213_1389, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51660, dest: /172.20.1.13:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742213_1389, duration(ns): 2055812
2025-03-26 02:24:21,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57632, dest: /172.20.1.11:9866, bytes: 1881, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742213_1389, duration(ns): 982789
2025-03-26 02:24:21,798 INFO terminating
2025-03-26 02:24:21,798 INFO terminating
2025-03-26 02:24:21,799 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742214_1390, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala._COPYING_
2025-03-26 02:24:21,802 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,802 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742214_1390 src: /172.20.1.10:58204 dest: /172.20.1.11:9866
2025-03-26 02:24:21,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742214_1390 src: /172.20.1.11:48826 dest: /172.20.1.12:9866
2025-03-26 02:24:21,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742214_1390 src: /172.20.1.12:55762 dest: /172.20.1.13:9866
2025-03-26 02:24:21,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48826, dest: /172.20.1.12:9866, bytes: 1730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742214_1390, duration(ns): 2395321
2025-03-26 02:24:21,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55762, dest: /172.20.1.13:9866, bytes: 1730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742214_1390, duration(ns): 1544930
2025-03-26 02:24:21,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742214_1390, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,815 INFO terminating
2025-03-26 02:24:21,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58204, dest: /172.20.1.11:9866, bytes: 1730, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742214_1390, duration(ns): 2537178
2025-03-26 02:24:21,816 INFO terminating
2025-03-26 02:24:21,817 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,820 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742215_1391, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala._COPYING_
2025-03-26 02:24:21,820 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,820 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,822 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742215_1391 src: /172.20.1.10:58216 dest: /172.20.1.11:9866
2025-03-26 02:24:21,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742215_1391 src: /172.20.1.11:35250 dest: /172.20.1.13:9866
2025-03-26 02:24:21,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742215_1391 src: /172.20.1.13:38908 dest: /172.20.1.12:9866
2025-03-26 02:24:21,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38908, dest: /172.20.1.12:9866, bytes: 2185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742215_1391, duration(ns): 2976984
2025-03-26 02:24:21,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742215_1391, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58216, dest: /172.20.1.11:9866, bytes: 2185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742215_1391, duration(ns): 1664962
2025-03-26 02:24:21,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35250, dest: /172.20.1.13:9866, bytes: 2185, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742215_1391, duration(ns): 3324410
2025-03-26 02:24:21,838 INFO terminating
2025-03-26 02:24:21,839 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,839 INFO terminating
2025-03-26 02:24:21,843 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742216_1392, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala._COPYING_
2025-03-26 02:24:21,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742216_1392 src: /172.20.1.10:51662 dest: /172.20.1.13:9866
2025-03-26 02:24:21,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742216_1392 src: /172.20.1.13:57640 dest: /172.20.1.11:9866
2025-03-26 02:24:21,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742216_1392 src: /172.20.1.11:48842 dest: /172.20.1.12:9866
2025-03-26 02:24:21,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48842, dest: /172.20.1.12:9866, bytes: 1283, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742216_1392, duration(ns): 952739
2025-03-26 02:24:21,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742216_1392, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,850 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51662, dest: /172.20.1.13:9866, bytes: 1283, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742216_1392, duration(ns): 1863360
2025-03-26 02:24:21,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57640, dest: /172.20.1.11:9866, bytes: 1283, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742216_1392, duration(ns): 1202538
2025-03-26 02:24:21,850 INFO terminating
2025-03-26 02:24:21,850 INFO terminating
2025-03-26 02:24:21,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742217_1393, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala._COPYING_
2025-03-26 02:24:21,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742217_1393 src: /172.20.1.10:44696 dest: /172.20.1.12:9866
2025-03-26 02:24:21,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742217_1393 src: /172.20.1.11:35258 dest: /172.20.1.13:9866
2025-03-26 02:24:21,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742217_1393 src: /172.20.1.12:55126 dest: /172.20.1.11:9866
2025-03-26 02:24:21,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35258, dest: /172.20.1.13:9866, bytes: 4111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742217_1393, duration(ns): 843906
2025-03-26 02:24:21,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742217_1393, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44696, dest: /172.20.1.12:9866, bytes: 4111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742217_1393, duration(ns): 2078246
2025-03-26 02:24:21,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55126, dest: /172.20.1.11:9866, bytes: 4111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742217_1393, duration(ns): 1464075
2025-03-26 02:24:21,861 INFO terminating
2025-03-26 02:24:21,861 INFO terminating
2025-03-26 02:24:21,862 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742218_1394, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala._COPYING_
2025-03-26 02:24:21,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742218_1394 src: /172.20.1.10:58222 dest: /172.20.1.11:9866
2025-03-26 02:24:21,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742218_1394 src: /172.20.1.11:35270 dest: /172.20.1.13:9866
2025-03-26 02:24:21,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742218_1394 src: /172.20.1.13:38916 dest: /172.20.1.12:9866
2025-03-26 02:24:21,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35270, dest: /172.20.1.13:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742218_1394, duration(ns): 996795
2025-03-26 02:24:21,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38916, dest: /172.20.1.12:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742218_1394, duration(ns): 792667
2025-03-26 02:24:21,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742218_1394, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,874 INFO terminating
2025-03-26 02:24:21,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58222, dest: /172.20.1.11:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742218_1394, duration(ns): 1372907
2025-03-26 02:24:21,875 INFO terminating
2025-03-26 02:24:21,876 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,880 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742219_1395, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala._COPYING_
2025-03-26 02:24:21,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742219_1395 src: /172.20.1.10:58234 dest: /172.20.1.11:9866
2025-03-26 02:24:21,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742219_1395 src: /172.20.1.11:48858 dest: /172.20.1.12:9866
2025-03-26 02:24:21,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742219_1395 src: /172.20.1.12:55772 dest: /172.20.1.13:9866
2025-03-26 02:24:21,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55772, dest: /172.20.1.13:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742219_1395, duration(ns): 793967
2025-03-26 02:24:21,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742219_1395, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58234, dest: /172.20.1.11:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742219_1395, duration(ns): 1233862
2025-03-26 02:24:21,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48858, dest: /172.20.1.12:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742219_1395, duration(ns): 973786
2025-03-26 02:24:21,885 INFO terminating
2025-03-26 02:24:21,886 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,886 INFO terminating
2025-03-26 02:24:21,889 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742220_1396, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala._COPYING_
2025-03-26 02:24:21,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742220_1396 src: /172.20.1.10:58238 dest: /172.20.1.11:9866
2025-03-26 02:24:21,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742220_1396 src: /172.20.1.11:35286 dest: /172.20.1.13:9866
2025-03-26 02:24:21,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742220_1396 src: /172.20.1.13:38928 dest: /172.20.1.12:9866
2025-03-26 02:24:21,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38928, dest: /172.20.1.12:9866, bytes: 4039, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742220_1396, duration(ns): 521506
2025-03-26 02:24:21,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742220_1396, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58238, dest: /172.20.1.11:9866, bytes: 4039, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742220_1396, duration(ns): 923610
2025-03-26 02:24:21,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35286, dest: /172.20.1.13:9866, bytes: 4039, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742220_1396, duration(ns): 762588
2025-03-26 02:24:21,894 INFO terminating
2025-03-26 02:24:21,894 INFO terminating
2025-03-26 02:24:21,895 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,898 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742221_1397, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala._COPYING_
2025-03-26 02:24:21,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742221_1397 src: /172.20.1.10:44708 dest: /172.20.1.12:9866
2025-03-26 02:24:21,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742221_1397 src: /172.20.1.11:35288 dest: /172.20.1.13:9866
2025-03-26 02:24:21,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742221_1397 src: /172.20.1.12:55142 dest: /172.20.1.11:9866
2025-03-26 02:24:21,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35288, dest: /172.20.1.13:9866, bytes: 2469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742221_1397, duration(ns): 585373
2025-03-26 02:24:21,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742221_1397, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44708, dest: /172.20.1.12:9866, bytes: 2469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742221_1397, duration(ns): 1385182
2025-03-26 02:24:21,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55142, dest: /172.20.1.11:9866, bytes: 2469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742221_1397, duration(ns): 763502
2025-03-26 02:24:21,902 INFO terminating
2025-03-26 02:24:21,902 INFO terminating
2025-03-26 02:24:21,903 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,906 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742222_1398, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala._COPYING_
2025-03-26 02:24:21,906 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,906 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742222_1398 src: /172.20.1.10:44716 dest: /172.20.1.12:9866
2025-03-26 02:24:21,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742222_1398 src: /172.20.1.12:55782 dest: /172.20.1.13:9866
2025-03-26 02:24:21,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742222_1398 src: /172.20.1.13:57652 dest: /172.20.1.11:9866
2025-03-26 02:24:21,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55782, dest: /172.20.1.13:9866, bytes: 2159, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742222_1398, duration(ns): 1015015
2025-03-26 02:24:21,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57652, dest: /172.20.1.11:9866, bytes: 2159, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742222_1398, duration(ns): 510441
2025-03-26 02:24:21,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742222_1398, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,910 INFO terminating
2025-03-26 02:24:21,911 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44716, dest: /172.20.1.12:9866, bytes: 2159, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742222_1398, duration(ns): 1525067
2025-03-26 02:24:21,911 INFO terminating
2025-03-26 02:24:21,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742223_1399, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala._COPYING_
2025-03-26 02:24:21,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742223_1399 src: /172.20.1.10:51664 dest: /172.20.1.13:9866
2025-03-26 02:24:21,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742223_1399 src: /172.20.1.13:38932 dest: /172.20.1.12:9866
2025-03-26 02:24:21,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742223_1399 src: /172.20.1.12:55146 dest: /172.20.1.11:9866
2025-03-26 02:24:21,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55146, dest: /172.20.1.11:9866, bytes: 4648, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742223_1399, duration(ns): 1245734
2025-03-26 02:24:21,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38932, dest: /172.20.1.12:9866, bytes: 4648, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742223_1399, duration(ns): 1493243
2025-03-26 02:24:21,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742223_1399, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,919 INFO terminating
2025-03-26 02:24:21,920 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51664, dest: /172.20.1.13:9866, bytes: 4648, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742223_1399, duration(ns): 1741575
2025-03-26 02:24:21,920 INFO terminating
2025-03-26 02:24:21,925 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742224_1400, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala._COPYING_
2025-03-26 02:24:21,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742224_1400 src: /172.20.1.10:51670 dest: /172.20.1.13:9866
2025-03-26 02:24:21,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742224_1400 src: /172.20.1.12:55150 dest: /172.20.1.11:9866
2025-03-26 02:24:21,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742224_1400 src: /172.20.1.13:38934 dest: /172.20.1.12:9866
2025-03-26 02:24:21,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51670, dest: /172.20.1.13:9866, bytes: 2705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742224_1400, duration(ns): 1011167
2025-03-26 02:24:21,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55150, dest: /172.20.1.11:9866, bytes: 2705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742224_1400, duration(ns): 725500
2025-03-26 02:24:21,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38934, dest: /172.20.1.12:9866, bytes: 2705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742224_1400, duration(ns): 830561
2025-03-26 02:24:21,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742224_1400, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,929 INFO terminating
2025-03-26 02:24:21,929 INFO terminating
2025-03-26 02:24:21,930 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742225_1401, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_
2025-03-26 02:24:21,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742225_1401 src: /172.20.1.10:51686 dest: /172.20.1.13:9866
2025-03-26 02:24:21,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742225_1401 src: /172.20.1.13:38942 dest: /172.20.1.12:9866
2025-03-26 02:24:21,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742225_1401 src: /172.20.1.12:55162 dest: /172.20.1.11:9866
2025-03-26 02:24:21,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55162, dest: /172.20.1.11:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742225_1401, duration(ns): 682758
2025-03-26 02:24:21,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38942, dest: /172.20.1.12:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742225_1401, duration(ns): 831116
2025-03-26 02:24:21,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742225_1401, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,936 INFO terminating
2025-03-26 02:24:21,937 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51686, dest: /172.20.1.13:9866, bytes: 1791, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742225_1401, duration(ns): 1012984
2025-03-26 02:24:21,937 INFO terminating
2025-03-26 02:24:21,940 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742226_1402, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala._COPYING_
2025-03-26 02:24:21,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742226_1402 src: /172.20.1.10:44722 dest: /172.20.1.12:9866
2025-03-26 02:24:21,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742226_1402 src: /172.20.1.12:55790 dest: /172.20.1.13:9866
2025-03-26 02:24:21,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742226_1402 src: /172.20.1.13:57668 dest: /172.20.1.11:9866
2025-03-26 02:24:21,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57668, dest: /172.20.1.11:9866, bytes: 1842, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742226_1402, duration(ns): 2821652
2025-03-26 02:24:21,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742226_1402, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44722, dest: /172.20.1.12:9866, bytes: 1842, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742226_1402, duration(ns): 3211564
2025-03-26 02:24:21,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55790, dest: /172.20.1.13:9866, bytes: 1842, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742226_1402, duration(ns): 3034863
2025-03-26 02:24:21,946 INFO terminating
2025-03-26 02:24:21,946 INFO terminating
2025-03-26 02:24:21,950 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742227_1403, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala._COPYING_
2025-03-26 02:24:21,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742227_1403 src: /172.20.1.10:58244 dest: /172.20.1.11:9866
2025-03-26 02:24:21,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742227_1403 src: /172.20.1.11:48870 dest: /172.20.1.12:9866
2025-03-26 02:24:21,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742227_1403 src: /172.20.1.12:55792 dest: /172.20.1.13:9866
2025-03-26 02:24:21,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55792, dest: /172.20.1.13:9866, bytes: 1669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742227_1403, duration(ns): 536716
2025-03-26 02:24:21,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742227_1403, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,958 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58244, dest: /172.20.1.11:9866, bytes: 1669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742227_1403, duration(ns): 870392
2025-03-26 02:24:21,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48870, dest: /172.20.1.12:9866, bytes: 1669, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742227_1403, duration(ns): 731293
2025-03-26 02:24:21,958 INFO terminating
2025-03-26 02:24:21,958 INFO terminating
2025-03-26 02:24:21,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742228_1404, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala._COPYING_
2025-03-26 02:24:21,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742228_1404 src: /172.20.1.10:44738 dest: /172.20.1.12:9866
2025-03-26 02:24:21,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742228_1404 src: /172.20.1.11:35302 dest: /172.20.1.13:9866
2025-03-26 02:24:21,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742228_1404 src: /172.20.1.12:55178 dest: /172.20.1.11:9866
2025-03-26 02:24:21,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35302, dest: /172.20.1.13:9866, bytes: 1920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742228_1404, duration(ns): 680105
2025-03-26 02:24:21,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44738, dest: /172.20.1.12:9866, bytes: 1920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742228_1404, duration(ns): 1088138
2025-03-26 02:24:21,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55178, dest: /172.20.1.11:9866, bytes: 1920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742228_1404, duration(ns): 826471
2025-03-26 02:24:21,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742228_1404, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,969 INFO terminating
2025-03-26 02:24:21,969 INFO terminating
2025-03-26 02:24:21,970 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742229_1405, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala._COPYING_
2025-03-26 02:24:21,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742229_1405 src: /172.20.1.10:44750 dest: /172.20.1.12:9866
2025-03-26 02:24:21,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742229_1405 src: /172.20.1.11:35316 dest: /172.20.1.13:9866
2025-03-26 02:24:21,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742229_1405 src: /172.20.1.12:55194 dest: /172.20.1.11:9866
2025-03-26 02:24:21,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35316, dest: /172.20.1.13:9866, bytes: 5351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742229_1405, duration(ns): 678550
2025-03-26 02:24:21,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742229_1405, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,979 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44750, dest: /172.20.1.12:9866, bytes: 5351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742229_1405, duration(ns): 1144171
2025-03-26 02:24:21,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55194, dest: /172.20.1.11:9866, bytes: 5351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742229_1405, duration(ns): 944378
2025-03-26 02:24:21,979 INFO terminating
2025-03-26 02:24:21,979 INFO terminating
2025-03-26 02:24:21,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742230_1406, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala._COPYING_
2025-03-26 02:24:21,983 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,983 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742230_1406 src: /172.20.1.10:44752 dest: /172.20.1.12:9866
2025-03-26 02:24:21,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742230_1406 src: /172.20.1.11:35318 dest: /172.20.1.13:9866
2025-03-26 02:24:21,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742230_1406 src: /172.20.1.12:55206 dest: /172.20.1.11:9866
2025-03-26 02:24:21,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35318, dest: /172.20.1.13:9866, bytes: 3444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742230_1406, duration(ns): 654495
2025-03-26 02:24:21,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742230_1406, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,987 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44752, dest: /172.20.1.12:9866, bytes: 3444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742230_1406, duration(ns): 1074405
2025-03-26 02:24:21,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55206, dest: /172.20.1.11:9866, bytes: 3444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742230_1406, duration(ns): 872539
2025-03-26 02:24:21,987 INFO terminating
2025-03-26 02:24:21,987 INFO terminating
2025-03-26 02:24:21,992 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742231_1407, replicas=172.20.1.13:9866, 172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_
2025-03-26 02:24:21,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:21,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742231_1407 src: /172.20.1.10:51692 dest: /172.20.1.13:9866
2025-03-26 02:24:21,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742231_1407 src: /172.20.1.13:57682 dest: /172.20.1.11:9866
2025-03-26 02:24:21,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742231_1407 src: /172.20.1.11:48884 dest: /172.20.1.12:9866
2025-03-26 02:24:21,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48884, dest: /172.20.1.12:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742231_1407, duration(ns): 751349
2025-03-26 02:24:21,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57682, dest: /172.20.1.11:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742231_1407, duration(ns): 965528
2025-03-26 02:24:21,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742231_1407, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:21,996 INFO terminating
2025-03-26 02:24:21,997 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:21,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51692, dest: /172.20.1.13:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742231_1407, duration(ns): 1156988
2025-03-26 02:24:21,997 INFO terminating
2025-03-26 02:24:22,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742232_1408, replicas=172.20.1.11:9866, 172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala._COPYING_
2025-03-26 02:24:22,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742232_1408 src: /172.20.1.10:58248 dest: /172.20.1.11:9866
2025-03-26 02:24:22,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742232_1408 src: /172.20.1.11:48900 dest: /172.20.1.12:9866
2025-03-26 02:24:22,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742232_1408 src: /172.20.1.12:55806 dest: /172.20.1.13:9866
2025-03-26 02:24:22,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58248, dest: /172.20.1.11:9866, bytes: 15338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742232_1408, duration(ns): 956524
2025-03-26 02:24:22,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48900, dest: /172.20.1.12:9866, bytes: 15338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742232_1408, duration(ns): 702570
2025-03-26 02:24:22,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55806, dest: /172.20.1.13:9866, bytes: 15338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742232_1408, duration(ns): 518293
2025-03-26 02:24:22,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742232_1408, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,006 INFO terminating
2025-03-26 02:24:22,006 INFO terminating
2025-03-26 02:24:22,007 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742233_1409, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_
2025-03-26 02:24:22,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742233_1409 src: /172.20.1.10:44760 dest: /172.20.1.12:9866
2025-03-26 02:24:22,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742233_1409 src: /172.20.1.12:55812 dest: /172.20.1.13:9866
2025-03-26 02:24:22,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742233_1409 src: /172.20.1.13:57688 dest: /172.20.1.11:9866
2025-03-26 02:24:22,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55812, dest: /172.20.1.13:9866, bytes: 5661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742233_1409, duration(ns): 928849
2025-03-26 02:24:22,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57688, dest: /172.20.1.11:9866, bytes: 5661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742233_1409, duration(ns): 779461
2025-03-26 02:24:22,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742233_1409, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,016 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44760, dest: /172.20.1.12:9866, bytes: 5661, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742233_1409, duration(ns): 1134059
2025-03-26 02:24:22,016 INFO terminating
2025-03-26 02:24:22,016 INFO terminating
2025-03-26 02:24:22,029 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742233_1409 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_
2025-03-26 02:24:22,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742032_1208 to 172.20.1.13:9866
2025-03-26 02:24:22,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742034_1210 to 172.20.1.13:9866
2025-03-26 02:24:22,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742032_1208 src: /172.20.1.11:35332 dest: /172.20.1.13:9866
2025-03-26 02:24:22,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742034_1210 src: /172.20.1.11:35342 dest: /172.20.1.13:9866
2025-03-26 02:24:22,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742034_1210 (numBytes=1345) to /172.20.1.13:9866
2025-03-26 02:24:22,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742032_1208 (numBytes=1458) to /172.20.1.13:9866
2025-03-26 02:24:22,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742032_1208 src: /172.20.1.11:35332 dest: /172.20.1.13:9866 of size 1458
2025-03-26 02:24:22,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742034_1210 src: /172.20.1.11:35342 dest: /172.20.1.13:9866 of size 1345
2025-03-26 02:24:22,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742033_1209 to 172.20.1.13:9866
2025-03-26 02:24:22,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742035_1211 to 172.20.1.13:9866
2025-03-26 02:24:22,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742033_1209 src: /172.20.1.12:55828 dest: /172.20.1.13:9866
2025-03-26 02:24:22,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742035_1211 src: /172.20.1.12:55844 dest: /172.20.1.13:9866
2025-03-26 02:24:22,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742033_1209 (numBytes=1558) to /172.20.1.13:9866
2025-03-26 02:24:22,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742035_1211 (numBytes=1980) to /172.20.1.13:9866
2025-03-26 02:24:22,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742033_1209 src: /172.20.1.12:55828 dest: /172.20.1.13:9866 of size 1558
2025-03-26 02:24:22,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742035_1211 src: /172.20.1.12:55844 dest: /172.20.1.13:9866 of size 1980
2025-03-26 02:24:22,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,435 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,435 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,435 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742234_1410, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala._COPYING_
2025-03-26 02:24:22,436 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,436 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,436 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742234_1410 src: /172.20.1.10:44766 dest: /172.20.1.12:9866
2025-03-26 02:24:22,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742234_1410 src: /172.20.1.12:55860 dest: /172.20.1.13:9866
2025-03-26 02:24:22,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44766, dest: /172.20.1.12:9866, bytes: 3236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742234_1410, duration(ns): 934594
2025-03-26 02:24:22,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55860, dest: /172.20.1.13:9866, bytes: 3236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742234_1410, duration(ns): 783100
2025-03-26 02:24:22,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742234_1410, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,440 INFO terminating
2025-03-26 02:24:22,444 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742235_1411, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala._COPYING_
2025-03-26 02:24:22,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,444 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,444 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,444 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742235_1411 src: /172.20.1.10:51700 dest: /172.20.1.13:9866
2025-03-26 02:24:22,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742235_1411 src: /172.20.1.13:38956 dest: /172.20.1.12:9866
2025-03-26 02:24:22,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51700, dest: /172.20.1.13:9866, bytes: 2552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742235_1411, duration(ns): 731158
2025-03-26 02:24:22,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38956, dest: /172.20.1.12:9866, bytes: 2552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742235_1411, duration(ns): 589541
2025-03-26 02:24:22,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742235_1411, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,447 INFO terminating
2025-03-26 02:24:22,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742236_1412, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala._COPYING_
2025-03-26 02:24:22,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,451 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,451 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,451 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742236_1412 src: /172.20.1.10:44778 dest: /172.20.1.12:9866
2025-03-26 02:24:22,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742236_1412 src: /172.20.1.12:55868 dest: /172.20.1.13:9866
2025-03-26 02:24:22,454 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44778, dest: /172.20.1.12:9866, bytes: 8698, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742236_1412, duration(ns): 674250
2025-03-26 02:24:22,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55868, dest: /172.20.1.13:9866, bytes: 8698, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742236_1412, duration(ns): 436908
2025-03-26 02:24:22,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742236_1412, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,454 INFO terminating
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,463 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742237_1413, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala._COPYING_
2025-03-26 02:24:22,463 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,463 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,463 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742237_1413 src: /172.20.1.10:44794 dest: /172.20.1.12:9866
2025-03-26 02:24:22,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742237_1413 src: /172.20.1.12:55878 dest: /172.20.1.13:9866
2025-03-26 02:24:22,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55878, dest: /172.20.1.13:9866, bytes: 2443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742237_1413, duration(ns): 471893
2025-03-26 02:24:22,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742237_1413, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,466 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44794, dest: /172.20.1.12:9866, bytes: 2443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742237_1413, duration(ns): 575749
2025-03-26 02:24:22,466 INFO terminating
2025-03-26 02:24:22,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742238_1414, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala._COPYING_
2025-03-26 02:24:22,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,469 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742238_1414 src: /172.20.1.10:44806 dest: /172.20.1.12:9866
2025-03-26 02:24:22,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742238_1414 src: /172.20.1.12:55880 dest: /172.20.1.13:9866
2025-03-26 02:24:22,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55880, dest: /172.20.1.13:9866, bytes: 4044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742238_1414, duration(ns): 1782176
2025-03-26 02:24:22,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742238_1414, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,474 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44806, dest: /172.20.1.12:9866, bytes: 4044, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742238_1414, duration(ns): 1977567
2025-03-26 02:24:22,474 INFO terminating
2025-03-26 02:24:22,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742239_1415, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala._COPYING_
2025-03-26 02:24:22,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,478 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,478 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,478 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742239_1415 src: /172.20.1.10:51716 dest: /172.20.1.13:9866
2025-03-26 02:24:22,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742239_1415 src: /172.20.1.13:38968 dest: /172.20.1.12:9866
2025-03-26 02:24:22,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38968, dest: /172.20.1.12:9866, bytes: 5410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742239_1415, duration(ns): 359703
2025-03-26 02:24:22,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742239_1415, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,481 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51716, dest: /172.20.1.13:9866, bytes: 5410, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742239_1415, duration(ns): 525870
2025-03-26 02:24:22,481 INFO terminating
2025-03-26 02:24:22,484 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742240_1416, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala._COPYING_
2025-03-26 02:24:22,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,484 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,484 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,484 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742240_1416 src: /172.20.1.10:44814 dest: /172.20.1.12:9866
2025-03-26 02:24:22,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742240_1416 src: /172.20.1.12:55892 dest: /172.20.1.13:9866
2025-03-26 02:24:22,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44814, dest: /172.20.1.12:9866, bytes: 3440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742240_1416, duration(ns): 1376852
2025-03-26 02:24:22,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55892, dest: /172.20.1.13:9866, bytes: 3440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742240_1416, duration(ns): 1261569
2025-03-26 02:24:22,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742240_1416, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,489 INFO terminating
2025-03-26 02:24:22,490 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,493 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742241_1417, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_
2025-03-26 02:24:22,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,493 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,493 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,493 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742241_1417 src: /172.20.1.10:44824 dest: /172.20.1.12:9866
2025-03-26 02:24:22,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742241_1417 src: /172.20.1.12:55900 dest: /172.20.1.13:9866
2025-03-26 02:24:22,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44824, dest: /172.20.1.12:9866, bytes: 11092, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742241_1417, duration(ns): 561750
2025-03-26 02:24:22,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55900, dest: /172.20.1.13:9866, bytes: 11092, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742241_1417, duration(ns): 349347
2025-03-26 02:24:22,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742241_1417, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,495 INFO terminating
2025-03-26 02:24:22,496 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742242_1418, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala._COPYING_
2025-03-26 02:24:22,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,499 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,499 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,499 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742242_1418 src: /172.20.1.10:51724 dest: /172.20.1.13:9866
2025-03-26 02:24:22,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742242_1418 src: /172.20.1.13:38980 dest: /172.20.1.12:9866
2025-03-26 02:24:22,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51724, dest: /172.20.1.13:9866, bytes: 3139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742242_1418, duration(ns): 452875
2025-03-26 02:24:22,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38980, dest: /172.20.1.12:9866, bytes: 3139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742242_1418, duration(ns): 349921
2025-03-26 02:24:22,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742242_1418, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,501 INFO terminating
2025-03-26 02:24:22,502 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742243_1419, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala._COPYING_
2025-03-26 02:24:22,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,506 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,506 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,506 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742243_1419 src: /172.20.1.10:51736 dest: /172.20.1.13:9866
2025-03-26 02:24:22,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742243_1419 src: /172.20.1.13:38992 dest: /172.20.1.12:9866
2025-03-26 02:24:22,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51736, dest: /172.20.1.13:9866, bytes: 3234, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742243_1419, duration(ns): 479309
2025-03-26 02:24:22,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:38992, dest: /172.20.1.12:9866, bytes: 3234, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742243_1419, duration(ns): 346021
2025-03-26 02:24:22,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742243_1419, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,509 INFO terminating
2025-03-26 02:24:22,511 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,517 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742244_1420, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_
2025-03-26 02:24:22,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,517 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,517 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,517 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742244_1420 src: /172.20.1.10:51748 dest: /172.20.1.13:9866
2025-03-26 02:24:22,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742244_1420 src: /172.20.1.13:39000 dest: /172.20.1.12:9866
2025-03-26 02:24:22,520 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51748, dest: /172.20.1.13:9866, bytes: 2178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742244_1420, duration(ns): 538885
2025-03-26 02:24:22,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39000, dest: /172.20.1.12:9866, bytes: 2178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742244_1420, duration(ns): 353969
2025-03-26 02:24:22,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742244_1420, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,520 INFO terminating
2025-03-26 02:24:22,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742245_1421, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala._COPYING_
2025-03-26 02:24:22,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,525 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,525 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,525 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742245_1421 src: /172.20.1.10:51754 dest: /172.20.1.13:9866
2025-03-26 02:24:22,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742245_1421 src: /172.20.1.13:39010 dest: /172.20.1.12:9866
2025-03-26 02:24:22,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51754, dest: /172.20.1.13:9866, bytes: 1575, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742245_1421, duration(ns): 551420
2025-03-26 02:24:22,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39010, dest: /172.20.1.12:9866, bytes: 1575, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742245_1421, duration(ns): 374074
2025-03-26 02:24:22,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742245_1421, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,528 INFO terminating
2025-03-26 02:24:22,529 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,534 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,534 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,534 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,534 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742246_1422, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala._COPYING_
2025-03-26 02:24:22,535 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,535 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742246_1422 src: /172.20.1.10:44840 dest: /172.20.1.12:9866
2025-03-26 02:24:22,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742246_1422 src: /172.20.1.12:55908 dest: /172.20.1.13:9866
2025-03-26 02:24:22,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44840, dest: /172.20.1.12:9866, bytes: 3268, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742246_1422, duration(ns): 487851
2025-03-26 02:24:22,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55908, dest: /172.20.1.13:9866, bytes: 3268, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742246_1422, duration(ns): 308066
2025-03-26 02:24:22,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742246_1422, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,538 INFO terminating
2025-03-26 02:24:22,539 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,542 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742247_1423, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala._COPYING_
2025-03-26 02:24:22,542 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,542 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,542 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,542 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,542 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,542 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742247_1423 src: /172.20.1.10:51766 dest: /172.20.1.13:9866
2025-03-26 02:24:22,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742247_1423 src: /172.20.1.13:39026 dest: /172.20.1.12:9866
2025-03-26 02:24:22,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51766, dest: /172.20.1.13:9866, bytes: 2670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742247_1423, duration(ns): 489864
2025-03-26 02:24:22,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39026, dest: /172.20.1.12:9866, bytes: 2670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742247_1423, duration(ns): 362251
2025-03-26 02:24:22,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742247_1423, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,544 INFO terminating
2025-03-26 02:24:22,545 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742248_1424, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala._COPYING_
2025-03-26 02:24:22,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,548 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,548 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,548 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742248_1424 src: /172.20.1.10:51772 dest: /172.20.1.13:9866
2025-03-26 02:24:22,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51772, dest: /172.20.1.13:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742248_1424, duration(ns): 471373
2025-03-26 02:24:22,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39038, dest: /172.20.1.12:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742248_1424, duration(ns): 296265
2025-03-26 02:24:22,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742248_1424, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742248_1424 src: /172.20.1.13:39038 dest: /172.20.1.12:9866
2025-03-26 02:24:22,551 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,551 INFO terminating
2025-03-26 02:24:22,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742249_1425, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala._COPYING_
2025-03-26 02:24:22,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,554 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,554 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,554 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,554 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742249_1425 src: /172.20.1.10:44850 dest: /172.20.1.12:9866
2025-03-26 02:24:22,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742249_1425 src: /172.20.1.12:55910 dest: /172.20.1.13:9866
2025-03-26 02:24:22,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44850, dest: /172.20.1.12:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742249_1425, duration(ns): 507805
2025-03-26 02:24:22,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55910, dest: /172.20.1.13:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742249_1425, duration(ns): 344149
2025-03-26 02:24:22,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742249_1425, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,557 INFO terminating
2025-03-26 02:24:22,558 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,561 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742250_1426, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala._COPYING_
2025-03-26 02:24:22,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,561 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,561 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,561 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742250_1426 src: /172.20.1.10:51782 dest: /172.20.1.13:9866
2025-03-26 02:24:22,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742250_1426 src: /172.20.1.13:39044 dest: /172.20.1.12:9866
2025-03-26 02:24:22,564 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51782, dest: /172.20.1.13:9866, bytes: 5326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742250_1426, duration(ns): 461643
2025-03-26 02:24:22,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39044, dest: /172.20.1.12:9866, bytes: 5326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742250_1426, duration(ns): 290131
2025-03-26 02:24:22,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742250_1426, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,564 INFO terminating
2025-03-26 02:24:22,570 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742251_1427, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala._COPYING_
2025-03-26 02:24:22,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,570 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,570 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,570 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742251_1427 src: /172.20.1.10:44862 dest: /172.20.1.12:9866
2025-03-26 02:24:22,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55920, dest: /172.20.1.13:9866, bytes: 3737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742251_1427, duration(ns): 317061
2025-03-26 02:24:22,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742251_1427, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742251_1427 src: /172.20.1.12:55920 dest: /172.20.1.13:9866
2025-03-26 02:24:22,573 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44862, dest: /172.20.1.12:9866, bytes: 3737, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742251_1427, duration(ns): 493137
2025-03-26 02:24:22,573 INFO terminating
2025-03-26 02:24:22,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742252_1428, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_
2025-03-26 02:24:22,577 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,577 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,577 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,577 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,577 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,577 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742252_1428 src: /172.20.1.10:44872 dest: /172.20.1.12:9866
2025-03-26 02:24:22,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742252_1428 src: /172.20.1.12:55924 dest: /172.20.1.13:9866
2025-03-26 02:24:22,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44872, dest: /172.20.1.12:9866, bytes: 4800, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742252_1428, duration(ns): 675450
2025-03-26 02:24:22,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55924, dest: /172.20.1.13:9866, bytes: 4800, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742252_1428, duration(ns): 447208
2025-03-26 02:24:22,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742252_1428, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,580 INFO terminating
2025-03-26 02:24:22,582 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742252_1428 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_
2025-03-26 02:24:22,982 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742253_1429, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala._COPYING_
2025-03-26 02:24:22,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,986 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,986 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,986 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742253_1429 src: /172.20.1.10:51784 dest: /172.20.1.13:9866
2025-03-26 02:24:22,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742253_1429 src: /172.20.1.13:39054 dest: /172.20.1.12:9866
2025-03-26 02:24:22,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39054, dest: /172.20.1.12:9866, bytes: 3780, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742253_1429, duration(ns): 489437
2025-03-26 02:24:22,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742253_1429, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,990 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51784, dest: /172.20.1.13:9866, bytes: 3780, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742253_1429, duration(ns): 707912
2025-03-26 02:24:22,990 INFO terminating
2025-03-26 02:24:22,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742254_1430, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala._COPYING_
2025-03-26 02:24:22,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:22,993 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:22,993 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:22,993 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:22,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742254_1430 src: /172.20.1.10:44886 dest: /172.20.1.12:9866
2025-03-26 02:24:22,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742254_1430 src: /172.20.1.12:55934 dest: /172.20.1.13:9866
2025-03-26 02:24:22,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55934, dest: /172.20.1.13:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742254_1430, duration(ns): 548605
2025-03-26 02:24:22,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742254_1430, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:22,997 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:22,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44886, dest: /172.20.1.12:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742254_1430, duration(ns): 572228
2025-03-26 02:24:22,997 INFO terminating
2025-03-26 02:24:23,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742255_1431, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_
2025-03-26 02:24:23,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,001 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,001 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,001 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742255_1431 src: /172.20.1.10:51798 dest: /172.20.1.13:9866
2025-03-26 02:24:23,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742255_1431 src: /172.20.1.13:39056 dest: /172.20.1.12:9866
2025-03-26 02:24:23,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51798, dest: /172.20.1.13:9866, bytes: 6363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742255_1431, duration(ns): 1021051
2025-03-26 02:24:23,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39056, dest: /172.20.1.12:9866, bytes: 6363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742255_1431, duration(ns): 522658
2025-03-26 02:24:23,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742255_1431, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,004 INFO terminating
2025-03-26 02:24:23,005 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,007 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,007 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,007 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742256_1432, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala._COPYING_
2025-03-26 02:24:23,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742256_1432 src: /172.20.1.10:44902 dest: /172.20.1.12:9866
2025-03-26 02:24:23,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742256_1432 src: /172.20.1.12:55950 dest: /172.20.1.13:9866
2025-03-26 02:24:23,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44902, dest: /172.20.1.12:9866, bytes: 3786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742256_1432, duration(ns): 572633
2025-03-26 02:24:23,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55950, dest: /172.20.1.13:9866, bytes: 3786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742256_1432, duration(ns): 303729
2025-03-26 02:24:23,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742256_1432, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,010 INFO terminating
2025-03-26 02:24:23,011 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,019 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742257_1433, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_
2025-03-26 02:24:23,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,019 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,019 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,019 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742257_1433 src: /172.20.1.10:44918 dest: /172.20.1.12:9866
2025-03-26 02:24:23,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742257_1433 src: /172.20.1.12:55964 dest: /172.20.1.13:9866
2025-03-26 02:24:23,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55964, dest: /172.20.1.13:9866, bytes: 4303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742257_1433, duration(ns): 499301
2025-03-26 02:24:23,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742257_1433, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44918, dest: /172.20.1.12:9866, bytes: 4303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742257_1433, duration(ns): 804104
2025-03-26 02:24:23,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742257_1433 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_
2025-03-26 02:24:23,023 INFO terminating
2025-03-26 02:24:23,425 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,443 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,444 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742258_1434, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java._COPYING_
2025-03-26 02:24:23,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742258_1434 src: /172.20.1.10:51814 dest: /172.20.1.13:9866
2025-03-26 02:24:23,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742258_1434 src: /172.20.1.13:39070 dest: /172.20.1.12:9866
2025-03-26 02:24:23,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39070, dest: /172.20.1.12:9866, bytes: 4032, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742258_1434, duration(ns): 656226
2025-03-26 02:24:23,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742258_1434, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,449 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51814, dest: /172.20.1.13:9866, bytes: 4032, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742258_1434, duration(ns): 1280352
2025-03-26 02:24:23,449 INFO terminating
2025-03-26 02:24:23,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,456 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742259_1435, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java._COPYING_
2025-03-26 02:24:23,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,456 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,456 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,456 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742259_1435 src: /172.20.1.10:51822 dest: /172.20.1.13:9866
2025-03-26 02:24:23,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742259_1435 src: /172.20.1.13:39080 dest: /172.20.1.12:9866
2025-03-26 02:24:23,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51822, dest: /172.20.1.13:9866, bytes: 3436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742259_1435, duration(ns): 684471
2025-03-26 02:24:23,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39080, dest: /172.20.1.12:9866, bytes: 3436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742259_1435, duration(ns): 500705
2025-03-26 02:24:23,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742259_1435, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,459 INFO terminating
2025-03-26 02:24:23,460 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,463 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742260_1436, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java._COPYING_
2025-03-26 02:24:23,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,463 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,463 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,463 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742260_1436 src: /172.20.1.10:51824 dest: /172.20.1.13:9866
2025-03-26 02:24:23,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39090, dest: /172.20.1.12:9866, bytes: 2411, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742260_1436, duration(ns): 362148
2025-03-26 02:24:23,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742260_1436, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742260_1436 src: /172.20.1.13:39090 dest: /172.20.1.12:9866
2025-03-26 02:24:23,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51824, dest: /172.20.1.13:9866, bytes: 2411, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742260_1436, duration(ns): 484514
2025-03-26 02:24:23,466 INFO terminating
2025-03-26 02:24:23,467 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742261_1437, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_
2025-03-26 02:24:23,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,469 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742261_1437 src: /172.20.1.10:51826 dest: /172.20.1.13:9866
2025-03-26 02:24:23,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742261_1437 src: /172.20.1.13:39096 dest: /172.20.1.12:9866
2025-03-26 02:24:23,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51826, dest: /172.20.1.13:9866, bytes: 3708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742261_1437, duration(ns): 551487
2025-03-26 02:24:23,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39096, dest: /172.20.1.12:9866, bytes: 3708, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742261_1437, duration(ns): 432009
2025-03-26 02:24:23,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742261_1437, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,472 INFO terminating
2025-03-26 02:24:23,473 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,475 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742262_1438, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java._COPYING_
2025-03-26 02:24:23,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,475 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,475 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,475 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742262_1438 src: /172.20.1.10:51842 dest: /172.20.1.13:9866
2025-03-26 02:24:23,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742262_1438 src: /172.20.1.13:39110 dest: /172.20.1.12:9866
2025-03-26 02:24:23,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51842, dest: /172.20.1.13:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742262_1438, duration(ns): 402174
2025-03-26 02:24:23,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39110, dest: /172.20.1.12:9866, bytes: 2173, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742262_1438, duration(ns): 272743
2025-03-26 02:24:23,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742262_1438, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,478 INFO terminating
2025-03-26 02:24:23,479 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,487 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742263_1439, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_
2025-03-26 02:24:23,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,487 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,487 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,487 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742263_1439 src: /172.20.1.10:44924 dest: /172.20.1.12:9866
2025-03-26 02:24:23,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55972, dest: /172.20.1.13:9866, bytes: 3387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742263_1439, duration(ns): 392360
2025-03-26 02:24:23,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742263_1439 src: /172.20.1.12:55972 dest: /172.20.1.13:9866
2025-03-26 02:24:23,490 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44924, dest: /172.20.1.12:9866, bytes: 3387, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742263_1439, duration(ns): 504786
2025-03-26 02:24:23,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742263_1439, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,490 INFO terminating
2025-03-26 02:24:23,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,493 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,493 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,493 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,494 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742264_1440, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_
2025-03-26 02:24:23,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742264_1440 src: /172.20.1.10:44938 dest: /172.20.1.12:9866
2025-03-26 02:24:23,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742264_1440 src: /172.20.1.12:55974 dest: /172.20.1.13:9866
2025-03-26 02:24:23,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44938, dest: /172.20.1.12:9866, bytes: 3631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742264_1440, duration(ns): 588288
2025-03-26 02:24:23,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55974, dest: /172.20.1.13:9866, bytes: 3631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742264_1440, duration(ns): 351635
2025-03-26 02:24:23,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742264_1440, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,496 INFO terminating
2025-03-26 02:24:23,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742264_1440 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_
2025-03-26 02:24:23,897 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,901 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742265_1441, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java._COPYING_
2025-03-26 02:24:23,901 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,901 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,901 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,901 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,901 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,901 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742265_1441 src: /172.20.1.10:44954 dest: /172.20.1.12:9866
2025-03-26 02:24:23,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742265_1441 src: /172.20.1.12:55976 dest: /172.20.1.13:9866
2025-03-26 02:24:23,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44954, dest: /172.20.1.12:9866, bytes: 3580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742265_1441, duration(ns): 797181
2025-03-26 02:24:23,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55976, dest: /172.20.1.13:9866, bytes: 3580, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742265_1441, duration(ns): 644211
2025-03-26 02:24:23,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742265_1441, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,904 INFO terminating
2025-03-26 02:24:23,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742266_1442, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java._COPYING_
2025-03-26 02:24:23,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,908 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,908 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,908 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742266_1442 src: /172.20.1.10:51858 dest: /172.20.1.13:9866
2025-03-26 02:24:23,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742266_1442 src: /172.20.1.13:39118 dest: /172.20.1.12:9866
2025-03-26 02:24:23,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39118, dest: /172.20.1.12:9866, bytes: 3223, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742266_1442, duration(ns): 497258
2025-03-26 02:24:23,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742266_1442, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,911 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51858, dest: /172.20.1.13:9866, bytes: 3223, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742266_1442, duration(ns): 725369
2025-03-26 02:24:23,911 INFO terminating
2025-03-26 02:24:23,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742267_1443, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java._COPYING_
2025-03-26 02:24:23,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,914 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,914 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,914 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742267_1443 src: /172.20.1.10:44970 dest: /172.20.1.12:9866
2025-03-26 02:24:23,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742267_1443 src: /172.20.1.12:55980 dest: /172.20.1.13:9866
2025-03-26 02:24:23,917 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44970, dest: /172.20.1.12:9866, bytes: 2239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742267_1443, duration(ns): 599514
2025-03-26 02:24:23,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55980, dest: /172.20.1.13:9866, bytes: 2239, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742267_1443, duration(ns): 544547
2025-03-26 02:24:23,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742267_1443, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,917 INFO terminating
2025-03-26 02:24:23,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742268_1444, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java._COPYING_
2025-03-26 02:24:23,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,920 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,920 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,920 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742268_1444 src: /172.20.1.10:44986 dest: /172.20.1.12:9866
2025-03-26 02:24:23,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742268_1444 src: /172.20.1.12:55984 dest: /172.20.1.13:9866
2025-03-26 02:24:23,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44986, dest: /172.20.1.12:9866, bytes: 2778, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742268_1444, duration(ns): 374609
2025-03-26 02:24:23,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55984, dest: /172.20.1.13:9866, bytes: 2778, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742268_1444, duration(ns): 344338
2025-03-26 02:24:23,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742268_1444, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,924 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,924 INFO terminating
2025-03-26 02:24:23,927 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742269_1445, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_
2025-03-26 02:24:23,927 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,927 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,927 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,927 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,927 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,927 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742269_1445 src: /172.20.1.10:44988 dest: /172.20.1.12:9866
2025-03-26 02:24:23,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55994, dest: /172.20.1.13:9866, bytes: 2602, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742269_1445, duration(ns): 293602
2025-03-26 02:24:23,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742269_1445, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742269_1445 src: /172.20.1.12:55994 dest: /172.20.1.13:9866
2025-03-26 02:24:23,930 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:23,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44988, dest: /172.20.1.12:9866, bytes: 2602, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742269_1445, duration(ns): 481236
2025-03-26 02:24:23,930 INFO terminating
2025-03-26 02:24:23,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742270_1446, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 02:24:23,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:23,933 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:23,933 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:23,933 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:23,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742270_1446 src: /172.20.1.10:51866 dest: /172.20.1.13:9866
2025-03-26 02:24:23,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742270_1446 src: /172.20.1.13:39122 dest: /172.20.1.12:9866
2025-03-26 02:24:23,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51866, dest: /172.20.1.13:9866, bytes: 3240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742270_1446, duration(ns): 718331
2025-03-26 02:24:23,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39122, dest: /172.20.1.12:9866, bytes: 3240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742270_1446, duration(ns): 413339
2025-03-26 02:24:23,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742270_1446, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:23,936 INFO terminating
2025-03-26 02:24:23,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742270_1446 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 02:24:24,337 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,341 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742271_1447, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java._COPYING_
2025-03-26 02:24:24,341 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,341 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,341 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,341 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,341 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,341 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742271_1447 src: /172.20.1.10:44998 dest: /172.20.1.12:9866
2025-03-26 02:24:24,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742271_1447 src: /172.20.1.12:56004 dest: /172.20.1.13:9866
2025-03-26 02:24:24,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:44998, dest: /172.20.1.12:9866, bytes: 3102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742271_1447, duration(ns): 626264
2025-03-26 02:24:24,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56004, dest: /172.20.1.13:9866, bytes: 3102, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742271_1447, duration(ns): 471140
2025-03-26 02:24:24,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742271_1447, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,344 INFO terminating
2025-03-26 02:24:24,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742272_1448, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java._COPYING_
2025-03-26 02:24:24,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,348 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,348 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,348 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742272_1448 src: /172.20.1.10:45004 dest: /172.20.1.12:9866
2025-03-26 02:24:24,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742272_1448 src: /172.20.1.12:56010 dest: /172.20.1.13:9866
2025-03-26 02:24:24,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45004, dest: /172.20.1.12:9866, bytes: 3773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742272_1448, duration(ns): 820812
2025-03-26 02:24:24,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56010, dest: /172.20.1.13:9866, bytes: 3773, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742272_1448, duration(ns): 339564
2025-03-26 02:24:24,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742272_1448, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,352 INFO terminating
2025-03-26 02:24:24,353 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,356 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742273_1449, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java._COPYING_
2025-03-26 02:24:24,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,356 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,356 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,356 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742273_1449 src: /172.20.1.10:51876 dest: /172.20.1.13:9866
2025-03-26 02:24:24,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742273_1449 src: /172.20.1.13:39136 dest: /172.20.1.12:9866
2025-03-26 02:24:24,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39136, dest: /172.20.1.12:9866, bytes: 2761, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742273_1449, duration(ns): 610115
2025-03-26 02:24:24,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742273_1449, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,360 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51876, dest: /172.20.1.13:9866, bytes: 2761, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742273_1449, duration(ns): 827445
2025-03-26 02:24:24,360 INFO terminating
2025-03-26 02:24:24,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742274_1450, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java._COPYING_
2025-03-26 02:24:24,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,363 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,363 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,363 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742274_1450 src: /172.20.1.10:51880 dest: /172.20.1.13:9866
2025-03-26 02:24:24,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39146, dest: /172.20.1.12:9866, bytes: 2415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742274_1450, duration(ns): 327770
2025-03-26 02:24:24,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742274_1450 src: /172.20.1.13:39146 dest: /172.20.1.12:9866
2025-03-26 02:24:24,366 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51880, dest: /172.20.1.13:9866, bytes: 2415, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742274_1450, duration(ns): 502379
2025-03-26 02:24:24,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742274_1450, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,366 INFO terminating
2025-03-26 02:24:24,369 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742275_1451, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java._COPYING_
2025-03-26 02:24:24,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,369 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,369 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,369 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742275_1451 src: /172.20.1.10:51884 dest: /172.20.1.13:9866
2025-03-26 02:24:24,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742275_1451 src: /172.20.1.13:39154 dest: /172.20.1.12:9866
2025-03-26 02:24:24,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51884, dest: /172.20.1.13:9866, bytes: 1913, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742275_1451, duration(ns): 948703
2025-03-26 02:24:24,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39154, dest: /172.20.1.12:9866, bytes: 1913, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742275_1451, duration(ns): 731314
2025-03-26 02:24:24,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742275_1451, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,372 INFO terminating
2025-03-26 02:24:24,373 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742276_1452, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java._COPYING_
2025-03-26 02:24:24,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,376 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,376 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,376 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742276_1452 src: /172.20.1.10:45006 dest: /172.20.1.12:9866
2025-03-26 02:24:24,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742276_1452 src: /172.20.1.12:56016 dest: /172.20.1.13:9866
2025-03-26 02:24:24,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56016, dest: /172.20.1.13:9866, bytes: 3157, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742276_1452, duration(ns): 415849
2025-03-26 02:24:24,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742276_1452, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,379 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45006, dest: /172.20.1.12:9866, bytes: 3157, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742276_1452, duration(ns): 584865
2025-03-26 02:24:24,379 INFO terminating
2025-03-26 02:24:24,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742277_1453, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java._COPYING_
2025-03-26 02:24:24,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,388 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,388 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,388 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742277_1453 src: /172.20.1.10:51896 dest: /172.20.1.13:9866
2025-03-26 02:24:24,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742277_1453 src: /172.20.1.13:39166 dest: /172.20.1.12:9866
2025-03-26 02:24:24,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39166, dest: /172.20.1.12:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742277_1453, duration(ns): 885218
2025-03-26 02:24:24,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742277_1453, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,392 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51896, dest: /172.20.1.13:9866, bytes: 2977, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742277_1453, duration(ns): 1061552
2025-03-26 02:24:24,392 INFO terminating
2025-03-26 02:24:24,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742278_1454, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java._COPYING_
2025-03-26 02:24:24,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,396 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,396 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,396 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742278_1454 src: /172.20.1.10:45010 dest: /172.20.1.12:9866
2025-03-26 02:24:24,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742278_1454 src: /172.20.1.12:56032 dest: /172.20.1.13:9866
2025-03-26 02:24:24,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56032, dest: /172.20.1.13:9866, bytes: 2137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742278_1454, duration(ns): 3612543
2025-03-26 02:24:24,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742278_1454, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45010, dest: /172.20.1.12:9866, bytes: 2137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742278_1454, duration(ns): 3750766
2025-03-26 02:24:24,403 INFO terminating
2025-03-26 02:24:24,404 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,407 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,407 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,407 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,408 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742279_1455, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java._COPYING_
2025-03-26 02:24:24,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742279_1455 src: /172.20.1.10:51902 dest: /172.20.1.13:9866
2025-03-26 02:24:24,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742279_1455 src: /172.20.1.13:39176 dest: /172.20.1.12:9866
2025-03-26 02:24:24,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39176, dest: /172.20.1.12:9866, bytes: 2741, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742279_1455, duration(ns): 430676
2025-03-26 02:24:24,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742279_1455, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,411 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51902, dest: /172.20.1.13:9866, bytes: 2741, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742279_1455, duration(ns): 605480
2025-03-26 02:24:24,411 INFO terminating
2025-03-26 02:24:24,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742280_1456, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java._COPYING_
2025-03-26 02:24:24,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,414 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,414 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,414 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742280_1456 src: /172.20.1.10:51904 dest: /172.20.1.13:9866
2025-03-26 02:24:24,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742280_1456 src: /172.20.1.13:39180 dest: /172.20.1.12:9866
2025-03-26 02:24:24,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51904, dest: /172.20.1.13:9866, bytes: 2802, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742280_1456, duration(ns): 510658
2025-03-26 02:24:24,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39180, dest: /172.20.1.12:9866, bytes: 2802, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742280_1456, duration(ns): 296497
2025-03-26 02:24:24,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742280_1456, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,417 INFO terminating
2025-03-26 02:24:24,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,420 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,420 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,421 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742281_1457, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_
2025-03-26 02:24:24,421 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742281_1457 src: /172.20.1.10:45014 dest: /172.20.1.12:9866
2025-03-26 02:24:24,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742281_1457 src: /172.20.1.12:56038 dest: /172.20.1.13:9866
2025-03-26 02:24:24,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56038, dest: /172.20.1.13:9866, bytes: 2715, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742281_1457, duration(ns): 418148
2025-03-26 02:24:24,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742281_1457, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45014, dest: /172.20.1.12:9866, bytes: 2715, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742281_1457, duration(ns): 609922
2025-03-26 02:24:24,424 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742281_1457 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_
2025-03-26 02:24:24,424 INFO terminating
2025-03-26 02:24:24,825 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,834 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742282_1458, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java._COPYING_
2025-03-26 02:24:24,835 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,835 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742282_1458 src: /172.20.1.10:45030 dest: /172.20.1.12:9866
2025-03-26 02:24:24,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742282_1458 src: /172.20.1.12:56050 dest: /172.20.1.13:9866
2025-03-26 02:24:24,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56050, dest: /172.20.1.13:9866, bytes: 2899, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742282_1458, duration(ns): 2122124
2025-03-26 02:24:24,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45030, dest: /172.20.1.12:9866, bytes: 2899, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742282_1458, duration(ns): 2880080
2025-03-26 02:24:24,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742282_1458, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,845 INFO terminating
2025-03-26 02:24:24,846 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742283_1459, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java._COPYING_
2025-03-26 02:24:24,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,855 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,855 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,855 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742283_1459 src: /172.20.1.10:45036 dest: /172.20.1.12:9866
2025-03-26 02:24:24,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742283_1459 src: /172.20.1.12:56066 dest: /172.20.1.13:9866
2025-03-26 02:24:24,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56066, dest: /172.20.1.13:9866, bytes: 2085, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742283_1459, duration(ns): 1365867
2025-03-26 02:24:24,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45036, dest: /172.20.1.12:9866, bytes: 2085, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742283_1459, duration(ns): 1913126
2025-03-26 02:24:24,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742283_1459, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,862 INFO terminating
2025-03-26 02:24:24,863 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742284_1460, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java._COPYING_
2025-03-26 02:24:24,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,871 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,871 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,871 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742284_1460 src: /172.20.1.10:51912 dest: /172.20.1.13:9866
2025-03-26 02:24:24,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742284_1460 src: /172.20.1.13:39190 dest: /172.20.1.12:9866
2025-03-26 02:24:24,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39190, dest: /172.20.1.12:9866, bytes: 3180, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742284_1460, duration(ns): 667009
2025-03-26 02:24:24,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742284_1460, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,876 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51912, dest: /172.20.1.13:9866, bytes: 3180, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742284_1460, duration(ns): 730699
2025-03-26 02:24:24,876 INFO terminating
2025-03-26 02:24:24,880 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742285_1461, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java._COPYING_
2025-03-26 02:24:24,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,880 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,880 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,880 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742285_1461 src: /172.20.1.10:51928 dest: /172.20.1.13:9866
2025-03-26 02:24:24,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742285_1461 src: /172.20.1.13:39198 dest: /172.20.1.12:9866
2025-03-26 02:24:24,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51928, dest: /172.20.1.13:9866, bytes: 2623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742285_1461, duration(ns): 480616
2025-03-26 02:24:24,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39198, dest: /172.20.1.12:9866, bytes: 2623, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742285_1461, duration(ns): 405902
2025-03-26 02:24:24,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742285_1461, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,883 INFO terminating
2025-03-26 02:24:24,884 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742286_1462, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java._COPYING_
2025-03-26 02:24:24,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,894 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,894 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,894 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742286_1462 src: /172.20.1.10:51940 dest: /172.20.1.13:9866
2025-03-26 02:24:24,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742286_1462 src: /172.20.1.13:39204 dest: /172.20.1.12:9866
2025-03-26 02:24:24,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51940, dest: /172.20.1.13:9866, bytes: 3973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742286_1462, duration(ns): 503261
2025-03-26 02:24:24,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39204, dest: /172.20.1.12:9866, bytes: 3973, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742286_1462, duration(ns): 380593
2025-03-26 02:24:24,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742286_1462, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,898 INFO terminating
2025-03-26 02:24:24,899 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,902 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,902 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,903 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742287_1463, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java._COPYING_
2025-03-26 02:24:24,903 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742287_1463 src: /172.20.1.10:45040 dest: /172.20.1.12:9866
2025-03-26 02:24:24,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742287_1463 src: /172.20.1.12:56082 dest: /172.20.1.13:9866
2025-03-26 02:24:24,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45040, dest: /172.20.1.12:9866, bytes: 3265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742287_1463, duration(ns): 748185
2025-03-26 02:24:24,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56082, dest: /172.20.1.13:9866, bytes: 3265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742287_1463, duration(ns): 487509
2025-03-26 02:24:24,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742287_1463, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,907 INFO terminating
2025-03-26 02:24:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,910 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,910 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,910 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742288_1464, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java._COPYING_
2025-03-26 02:24:24,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742288_1464 src: /172.20.1.10:51950 dest: /172.20.1.13:9866
2025-03-26 02:24:24,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742288_1464 src: /172.20.1.13:39212 dest: /172.20.1.12:9866
2025-03-26 02:24:24,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39212, dest: /172.20.1.12:9866, bytes: 2238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742288_1464, duration(ns): 432094
2025-03-26 02:24:24,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742288_1464, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,915 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51950, dest: /172.20.1.13:9866, bytes: 2238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742288_1464, duration(ns): 943870
2025-03-26 02:24:24,915 INFO terminating
2025-03-26 02:24:24,918 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,918 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,918 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,918 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,919 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742289_1465, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_
2025-03-26 02:24:24,919 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,919 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742289_1465 src: /172.20.1.10:51958 dest: /172.20.1.13:9866
2025-03-26 02:24:24,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742289_1465 src: /172.20.1.13:39226 dest: /172.20.1.12:9866
2025-03-26 02:24:24,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51958, dest: /172.20.1.13:9866, bytes: 2546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742289_1465, duration(ns): 430879
2025-03-26 02:24:24,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39226, dest: /172.20.1.12:9866, bytes: 2546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742289_1465, duration(ns): 376792
2025-03-26 02:24:24,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742289_1465, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,922 INFO terminating
2025-03-26 02:24:24,923 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,979 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742290_1466, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java._COPYING_
2025-03-26 02:24:24,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,979 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,979 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,979 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742290_1466 src: /172.20.1.10:51964 dest: /172.20.1.13:9866
2025-03-26 02:24:24,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742290_1466 src: /172.20.1.13:39230 dest: /172.20.1.12:9866
2025-03-26 02:24:24,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51964, dest: /172.20.1.13:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742290_1466, duration(ns): 571883
2025-03-26 02:24:24,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39230, dest: /172.20.1.12:9866, bytes: 1894, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742290_1466, duration(ns): 426209
2025-03-26 02:24:24,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742290_1466, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,983 INFO terminating
2025-03-26 02:24:24,984 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742291_1467, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java._COPYING_
2025-03-26 02:24:24,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,987 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,987 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,987 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742291_1467 src: /172.20.1.10:51970 dest: /172.20.1.13:9866
2025-03-26 02:24:24,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39246, dest: /172.20.1.12:9866, bytes: 5729, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742291_1467, duration(ns): 367930
2025-03-26 02:24:24,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742291_1467 src: /172.20.1.13:39246 dest: /172.20.1.12:9866
2025-03-26 02:24:24,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:24,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:51970, dest: /172.20.1.13:9866, bytes: 5729, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742291_1467, duration(ns): 522712
2025-03-26 02:24:24,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742291_1467, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,992 INFO terminating
2025-03-26 02:24:24,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742292_1468, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java._COPYING_
2025-03-26 02:24:24,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:24,995 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:24,995 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:24,995 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:24,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742292_1468 src: /172.20.1.10:45042 dest: /172.20.1.12:9866
2025-03-26 02:24:24,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742292_1468 src: /172.20.1.12:56088 dest: /172.20.1.13:9866
2025-03-26 02:24:24,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45042, dest: /172.20.1.12:9866, bytes: 2123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742292_1468, duration(ns): 869402
2025-03-26 02:24:24,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56088, dest: /172.20.1.13:9866, bytes: 2123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742292_1468, duration(ns): 368759
2025-03-26 02:24:24,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742292_1468, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:24,999 INFO terminating
2025-03-26 02:24:25,000 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,003 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742293_1469, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java._COPYING_
2025-03-26 02:24:25,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,003 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,003 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,003 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742293_1469 src: /172.20.1.10:45044 dest: /172.20.1.12:9866
2025-03-26 02:24:25,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742293_1469 src: /172.20.1.12:56090 dest: /172.20.1.13:9866
2025-03-26 02:24:25,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45044, dest: /172.20.1.12:9866, bytes: 3381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742293_1469, duration(ns): 845770
2025-03-26 02:24:25,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56090, dest: /172.20.1.13:9866, bytes: 3381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742293_1469, duration(ns): 353629
2025-03-26 02:24:25,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742293_1469, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,006 INFO terminating
2025-03-26 02:24:25,010 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,017 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742294_1470, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java._COPYING_
2025-03-26 02:24:25,017 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,017 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742294_1470 src: /172.20.1.10:58250 dest: /172.20.1.11:9866
2025-03-26 02:24:25,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742294_1470 src: /172.20.1.11:35352 dest: /172.20.1.13:9866
2025-03-26 02:24:25,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742294_1470 src: /172.20.1.13:39250 dest: /172.20.1.12:9866
2025-03-26 02:24:25,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:39250, dest: /172.20.1.12:9866, bytes: 1258, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742294_1470, duration(ns): 605531
2025-03-26 02:24:25,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742294_1470, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58250, dest: /172.20.1.11:9866, bytes: 1258, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742294_1470, duration(ns): 1543911
2025-03-26 02:24:25,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35352, dest: /172.20.1.13:9866, bytes: 1258, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742294_1470, duration(ns): 757560
2025-03-26 02:24:25,022 INFO terminating
2025-03-26 02:24:25,022 INFO terminating
2025-03-26 02:24:25,023 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742295_1471, replicas=172.20.1.12:9866, 172.20.1.13:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java._COPYING_
2025-03-26 02:24:25,026 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,026 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742295_1471 src: /172.20.1.10:45046 dest: /172.20.1.12:9866
2025-03-26 02:24:25,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742295_1471 src: /172.20.1.12:56094 dest: /172.20.1.13:9866
2025-03-26 02:24:25,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742295_1471 src: /172.20.1.13:57690 dest: /172.20.1.11:9866
2025-03-26 02:24:25,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45046, dest: /172.20.1.12:9866, bytes: 3202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742295_1471, duration(ns): 886353
2025-03-26 02:24:25,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:56094, dest: /172.20.1.13:9866, bytes: 3202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742295_1471, duration(ns): 650548
2025-03-26 02:24:25,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:57690, dest: /172.20.1.11:9866, bytes: 3202, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742295_1471, duration(ns): 465405
2025-03-26 02:24:25,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742295_1471, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,029 INFO terminating
2025-03-26 02:24:25,030 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,030 INFO terminating
2025-03-26 02:24:25,033 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742296_1472, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_
2025-03-26 02:24:25,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,033 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,033 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,033 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742296_1472 src: /172.20.1.10:45058 dest: /172.20.1.12:9866
2025-03-26 02:24:25,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742296_1472 src: /172.20.1.12:55214 dest: /172.20.1.11:9866
2025-03-26 02:24:25,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45058, dest: /172.20.1.12:9866, bytes: 2846, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742296_1472, duration(ns): 2656405
2025-03-26 02:24:25,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55214, dest: /172.20.1.11:9866, bytes: 2846, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742296_1472, duration(ns): 2601287
2025-03-26 02:24:25,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742296_1472, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,038 INFO terminating
2025-03-26 02:24:25,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742296_1472 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_
2025-03-26 02:24:25,439 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742297_1473, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java._COPYING_
2025-03-26 02:24:25,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,443 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742297_1473 src: /172.20.1.10:58266 dest: /172.20.1.11:9866
2025-03-26 02:24:25,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742297_1473 src: /172.20.1.11:48908 dest: /172.20.1.12:9866
2025-03-26 02:24:25,447 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58266, dest: /172.20.1.11:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742297_1473, duration(ns): 1616713
2025-03-26 02:24:25,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48908, dest: /172.20.1.12:9866, bytes: 2446, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742297_1473, duration(ns): 1445709
2025-03-26 02:24:25,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742297_1473, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,447 INFO terminating
2025-03-26 02:24:25,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,450 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,450 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,450 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742298_1474, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java._COPYING_
2025-03-26 02:24:25,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742298_1474 src: /172.20.1.10:58272 dest: /172.20.1.11:9866
2025-03-26 02:24:25,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742298_1474 src: /172.20.1.11:48924 dest: /172.20.1.12:9866
2025-03-26 02:24:25,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48924, dest: /172.20.1.12:9866, bytes: 3553, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742298_1474, duration(ns): 451113
2025-03-26 02:24:25,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742298_1474, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,454 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58272, dest: /172.20.1.11:9866, bytes: 3553, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742298_1474, duration(ns): 644683
2025-03-26 02:24:25,454 INFO terminating
2025-03-26 02:24:25,457 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,458 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742299_1475, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java._COPYING_
2025-03-26 02:24:25,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,458 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,458 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,458 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742299_1475 src: /172.20.1.10:45072 dest: /172.20.1.12:9866
2025-03-26 02:24:25,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742299_1475 src: /172.20.1.12:55222 dest: /172.20.1.11:9866
2025-03-26 02:24:25,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,460 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,460 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,461 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45072, dest: /172.20.1.12:9866, bytes: 2506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742299_1475, duration(ns): 1012196
2025-03-26 02:24:25,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55222, dest: /172.20.1.11:9866, bytes: 2506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742299_1475, duration(ns): 829725
2025-03-26 02:24:25,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742299_1475, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,461 INFO terminating
2025-03-26 02:24:25,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742300_1476, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_
2025-03-26 02:24:25,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,466 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,466 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,466 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742300_1476 src: /172.20.1.10:45074 dest: /172.20.1.12:9866
2025-03-26 02:24:25,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55230, dest: /172.20.1.11:9866, bytes: 5226, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742300_1476, duration(ns): 361904
2025-03-26 02:24:25,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742300_1476, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742300_1476 src: /172.20.1.12:55230 dest: /172.20.1.11:9866
2025-03-26 02:24:25,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45074, dest: /172.20.1.12:9866, bytes: 5226, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742300_1476, duration(ns): 390894
2025-03-26 02:24:25,470 INFO terminating
2025-03-26 02:24:25,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,473 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,473 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,473 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,474 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742301_1477, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java._COPYING_
2025-03-26 02:24:25,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742301_1477 src: /172.20.1.10:58280 dest: /172.20.1.11:9866
2025-03-26 02:24:25,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742301_1477 src: /172.20.1.11:48936 dest: /172.20.1.12:9866
2025-03-26 02:24:25,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58280, dest: /172.20.1.11:9866, bytes: 2612, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742301_1477, duration(ns): 612450
2025-03-26 02:24:25,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48936, dest: /172.20.1.12:9866, bytes: 2612, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742301_1477, duration(ns): 412854
2025-03-26 02:24:25,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742301_1477, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,476 INFO terminating
2025-03-26 02:24:25,477 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742302_1478, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java._COPYING_
2025-03-26 02:24:25,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,479 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,479 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,479 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742302_1478 src: /172.20.1.10:45084 dest: /172.20.1.12:9866
2025-03-26 02:24:25,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742302_1478 src: /172.20.1.12:55234 dest: /172.20.1.11:9866
2025-03-26 02:24:25,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45084, dest: /172.20.1.12:9866, bytes: 4317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742302_1478, duration(ns): 507886
2025-03-26 02:24:25,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55234, dest: /172.20.1.11:9866, bytes: 4317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742302_1478, duration(ns): 351278
2025-03-26 02:24:25,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742302_1478, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,482 INFO terminating
2025-03-26 02:24:25,483 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,488 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,488 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,489 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742303_1479, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java._COPYING_
2025-03-26 02:24:25,489 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742303_1479 src: /172.20.1.10:45094 dest: /172.20.1.12:9866
2025-03-26 02:24:25,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742303_1479 src: /172.20.1.12:55240 dest: /172.20.1.11:9866
2025-03-26 02:24:25,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45094, dest: /172.20.1.12:9866, bytes: 3304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742303_1479, duration(ns): 517413
2025-03-26 02:24:25,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55240, dest: /172.20.1.11:9866, bytes: 3304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742303_1479, duration(ns): 362448
2025-03-26 02:24:25,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742303_1479, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,491 INFO terminating
2025-03-26 02:24:25,492 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,496 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742304_1480, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java._COPYING_
2025-03-26 02:24:25,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,496 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,496 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,496 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742304_1480 src: /172.20.1.10:58284 dest: /172.20.1.11:9866
2025-03-26 02:24:25,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742304_1480 src: /172.20.1.11:48940 dest: /172.20.1.12:9866
2025-03-26 02:24:25,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58284, dest: /172.20.1.11:9866, bytes: 2450, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742304_1480, duration(ns): 532722
2025-03-26 02:24:25,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48940, dest: /172.20.1.12:9866, bytes: 2450, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742304_1480, duration(ns): 292251
2025-03-26 02:24:25,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742304_1480, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,498 INFO terminating
2025-03-26 02:24:25,499 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,502 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742305_1481, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java._COPYING_
2025-03-26 02:24:25,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,502 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,502 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,502 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742305_1481 src: /172.20.1.10:45098 dest: /172.20.1.12:9866
2025-03-26 02:24:25,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55250, dest: /172.20.1.11:9866, bytes: 2467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742305_1481, duration(ns): 307994
2025-03-26 02:24:25,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742305_1481, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742305_1481 src: /172.20.1.12:55250 dest: /172.20.1.11:9866
2025-03-26 02:24:25,505 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45098, dest: /172.20.1.12:9866, bytes: 2467, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742305_1481, duration(ns): 474894
2025-03-26 02:24:25,505 INFO terminating
2025-03-26 02:24:25,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,508 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742306_1482, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java._COPYING_
2025-03-26 02:24:25,509 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,509 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742306_1482 src: /172.20.1.10:45106 dest: /172.20.1.12:9866
2025-03-26 02:24:25,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742306_1482 src: /172.20.1.12:55252 dest: /172.20.1.11:9866
2025-03-26 02:24:25,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45106, dest: /172.20.1.12:9866, bytes: 3122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742306_1482, duration(ns): 408937
2025-03-26 02:24:25,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55252, dest: /172.20.1.11:9866, bytes: 3122, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742306_1482, duration(ns): 327812
2025-03-26 02:24:25,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742306_1482, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,512 INFO terminating
2025-03-26 02:24:25,513 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,516 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742307_1483, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java._COPYING_
2025-03-26 02:24:25,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,516 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,516 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,516 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742307_1483 src: /172.20.1.10:58300 dest: /172.20.1.11:9866
2025-03-26 02:24:25,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48956, dest: /172.20.1.12:9866, bytes: 2851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742307_1483, duration(ns): 327844
2025-03-26 02:24:25,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742307_1483, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742307_1483 src: /172.20.1.11:48956 dest: /172.20.1.12:9866
2025-03-26 02:24:25,519 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58300, dest: /172.20.1.11:9866, bytes: 2851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742307_1483, duration(ns): 352393
2025-03-26 02:24:25,519 INFO terminating
2025-03-26 02:24:25,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,521 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,521 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,521 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,522 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742308_1484, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java._COPYING_
2025-03-26 02:24:25,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742308_1484 src: /172.20.1.10:45116 dest: /172.20.1.12:9866
2025-03-26 02:24:25,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742308_1484 src: /172.20.1.12:55258 dest: /172.20.1.11:9866
2025-03-26 02:24:25,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45116, dest: /172.20.1.12:9866, bytes: 2349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742308_1484, duration(ns): 455978
2025-03-26 02:24:25,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55258, dest: /172.20.1.11:9866, bytes: 2349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742308_1484, duration(ns): 313311
2025-03-26 02:24:25,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742308_1484, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,524 INFO terminating
2025-03-26 02:24:25,525 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,527 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742309_1485, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java._COPYING_
2025-03-26 02:24:25,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,527 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,527 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,527 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742309_1485 src: /172.20.1.10:45124 dest: /172.20.1.12:9866
2025-03-26 02:24:25,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742309_1485 src: /172.20.1.12:55266 dest: /172.20.1.11:9866
2025-03-26 02:24:25,530 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45124, dest: /172.20.1.12:9866, bytes: 2213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742309_1485, duration(ns): 439236
2025-03-26 02:24:25,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55266, dest: /172.20.1.11:9866, bytes: 2213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742309_1485, duration(ns): 303764
2025-03-26 02:24:25,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742309_1485, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,530 INFO terminating
2025-03-26 02:24:25,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742310_1486, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java._COPYING_
2025-03-26 02:24:25,533 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,533 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,533 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,533 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,533 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,533 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742310_1486 src: /172.20.1.10:45136 dest: /172.20.1.12:9866
2025-03-26 02:24:25,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742310_1486 src: /172.20.1.12:55280 dest: /172.20.1.11:9866
2025-03-26 02:24:25,536 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45136, dest: /172.20.1.12:9866, bytes: 4024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742310_1486, duration(ns): 519622
2025-03-26 02:24:25,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55280, dest: /172.20.1.11:9866, bytes: 4024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742310_1486, duration(ns): 344543
2025-03-26 02:24:25,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742310_1486, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,536 INFO terminating
2025-03-26 02:24:25,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742311_1487, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java._COPYING_
2025-03-26 02:24:25,539 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,539 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,539 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,539 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,539 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,539 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742311_1487 src: /172.20.1.10:58316 dest: /172.20.1.11:9866
2025-03-26 02:24:25,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742311_1487 src: /172.20.1.11:48966 dest: /172.20.1.12:9866
2025-03-26 02:24:25,542 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58316, dest: /172.20.1.11:9866, bytes: 2548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742311_1487, duration(ns): 452231
2025-03-26 02:24:25,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48966, dest: /172.20.1.12:9866, bytes: 2548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742311_1487, duration(ns): 289683
2025-03-26 02:24:25,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742311_1487, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,542 INFO terminating
2025-03-26 02:24:25,545 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742312_1488, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_
2025-03-26 02:24:25,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,545 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,545 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,545 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742312_1488 src: /172.20.1.10:58320 dest: /172.20.1.11:9866
2025-03-26 02:24:25,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742312_1488 src: /172.20.1.11:48968 dest: /172.20.1.12:9866
2025-03-26 02:24:25,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58320, dest: /172.20.1.11:9866, bytes: 3273, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742312_1488, duration(ns): 725645
2025-03-26 02:24:25,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48968, dest: /172.20.1.12:9866, bytes: 3273, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742312_1488, duration(ns): 283766
2025-03-26 02:24:25,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742312_1488, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,548 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742312_1488 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_
2025-03-26 02:24:25,548 INFO terminating
2025-03-26 02:24:25,949 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,957 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742313_1489, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java._COPYING_
2025-03-26 02:24:25,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,957 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,957 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,957 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742313_1489 src: /172.20.1.10:58326 dest: /172.20.1.11:9866
2025-03-26 02:24:25,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742313_1489 src: /172.20.1.11:48984 dest: /172.20.1.12:9866
2025-03-26 02:24:25,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58326, dest: /172.20.1.11:9866, bytes: 2758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742313_1489, duration(ns): 843230
2025-03-26 02:24:25,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48984, dest: /172.20.1.12:9866, bytes: 2758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742313_1489, duration(ns): 628357
2025-03-26 02:24:25,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742313_1489, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,961 INFO terminating
2025-03-26 02:24:25,962 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742314_1490, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java._COPYING_
2025-03-26 02:24:25,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,965 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,965 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,965 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742314_1490 src: /172.20.1.10:45148 dest: /172.20.1.12:9866
2025-03-26 02:24:25,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742314_1490 src: /172.20.1.12:55288 dest: /172.20.1.11:9866
2025-03-26 02:24:25,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55288, dest: /172.20.1.11:9866, bytes: 4577, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742314_1490, duration(ns): 630931
2025-03-26 02:24:25,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742314_1490, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,969 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45148, dest: /172.20.1.12:9866, bytes: 4577, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742314_1490, duration(ns): 756706
2025-03-26 02:24:25,969 INFO terminating
2025-03-26 02:24:25,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742315_1491, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java._COPYING_
2025-03-26 02:24:25,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,973 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,973 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,973 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742315_1491 src: /172.20.1.10:58332 dest: /172.20.1.11:9866
2025-03-26 02:24:25,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742315_1491 src: /172.20.1.11:48986 dest: /172.20.1.12:9866
2025-03-26 02:24:25,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:48986, dest: /172.20.1.12:9866, bytes: 1827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742315_1491, duration(ns): 520191
2025-03-26 02:24:25,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742315_1491, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,977 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:25,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58332, dest: /172.20.1.11:9866, bytes: 1827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742315_1491, duration(ns): 664581
2025-03-26 02:24:25,977 INFO terminating
2025-03-26 02:24:25,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742316_1492, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_
2025-03-26 02:24:25,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:25,980 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:25,980 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:25,980 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:25,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742316_1492 src: /172.20.1.10:45164 dest: /172.20.1.12:9866
2025-03-26 02:24:25,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742316_1492 src: /172.20.1.12:55304 dest: /172.20.1.11:9866
2025-03-26 02:24:25,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45164, dest: /172.20.1.12:9866, bytes: 2627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742316_1492, duration(ns): 743694
2025-03-26 02:24:25,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55304, dest: /172.20.1.11:9866, bytes: 2627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742316_1492, duration(ns): 619476
2025-03-26 02:24:25,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742316_1492, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:25,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742316_1492 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_
2025-03-26 02:24:25,984 INFO terminating
2025-03-26 02:24:26,385 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742317_1493, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java._COPYING_
2025-03-26 02:24:26,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,392 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,392 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,392 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742317_1493 src: /172.20.1.10:45166 dest: /172.20.1.12:9866
2025-03-26 02:24:26,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742317_1493 src: /172.20.1.12:55310 dest: /172.20.1.11:9866
2025-03-26 02:24:26,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55310, dest: /172.20.1.11:9866, bytes: 4114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742317_1493, duration(ns): 1497623
2025-03-26 02:24:26,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742317_1493, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45166, dest: /172.20.1.12:9866, bytes: 4114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742317_1493, duration(ns): 3196507
2025-03-26 02:24:26,403 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,403 INFO terminating
2025-03-26 02:24:26,411 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742318_1494, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java._COPYING_
2025-03-26 02:24:26,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,411 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,411 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,411 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742318_1494 src: /172.20.1.10:45174 dest: /172.20.1.12:9866
2025-03-26 02:24:26,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742318_1494 src: /172.20.1.12:55316 dest: /172.20.1.11:9866
2025-03-26 02:24:26,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55316, dest: /172.20.1.11:9866, bytes: 2611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742318_1494, duration(ns): 2409299
2025-03-26 02:24:26,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45174, dest: /172.20.1.12:9866, bytes: 2611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742318_1494, duration(ns): 3023650
2025-03-26 02:24:26,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742318_1494, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,450 INFO terminating
2025-03-26 02:24:26,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,459 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,460 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742319_1495, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java._COPYING_
2025-03-26 02:24:26,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742319_1495 src: /172.20.1.10:58340 dest: /172.20.1.11:9866
2025-03-26 02:24:26,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742319_1495 src: /172.20.1.11:49002 dest: /172.20.1.12:9866
2025-03-26 02:24:26,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58340, dest: /172.20.1.11:9866, bytes: 2390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742319_1495, duration(ns): 1038903
2025-03-26 02:24:26,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49002, dest: /172.20.1.12:9866, bytes: 2390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742319_1495, duration(ns): 736490
2025-03-26 02:24:26,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742319_1495, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,464 INFO terminating
2025-03-26 02:24:26,467 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,473 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742320_1496, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java._COPYING_
2025-03-26 02:24:26,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,473 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,473 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,473 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742320_1496 src: /172.20.1.10:45180 dest: /172.20.1.12:9866
2025-03-26 02:24:26,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742320_1496 src: /172.20.1.12:55326 dest: /172.20.1.11:9866
2025-03-26 02:24:26,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55326, dest: /172.20.1.11:9866, bytes: 3047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742320_1496, duration(ns): 573445
2025-03-26 02:24:26,477 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45180, dest: /172.20.1.12:9866, bytes: 3047, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742320_1496, duration(ns): 740532
2025-03-26 02:24:26,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742320_1496, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,477 INFO terminating
2025-03-26 02:24:26,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742321_1497, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java._COPYING_
2025-03-26 02:24:26,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,480 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,480 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,480 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,480 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742321_1497 src: /172.20.1.10:58356 dest: /172.20.1.11:9866
2025-03-26 02:24:26,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742321_1497 src: /172.20.1.11:49014 dest: /172.20.1.12:9866
2025-03-26 02:24:26,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58356, dest: /172.20.1.11:9866, bytes: 2317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742321_1497, duration(ns): 573182
2025-03-26 02:24:26,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49014, dest: /172.20.1.12:9866, bytes: 2317, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742321_1497, duration(ns): 456054
2025-03-26 02:24:26,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742321_1497, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,483 INFO terminating
2025-03-26 02:24:26,484 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742322_1498, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java._COPYING_
2025-03-26 02:24:26,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,486 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,486 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,486 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742322_1498 src: /172.20.1.10:58358 dest: /172.20.1.11:9866
2025-03-26 02:24:26,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742322_1498 src: /172.20.1.11:49026 dest: /172.20.1.12:9866
2025-03-26 02:24:26,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58358, dest: /172.20.1.11:9866, bytes: 2861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742322_1498, duration(ns): 476763
2025-03-26 02:24:26,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49026, dest: /172.20.1.12:9866, bytes: 2861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742322_1498, duration(ns): 293685
2025-03-26 02:24:26,489 INFO terminating
2025-03-26 02:24:26,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742322_1498, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,496 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742323_1499, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java._COPYING_
2025-03-26 02:24:26,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,499 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,499 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,499 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742323_1499 src: /172.20.1.10:45182 dest: /172.20.1.12:9866
2025-03-26 02:24:26,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742323_1499 src: /172.20.1.12:55340 dest: /172.20.1.11:9866
2025-03-26 02:24:26,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45182, dest: /172.20.1.12:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742323_1499, duration(ns): 527099
2025-03-26 02:24:26,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55340, dest: /172.20.1.11:9866, bytes: 5217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742323_1499, duration(ns): 351145
2025-03-26 02:24:26,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742323_1499, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,502 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,502 INFO terminating
2025-03-26 02:24:26,504 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742324_1500, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java._COPYING_
2025-03-26 02:24:26,504 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,504 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,504 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,504 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,504 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,504 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742324_1500 src: /172.20.1.10:58360 dest: /172.20.1.11:9866
2025-03-26 02:24:26,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742324_1500 src: /172.20.1.11:49032 dest: /172.20.1.12:9866
2025-03-26 02:24:26,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49032, dest: /172.20.1.12:9866, bytes: 3947, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742324_1500, duration(ns): 739681
2025-03-26 02:24:26,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742324_1500, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,508 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58360, dest: /172.20.1.11:9866, bytes: 3947, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742324_1500, duration(ns): 930725
2025-03-26 02:24:26,508 INFO terminating
2025-03-26 02:24:26,512 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742325_1501, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java._COPYING_
2025-03-26 02:24:26,512 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,512 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,512 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,512 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,512 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,512 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742325_1501 src: /172.20.1.10:58368 dest: /172.20.1.11:9866
2025-03-26 02:24:26,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742325_1501 src: /172.20.1.11:49048 dest: /172.20.1.12:9866
2025-03-26 02:24:26,515 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58368, dest: /172.20.1.11:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742325_1501, duration(ns): 829284
2025-03-26 02:24:26,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49048, dest: /172.20.1.12:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742325_1501, duration(ns): 424485
2025-03-26 02:24:26,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742325_1501, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,515 INFO terminating
2025-03-26 02:24:26,519 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742326_1502, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java._COPYING_
2025-03-26 02:24:26,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,519 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,519 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,519 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742326_1502 src: /172.20.1.10:58372 dest: /172.20.1.11:9866
2025-03-26 02:24:26,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49056, dest: /172.20.1.12:9866, bytes: 2630, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742326_1502, duration(ns): 299947
2025-03-26 02:24:26,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742326_1502, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742326_1502 src: /172.20.1.11:49056 dest: /172.20.1.12:9866
2025-03-26 02:24:26,522 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58372, dest: /172.20.1.11:9866, bytes: 2630, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742326_1502, duration(ns): 388389
2025-03-26 02:24:26,522 INFO terminating
2025-03-26 02:24:26,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742327_1503, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java._COPYING_
2025-03-26 02:24:26,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,525 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,525 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,525 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742327_1503 src: /172.20.1.10:45188 dest: /172.20.1.12:9866
2025-03-26 02:24:26,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742327_1503 src: /172.20.1.12:55350 dest: /172.20.1.11:9866
2025-03-26 02:24:26,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55350, dest: /172.20.1.11:9866, bytes: 2309, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742327_1503, duration(ns): 495712
2025-03-26 02:24:26,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742327_1503, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,528 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45188, dest: /172.20.1.12:9866, bytes: 2309, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742327_1503, duration(ns): 643637
2025-03-26 02:24:26,528 INFO terminating
2025-03-26 02:24:26,530 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,531 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742328_1504, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java._COPYING_
2025-03-26 02:24:26,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,531 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,531 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,531 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742328_1504 src: /172.20.1.10:45202 dest: /172.20.1.12:9866
2025-03-26 02:24:26,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742328_1504 src: /172.20.1.12:55366 dest: /172.20.1.11:9866
2025-03-26 02:24:26,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45202, dest: /172.20.1.12:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742328_1504, duration(ns): 538490
2025-03-26 02:24:26,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55366, dest: /172.20.1.11:9866, bytes: 2658, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742328_1504, duration(ns): 320840
2025-03-26 02:24:26,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742328_1504, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,533 INFO terminating
2025-03-26 02:24:26,534 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,537 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742329_1505, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java._COPYING_
2025-03-26 02:24:26,537 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,537 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,537 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742329_1505 src: /172.20.1.10:45218 dest: /172.20.1.12:9866
2025-03-26 02:24:26,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742329_1505 src: /172.20.1.12:55372 dest: /172.20.1.11:9866
2025-03-26 02:24:26,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55372, dest: /172.20.1.11:9866, bytes: 2187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742329_1505, duration(ns): 340416
2025-03-26 02:24:26,540 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45218, dest: /172.20.1.12:9866, bytes: 2187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742329_1505, duration(ns): 778700
2025-03-26 02:24:26,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742329_1505, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,540 INFO terminating
2025-03-26 02:24:26,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742330_1506, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java._COPYING_
2025-03-26 02:24:26,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,543 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,543 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,543 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742330_1506 src: /172.20.1.10:45232 dest: /172.20.1.12:9866
2025-03-26 02:24:26,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742330_1506 src: /172.20.1.12:55384 dest: /172.20.1.11:9866
2025-03-26 02:24:26,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45232, dest: /172.20.1.12:9866, bytes: 2422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742330_1506, duration(ns): 563647
2025-03-26 02:24:26,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55384, dest: /172.20.1.11:9866, bytes: 2422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742330_1506, duration(ns): 319777
2025-03-26 02:24:26,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742330_1506, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,546 INFO terminating
2025-03-26 02:24:26,547 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742331_1507, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java._COPYING_
2025-03-26 02:24:26,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,549 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,549 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,549 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742331_1507 src: /172.20.1.10:58388 dest: /172.20.1.11:9866
2025-03-26 02:24:26,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742331_1507 src: /172.20.1.11:49060 dest: /172.20.1.12:9866
2025-03-26 02:24:26,552 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58388, dest: /172.20.1.11:9866, bytes: 2270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742331_1507, duration(ns): 456740
2025-03-26 02:24:26,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49060, dest: /172.20.1.12:9866, bytes: 2270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742331_1507, duration(ns): 282838
2025-03-26 02:24:26,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742331_1507, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,552 INFO terminating
2025-03-26 02:24:26,555 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742332_1508, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_
2025-03-26 02:24:26,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,555 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,555 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,555 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742332_1508 src: /172.20.1.10:45240 dest: /172.20.1.12:9866
2025-03-26 02:24:26,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742332_1508 src: /172.20.1.12:55394 dest: /172.20.1.11:9866
2025-03-26 02:24:26,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:45240, dest: /172.20.1.12:9866, bytes: 3520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742332_1508, duration(ns): 622930
2025-03-26 02:24:26,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:55394, dest: /172.20.1.11:9866, bytes: 3520, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742332_1508, duration(ns): 359831
2025-03-26 02:24:26,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742332_1508, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,560 INFO terminating
2025-03-26 02:24:26,561 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742332_1508 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_
2025-03-26 02:24:26,961 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742333_1509, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java._COPYING_
2025-03-26 02:24:26,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,965 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,965 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,965 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742333_1509 src: /172.20.1.10:58392 dest: /172.20.1.11:9866
2025-03-26 02:24:26,967 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742333_1509 src: /172.20.1.11:49066 dest: /172.20.1.12:9866
2025-03-26 02:24:26,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49066, dest: /172.20.1.12:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742333_1509, duration(ns): 543454
2025-03-26 02:24:26,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742333_1509, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,969 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:26,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58392, dest: /172.20.1.11:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742333_1509, duration(ns): 702360
2025-03-26 02:24:26,969 INFO terminating
2025-03-26 02:24:26,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742334_1510, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_
2025-03-26 02:24:26,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:26,973 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:26,973 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:26,973 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:26,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742334_1510 src: /172.20.1.10:58402 dest: /172.20.1.11:9866
2025-03-26 02:24:26,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742334_1510 src: /172.20.1.11:49068 dest: /172.20.1.12:9866
2025-03-26 02:24:26,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:58402, dest: /172.20.1.11:9866, bytes: 1271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742334_1510, duration(ns): 670533
2025-03-26 02:24:26,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:49068, dest: /172.20.1.12:9866, bytes: 1271, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742334_1510, duration(ns): 418020
2025-03-26 02:24:26,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742334_1510, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:26,976 INFO terminating
2025-03-26 02:24:26,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742334_1510 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_
2025-03-26 02:24:27,378 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742335_1511, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java._COPYING_
2025-03-26 02:24:27,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,389 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,389 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,389 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742335_1511 src: /172.20.1.10:59950 dest: /172.20.1.11:9866
2025-03-26 02:24:27,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742335_1511 src: /172.20.1.11:35232 dest: /172.20.1.12:9866
2025-03-26 02:24:27,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:59950, dest: /172.20.1.11:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742335_1511, duration(ns): 3882703
2025-03-26 02:24:27,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35232, dest: /172.20.1.12:9866, bytes: 4083, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742335_1511, duration(ns): 3623948
2025-03-26 02:24:27,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742335_1511, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,399 INFO terminating
2025-03-26 02:24:27,402 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742336_1512, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java._COPYING_
2025-03-26 02:24:27,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,407 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,407 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,407 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742336_1512 src: /172.20.1.10:49994 dest: /172.20.1.12:9866
2025-03-26 02:24:27,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742336_1512 src: /172.20.1.12:38462 dest: /172.20.1.11:9866
2025-03-26 02:24:27,413 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:49994, dest: /172.20.1.12:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742336_1512, duration(ns): 455162
2025-03-26 02:24:27,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:38462, dest: /172.20.1.11:9866, bytes: 2078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742336_1512, duration(ns): 441356
2025-03-26 02:24:27,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742336_1512, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,413 INFO terminating
2025-03-26 02:24:27,417 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742337_1513, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java._COPYING_
2025-03-26 02:24:27,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,417 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,417 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,417 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742337_1513 src: /172.20.1.10:59962 dest: /172.20.1.11:9866
2025-03-26 02:24:27,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742337_1513 src: /172.20.1.11:35236 dest: /172.20.1.12:9866
2025-03-26 02:24:27,421 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:59962, dest: /172.20.1.11:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742337_1513, duration(ns): 901002
2025-03-26 02:24:27,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35236, dest: /172.20.1.12:9866, bytes: 2439, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742337_1513, duration(ns): 510080
2025-03-26 02:24:27,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742337_1513, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,421 INFO terminating
2025-03-26 02:24:27,425 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742338_1514, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java._COPYING_
2025-03-26 02:24:27,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,425 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,425 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,425 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742338_1514 src: /172.20.1.10:50006 dest: /172.20.1.12:9866
2025-03-26 02:24:27,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:38476, dest: /172.20.1.11:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742338_1514, duration(ns): 254775
2025-03-26 02:24:27,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742338_1514, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742338_1514 src: /172.20.1.12:38476 dest: /172.20.1.11:9866
2025-03-26 02:24:27,428 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50006, dest: /172.20.1.12:9866, bytes: 2231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742338_1514, duration(ns): 422857
2025-03-26 02:24:27,428 INFO terminating
2025-03-26 02:24:27,435 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742339_1515, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java._COPYING_
2025-03-26 02:24:27,435 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,435 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,435 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,435 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,435 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,435 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742339_1515 src: /172.20.1.10:50010 dest: /172.20.1.12:9866
2025-03-26 02:24:27,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742339_1515 src: /172.20.1.12:38492 dest: /172.20.1.11:9866
2025-03-26 02:24:27,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50010, dest: /172.20.1.12:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742339_1515, duration(ns): 515566
2025-03-26 02:24:27,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:38492, dest: /172.20.1.11:9866, bytes: 2664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742339_1515, duration(ns): 437006
2025-03-26 02:24:27,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742339_1515, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,440 INFO terminating
2025-03-26 02:24:27,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742340_1516, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_
2025-03-26 02:24:27,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,443 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742340_1516 src: /172.20.1.10:50020 dest: /172.20.1.12:9866
2025-03-26 02:24:27,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:38496, dest: /172.20.1.11:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742340_1516, duration(ns): 248598
2025-03-26 02:24:27,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742340_1516 src: /172.20.1.12:38496 dest: /172.20.1.11:9866
2025-03-26 02:24:27,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50020, dest: /172.20.1.12:9866, bytes: 2364, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742340_1516, duration(ns): 1158339
2025-03-26 02:24:27,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742340_1516, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,446 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742340_1516 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_
2025-03-26 02:24:27,446 INFO terminating
2025-03-26 02:24:27,847 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,853 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742341_1517, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java._COPYING_
2025-03-26 02:24:27,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,853 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,853 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,853 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742341_1517 src: /172.20.1.10:59964 dest: /172.20.1.11:9866
2025-03-26 02:24:27,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742341_1517 src: /172.20.1.11:35246 dest: /172.20.1.12:9866
2025-03-26 02:24:27,856 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:59964, dest: /172.20.1.11:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742341_1517, duration(ns): 736569
2025-03-26 02:24:27,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35246, dest: /172.20.1.12:9866, bytes: 2140, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742341_1517, duration(ns): 596224
2025-03-26 02:24:27,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742341_1517, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,856 INFO terminating
2025-03-26 02:24:27,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742342_1518, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java._COPYING_
2025-03-26 02:24:27,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,864 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,864 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,864 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742342_1518 src: /172.20.1.10:59976 dest: /172.20.1.11:9866
2025-03-26 02:24:27,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742342_1518 src: /172.20.1.11:35248 dest: /172.20.1.12:9866
2025-03-26 02:24:27,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35248, dest: /172.20.1.12:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742342_1518, duration(ns): 547909
2025-03-26 02:24:27,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742342_1518, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,868 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:59976, dest: /172.20.1.11:9866, bytes: 3376, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742342_1518, duration(ns): 666363
2025-03-26 02:24:27,868 INFO terminating
2025-03-26 02:24:27,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742343_1519, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java._COPYING_
2025-03-26 02:24:27,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,873 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,873 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,873 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742343_1519 src: /172.20.1.10:50034 dest: /172.20.1.12:9866
2025-03-26 02:24:27,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742343_1519 src: /172.20.1.12:38508 dest: /172.20.1.11:9866
2025-03-26 02:24:27,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50034, dest: /172.20.1.12:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742343_1519, duration(ns): 11012756
2025-03-26 02:24:27,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:38508, dest: /172.20.1.11:9866, bytes: 2442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742343_1519, duration(ns): 10732108
2025-03-26 02:24:27,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742343_1519, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,894 INFO terminating
2025-03-26 02:24:27,897 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,902 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,902 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,902 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,903 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742344_1520, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java._COPYING_
2025-03-26 02:24:27,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742344_1520 src: /172.20.1.10:50048 dest: /172.20.1.12:9866
2025-03-26 02:24:27,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742344_1520 src: /172.20.1.12:38518 dest: /172.20.1.11:9866
2025-03-26 02:24:27,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50048, dest: /172.20.1.12:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742344_1520, duration(ns): 798845
2025-03-26 02:24:27,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:38518, dest: /172.20.1.11:9866, bytes: 1954, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742344_1520, duration(ns): 682170
2025-03-26 02:24:27,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742344_1520, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,909 INFO terminating
2025-03-26 02:24:27,910 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742345_1521, replicas=172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:24:27,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,914 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,914 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,914 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742345_1521 src: /172.20.1.10:50060 dest: /172.20.1.12:9866
2025-03-26 02:24:27,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742345_1521 src: /172.20.1.12:38534 dest: /172.20.1.11:9866
2025-03-26 02:24:27,917 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50060, dest: /172.20.1.12:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742345_1521, duration(ns): 624601
2025-03-26 02:24:27,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:38534, dest: /172.20.1.11:9866, bytes: 2534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742345_1521, duration(ns): 497180
2025-03-26 02:24:27,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742345_1521, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,917 INFO terminating
2025-03-26 02:24:27,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742346_1522, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java._COPYING_
2025-03-26 02:24:27,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,921 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,921 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,921 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742346_1522 src: /172.20.1.10:59980 dest: /172.20.1.11:9866
2025-03-26 02:24:27,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742346_1522 src: /172.20.1.11:35252 dest: /172.20.1.12:9866
2025-03-26 02:24:27,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:59980, dest: /172.20.1.11:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742346_1522, duration(ns): 594827
2025-03-26 02:24:27,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35252, dest: /172.20.1.12:9866, bytes: 3545, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742346_1522, duration(ns): 479198
2025-03-26 02:24:27,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742346_1522, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,924 INFO terminating
2025-03-26 02:24:27,925 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,928 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742347_1523, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java._COPYING_
2025-03-26 02:24:27,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,928 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,928 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,928 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742347_1523 src: /172.20.1.10:59994 dest: /172.20.1.11:9866
2025-03-26 02:24:27,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742347_1523 src: /172.20.1.11:35258 dest: /172.20.1.12:9866
2025-03-26 02:24:27,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:59994, dest: /172.20.1.11:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742347_1523, duration(ns): 503438
2025-03-26 02:24:27,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35258, dest: /172.20.1.12:9866, bytes: 2492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742347_1523, duration(ns): 379989
2025-03-26 02:24:27,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742347_1523, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,932 INFO terminating
2025-03-26 02:24:27,933 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,935 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,935 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,935 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,936 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742348_1524, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java._COPYING_
2025-03-26 02:24:27,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742348_1524 src: /172.20.1.10:60010 dest: /172.20.1.11:9866
2025-03-26 02:24:27,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742348_1524 src: /172.20.1.11:35260 dest: /172.20.1.12:9866
2025-03-26 02:24:27,938 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:60010, dest: /172.20.1.11:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742348_1524, duration(ns): 423235
2025-03-26 02:24:27,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35260, dest: /172.20.1.12:9866, bytes: 2110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742348_1524, duration(ns): 273723
2025-03-26 02:24:27,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742348_1524, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,938 INFO terminating
2025-03-26 02:24:27,941 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742349_1525, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java._COPYING_
2025-03-26 02:24:27,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,941 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,941 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,941 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742349_1525 src: /172.20.1.10:60020 dest: /172.20.1.11:9866
2025-03-26 02:24:27,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742349_1525 src: /172.20.1.11:35268 dest: /172.20.1.12:9866
2025-03-26 02:24:27,944 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:60020, dest: /172.20.1.11:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742349_1525, duration(ns): 431875
2025-03-26 02:24:27,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35268, dest: /172.20.1.12:9866, bytes: 2993, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742349_1525, duration(ns): 269779
2025-03-26 02:24:27,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742349_1525, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,944 INFO terminating
2025-03-26 02:24:27,948 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742350_1526, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java._COPYING_
2025-03-26 02:24:27,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,948 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,948 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,948 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742350_1526 src: /172.20.1.10:60034 dest: /172.20.1.11:9866
2025-03-26 02:24:27,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742350_1526 src: /172.20.1.11:35276 dest: /172.20.1.12:9866
2025-03-26 02:24:27,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:60034, dest: /172.20.1.11:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742350_1526, duration(ns): 815990
2025-03-26 02:24:27,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35276, dest: /172.20.1.12:9866, bytes: 2574, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742350_1526, duration(ns): 624072
2025-03-26 02:24:27,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742350_1526, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,952 INFO terminating
2025-03-26 02:24:27,953 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742351_1527, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:24:27,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,960 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,960 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,960 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742351_1527 src: /172.20.1.10:60050 dest: /172.20.1.11:9866
2025-03-26 02:24:27,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742351_1527 src: /172.20.1.11:35290 dest: /172.20.1.12:9866
2025-03-26 02:24:27,964 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:60050, dest: /172.20.1.11:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742351_1527, duration(ns): 1855299
2025-03-26 02:24:27,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35290, dest: /172.20.1.12:9866, bytes: 2551, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742351_1527, duration(ns): 1663443
2025-03-26 02:24:27,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742351_1527, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,964 INFO terminating
2025-03-26 02:24:27,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742352_1528, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java._COPYING_
2025-03-26 02:24:27,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,970 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,970 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,970 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742352_1528 src: /172.20.1.10:60062 dest: /172.20.1.11:9866
2025-03-26 02:24:27,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742352_1528 src: /172.20.1.11:35302 dest: /172.20.1.12:9866
2025-03-26 02:24:27,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:60062, dest: /172.20.1.11:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742352_1528, duration(ns): 533501
2025-03-26 02:24:27,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35302, dest: /172.20.1.12:9866, bytes: 2465, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742352_1528, duration(ns): 360550
2025-03-26 02:24:27,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742352_1528, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,973 INFO terminating
2025-03-26 02:24:27,974 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,977 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742353_1529, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java._COPYING_
2025-03-26 02:24:27,978 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,978 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,978 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,978 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,978 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742353_1529 src: /172.20.1.10:60078 dest: /172.20.1.11:9866
2025-03-26 02:24:27,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742353_1529 src: /172.20.1.11:35306 dest: /172.20.1.12:9866
2025-03-26 02:24:27,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35306, dest: /172.20.1.12:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742353_1529, duration(ns): 422749
2025-03-26 02:24:27,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742353_1529, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,981 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:27,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:60078, dest: /172.20.1.11:9866, bytes: 3238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742353_1529, duration(ns): 633854
2025-03-26 02:24:27,981 INFO terminating
2025-03-26 02:24:27,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742354_1530, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java._COPYING_
2025-03-26 02:24:27,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:27,985 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:27,985 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:27,985 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:27,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742354_1530 src: /172.20.1.10:60090 dest: /172.20.1.11:9866
2025-03-26 02:24:27,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742354_1530 src: /172.20.1.11:35318 dest: /172.20.1.12:9866
2025-03-26 02:24:27,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:60090, dest: /172.20.1.11:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742354_1530, duration(ns): 510262
2025-03-26 02:24:27,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35318, dest: /172.20.1.12:9866, bytes: 4627, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742354_1530, duration(ns): 327481
2025-03-26 02:24:27,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742354_1530, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:27,988 INFO terminating
2025-03-26 02:24:27,989 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742355_1531, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java._COPYING_
2025-03-26 02:24:28,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,004 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,004 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,004 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742355_1531 src: /172.20.1.10:60098 dest: /172.20.1.11:9866
2025-03-26 02:24:28,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742355_1531 src: /172.20.1.11:35332 dest: /172.20.1.12:9866
2025-03-26 02:24:28,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:60098, dest: /172.20.1.11:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742355_1531, duration(ns): 636685
2025-03-26 02:24:28,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35332, dest: /172.20.1.12:9866, bytes: 2290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742355_1531, duration(ns): 440267
2025-03-26 02:24:28,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742355_1531, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,008 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,008 INFO terminating
2025-03-26 02:24:28,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742356_1532, replicas=172.20.1.11:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java._COPYING_
2025-03-26 02:24:28,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,012 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,012 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,012 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742356_1532 src: /172.20.1.10:60100 dest: /172.20.1.11:9866
2025-03-26 02:24:28,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742356_1532 src: /172.20.1.11:35342 dest: /172.20.1.12:9866
2025-03-26 02:24:28,017 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:60100, dest: /172.20.1.11:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742356_1532, duration(ns): 2495507
2025-03-26 02:24:28,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:35342, dest: /172.20.1.12:9866, bytes: 2942, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742356_1532, duration(ns): 2351285
2025-03-26 02:24:28,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742356_1532, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,017 INFO terminating
2025-03-26 02:24:28,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742357_1533, replicas=172.20.1.12:9866, 172.20.1.11:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java._COPYING_
2025-03-26 02:24:28,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742357_1533 src: /172.20.1.10:50068 dest: /172.20.1.12:9866
2025-03-26 02:24:28,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742357_1533 src: /172.20.1.12:38540 dest: /172.20.1.11:9866
2025-03-26 02:24:28,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742357_1533 src: /172.20.1.11:42806 dest: /172.20.1.13:9866
2025-03-26 02:24:28,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:42806, dest: /172.20.1.13:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742357_1533, duration(ns): 729030
2025-03-26 02:24:28,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:38540, dest: /172.20.1.11:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742357_1533, duration(ns): 959732
2025-03-26 02:24:28,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742357_1533, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50068, dest: /172.20.1.12:9866, bytes: 3224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742357_1533, duration(ns): 1111742
2025-03-26 02:24:28,025 INFO terminating
2025-03-26 02:24:28,025 INFO terminating
2025-03-26 02:24:28,026 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742358_1534, replicas=172.20.1.11:9866, 172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java._COPYING_
2025-03-26 02:24:28,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742358_1534 src: /172.20.1.10:60102 dest: /172.20.1.11:9866
2025-03-26 02:24:28,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742358_1534 src: /172.20.1.11:42822 dest: /172.20.1.13:9866
2025-03-26 02:24:28,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742358_1534 src: /172.20.1.13:48348 dest: /172.20.1.12:9866
2025-03-26 02:24:28,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48348, dest: /172.20.1.12:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742358_1534, duration(ns): 613867
2025-03-26 02:24:28,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742358_1534, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,035 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:60102, dest: /172.20.1.11:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742358_1534, duration(ns): 1086033
2025-03-26 02:24:28,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.11:42822, dest: /172.20.1.13:9866, bytes: 2252, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742358_1534, duration(ns): 787137
2025-03-26 02:24:28,035 INFO terminating
2025-03-26 02:24:28,035 INFO terminating
2025-03-26 02:24:28,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742234_1410 to 172.20.1.11:9866
2025-03-26 02:24:28,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742235_1411 to 172.20.1.11:9866
2025-03-26 02:24:28,040 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742359_1535, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java._COPYING_
2025-03-26 02:24:28,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,040 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,040 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,040 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742359_1535 src: /172.20.1.10:39868 dest: /172.20.1.13:9866
2025-03-26 02:24:28,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742359_1535 src: /172.20.1.13:48362 dest: /172.20.1.12:9866
2025-03-26 02:24:28,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742234_1410 src: /172.20.1.13:37440 dest: /172.20.1.11:9866
2025-03-26 02:24:28,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48362, dest: /172.20.1.12:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742359_1535, duration(ns): 24719881
2025-03-26 02:24:28,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742359_1535, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742235_1411 src: /172.20.1.13:37442 dest: /172.20.1.11:9866
2025-03-26 02:24:28,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742234_1410 (numBytes=3236) to /172.20.1.11:9866
2025-03-26 02:24:28,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742234_1410 src: /172.20.1.13:37440 dest: /172.20.1.11:9866 of size 3236
2025-03-26 02:24:28,070 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39868, dest: /172.20.1.13:9866, bytes: 4077, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742359_1535, duration(ns): 1870528
2025-03-26 02:24:28,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742235_1411 (numBytes=2552) to /172.20.1.11:9866
2025-03-26 02:24:28,070 INFO terminating
2025-03-26 02:24:28,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742235_1411 src: /172.20.1.13:37442 dest: /172.20.1.11:9866 of size 2552
2025-03-26 02:24:28,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742360_1536, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java._COPYING_
2025-03-26 02:24:28,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,079 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,079 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,079 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742360_1536 src: /172.20.1.10:50072 dest: /172.20.1.12:9866
2025-03-26 02:24:28,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742360_1536 src: /172.20.1.12:57460 dest: /172.20.1.13:9866
2025-03-26 02:24:28,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50072, dest: /172.20.1.12:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742360_1536, duration(ns): 970184
2025-03-26 02:24:28,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57460, dest: /172.20.1.13:9866, bytes: 3469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742360_1536, duration(ns): 732289
2025-03-26 02:24:28,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742360_1536, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,083 INFO terminating
2025-03-26 02:24:28,085 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,089 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742361_1537, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java._COPYING_
2025-03-26 02:24:28,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,089 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,089 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,089 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742361_1537 src: /172.20.1.10:50082 dest: /172.20.1.12:9866
2025-03-26 02:24:28,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742361_1537 src: /172.20.1.12:57464 dest: /172.20.1.13:9866
2025-03-26 02:24:28,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50082, dest: /172.20.1.12:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742361_1537, duration(ns): 809046
2025-03-26 02:24:28,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57464, dest: /172.20.1.13:9866, bytes: 4460, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742361_1537, duration(ns): 630822
2025-03-26 02:24:28,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742361_1537, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,092 INFO terminating
2025-03-26 02:24:28,093 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,096 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,096 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,096 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,096 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,096 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,096 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742362_1538, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java._COPYING_
2025-03-26 02:24:28,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742362_1538 src: /172.20.1.10:50098 dest: /172.20.1.12:9866
2025-03-26 02:24:28,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742362_1538 src: /172.20.1.12:57472 dest: /172.20.1.13:9866
2025-03-26 02:24:28,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50098, dest: /172.20.1.12:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742362_1538, duration(ns): 2934430
2025-03-26 02:24:28,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57472, dest: /172.20.1.13:9866, bytes: 3155, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742362_1538, duration(ns): 2489162
2025-03-26 02:24:28,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742362_1538, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,102 INFO terminating
2025-03-26 02:24:28,103 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,107 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742363_1539, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_
2025-03-26 02:24:28,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,107 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,107 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,107 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742363_1539 src: /172.20.1.10:50110 dest: /172.20.1.12:9866
2025-03-26 02:24:28,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742363_1539 src: /172.20.1.12:57486 dest: /172.20.1.13:9866
2025-03-26 02:24:28,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50110, dest: /172.20.1.12:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742363_1539, duration(ns): 566377
2025-03-26 02:24:28,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57486, dest: /172.20.1.13:9866, bytes: 1921, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742363_1539, duration(ns): 334656
2025-03-26 02:24:28,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742363_1539, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,110 INFO terminating
2025-03-26 02:24:28,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742363_1539 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_
2025-03-26 02:24:28,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,460 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,460 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,461 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,461 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,461 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,461 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,461 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,461 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,461 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,461 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,461 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,511 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,519 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742364_1540, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java._COPYING_
2025-03-26 02:24:28,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,519 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,519 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,519 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742364_1540 src: /172.20.1.10:39880 dest: /172.20.1.13:9866
2025-03-26 02:24:28,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742364_1540 src: /172.20.1.13:48366 dest: /172.20.1.12:9866
2025-03-26 02:24:28,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39880, dest: /172.20.1.13:9866, bytes: 2645, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742364_1540, duration(ns): 671187
2025-03-26 02:24:28,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48366, dest: /172.20.1.12:9866, bytes: 2645, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742364_1540, duration(ns): 592477
2025-03-26 02:24:28,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742364_1540, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,523 INFO terminating
2025-03-26 02:24:28,524 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,526 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,527 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742365_1541, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java._COPYING_
2025-03-26 02:24:28,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,527 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,527 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,527 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742365_1541 src: /172.20.1.10:39894 dest: /172.20.1.13:9866
2025-03-26 02:24:28,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742365_1541 src: /172.20.1.13:48382 dest: /172.20.1.12:9866
2025-03-26 02:24:28,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39894, dest: /172.20.1.13:9866, bytes: 4683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742365_1541, duration(ns): 667160
2025-03-26 02:24:28,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48382, dest: /172.20.1.12:9866, bytes: 4683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742365_1541, duration(ns): 494177
2025-03-26 02:24:28,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742365_1541, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,532 INFO terminating
2025-03-26 02:24:28,533 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,536 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,537 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742366_1542, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java._COPYING_
2025-03-26 02:24:28,537 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,537 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742366_1542 src: /172.20.1.10:39906 dest: /172.20.1.13:9866
2025-03-26 02:24:28,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742366_1542 src: /172.20.1.13:48394 dest: /172.20.1.12:9866
2025-03-26 02:24:28,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39906, dest: /172.20.1.13:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742366_1542, duration(ns): 793108
2025-03-26 02:24:28,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48394, dest: /172.20.1.12:9866, bytes: 1943, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742366_1542, duration(ns): 637684
2025-03-26 02:24:28,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742366_1542, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,540 INFO terminating
2025-03-26 02:24:28,544 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,547 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742367_1543, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_
2025-03-26 02:24:28,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,548 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,548 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,548 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742367_1543 src: /172.20.1.10:50114 dest: /172.20.1.12:9866
2025-03-26 02:24:28,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742367_1543 src: /172.20.1.12:57496 dest: /172.20.1.13:9866
2025-03-26 02:24:28,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50114, dest: /172.20.1.12:9866, bytes: 1968, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742367_1543, duration(ns): 855530
2025-03-26 02:24:28,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57496, dest: /172.20.1.13:9866, bytes: 1968, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742367_1543, duration(ns): 532478
2025-03-26 02:24:28,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742367_1543, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742367_1543 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_
2025-03-26 02:24:28,551 INFO terminating
2025-03-26 02:24:28,952 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,955 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742368_1544, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java._COPYING_
2025-03-26 02:24:28,955 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,955 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,955 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,955 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,955 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,955 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742368_1544 src: /172.20.1.10:50120 dest: /172.20.1.12:9866
2025-03-26 02:24:28,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742368_1544 src: /172.20.1.12:57506 dest: /172.20.1.13:9866
2025-03-26 02:24:28,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50120, dest: /172.20.1.12:9866, bytes: 4506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742368_1544, duration(ns): 481167
2025-03-26 02:24:28,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57506, dest: /172.20.1.13:9866, bytes: 4506, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742368_1544, duration(ns): 356047
2025-03-26 02:24:28,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742368_1544, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,958 INFO terminating
2025-03-26 02:24:28,959 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742369_1545, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java._COPYING_
2025-03-26 02:24:28,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,961 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,961 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,961 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742369_1545 src: /172.20.1.10:50136 dest: /172.20.1.12:9866
2025-03-26 02:24:28,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742369_1545 src: /172.20.1.12:57522 dest: /172.20.1.13:9866
2025-03-26 02:24:28,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57522, dest: /172.20.1.13:9866, bytes: 2721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742369_1545, duration(ns): 574161
2025-03-26 02:24:28,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742369_1545, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,965 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50136, dest: /172.20.1.12:9866, bytes: 2721, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742369_1545, duration(ns): 740367
2025-03-26 02:24:28,965 INFO terminating
2025-03-26 02:24:28,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742370_1546, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/JavaTC.java._COPYING_
2025-03-26 02:24:28,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,969 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,969 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,969 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742370_1546 src: /172.20.1.10:39916 dest: /172.20.1.13:9866
2025-03-26 02:24:28,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742370_1546 src: /172.20.1.13:48402 dest: /172.20.1.12:9866
2025-03-26 02:24:28,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39916, dest: /172.20.1.13:9866, bytes: 3473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742370_1546, duration(ns): 745799
2025-03-26 02:24:28,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48402, dest: /172.20.1.12:9866, bytes: 3473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742370_1546, duration(ns): 608704
2025-03-26 02:24:28,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742370_1546, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,972 INFO terminating
2025-03-26 02:24:28,973 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/JavaTC.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742371_1547, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java._COPYING_
2025-03-26 02:24:28,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,980 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,980 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,980 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742371_1547 src: /172.20.1.10:50150 dest: /172.20.1.12:9866
2025-03-26 02:24:28,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742371_1547 src: /172.20.1.12:57534 dest: /172.20.1.13:9866
2025-03-26 02:24:28,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50150, dest: /172.20.1.12:9866, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742371_1547, duration(ns): 764969
2025-03-26 02:24:28,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57534, dest: /172.20.1.13:9866, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742371_1547, duration(ns): 632446
2025-03-26 02:24:28,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742371_1547, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,983 INFO terminating
2025-03-26 02:24:28,984 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:28,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742372_1548, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java._COPYING_
2025-03-26 02:24:28,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:28,987 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:28,987 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:28,987 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:28,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742372_1548 src: /172.20.1.10:39930 dest: /172.20.1.13:9866
2025-03-26 02:24:28,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742372_1548 src: /172.20.1.13:48406 dest: /172.20.1.12:9866
2025-03-26 02:24:28,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39930, dest: /172.20.1.13:9866, bytes: 4979, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742372_1548, duration(ns): 9097820
2025-03-26 02:24:28,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48406, dest: /172.20.1.12:9866, bytes: 4979, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742372_1548, duration(ns): 8800205
2025-03-26 02:24:28,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742372_1548, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:28,999 INFO terminating
2025-03-26 02:24:29,002 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:29,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,008 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:29,008 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:29,008 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:29,009 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742373_1549, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java._COPYING_
2025-03-26 02:24:29,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742373_1549 src: /172.20.1.10:50164 dest: /172.20.1.12:9866
2025-03-26 02:24:29,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742373_1549 src: /172.20.1.12:57540 dest: /172.20.1.13:9866
2025-03-26 02:24:29,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50164, dest: /172.20.1.12:9866, bytes: 10904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742373_1549, duration(ns): 1518379
2025-03-26 02:24:29,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57540, dest: /172.20.1.13:9866, bytes: 10904, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742373_1549, duration(ns): 1321529
2025-03-26 02:24:29,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742373_1549, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,013 INFO terminating
2025-03-26 02:24:29,014 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:29,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742374_1550, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java._COPYING_
2025-03-26 02:24:29,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,021 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:29,021 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:29,021 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:29,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742374_1550 src: /172.20.1.10:39940 dest: /172.20.1.13:9866
2025-03-26 02:24:29,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742374_1550 src: /172.20.1.13:48416 dest: /172.20.1.12:9866
2025-03-26 02:24:29,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48416, dest: /172.20.1.12:9866, bytes: 17432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742374_1550, duration(ns): 474361
2025-03-26 02:24:29,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742374_1550, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,025 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:29,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39940, dest: /172.20.1.13:9866, bytes: 17432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742374_1550, duration(ns): 661433
2025-03-26 02:24:29,025 INFO terminating
2025-03-26 02:24:29,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742375_1551, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java._COPYING_
2025-03-26 02:24:29,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,031 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:29,031 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:29,031 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:29,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742375_1551 src: /172.20.1.10:39950 dest: /172.20.1.13:9866
2025-03-26 02:24:29,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48420, dest: /172.20.1.12:9866, bytes: 4187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742375_1551, duration(ns): 496079
2025-03-26 02:24:29,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742375_1551 src: /172.20.1.13:48420 dest: /172.20.1.12:9866
2025-03-26 02:24:29,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:29,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39950, dest: /172.20.1.13:9866, bytes: 4187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742375_1551, duration(ns): 703950
2025-03-26 02:24:29,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742375_1551, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,034 INFO terminating
2025-03-26 02:24:29,037 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742376_1552, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java._COPYING_
2025-03-26 02:24:29,037 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,037 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,037 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,037 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:29,037 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:29,037 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:29,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742376_1552 src: /172.20.1.10:39962 dest: /172.20.1.13:9866
2025-03-26 02:24:29,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742376_1552 src: /172.20.1.13:48432 dest: /172.20.1.12:9866
2025-03-26 02:24:29,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39962, dest: /172.20.1.13:9866, bytes: 2898, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742376_1552, duration(ns): 551097
2025-03-26 02:24:29,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48432, dest: /172.20.1.12:9866, bytes: 2898, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742376_1552, duration(ns): 432366
2025-03-26 02:24:29,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742376_1552, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,040 INFO terminating
2025-03-26 02:24:29,041 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:29,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742377_1553, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java._COPYING_
2025-03-26 02:24:29,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,045 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:29,045 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:29,045 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:29,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742377_1553 src: /172.20.1.10:50174 dest: /172.20.1.12:9866
2025-03-26 02:24:29,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742377_1553 src: /172.20.1.12:57556 dest: /172.20.1.13:9866
2025-03-26 02:24:29,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50174, dest: /172.20.1.12:9866, bytes: 16348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742377_1553, duration(ns): 566482
2025-03-26 02:24:29,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57556, dest: /172.20.1.13:9866, bytes: 16348, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742377_1553, duration(ns): 477745
2025-03-26 02:24:29,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742377_1553, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,048 INFO terminating
2025-03-26 02:24:29,049 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:29,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742378_1554, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_
2025-03-26 02:24:29,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,052 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,052 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:29,052 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:29,052 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:29,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742378_1554 src: /172.20.1.10:50182 dest: /172.20.1.12:9866
2025-03-26 02:24:29,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742378_1554 src: /172.20.1.12:57570 dest: /172.20.1.13:9866
2025-03-26 02:24:29,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57570, dest: /172.20.1.13:9866, bytes: 5473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742378_1554, duration(ns): 433094
2025-03-26 02:24:29,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742378_1554, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50182, dest: /172.20.1.12:9866, bytes: 5473, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742378_1554, duration(ns): 506600
2025-03-26 02:24:29,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742378_1554 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_
2025-03-26 02:24:29,055 INFO terminating
2025-03-26 02:24:29,455 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:29,458 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742379_1555, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java._COPYING_
2025-03-26 02:24:29,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,458 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:29,458 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:29,458 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:29,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742379_1555 src: /172.20.1.10:50194 dest: /172.20.1.12:9866
2025-03-26 02:24:29,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742379_1555 src: /172.20.1.12:57580 dest: /172.20.1.13:9866
2025-03-26 02:24:29,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57580, dest: /172.20.1.13:9866, bytes: 4663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742379_1555, duration(ns): 614070
2025-03-26 02:24:29,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742379_1555, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,462 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:29,462 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50194, dest: /172.20.1.12:9866, bytes: 4663, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742379_1555, duration(ns): 728589
2025-03-26 02:24:29,462 INFO terminating
2025-03-26 02:24:29,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742380_1556, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_
2025-03-26 02:24:29,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,465 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:29,465 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:29,465 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:29,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742380_1556 src: /172.20.1.10:50196 dest: /172.20.1.12:9866
2025-03-26 02:24:29,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742380_1556 src: /172.20.1.12:57594 dest: /172.20.1.13:9866
2025-03-26 02:24:29,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50196, dest: /172.20.1.12:9866, bytes: 3479, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742380_1556, duration(ns): 783100
2025-03-26 02:24:29,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57594, dest: /172.20.1.13:9866, bytes: 3479, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742380_1556, duration(ns): 570878
2025-03-26 02:24:29,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742380_1556, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,469 INFO terminating
2025-03-26 02:24:29,471 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742380_1556 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_
2025-03-26 02:24:29,872 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:29,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742381_1557, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_
2025-03-26 02:24:29,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:29,879 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:29,879 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:29,879 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:29,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742381_1557 src: /172.20.1.10:39970 dest: /172.20.1.13:9866
2025-03-26 02:24:29,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742381_1557 src: /172.20.1.13:48434 dest: /172.20.1.12:9866
2025-03-26 02:24:29,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39970, dest: /172.20.1.13:9866, bytes: 3285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742381_1557, duration(ns): 656803
2025-03-26 02:24:29,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48434, dest: /172.20.1.12:9866, bytes: 3285, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742381_1557, duration(ns): 405017
2025-03-26 02:24:29,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742381_1557, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:29,882 INFO terminating
2025-03-26 02:24:29,883 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742381_1557 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_
2025-03-26 02:24:30,283 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:30,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742382_1558, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java._COPYING_
2025-03-26 02:24:30,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,287 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:30,287 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:30,287 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:30,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742382_1558 src: /172.20.1.10:39984 dest: /172.20.1.13:9866
2025-03-26 02:24:30,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742382_1558 src: /172.20.1.13:48444 dest: /172.20.1.12:9866
2025-03-26 02:24:30,290 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:30,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39984, dest: /172.20.1.13:9866, bytes: 2742, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742382_1558, duration(ns): 475004
2025-03-26 02:24:30,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48444, dest: /172.20.1.12:9866, bytes: 2742, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742382_1558, duration(ns): 356986
2025-03-26 02:24:30,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742382_1558, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,290 INFO terminating
2025-03-26 02:24:30,295 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742383_1559, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java._COPYING_
2025-03-26 02:24:30,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,295 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:30,295 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:30,295 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:30,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742383_1559 src: /172.20.1.10:50206 dest: /172.20.1.12:9866
2025-03-26 02:24:30,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742383_1559 src: /172.20.1.12:57610 dest: /172.20.1.13:9866
2025-03-26 02:24:30,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50206, dest: /172.20.1.12:9866, bytes: 6228, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742383_1559, duration(ns): 514994
2025-03-26 02:24:30,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57610, dest: /172.20.1.13:9866, bytes: 6228, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742383_1559, duration(ns): 332194
2025-03-26 02:24:30,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742383_1559, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,298 INFO terminating
2025-03-26 02:24:30,299 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:30,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,302 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742384_1560, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_
2025-03-26 02:24:30,302 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,302 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,302 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:30,302 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:30,302 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:30,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742384_1560 src: /172.20.1.10:50222 dest: /172.20.1.12:9866
2025-03-26 02:24:30,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742384_1560 src: /172.20.1.12:57612 dest: /172.20.1.13:9866
2025-03-26 02:24:30,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50222, dest: /172.20.1.12:9866, bytes: 1121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742384_1560, duration(ns): 792736
2025-03-26 02:24:30,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57612, dest: /172.20.1.13:9866, bytes: 1121, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742384_1560, duration(ns): 602451
2025-03-26 02:24:30,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742384_1560, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,305 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742384_1560 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_
2025-03-26 02:24:30,305 INFO terminating
2025-03-26 02:24:30,706 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:30,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742385_1561, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java._COPYING_
2025-03-26 02:24:30,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,709 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:30,709 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:30,709 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:30,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742385_1561 src: /172.20.1.10:39994 dest: /172.20.1.13:9866
2025-03-26 02:24:30,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742385_1561 src: /172.20.1.13:48460 dest: /172.20.1.12:9866
2025-03-26 02:24:30,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:39994, dest: /172.20.1.13:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742385_1561, duration(ns): 751957
2025-03-26 02:24:30,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48460, dest: /172.20.1.12:9866, bytes: 3105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742385_1561, duration(ns): 615459
2025-03-26 02:24:30,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742385_1561, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,713 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:30,713 INFO terminating
2025-03-26 02:24:30,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742386_1562, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java._COPYING_
2025-03-26 02:24:30,716 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,716 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,716 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,716 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:30,716 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:30,716 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:30,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742386_1562 src: /172.20.1.10:50230 dest: /172.20.1.12:9866
2025-03-26 02:24:30,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742386_1562 src: /172.20.1.12:57618 dest: /172.20.1.13:9866
2025-03-26 02:24:30,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57618, dest: /172.20.1.13:9866, bytes: 4153, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742386_1562, duration(ns): 900312
2025-03-26 02:24:30,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742386_1562, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,720 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:30,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50230, dest: /172.20.1.12:9866, bytes: 4153, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742386_1562, duration(ns): 1134350
2025-03-26 02:24:30,720 INFO terminating
2025-03-26 02:24:30,723 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742387_1563, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java._COPYING_
2025-03-26 02:24:30,723 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,723 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,723 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,723 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:30,723 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:30,723 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:30,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742387_1563 src: /172.20.1.10:40008 dest: /172.20.1.13:9866
2025-03-26 02:24:30,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742387_1563 src: /172.20.1.13:48476 dest: /172.20.1.12:9866
2025-03-26 02:24:30,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48476, dest: /172.20.1.12:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742387_1563, duration(ns): 552680
2025-03-26 02:24:30,727 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:30,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:40008, dest: /172.20.1.13:9866, bytes: 3831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742387_1563, duration(ns): 824081
2025-03-26 02:24:30,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742387_1563, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,727 INFO terminating
2025-03-26 02:24:30,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742388_1564, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java._COPYING_
2025-03-26 02:24:30,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,730 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:30,730 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:30,730 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:30,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742388_1564 src: /172.20.1.10:40016 dest: /172.20.1.13:9866
2025-03-26 02:24:30,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742388_1564 src: /172.20.1.13:48478 dest: /172.20.1.12:9866
2025-03-26 02:24:30,733 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:30,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:40016, dest: /172.20.1.13:9866, bytes: 5118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742388_1564, duration(ns): 497562
2025-03-26 02:24:30,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48478, dest: /172.20.1.12:9866, bytes: 5118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742388_1564, duration(ns): 335422
2025-03-26 02:24:30,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742388_1564, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,733 INFO terminating
2025-03-26 02:24:30,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742389_1565, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java._COPYING_
2025-03-26 02:24:30,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,736 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:30,736 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:30,736 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:30,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742389_1565 src: /172.20.1.10:40024 dest: /172.20.1.13:9866
2025-03-26 02:24:30,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742389_1565 src: /172.20.1.13:48484 dest: /172.20.1.12:9866
2025-03-26 02:24:30,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48484, dest: /172.20.1.12:9866, bytes: 2485, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742389_1565, duration(ns): 1536618
2025-03-26 02:24:30,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742389_1565, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,740 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:30,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:40024, dest: /172.20.1.13:9866, bytes: 2485, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742389_1565, duration(ns): 1757163
2025-03-26 02:24:30,740 INFO terminating
2025-03-26 02:24:30,743 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742390_1566, replicas=172.20.1.13:9866, 172.20.1.12:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java._COPYING_
2025-03-26 02:24:30,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,743 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:30,743 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:30,743 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:30,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742390_1566 src: /172.20.1.10:40034 dest: /172.20.1.13:9866
2025-03-26 02:24:30,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48498, dest: /172.20.1.12:9866, bytes: 4343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742390_1566, duration(ns): 284561
2025-03-26 02:24:30,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742390_1566, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742390_1566 src: /172.20.1.13:48498 dest: /172.20.1.12:9866
2025-03-26 02:24:30,746 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:30,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:40034, dest: /172.20.1.13:9866, bytes: 4343, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742390_1566, duration(ns): 479472
2025-03-26 02:24:30,746 INFO terminating
2025-03-26 02:24:30,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NODE_TOO_BUSY=1, NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:30,748 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2025-03-26 02:24:30,748 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2025-03-26 02:24:30,748 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2025-03-26 02:24:30,749 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742391_1567, replicas=172.20.1.12:9866, 172.20.1.13:9866 for /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_
2025-03-26 02:24:30,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742391_1567 src: /172.20.1.10:50238 dest: /172.20.1.12:9866
2025-03-26 02:24:30,751 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742391_1567 src: /172.20.1.12:57620 dest: /172.20.1.13:9866
2025-03-26 02:24:30,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:50238, dest: /172.20.1.12:9866, bytes: 7759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742391_1567, duration(ns): 602180
2025-03-26 02:24:30,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:57620, dest: /172.20.1.13:9866, bytes: 7759, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742391_1567, duration(ns): 417233
2025-03-26 02:24:30,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742391_1567, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:30,752 INFO terminating
2025-03-26 02:24:30,754 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073742391_1567 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_
2025-03-26 02:24:31,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:31,158 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742392_1568, replicas=172.20.1.13:9866, 172.20.1.12:9866, 172.20.1.11:9866 for /user/root/examples/src/main/scripts/getGpusResources.sh._COPYING_
2025-03-26 02:24:31,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742392_1568 src: /172.20.1.10:40036 dest: /172.20.1.13:9866
2025-03-26 02:24:31,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742392_1568 src: /172.20.1.13:48504 dest: /172.20.1.12:9866
2025-03-26 02:24:31,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742392_1568 src: /172.20.1.12:38542 dest: /172.20.1.11:9866
2025-03-26 02:24:31,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.12:38542, dest: /172.20.1.11:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 903bdc20-a9b6-4db4-8b5b-e6a9770aac21, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742392_1568, duration(ns): 763928
2025-03-26 02:24:31,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.10:40036, dest: /172.20.1.13:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: 8ddc3d11-0e3c-4077-bb7c-318b56db161c, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742392_1568, duration(ns): 1449859
2025-03-26 02:24:31,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.20.1.13:48504, dest: /172.20.1.12:9866, bytes: 1754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1599953218_1, offset: 0, srvID: cd114bfc-65b3-46fa-95af-8f400926efdc, blockid: BP-1623824107-172.20.1.10-1742955811035:blk_1073742392_1568, duration(ns): 1210601
2025-03-26 02:24:31,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1623824107-172.20.1.10-1742955811035:blk_1073742392_1568, type=LAST_IN_PIPELINE terminating
2025-03-26 02:24:31,163 INFO terminating
2025-03-26 02:24:31,164 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/root/examples/src/main/scripts/getGpusResources.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1599953218_1
2025-03-26 02:24:31,164 INFO terminating
2025-03-26 02:24:31,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:31,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742244_1420 to 172.20.1.11:9866
2025-03-26 02:24:34,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742246_1422 to 172.20.1.11:9866
2025-03-26 02:24:34,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742244_1420 (numBytes=2178) to /172.20.1.11:9866
2025-03-26 02:24:34,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742246_1422 (numBytes=3268) to /172.20.1.11:9866
2025-03-26 02:24:34,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742244_1420 src: /172.20.1.13:37460 dest: /172.20.1.11:9866
2025-03-26 02:24:34,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742246_1422 src: /172.20.1.13:37458 dest: /172.20.1.11:9866
2025-03-26 02:24:34,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742244_1420 src: /172.20.1.13:37460 dest: /172.20.1.11:9866 of size 2178
2025-03-26 02:24:34,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742246_1422 src: /172.20.1.13:37458 dest: /172.20.1.11:9866 of size 3268
2025-03-26 02:24:34,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742245_1421 to 172.20.1.11:9866
2025-03-26 02:24:34,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742247_1423 to 172.20.1.11:9866
2025-03-26 02:24:34,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742247_1423 (numBytes=2670) to /172.20.1.11:9866
2025-03-26 02:24:34,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742245_1421 src: /172.20.1.12:38556 dest: /172.20.1.11:9866
2025-03-26 02:24:34,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742247_1423 src: /172.20.1.12:38554 dest: /172.20.1.11:9866
2025-03-26 02:24:34,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742245_1421 (numBytes=1575) to /172.20.1.11:9866
2025-03-26 02:24:34,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742245_1421 src: /172.20.1.12:38556 dest: /172.20.1.11:9866 of size 1575
2025-03-26 02:24:34,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742247_1423 src: /172.20.1.12:38554 dest: /172.20.1.11:9866 of size 2670
2025-03-26 02:24:34,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:34,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742251_1427 to 172.20.1.11:9866
2025-03-26 02:24:37,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742253_1429 to 172.20.1.11:9866
2025-03-26 02:24:37,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742251_1427 src: /172.20.1.13:52940 dest: /172.20.1.11:9866
2025-03-26 02:24:37,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742251_1427 (numBytes=3737) to /172.20.1.11:9866
2025-03-26 02:24:37,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742253_1429 (numBytes=3780) to /172.20.1.11:9866
2025-03-26 02:24:37,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742251_1427 src: /172.20.1.13:52940 dest: /172.20.1.11:9866 of size 3737
2025-03-26 02:24:37,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742253_1429 src: /172.20.1.13:52952 dest: /172.20.1.11:9866
2025-03-26 02:24:37,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742253_1429 src: /172.20.1.13:52952 dest: /172.20.1.11:9866 of size 3780
2025-03-26 02:24:37,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742250_1426 to 172.20.1.11:9866
2025-03-26 02:24:37,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742252_1428 to 172.20.1.11:9866
2025-03-26 02:24:37,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742252_1428 (numBytes=4800) to /172.20.1.11:9866
2025-03-26 02:24:37,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742252_1428 src: /172.20.1.12:57036 dest: /172.20.1.11:9866
2025-03-26 02:24:37,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742250_1426 (numBytes=5326) to /172.20.1.11:9866
2025-03-26 02:24:37,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742252_1428 src: /172.20.1.12:57036 dest: /172.20.1.11:9866 of size 4800
2025-03-26 02:24:37,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742250_1426 src: /172.20.1.12:57044 dest: /172.20.1.11:9866 of size 5326
2025-03-26 02:24:37,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742250_1426 src: /172.20.1.12:57044 dest: /172.20.1.11:9866
2025-03-26 02:24:37,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:37,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:38,914 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 3467
2025-03-26 02:24:38,914 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3468 Total time for transactions(ms): 99 Number of transactions batched in Syncs: 778 Number of syncs: 2690 SyncTimes(ms): 18975
2025-03-26 02:24:38,914 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2025-03-26 02:24:38,914 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.20.1.10
2025-03-26 02:24:38,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3468 Total time for transactions(ms): 99 Number of transactions batched in Syncs: 778 Number of syncs: 2691 SyncTimes(ms): 18975
2025-03-26 02:24:38,915 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /data/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000003468
2025-03-26 02:24:38,934 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3469
2025-03-26 02:24:38,969 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2025-03-26 02:24:38,971 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master:9870/imagetransfer?getimage=1&txid=0&storageInfo=-66:424945276:1742955811035:CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79&bootstrapstandby=false
2025-03-26 02:24:39,030 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/name/current/fsimage_0000000000000000000, fileSize: 399. Sent total: 399 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:24:39,034 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.01s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000000000 took 0.00s.
2025-03-26 02:24:39,034 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 399 bytes.
2025-03-26 02:24:39,038 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://master:9870/imagetransfer?getedit=1&startTxId=1&endTxId=3468&storageInfo=-66:424945276:1742955811035:CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79
2025-03-26 02:24:39,042 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/name/current/edits_0000000000000000001-0000000000000003468, fileSize: 479859. Sent total: 479859 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:24:39,046 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.common.Util: Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 468000.00 KB/s. Synchronous (fsync) write to disk of /data/tmp/dfs/namesecondary/current/edits_tmp_0000000000000000001-0000000000000003468_0000000000007212979 took 0.00s.
2025-03-26 02:24:39,046 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000003468_0000000000007212979 size 0 bytes.
2025-03-26 02:24:39,094 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2025-03-26 02:24:39,101 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
2025-03-26 02:24:39,105 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-26 02:24:39,109 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /data/tmp/dfs/namesecondary/current/fsimage_0000000000000000000
2025-03-26 02:24:39,109 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2025-03-26 02:24:39,109 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2025-03-26 02:24:39,112 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2025-03-26 02:24:39,115 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468 expecting start txid #1
2025-03-26 02:24:39,115 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468 maxTxnsToRead = 9223372036854775807
2025-03-26 02:24:39,349 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded 1 edits file(s) (the last named /data/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000003468) of total size 479859.0, total edits 3468.0, total load time 221.0 ms
2025-03-26 02:24:39,375 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003468 using no compression
2025-03-26 02:24:39,442 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /data/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003468 of size 54040 bytes saved in 0 seconds .
2025-03-26 02:24:39,444 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/namesecondary
2025-03-26 02:24:39,447 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/namesecondary
2025-03-26 02:24:39,468 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2025-03-26 02:24:39,469 INFO [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /data/tmp/dfs/namesecondary/current/fsimage_0000000000000003468, fileSize: 54040. Sent total: 54040 bytes. Size of last segment intended to send: -1 bytes.
2025-03-26 02:24:39,472 INFO org.apache.hadoop.hdfs.server.namenode.ImageServlet: Rejecting a fsimage due to small time delta and txnid delta. Time since previous checkpoint is 68 expecting at least 2700 txnid delta since previous checkpoint is 3468 expecting at least 1000000
2025-03-26 02:24:39,474 WARN [SecondaryNameNode Status Name Node Address      : master/172.20.1.10:9000 Start Time             : Wed Mar 26 02:23:37 GMT 2025 Last Checkpoint        : -- (7152 seconds ago) Checkpoint Period      : 3600 seconds Checkpoint Transactions: 1000000 Checkpoint Dirs        : [file:///data/tmp/dfs/namesecondary] Checkpoint Edits Dirs  : [file:///data/tmp/dfs/namesecondary]] org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 54040
2025-03-26 02:24:40,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742256_1432 to 172.20.1.11:9866
2025-03-26 02:24:40,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742259_1435 to 172.20.1.11:9866
2025-03-26 02:24:40,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742256_1432 src: /172.20.1.13:52956 dest: /172.20.1.11:9866
2025-03-26 02:24:40,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742256_1432 (numBytes=3786) to /172.20.1.11:9866
2025-03-26 02:24:40,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742256_1432 src: /172.20.1.13:52956 dest: /172.20.1.11:9866 of size 3786
2025-03-26 02:24:40,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742259_1435 (numBytes=3436) to /172.20.1.11:9866
2025-03-26 02:24:40,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742259_1435 src: /172.20.1.13:52962 dest: /172.20.1.11:9866
2025-03-26 02:24:40,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742259_1435 src: /172.20.1.13:52962 dest: /172.20.1.11:9866 of size 3436
2025-03-26 02:24:40,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742257_1433 to 172.20.1.11:9866
2025-03-26 02:24:40,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742258_1434 to 172.20.1.11:9866
2025-03-26 02:24:40,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742257_1433 (numBytes=4303) to /172.20.1.11:9866
2025-03-26 02:24:40,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742258_1434 (numBytes=4032) to /172.20.1.11:9866
2025-03-26 02:24:40,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742258_1434 src: /172.20.1.12:57054 dest: /172.20.1.11:9866 of size 4032
2025-03-26 02:24:40,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742258_1434 src: /172.20.1.12:57054 dest: /172.20.1.11:9866
2025-03-26 02:24:40,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742257_1433 src: /172.20.1.12:57052 dest: /172.20.1.11:9866 of size 4303
2025-03-26 02:24:40,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742257_1433 src: /172.20.1.12:57052 dest: /172.20.1.11:9866
2025-03-26 02:24:40,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:40,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:40,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:40,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:43,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742262_1438 to 172.20.1.11:9866
2025-03-26 02:24:43,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742263_1439 (numBytes=3387) to /172.20.1.11:9866
2025-03-26 02:24:43,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742263_1439 to 172.20.1.11:9866
2025-03-26 02:24:43,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742262_1438 src: /172.20.1.13:52972 dest: /172.20.1.11:9866
2025-03-26 02:24:43,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742263_1439 src: /172.20.1.13:52964 dest: /172.20.1.11:9866
2025-03-26 02:24:43,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742262_1438 (numBytes=2173) to /172.20.1.11:9866
2025-03-26 02:24:43,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742262_1438 src: /172.20.1.13:52972 dest: /172.20.1.11:9866 of size 2173
2025-03-26 02:24:43,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742263_1439 src: /172.20.1.13:52964 dest: /172.20.1.11:9866 of size 3387
2025-03-26 02:24:43,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742264_1440 to 172.20.1.11:9866
2025-03-26 02:24:43,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742265_1441 to 172.20.1.11:9866
2025-03-26 02:24:43,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742264_1440 (numBytes=3631) to /172.20.1.11:9866
2025-03-26 02:24:43,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742265_1441 (numBytes=3580) to /172.20.1.11:9866
2025-03-26 02:24:43,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742264_1440 src: /172.20.1.12:57066 dest: /172.20.1.11:9866
2025-03-26 02:24:43,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742265_1441 src: /172.20.1.12:57082 dest: /172.20.1.11:9866
2025-03-26 02:24:43,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742264_1440 src: /172.20.1.12:57066 dest: /172.20.1.11:9866 of size 3631
2025-03-26 02:24:43,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742265_1441 src: /172.20.1.12:57082 dest: /172.20.1.11:9866 of size 3580
2025-03-26 02:24:43,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:43,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:43,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:43,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:46,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742270_1446 to 172.20.1.11:9866
2025-03-26 02:24:46,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742271_1447 to 172.20.1.11:9866
2025-03-26 02:24:46,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742270_1446 (numBytes=3240) to /172.20.1.11:9866
2025-03-26 02:24:46,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742271_1447 (numBytes=3102) to /172.20.1.11:9866
2025-03-26 02:24:46,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742271_1447 src: /172.20.1.13:52990 dest: /172.20.1.11:9866
2025-03-26 02:24:46,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742271_1447 src: /172.20.1.13:52990 dest: /172.20.1.11:9866 of size 3102
2025-03-26 02:24:46,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742270_1446 src: /172.20.1.13:52988 dest: /172.20.1.11:9866
2025-03-26 02:24:46,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742270_1446 src: /172.20.1.13:52988 dest: /172.20.1.11:9866 of size 3240
2025-03-26 02:24:46,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742268_1444 to 172.20.1.11:9866
2025-03-26 02:24:46,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742269_1445 to 172.20.1.11:9866
2025-03-26 02:24:46,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742268_1444 (numBytes=2778) to /172.20.1.11:9866
2025-03-26 02:24:46,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742268_1444 src: /172.20.1.12:57088 dest: /172.20.1.11:9866
2025-03-26 02:24:46,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742269_1445 src: /172.20.1.12:57100 dest: /172.20.1.11:9866
2025-03-26 02:24:46,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742268_1444 src: /172.20.1.12:57088 dest: /172.20.1.11:9866 of size 2778
2025-03-26 02:24:46,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742269_1445 (numBytes=2602) to /172.20.1.11:9866
2025-03-26 02:24:46,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742269_1445 src: /172.20.1.12:57100 dest: /172.20.1.11:9866 of size 2602
2025-03-26 02:24:46,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:46,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:46,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:46,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:49,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742274_1450 to 172.20.1.11:9866
2025-03-26 02:24:49,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742274_1450 (numBytes=2415) to /172.20.1.11:9866
2025-03-26 02:24:49,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742276_1452 to 172.20.1.11:9866
2025-03-26 02:24:49,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742274_1450 src: /172.20.1.13:55678 dest: /172.20.1.11:9866
2025-03-26 02:24:49,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742276_1452 (numBytes=3157) to /172.20.1.11:9866
2025-03-26 02:24:49,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742274_1450 src: /172.20.1.13:55678 dest: /172.20.1.11:9866 of size 2415
2025-03-26 02:24:49,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742276_1452 src: /172.20.1.13:55684 dest: /172.20.1.11:9866 of size 3157
2025-03-26 02:24:49,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742276_1452 src: /172.20.1.13:55684 dest: /172.20.1.11:9866
2025-03-26 02:24:49,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742275_1451 to 172.20.1.11:9866
2025-03-26 02:24:49,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742277_1453 to 172.20.1.11:9866
2025-03-26 02:24:49,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742275_1451 (numBytes=1913) to /172.20.1.11:9866
2025-03-26 02:24:49,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742277_1453 (numBytes=2977) to /172.20.1.11:9866
2025-03-26 02:24:49,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742275_1451 src: /172.20.1.12:45828 dest: /172.20.1.11:9866
2025-03-26 02:24:49,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742277_1453 src: /172.20.1.12:45842 dest: /172.20.1.11:9866
2025-03-26 02:24:49,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742275_1451 src: /172.20.1.12:45828 dest: /172.20.1.11:9866 of size 1913
2025-03-26 02:24:49,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742277_1453 src: /172.20.1.12:45842 dest: /172.20.1.11:9866 of size 2977
2025-03-26 02:24:49,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:49,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:49,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:49,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:52,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742280_1456 to 172.20.1.11:9866
2025-03-26 02:24:52,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742280_1456 (numBytes=2802) to /172.20.1.11:9866
2025-03-26 02:24:52,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742283_1459 (numBytes=2085) to /172.20.1.11:9866
2025-03-26 02:24:52,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742283_1459 to 172.20.1.11:9866
2025-03-26 02:24:52,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742280_1456 src: /172.20.1.13:55686 dest: /172.20.1.11:9866
2025-03-26 02:24:52,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742283_1459 src: /172.20.1.13:55688 dest: /172.20.1.11:9866
2025-03-26 02:24:52,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742280_1456 src: /172.20.1.13:55686 dest: /172.20.1.11:9866 of size 2802
2025-03-26 02:24:52,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742283_1459 src: /172.20.1.13:55688 dest: /172.20.1.11:9866 of size 2085
2025-03-26 02:24:52,073 DEBUG org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-26 02:24:52,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742281_1457 to 172.20.1.11:9866
2025-03-26 02:24:52,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742282_1458 to 172.20.1.11:9866
2025-03-26 02:24:52,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742281_1457 (numBytes=2715) to /172.20.1.11:9866
2025-03-26 02:24:52,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742281_1457 src: /172.20.1.12:45844 dest: /172.20.1.11:9866
2025-03-26 02:24:52,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742282_1458 (numBytes=2899) to /172.20.1.11:9866
2025-03-26 02:24:52,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742281_1457 src: /172.20.1.12:45844 dest: /172.20.1.11:9866 of size 2715
2025-03-26 02:24:52,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742282_1458 src: /172.20.1.12:45850 dest: /172.20.1.11:9866
2025-03-26 02:24:52,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742282_1458 src: /172.20.1.12:45850 dest: /172.20.1.11:9866 of size 2899
2025-03-26 02:24:52,102 DEBUG org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-26 02:24:52,141 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-26 02:24:52,143 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-26 02:24:52,144 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-26 02:24:52,144 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-26 02:24:52,144 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-26 02:24:52,144 DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-26 02:24:52,154 DEBUG org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-26 02:24:52,164 DEBUG org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-26 02:24:52,165 DEBUG org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-26 02:24:52,165 DEBUG org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-26 02:24:52,165 DEBUG org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-26 02:24:52,165 DEBUG org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-26 02:24:52,165 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-26 02:24:52,166 DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-26 02:24:52,210 DEBUG org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-26 02:24:52,212 DEBUG org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-26 02:24:52,212 DEBUG org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-26 02:24:52,214 DEBUG org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-26 02:24:52,215 DEBUG org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-26 02:24:52,215 DEBUG org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-26 02:24:52,215 DEBUG org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-26 02:24:52,216 DEBUG org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.000s
2025-03-26 02:24:52,216 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:24:52,217 DEBUG org.apache.hadoop.fs.FileSystem: Loading filesystems
2025-03-26 02:24:52,217 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Creating FS file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:24:52,223 DEBUG org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.fs.LocalFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:24:52,226 DEBUG org.apache.hadoop.fs.FileSystem: viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:24:52,227 DEBUG org.apache.hadoop.fs.FileSystem: har:// = class org.apache.hadoop.fs.HarFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:24:52,228 DEBUG org.apache.hadoop.fs.FileSystem: http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:24:52,228 DEBUG org.apache.hadoop.fs.FileSystem: https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:24:52,233 DEBUG org.apache.hadoop.fs.FileSystem: hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:24:52,238 DEBUG org.apache.hadoop.fs.FileSystem: swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:24:52,238 DEBUG org.apache.hadoop.fs.FileSystem: webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /spark/jars/hadoop-client-api-3.3.2.jar
2025-03-26 02:24:52,239 DEBUG org.apache.hadoop.fs.FileSystem: nullscan:// = class org.apache.hadoop.hive.ql.io.NullScanFileSystem from /spark/jars/hive-exec-2.3.9-core.jar
2025-03-26 02:24:52,240 DEBUG org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 02:24:52,240 DEBUG org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem from /spark/jars/hive-exec-2.3.9-core.jar
2025-03-26 02:24:52,240 DEBUG org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 02:24:52,260 DEBUG org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 02:24:52,260 DEBUG org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 02:24:52,263 DEBUG org.apache.hadoop.fs.FileSystem: Creating FS file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.046s
2025-03-26 02:24:52,264 DEBUG org.apache.hadoop.fs.Globber: Created Globber for path=file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar, symlinks=true
2025-03-26 02:24:52,264 DEBUG org.apache.hadoop.fs.Globber: Starting: glob file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:24:52,265 DEBUG org.apache.hadoop.fs.Globber: Filesystem glob /spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:24:52,265 DEBUG org.apache.hadoop.fs.Globber: Pattern: /spark/examples/jars/spark-examples_2.12-3.3.2.jar
2025-03-26 02:24:52,280 DEBUG org.apache.hadoop.fs.Globber: Component spark, patterned=false
2025-03-26 02:24:52,282 DEBUG org.apache.hadoop.fs.Globber: Component examples, patterned=false
2025-03-26 02:24:52,282 DEBUG org.apache.hadoop.fs.Globber: Component jars, patterned=false
2025-03-26 02:24:52,283 DEBUG org.apache.hadoop.fs.Globber: Component spark-examples_2.12-3.3.2.jar, patterned=false
2025-03-26 02:24:52,284 DEBUG org.apache.hadoop.fs.Globber: glob file:/spark/examples/jars/spark-examples_2.12-3.3.2.jar: duration 0:00.020s
2025-03-26 02:24:52,335 DEBUG org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.YarnClientImpl entered state INITED
2025-03-26 02:24:52,367 INFO org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.10:8032
2025-03-26 02:24:52,368 DEBUG org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.RMProxy$1@184497d1] java.lang.Exception at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852) at org.apache.hadoop.yarn.client.RMProxy.getProxy(RMProxy.java:145) at org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider.init(DefaultNoHARMFailoverProxyProvider.java:65) at org.apache.hadoop.yarn.client.RMProxy.createNonHaRMFailoverProxyProvider(RMProxy.java:172) at org.apache.hadoop.yarn.client.RMProxy.newProxyInstance(RMProxy.java:132) at org.apache.hadoop.yarn.client.RMProxy.createRMProxy(RMProxy.java:103) at org.apache.hadoop.yarn.client.ClientRMProxy.createRMProxy(ClientRMProxy.java:73) at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceStart(YarnClientImpl.java:242) at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194) at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:192) at org.apache.spark.deploy.yarn.Client.run(Client.scala:1327) at org.apache.spark.deploy.yarn.YarnClusterApplication.start(Client.scala:1764) at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958) at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180) at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203) at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90) at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046) at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055) at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2025-03-26 02:24:52,369 DEBUG org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 02:24:52,370 DEBUG org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ApplicationClientProtocol
2025-03-26 02:24:52,384 DEBUG org.apache.hadoop.ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker@3bde62ff
2025-03-26 02:24:52,388 DEBUG org.apache.hadoop.ipc.Client: getting client out of cache: Client-b1320281a9d4463e8f270ba21ea28a9f
2025-03-26 02:24:52,442 DEBUG org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.YarnClientImpl is started
2025-03-26 02:24:52,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:52,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:52,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:52,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:52,481 DEBUG org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 02:24:52,482 DEBUG org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.10:8032
2025-03-26 02:24:52,482 DEBUG org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.10:8032
2025-03-26 02:24:52,494 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:8032 from root: starting, having connections 1
2025-03-26 02:24:52,495 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:8032 from root sending #0 org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getClusterMetrics
2025-03-26 02:24:52,506 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:8032 from root got value #0
2025-03-26 02:24:52,506 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getClusterMetrics took 47ms
2025-03-26 02:24:52,508 DEBUG org.apache.spark.deploy.yarn.Client: Requesting a new application from cluster with 3 NodeManagers
2025-03-26 02:24:52,519 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:8032 from root sending #1 org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getNewApplication
2025-03-26 02:24:52,525 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2025-03-26 02:24:52,530 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:8032 from root got value #1
2025-03-26 02:24:52,530 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getNewApplication took 11ms
2025-03-26 02:24:52,534 DEBUG org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for hdfs://master:9000: duration 0:00.000s
2025-03-26 02:24:52,534 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for hdfs://master:9000
2025-03-26 02:24:52,535 DEBUG org.apache.hadoop.fs.FileSystem: FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2025-03-26 02:24:52,535 DEBUG org.apache.hadoop.fs.FileSystem: Looking for FS supporting hdfs
2025-03-26 02:24:52,535 DEBUG org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 02:24:52,535 DEBUG org.apache.hadoop.fs.FileSystem: Starting: Creating FS hdfs://master:9000
2025-03-26 02:24:52,535 DEBUG org.apache.hadoop.fs.FileSystem: looking for configuration option fs.hdfs.impl
2025-03-26 02:24:52,546 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.domain.socket.data.traffic = false
2025-03-26 02:24:52,546 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.read.shortcircuit = false
2025-03-26 02:24:52,546 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.use.legacy.blockreader.local = false
2025-03-26 02:24:52,546 DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.domain.socket.path =
2025-03-26 02:24:52,549 DEBUG org.apache.hadoop.hdfs.DFSClient: Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2025-03-26 02:24:52,552 DEBUG org.apache.hadoop.io.retry.RetryUtils: multipleLinearRandomRetry = null
2025-03-26 02:24:52,556 DEBUG org.apache.hadoop.ipc.Client: getting client out of cache: Client-b1320281a9d4463e8f270ba21ea28a9f
2025-03-26 02:24:52,760 DEBUG org.apache.hadoop.util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
2025-03-26 02:24:52,764 DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2025-03-26 02:24:52,766 DEBUG org.apache.hadoop.fs.FileSystem: Creating FS hdfs://master:9000: duration 0:00.231s
2025-03-26 02:24:52,807 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 02:24:52,807 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 02:24:52,810 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
2025-03-26 02:24:52,810 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE
2025-03-26 02:24:52,810 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-mb'
2025-03-26 02:24:52,810 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-mb'
2025-03-26 02:24:52,810 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-vcores'
2025-03-26 02:24:52,810 DEBUG org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-vcores'
2025-03-26 02:24:52,814 INFO org.apache.spark.deploy.yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
2025-03-26 02:24:52,816 DEBUG org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.10:9000
2025-03-26 02:24:52,816 DEBUG org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.10:9000
2025-03-26 02:24:52,816 DEBUG org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 02:24:52,817 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:9000 from root sending #2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete
2025-03-26 02:24:52,817 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:9000 from root: starting, having connections 2
2025-03-26 02:24:52,821 DEBUG org.apache.hadoop.ipc.Client: IPC Client (546796969) connection to master/172.20.1.10:9000 from root got value #2
2025-03-26 02:24:52,821 DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: delete took 5ms
2025-03-26 02:24:52,823 INFO org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-26 02:24:52,824 INFO org.apache.spark.util.ShutdownHookManager: Deleting directory /tmp/spark-189eaecb-6c57-494a-86cb-ecae71bdba89
2025-03-26 02:24:52,825 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (root (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 5a34cddc
2025-03-26 02:24:52,825 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 6a09079
2025-03-26 02:24:52,825 DEBUG org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:1518)); Key: (root (auth:SIMPLE))@hdfs://master:9000; URI: hdfs://master:9000; Object Identity Hash: 768ccb26
2025-03-26 02:24:52,825 DEBUG org.apache.hadoop.ipc.Client: stopping client from cache: Client-b1320281a9d4463e8f270ba21ea28a9f
2025-03-26 02:24:52,826 DEBUG org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.004 seconds; Timeouts: 0
2025-03-26 02:24:52,835 DEBUG org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
2025-03-26 02:24:55,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742286_1462 to 172.20.1.11:9866
2025-03-26 02:24:55,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742286_1462 (numBytes=3973) to /172.20.1.11:9866
2025-03-26 02:24:55,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave2:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742287_1463 (numBytes=3265) to /172.20.1.11:9866
2025-03-26 02:24:55,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.13:9866, datanodeUuid=8ddc3d11-0e3c-4077-bb7c-318b56db161c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742287_1463 to 172.20.1.11:9866
2025-03-26 02:24:55,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742286_1462 src: /172.20.1.13:55712 dest: /172.20.1.11:9866
2025-03-26 02:24:55,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742287_1463 src: /172.20.1.13:55720 dest: /172.20.1.11:9866
2025-03-26 02:24:55,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742287_1463 src: /172.20.1.13:55720 dest: /172.20.1.11:9866 of size 3265
2025-03-26 02:24:55,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742286_1462 src: /172.20.1.13:55712 dest: /172.20.1.11:9866 of size 3973
2025-03-26 02:24:55,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742288_1464 to 172.20.1.11:9866
2025-03-26 02:24:55,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742289_1465 to 172.20.1.11:9866
2025-03-26 02:24:55,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742288_1464 (numBytes=2238) to /172.20.1.11:9866
2025-03-26 02:24:55,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742289_1465 (numBytes=2546) to /172.20.1.11:9866
2025-03-26 02:24:55,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742288_1464 src: /172.20.1.12:45862 dest: /172.20.1.11:9866
2025-03-26 02:24:55,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742289_1465 src: /172.20.1.12:45860 dest: /172.20.1.11:9866
2025-03-26 02:24:55,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742288_1464 src: /172.20.1.12:45862 dest: /172.20.1.11:9866 of size 2238
2025-03-26 02:24:55,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742289_1465 src: /172.20.1.12:45860 dest: /172.20.1.11:9866 of size 2546
2025-03-26 02:24:55,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:55,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:55,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:55,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:58,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742296_1472 to 172.20.1.13:9866
2025-03-26 02:24:58,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742297_1473 to 172.20.1.13:9866
2025-03-26 02:24:58,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742296_1472 src: /172.20.1.11:56066 dest: /172.20.1.13:9866
2025-03-26 02:24:58,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742297_1473 src: /172.20.1.11:56064 dest: /172.20.1.13:9866
2025-03-26 02:24:58,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742296_1472 (numBytes=2846) to /172.20.1.13:9866
2025-03-26 02:24:58,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742297_1473 (numBytes=2446) to /172.20.1.13:9866
2025-03-26 02:24:58,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742296_1472 src: /172.20.1.11:56066 dest: /172.20.1.13:9866 of size 2846
2025-03-26 02:24:58,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742297_1473 src: /172.20.1.11:56064 dest: /172.20.1.13:9866 of size 2446
2025-03-26 02:24:58,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742292_1468 to 172.20.1.11:9866
2025-03-26 02:24:58,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742293_1469 to 172.20.1.11:9866
2025-03-26 02:24:58,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742292_1468 (numBytes=2123) to /172.20.1.11:9866
2025-03-26 02:24:58,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742293_1469 (numBytes=3381) to /172.20.1.11:9866
2025-03-26 02:24:58,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742293_1469 src: /172.20.1.12:55992 dest: /172.20.1.11:9866
2025-03-26 02:24:58,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742293_1469 src: /172.20.1.12:55992 dest: /172.20.1.11:9866 of size 3381
2025-03-26 02:24:58,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742292_1468 src: /172.20.1.12:56000 dest: /172.20.1.11:9866
2025-03-26 02:24:58,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742292_1468 src: /172.20.1.12:56000 dest: /172.20.1.11:9866 of size 2123
2025-03-26 02:24:58,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:58,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:58,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:24:58,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:01,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742301_1477 to 172.20.1.13:9866
2025-03-26 02:25:01,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742302_1478 to 172.20.1.13:9866
2025-03-26 02:25:01,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742301_1477 (numBytes=2612) to /172.20.1.13:9866
2025-03-26 02:25:01,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742302_1478 (numBytes=4317) to /172.20.1.13:9866
2025-03-26 02:25:01,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742301_1477 src: /172.20.1.11:56076 dest: /172.20.1.13:9866
2025-03-26 02:25:01,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742302_1478 src: /172.20.1.11:56078 dest: /172.20.1.13:9866
2025-03-26 02:25:01,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742301_1477 src: /172.20.1.11:56076 dest: /172.20.1.13:9866 of size 2612
2025-03-26 02:25:01,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742302_1478 src: /172.20.1.11:56078 dest: /172.20.1.13:9866 of size 4317
2025-03-26 02:25:01,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742300_1476 to 172.20.1.13:9866
2025-03-26 02:25:01,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742303_1479 to 172.20.1.13:9866
2025-03-26 02:25:01,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742303_1479 src: /172.20.1.12:55976 dest: /172.20.1.13:9866
2025-03-26 02:25:01,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742300_1476 (numBytes=5226) to /172.20.1.13:9866
2025-03-26 02:25:01,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742303_1479 (numBytes=3304) to /172.20.1.13:9866
2025-03-26 02:25:01,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742303_1479 src: /172.20.1.12:55976 dest: /172.20.1.13:9866 of size 3304
2025-03-26 02:25:01,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742300_1476 src: /172.20.1.12:55964 dest: /172.20.1.13:9866 of size 5226
2025-03-26 02:25:01,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742300_1476 src: /172.20.1.12:55964 dest: /172.20.1.13:9866
2025-03-26 02:25:01,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:01,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:01,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:01,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:04,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742308_1484 to 172.20.1.13:9866
2025-03-26 02:25:04,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742309_1485 to 172.20.1.13:9866
2025-03-26 02:25:04,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742308_1484 src: /172.20.1.11:56090 dest: /172.20.1.13:9866
2025-03-26 02:25:04,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742308_1484 (numBytes=2349) to /172.20.1.13:9866
2025-03-26 02:25:04,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742309_1485 (numBytes=2213) to /172.20.1.13:9866
2025-03-26 02:25:04,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742308_1484 src: /172.20.1.11:56090 dest: /172.20.1.13:9866 of size 2349
2025-03-26 02:25:04,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742309_1485 src: /172.20.1.11:56098 dest: /172.20.1.13:9866
2025-03-26 02:25:04,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742309_1485 src: /172.20.1.11:56098 dest: /172.20.1.13:9866 of size 2213
2025-03-26 02:25:04,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742306_1482 to 172.20.1.13:9866
2025-03-26 02:25:04,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742307_1483 to 172.20.1.13:9866
2025-03-26 02:25:04,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742306_1482 src: /172.20.1.12:55978 dest: /172.20.1.13:9866
2025-03-26 02:25:04,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742306_1482 (numBytes=3122) to /172.20.1.13:9866
2025-03-26 02:25:04,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742307_1483 (numBytes=2851) to /172.20.1.13:9866
2025-03-26 02:25:04,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742306_1482 src: /172.20.1.12:55978 dest: /172.20.1.13:9866 of size 3122
2025-03-26 02:25:04,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742307_1483 src: /172.20.1.12:55982 dest: /172.20.1.13:9866
2025-03-26 02:25:04,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742307_1483 src: /172.20.1.12:55982 dest: /172.20.1.13:9866 of size 2851
2025-03-26 02:25:04,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:04,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:04,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:04,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:07,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742314_1490 to 172.20.1.13:9866
2025-03-26 02:25:07,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742315_1491 to 172.20.1.13:9866
2025-03-26 02:25:07,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742314_1490 (numBytes=4577) to /172.20.1.13:9866
2025-03-26 02:25:07,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742315_1491 (numBytes=1827) to /172.20.1.13:9866
2025-03-26 02:25:07,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742314_1490 src: /172.20.1.11:56102 dest: /172.20.1.13:9866
2025-03-26 02:25:07,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742315_1491 src: /172.20.1.11:56116 dest: /172.20.1.13:9866
2025-03-26 02:25:07,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742314_1490 src: /172.20.1.11:56102 dest: /172.20.1.13:9866 of size 4577
2025-03-26 02:25:07,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742315_1491 src: /172.20.1.11:56116 dest: /172.20.1.13:9866 of size 1827
2025-03-26 02:25:07,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742312_1488 to 172.20.1.13:9866
2025-03-26 02:25:07,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742313_1489 to 172.20.1.13:9866
2025-03-26 02:25:07,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742312_1488 src: /172.20.1.12:47714 dest: /172.20.1.13:9866
2025-03-26 02:25:07,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742313_1489 src: /172.20.1.12:47728 dest: /172.20.1.13:9866
2025-03-26 02:25:07,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742312_1488 src: /172.20.1.12:47714 dest: /172.20.1.13:9866 of size 3273
2025-03-26 02:25:07,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742313_1489 src: /172.20.1.12:47728 dest: /172.20.1.13:9866 of size 2758
2025-03-26 02:25:07,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742312_1488 (numBytes=3273) to /172.20.1.13:9866
2025-03-26 02:25:07,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742313_1489 (numBytes=2758) to /172.20.1.13:9866
2025-03-26 02:25:07,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:07,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:07,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:07,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:10,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742320_1496 to 172.20.1.13:9866
2025-03-26 02:25:10,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742321_1497 to 172.20.1.13:9866
2025-03-26 02:25:10,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742320_1496 src: /172.20.1.11:42354 dest: /172.20.1.13:9866
2025-03-26 02:25:10,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742320_1496 (numBytes=3047) to /172.20.1.13:9866
2025-03-26 02:25:10,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742321_1497 (numBytes=2317) to /172.20.1.13:9866
2025-03-26 02:25:10,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742321_1497 src: /172.20.1.11:42366 dest: /172.20.1.13:9866
2025-03-26 02:25:10,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742320_1496 src: /172.20.1.11:42354 dest: /172.20.1.13:9866 of size 3047
2025-03-26 02:25:10,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742321_1497 src: /172.20.1.11:42366 dest: /172.20.1.13:9866 of size 2317
2025-03-26 02:25:10,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742318_1494 to 172.20.1.13:9866
2025-03-26 02:25:10,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742319_1495 to 172.20.1.13:9866
2025-03-26 02:25:10,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742318_1494 (numBytes=2611) to /172.20.1.13:9866
2025-03-26 02:25:10,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742318_1494 src: /172.20.1.12:47736 dest: /172.20.1.13:9866 of size 2611
2025-03-26 02:25:10,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742318_1494 src: /172.20.1.12:47736 dest: /172.20.1.13:9866
2025-03-26 02:25:10,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742319_1495 src: /172.20.1.12:47740 dest: /172.20.1.13:9866
2025-03-26 02:25:10,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742319_1495 (numBytes=2390) to /172.20.1.13:9866
2025-03-26 02:25:10,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742319_1495 src: /172.20.1.12:47740 dest: /172.20.1.13:9866 of size 2390
2025-03-26 02:25:10,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:10,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:10,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:10,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason: {NO_REQUIRED_STORAGE_TYPE=1}
2025-03-26 02:25:13,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742326_1502 to 172.20.1.13:9866
2025-03-26 02:25:13,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.11:9866, datanodeUuid=903bdc20-a9b6-4db4-8b5b-e6a9770aac21, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742327_1503 to 172.20.1.13:9866
2025-03-26 02:25:13,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742326_1502 (numBytes=2630) to /172.20.1.13:9866
2025-03-26 02:25:13,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave0:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742327_1503 (numBytes=2309) to /172.20.1.13:9866
2025-03-26 02:25:13,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742327_1503 src: /172.20.1.11:42370 dest: /172.20.1.13:9866 of size 2309
2025-03-26 02:25:13,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742326_1502 src: /172.20.1.11:42368 dest: /172.20.1.13:9866
2025-03-26 02:25:13,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742327_1503 src: /172.20.1.11:42370 dest: /172.20.1.13:9866
2025-03-26 02:25:13,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742326_1502 src: /172.20.1.11:42368 dest: /172.20.1.13:9866 of size 2630
2025-03-26 02:25:13,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742324_1500 to 172.20.1.13:9866
2025-03-26 02:25:13,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.20.1.12:9866, datanodeUuid=cd114bfc-65b3-46fa-95af-8f400926efdc, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e8216fcc-bb74-4a3d-a80b-abe39c7faf79;nsid=424945276;c=1742955811035) Starting thread to transfer BP-1623824107-172.20.1.10-1742955811035:blk_1073742325_1501 to 172.20.1.13:9866
2025-03-26 02:25:13,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742324_1500 (numBytes=3947) to /172.20.1.13:9866
2025-03-26 02:25:13,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at slave1:9866: Transmitted BP-1623824107-172.20.1.10-1742955811035:blk_1073742325_1501 (numBytes=2110) to /172.20.1.13:9866
2025-03-26 02:25:13,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742324_1500 src: /172.20.1.12:47748 dest: /172.20.1.13:9866
2025-03-26 02:25:13,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742324_1500 src: /172.20.1.12:47748 dest: /172.20.1.13:9866 of size 3947
2025-03-26 02:25:13,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1623824107-172.20.1.10-1742955811035:blk_1073742325_1501 src: /172.20.1.12:47752 dest: /172.20.1.13:9866
2025-03-26 02:25:13,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received BP-1623824107-172.20.1.10-1742955811035:blk_1073742325_1501 src: /172.20.1.12:47752 dest: /172.20.1.13:9866 of size 2110
