program=ml.DeveloperApiExample
SPARKLORD_MODE=CONFIG_INJECTION
cpu_cores=2
cpu_util=200
memory=4g
config_file_name=spark-defaults.conf
config_key=spark.scheduler.listenerbus.eventqueue.shared.capacity
config_value=2

2025-03-26 04:47:19,507 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for TERM
2025-03-26 04:47:19,510 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for HUP
2025-03-26 04:47:19,511 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for INT
2025-03-26 04:47:19,741 DEBUG [main] org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-26 04:47:19,874 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:47:19,875 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:47:19,875 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:47:19,875 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:47:19,876 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:47:19,939 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-26 04:47:19,945 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-26 04:47:19,945 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-26 04:47:19,945 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-26 04:47:19,945 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-26 04:47:19,946 DEBUG [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-26 04:47:19,962 DEBUG [main] org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-26 04:47:19,974 DEBUG [main] org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-26 04:47:19,975 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-26 04:47:19,975 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-26 04:47:19,975 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-26 04:47:19,975 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-26 04:47:19,975 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-26 04:47:19,976 DEBUG [main] org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-26 04:47:20,020 DEBUG [main] org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-26 04:47:20,094 DEBUG [main] org.apache.spark.deploy.SparkHadoopUtil: creating UGI for user: root
2025-03-26 04:47:20,097 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-26 04:47:20,097 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-26 04:47:20,098 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-26 04:47:20,099 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-26 04:47:20,099 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-26 04:47:20,099 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Reading credentials from location /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000001/container_tokens
2025-03-26 04:47:20,102 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Loaded 1 tokens from /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000001/container_tokens
2025-03-26 04:47:20,103 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-26 04:47:20,103 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3@1522d8a0]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:47:20,111 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1742964381735_0001_000001
2025-03-26 04:47:20,112 DEBUG [main] org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-26 04:47:20,139 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Starting the user application in a separate Thread
2025-03-26 04:47:20,141 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Waiting for spark context initialization...
2025-03-26 04:47:20,180 INFO [Driver] org.apache.spark.SparkContext: Running Spark version 3.3.2
2025-03-26 04:47:20,203 INFO [Driver] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:47:20,203 INFO [Driver] org.apache.spark.resource.ResourceUtils: No custom resources configured for spark.driver.
2025-03-26 04:47:20,203 INFO [Driver] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:47:20,204 INFO [Driver] org.apache.spark.SparkContext: Submitted application: DeveloperApiExample
2025-03-26 04:47:20,223 INFO [Driver] org.apache.spark.resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-26 04:47:20,227 INFO [Driver] org.apache.spark.resource.ResourceProfile: Limiting resource is cpus at 2 tasks per executor
2025-03-26 04:47:20,228 INFO [Driver] org.apache.spark.resource.ResourceProfileManager: Added ResourceProfile id: 0
2025-03-26 04:47:20,269 INFO [Driver] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:47:20,269 INFO [Driver] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:47:20,269 INFO [Driver] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:47:20,269 INFO [Driver] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:47:20,270 INFO [Driver] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:47:20,318 DEBUG [Driver] io.netty.util.internal.logging.InternalLoggerFactory: Using SLF4J as the default logging framework
2025-03-26 04:47:20,323 DEBUG [Driver] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2025-03-26 04:47:20,323 DEBUG [Driver] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2025-03-26 04:47:20,330 DEBUG [Driver] io.netty.channel.MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 4
2025-03-26 04:47:20,351 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: -Dio.netty.noUnsafe: false
2025-03-26 04:47:20,351 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: Java version: 8
2025-03-26 04:47:20,351 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
2025-03-26 04:47:20,351 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
2025-03-26 04:47:20,351 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.Buffer.address: available
2025-03-26 04:47:20,352 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: direct buffer constructor: available
2025-03-26 04:47:20,352 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.Bits.unaligned: available, true
2025-03-26 04:47:20,352 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2025-03-26 04:47:20,352 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
2025-03-26 04:47:20,352 DEBUG [Driver] io.netty.util.internal.PlatformDependent: sun.misc.Unsafe: available
2025-03-26 04:47:20,352 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.tmpdir: /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000001/tmp (java.io.tmpdir)
2025-03-26 04:47:20,352 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
2025-03-26 04:47:20,353 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.maxDirectMemory: 3817865216 bytes
2025-03-26 04:47:20,353 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.uninitializedArrayAllocationThreshold: -1
2025-03-26 04:47:20,353 DEBUG [Driver] io.netty.util.internal.CleanerJava6: java.nio.ByteBuffer.cleaner(): available
2025-03-26 04:47:20,353 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.noPreferDirect: false
2025-03-26 04:47:20,354 DEBUG [Driver] io.netty.channel.nio.NioEventLoop: -Dio.netty.noKeySetOptimization: false
2025-03-26 04:47:20,354 DEBUG [Driver] io.netty.channel.nio.NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
2025-03-26 04:47:20,357 DEBUG [Driver] io.netty.util.internal.PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
2025-03-26 04:47:20,364 DEBUG [Driver] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
2025-03-26 04:47:20,364 DEBUG [Driver] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.targetRecords: 4
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 4
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 4
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.useCacheForAllThreads: true
2025-03-26 04:47:20,366 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2025-03-26 04:47:20,382 DEBUG [Driver] io.netty.channel.DefaultChannelId: -Dio.netty.processId: 1503 (auto-detected)
2025-03-26 04:47:20,383 DEBUG [Driver] io.netty.util.NetUtil: -Djava.net.preferIPv4Stack: false
2025-03-26 04:47:20,383 DEBUG [Driver] io.netty.util.NetUtil: -Djava.net.preferIPv6Addresses: false
2025-03-26 04:47:20,384 DEBUG [Driver] io.netty.util.NetUtilInitializations: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2025-03-26 04:47:20,385 DEBUG [Driver] io.netty.util.NetUtil: /proc/sys/net/core/somaxconn: 4096
2025-03-26 04:47:20,385 DEBUG [Driver] io.netty.channel.DefaultChannelId: -Dio.netty.machineId: 02:42:ac:ff:fe:14:01:0d (auto-detected)
2025-03-26 04:47:20,397 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.allocator.type: pooled
2025-03-26 04:47:20,397 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 0
2025-03-26 04:47:20,397 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
2025-03-26 04:47:20,405 DEBUG [Driver] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 45495
2025-03-26 04:47:20,416 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'sparkDriver' on port 45495.
2025-03-26 04:47:20,417 DEBUG [Driver] org.apache.spark.SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
2025-03-26 04:47:20,437 INFO [Driver] org.apache.spark.SparkEnv: Registering MapOutputTracker
2025-03-26 04:47:20,437 DEBUG [Driver] org.apache.spark.MapOutputTrackerMasterEndpoint: init
2025-03-26 04:47:20,467 INFO [Driver] org.apache.spark.SparkEnv: Registering BlockManagerMaster
2025-03-26 04:47:20,484 INFO [Driver] org.apache.spark.storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-26 04:47:20,484 INFO [Driver] org.apache.spark.storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-03-26 04:47:20,523 INFO [Driver] org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2025-03-26 04:47:20,551 INFO [Driver] org.apache.spark.storage.DiskBlockManager: Created local directory at /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/blockmgr-808a7707-8fd1-4e91-885a-0b71e182ba4f
2025-03-26 04:47:20,553 DEBUG [Driver] org.apache.spark.storage.DiskBlockManager: Adding shutdown hook
2025-03-26 04:47:20,574 INFO [Driver] org.apache.spark.storage.memory.MemoryStore: MemoryStore started with capacity 2004.6 MiB
2025-03-26 04:47:20,627 INFO [Driver] org.apache.spark.SparkEnv: Registering OutputCommitCoordinator
2025-03-26 04:47:20,627 DEBUG [Driver] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: init
2025-03-26 04:47:20,640 DEBUG [Driver] org.apache.spark.SecurityManager: Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2025-03-26 04:47:20,851 DEBUG [Driver] org.apache.spark.ui.JettyUtils: Using requestHeaderSize: 8192
2025-03-26 04:47:20,879 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'SparkUI' on port 41959.
2025-03-26 04:47:20,880 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:20,996 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Created YarnClusterScheduler
2025-03-26 04:47:21,050 DEBUG [Driver] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 40899
2025-03-26 04:47:21,050 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40899.
2025-03-26 04:47:21,050 INFO [Driver] org.apache.spark.network.netty.NettyBlockTransferService: Server created on slave2:40899
2025-03-26 04:47:21,051 INFO [Driver] org.apache.spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-26 04:47:21,056 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, slave2, 40899, None)
2025-03-26 04:47:21,057 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave2
2025-03-26 04:47:21,058 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave2:40899 with 2004.6 MiB RAM, BlockManagerId(driver, slave2, 40899, None)
2025-03-26 04:47:21,060 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, slave2, 40899, None)
2025-03-26 04:47:21,060 INFO [Driver] org.apache.spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, slave2, 40899, None)
2025-03-26 04:47:21,210 DEBUG [Driver] org.apache.spark.util.YarnContainerInfoHelper: Base URL for logs: http://slave2:8042/node/containerlogs/container_1742964381735_0001_01_000001/root
2025-03-26 04:47:21,238 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,240 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,243 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,245 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,247 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,248 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,249 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,252 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,253 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/pool: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,255 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/pool/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,258 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,261 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,262 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/rdd: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,263 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/rdd/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,264 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /environment: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,265 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /environment/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,266 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,268 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,272 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/threadDump: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,274 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/threadDump/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,276 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /static: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,287 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,288 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /api: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,293 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,295 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,302 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:21,304 DEBUG [Driver] org.apache.spark.SparkContext: Adding shutdown hook
2025-03-26 04:47:21,312 DEBUG [main] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl entered state INITED
2025-03-26 04:47:21,319 INFO [main] org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.10:8030
2025-03-26 04:47:21,319 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.RMProxy$1@12dae582]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.RMProxy.getProxy(RMProxy.java:145)
	at org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider.init(DefaultNoHARMFailoverProxyProvider.java:65)
	at org.apache.hadoop.yarn.client.RMProxy.createNonHaRMFailoverProxyProvider(RMProxy.java:172)
	at org.apache.hadoop.yarn.client.RMProxy.newProxyInstance(RMProxy.java:132)
	at org.apache.hadoop.yarn.client.RMProxy.createRMProxy(RMProxy.java:103)
	at org.apache.hadoop.yarn.client.ClientRMProxy.createRMProxy(ClientRMProxy.java:73)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.serviceStart(AMRMClientImpl.java:193)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.spark.deploy.yarn.YarnRMClient.register(YarnRMClient.scala:63)
	at org.apache.spark.deploy.yarn.ApplicationMaster.registerAM(ApplicationMaster.scala:440)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:518)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:47:21,320 DEBUG [main] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:47:21,321 DEBUG [main] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ApplicationMasterProtocol
2025-03-26 04:47:21,333 DEBUG [main] org.apache.hadoop.ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker@2611b9a3
2025-03-26 04:47:21,338 DEBUG [main] org.apache.hadoop.ipc.Client: getting client out of cache: Client-bb9716f5c6784f7384d840c421a623f3
2025-03-26 04:47:21,359 DEBUG [main] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl is started
2025-03-26 04:47:21,359 INFO [main] org.apache.spark.deploy.yarn.YarnRMClient: Registering the ApplicationMaster
2025-03-26 04:47:21,397 DEBUG [main] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:47:21,397 DEBUG [main] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.10:8030
2025-03-26 04:47:21,397 DEBUG [main] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.10:8030
2025-03-26 04:47:21,402 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@3ebff828]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy31.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.registerApplicationMaster(ApplicationMasterProtocolPBClientImpl.java:108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy32.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:247)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:234)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:214)
	at org.apache.spark.deploy.yarn.YarnRMClient.register(YarnRMClient.scala:72)
	at org.apache.spark.deploy.yarn.ApplicationMaster.registerAM(ApplicationMaster.scala:440)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:518)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:47:21,473 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:47:21,480 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB info:org.apache.hadoop.yarn.security.SchedulerSecurityInfo$1@2a76b80a
2025-03-26 04:47:21,481 DEBUG [main] org.apache.hadoop.yarn.security.AMRMTokenSelector: Looking for a token with service 172.20.1.10:8030
2025-03-26 04:47:21,481 DEBUG [main] org.apache.hadoop.yarn.security.AMRMTokenSelector: Token kind is YARN_AM_RM_TOKEN and the token's service name is 172.20.1.10:8030
2025-03-26 04:47:21,484 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:47:21,486 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ApplicationMasterProtocolPB
2025-03-26 04:47:21,487 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEKewl4bdMhABEPjbsIn//////wE=
2025-03-26 04:47:21,487 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:47:21,487 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:47:21,489 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEKewl4bdMhABEPjbsIn//////wE=\",realm=\"default\",nonce=\"ag1e1NDRFmsm/N5g92CMIXEVVNE60+AY4VTBWlFQ\",nc=00000001,cnonce=\"ef10sVn8hQrAHkDuhMGJXxcqhXXN2a6RKjpGRH6b\",digest-uri=\"/default\",maxbuf=65536,response=9c8e264ea4275e2650a0778c016effbd,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:47:21,492 DEBUG [main] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:47:21,496 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root: starting, having connections 1
2025-03-26 04:47:21,497 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #0 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.registerApplicationMaster
2025-03-26 04:47:21,512 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #0
2025-03-26 04:47:21,513 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: registerApplicationMaster took 149ms
2025-03-26 04:47:21,528 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Preparing Local resources
2025-03-26 04:47:21,565 DEBUG [main] org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for hdfs://master:9000/user/root/.sparkStaging/application_1742964381735_0001/__spark_conf__.zip
2025-03-26 04:47:21,565 DEBUG [main] org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for hdfs://master:9000/user/root/.sparkStaging/application_1742964381735_0001/__spark_conf__.zip: duration 0:00.000s
2025-03-26 04:47:21,566 DEBUG [main] org.apache.hadoop.fs.FileSystem: Starting: Creating FS hdfs://master:9000/user/root/.sparkStaging/application_1742964381735_0001/__spark_conf__.zip
2025-03-26 04:47:21,566 DEBUG [main] org.apache.hadoop.fs.FileSystem: Loading filesystems
2025-03-26 04:47:21,572 DEBUG [main] org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.fs.LocalFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__787547128427141615.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:47:21,575 DEBUG [main] org.apache.hadoop.fs.FileSystem: viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__787547128427141615.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:47:21,577 DEBUG [main] org.apache.hadoop.fs.FileSystem: har:// = class org.apache.hadoop.fs.HarFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__787547128427141615.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:47:21,577 DEBUG [main] org.apache.hadoop.fs.FileSystem: http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__787547128427141615.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:47:21,578 DEBUG [main] org.apache.hadoop.fs.FileSystem: https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__787547128427141615.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:47:21,583 DEBUG [main] org.apache.hadoop.fs.FileSystem: hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__787547128427141615.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:47:21,587 DEBUG [main] org.apache.hadoop.fs.FileSystem: webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__787547128427141615.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:47:21,588 DEBUG [main] org.apache.hadoop.fs.FileSystem: swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__787547128427141615.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:47:21,588 DEBUG [main] org.apache.hadoop.fs.FileSystem: nullscan:// = class org.apache.hadoop.hive.ql.io.NullScanFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__787547128427141615.zip/hive-exec-2.3.9-core.jar
2025-03-26 04:47:21,589 DEBUG [main] org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__787547128427141615.zip/hive-exec-2.3.9-core.jar
2025-03-26 04:47:21,589 DEBUG [main] org.apache.hadoop.fs.FileSystem: Looking for FS supporting hdfs
2025-03-26 04:47:21,589 DEBUG [main] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.hdfs.impl
2025-03-26 04:47:21,598 DEBUG [main] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:47:21,598 DEBUG [main] org.apache.hadoop.fs.FileSystem: FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2025-03-26 04:47:21,609 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.use.legacy.blockreader.local = false
2025-03-26 04:47:21,609 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.read.shortcircuit = false
2025-03-26 04:47:21,609 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.domain.socket.data.traffic = false
2025-03-26 04:47:21,609 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.domain.socket.path = 
2025-03-26 04:47:21,612 DEBUG [main] org.apache.hadoop.hdfs.DFSClient: Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2025-03-26 04:47:21,615 DEBUG [main] org.apache.hadoop.io.retry.RetryUtils: multipleLinearRandomRetry = null
2025-03-26 04:47:21,617 DEBUG [main] org.apache.hadoop.ipc.Client: getting client out of cache: Client-bb9716f5c6784f7384d840c421a623f3
2025-03-26 04:47:21,768 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
2025-03-26 04:47:21,772 DEBUG [main] org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2025-03-26 04:47:21,773 DEBUG [main] org.apache.hadoop.fs.FileSystem: Creating FS hdfs://master:9000/user/root/.sparkStaging/application_1742964381735_0001/__spark_conf__.zip: duration 0:00.207s
2025-03-26 04:47:21,776 DEBUG [main] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:47:21,776 DEBUG [main] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.10:9000
2025-03-26 04:47:21,776 DEBUG [main] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.10:9000
2025-03-26 04:47:21,777 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@4b2a30d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy36.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:965)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy37.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1739)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1753)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1750)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1765)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$prepareLocalResources$4(ApplicationMaster.scala:200)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$prepareLocalResources$4$adapted(ApplicationMaster.scala:197)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.deploy.yarn.ApplicationMaster.prepareLocalResources(ApplicationMaster.scala:197)
	at org.apache.spark.deploy.yarn.ApplicationMaster.createAllocator(ApplicationMaster.scala:463)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:523)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:47:21,777 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:47:21,778 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSelector)
2025-03-26 04:47:21,778 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: tokens aren't supported for this protocol or user doesn't have one
2025-03-26 04:47:21,778 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Use SIMPLE authentication for protocol ClientNamenodeProtocolPB
2025-03-26 04:47:21,778 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

2025-03-26 04:47:21,779 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root sending #1 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2025-03-26 04:47:21,779 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root: starting, having connections 2
2025-03-26 04:47:21,779 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root got value #1
2025-03-26 04:47:21,779 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getFileInfo took 3ms
2025-03-26 04:47:21,806 DEBUG [main] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:47:21,830 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: 
===============================================================================
Default YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_YARN_STAGING_DIR -> hdfs://master:9000/user/root/.sparkStaging/application_1742964381735_0001
    SPARK_USER -> root

  command:
    {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx2048m \ 
      '-XX:+IgnoreUnrecognizedVMOptions' \ 
      '--add-opens=java.base/java.lang=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.lang.invoke=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.lang.reflect=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.io=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.net=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.nio=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util.concurrent=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.nio.ch=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.nio.cs=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.security.action=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.util.calendar=ALL-UNNAMED' \ 
      '--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED' \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.driver.port=45495' \ 
      '-Dspark.ui.port=0' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.YarnCoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@slave2:45495 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      2 \ 
      --app-id \ 
      application_1742964381735_0001 \ 
      --resourceProfileId \ 
      0 \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    __app__.jar -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742964381735_0001/scopt_2.12-3.7.1.jar" } size: 78803 timestamp: 1742964435855 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742964381735_0001/__spark_libs__787547128427141615.zip" } size: 301733843 timestamp: 1742964435793 type: ARCHIVE visibility: PRIVATE
    __spark_conf__ -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742964381735_0001/__spark_conf__.zip" } size: 947010 timestamp: 1742964435986 type: ARCHIVE visibility: PRIVATE
    spark-examples_2.12-3.3.2.jar -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742964381735_0001/spark-examples_2.12-3.3.2.jar" } size: 1567446 timestamp: 1742964435877 type: FILE visibility: PRIVATE

===============================================================================
2025-03-26 04:47:21,847 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Resource profile 0 doesn't exist, adding it
2025-03-26 04:47:21,864 INFO [main] org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 04:47:21,865 INFO [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 04:47:21,867 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
2025-03-26 04:47:21,867 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE
2025-03-26 04:47:21,867 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-mb'
2025-03-26 04:47:21,867 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-mb'
2025-03-26 04:47:21,867 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-vcores'
2025-03-26 04:47:21,867 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-vcores'
2025-03-26 04:47:21,868 DEBUG [main] org.apache.spark.deploy.yarn.ResourceRequestHelper: Custom resources requested: Map()
2025-03-26 04:47:21,868 DEBUG [main] org.apache.spark.deploy.yarn.YarnAllocator: Created resource capability: <memory:2432, vCores:2>
2025-03-26 04:47:21,870 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@slave2:45495)
2025-03-26 04:47:21,872 DEBUG [main] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-26 04:47:21,875 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:47:21,885 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-26 04:47:21,886 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-26 04:47:21,896 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #2 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:47:21,902 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #2
2025-03-26 04:47:21,902 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 6ms
2025-03-26 04:47:21,909 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:47:21,910 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
2025-03-26 04:47:21,911 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-26 04:47:21,911 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #3 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:47:21,912 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #3
2025-03-26 04:47:21,912 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-26 04:47:22,119 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200175961/200.
2025-03-26 04:47:22,120 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:47:22,120 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-26 04:47:22,120 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #4 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:47:22,122 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #4
2025-03-26 04:47:22,122 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-26 04:47:22,522 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400152341/400.
2025-03-26 04:47:22,523 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:47:22,523 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-26 04:47:22,525 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #5 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:47:22,542 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #5
2025-03-26 04:47:22,543 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 19ms
2025-03-26 04:47:22,553 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave0:40385
2025-03-26 04:47:22,554 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave2:46085
2025-03-26 04:47:22,554 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave1:36071
2025-03-26 04:47:22,560 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 3. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-26 04:47:22,561 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-26 04:47:22,561 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-26 04:47:22,561 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-26 04:47:22,564 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:47:22,564 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:47:22,564 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-26 04:47:22,565 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-26 04:47:22,566 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742964381735_0001_01_000002 on host slave0 for executor with ID 1 for ResourceProfile Id 0
2025-03-26 04:47:22,568 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742964381735_0001_01_000003 on host slave1 for executor with ID 2 for ResourceProfile Id 0
2025-03-26 04:47:22,568 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:47:22,568 DEBUG [ContainerLauncher-0] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-26 04:47:22,569 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-26 04:47:22,570 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742964381735_0001_01_000004 on host slave2 for executor with ID 3 for ResourceProfile Id 0
2025-03-26 04:47:22,570 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-26 04:47:22,571 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:47:22,571 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-26 04:47:22,572 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:47:22,572 DEBUG [ContainerLauncher-1] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-26 04:47:22,572 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-26 04:47:22,573 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-26 04:47:22,574 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:47:22,574 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-26 04:47:22,574 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 3 containers from YARN, launching executors on 3 of them.
2025-03-26 04:47:22,575 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:47:22,577 DEBUG [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-26 04:47:22,577 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-26 04:47:22,578 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-26 04:47:22,578 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:47:22,578 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-26 04:47:22,582 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:40385
2025-03-26 04:47:22,586 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:36071
2025-03-26 04:47:22,587 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:46085
2025-03-26 04:47:22,594 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.13:46085, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964381735 } attemptId: 1 } nodeId { host: "slave2" port: 46085 } appSubmitter: "root" keyId: 1848258442)
2025-03-26 04:47:22,596 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964381735_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@3b2614fa]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:47:22,596 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-26 04:47:22,667 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.12:36071, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964381735 } attemptId: 1 } nodeId { host: "slave1" port: 36071 } appSubmitter: "root" keyId: 1848258442)
2025-03-26 04:47:22,667 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964381735_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@226b48f2]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:47:22,668 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-26 04:47:22,668 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.11:40385, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964381735 } attemptId: 1 } nodeId { host: "slave0" port: 40385 } appSubmitter: "root" keyId: 1848258442)
2025-03-26 04:47:22,669 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964381735_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@96e1070]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:47:22,669 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-26 04:47:22,670 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: getting client out of cache: Client-bb9716f5c6784f7384d840c421a623f3
2025-03-26 04:47:22,672 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: getting client out of cache: Client-bb9716f5c6784f7384d840c421a623f3
2025-03-26 04:47:22,673 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: getting client out of cache: Client-bb9716f5c6784f7384d840c421a623f3
2025-03-26 04:47:22,696 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:47:22,696 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.12:36071
2025-03-26 04:47:22,696 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.12:36071
2025-03-26 04:47:22,697 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964381735_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@653cb816]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:47:22,697 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:47:22,698 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:47:22,698 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.11:40385
2025-03-26 04:47:22,698 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.11:40385
2025-03-26 04:47:22,698 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:47:22,699 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.13:46085
2025-03-26 04:47:22,699 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.13:46085
2025-03-26 04:47:22,698 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964381735_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@76f8af0a]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:47:22,699 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:47:22,699 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742964381735_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@98d9482]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:47:22,700 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:47:22,700 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@6008e322
2025-03-26 04:47:22,701 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.13:46085. Current token is Kind: NMToken, Service: 172.20.1.13:46085, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964381735 } attemptId: 1 } nodeId { host: "slave2" port: 46085 } appSubmitter: "root" keyId: 1848258442)
2025-03-26 04:47:22,701 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:47:22,701 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-26 04:47:22,701 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEKewl4bdMhABEgwKBnNsYXZlMhCF6AIaBHJvb3Qgit+o8QY=
2025-03-26 04:47:22,701 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:47:22,701 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:47:22,701 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEKewl4bdMhABEgwKBnNsYXZlMhCF6AIaBHJvb3Qgit+o8QY=\",realm=\"default\",nonce=\"0JadN9J6z9qPx7jXPiHcZIhTSJk9psCUWRuLlo2p\",nc=00000001,cnonce=\"c5FMNjL5juiM48IwTiZPNaE5upjEIXsFQAswT1Ys\",digest-uri=\"/default\",maxbuf=65536,response=1b068cb736e963106623bb7487b24dce,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@46c9846d
2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.12:36071. Current token is Kind: NMToken, Service: 172.20.1.12:36071, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964381735 } attemptId: 1 } nodeId { host: "slave1" port: 36071 } appSubmitter: "root" keyId: 1848258442)
2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEKewl4bdMhABEgwKBnNsYXZlMRDnmQIaBHJvb3Qgit+o8QY=
2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEKewl4bdMhABEgwKBnNsYXZlMRDnmQIaBHJvb3Qgit+o8QY=\",realm=\"default\",nonce=\"hbfD65j9BXkmnmmStdcQ83UKZ34anXxqbKbr+rv3\",nc=00000001,cnonce=\"6sXWicIZ1ndpj4Ia195kIzQtOulCDRSwx0KAP0Wl\",digest-uri=\"/default\",maxbuf=65536,response=33c4da1d570f843441021a6c49c2aff5,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@5f956cae
2025-03-26 04:47:22,704 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.11:40385. Current token is Kind: NMToken, Service: 172.20.1.11:40385, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742964381735 } attemptId: 1 } nodeId { host: "slave0" port: 40385 } appSubmitter: "root" keyId: 1848258442)
2025-03-26 04:47:22,705 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:47:22,705 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-26 04:47:22,705 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEKewl4bdMhABEgwKBnNsYXZlMBDBuwIaBHJvb3Qgit+o8QY=
2025-03-26 04:47:22,705 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:47:22,705 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:47:22,705 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEKewl4bdMhABEgwKBnNsYXZlMBDBuwIaBHJvb3Qgit+o8QY=\",realm=\"default\",nonce=\"k3EPii1JmnUFqNW1byH3jlaanEJ4Fkt6ni9U4sMw\",nc=00000001,cnonce=\"sVIqQO9sjPVT7xsVBDlDGpSqwkUdA1qILYb4m8xT\",digest-uri=\"/default\",maxbuf=65536,response=90c3d5ddfe4ad4b1de6d1d056c27f05e,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:47:22,705 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:46085 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:46085 from appattempt_1742964381735_0001_000001: starting, having connections 5
2025-03-26 04:47:22,707 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:46085 from appattempt_1742964381735_0001_000001 sending #7 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-26 04:47:22,715 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:47:22,716 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:47:22,722 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:40385 from appattempt_1742964381735_0001_000001 sending #8 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-26 04:47:22,722 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:46085 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:46085 from appattempt_1742964381735_0001_000001 got value #7
2025-03-26 04:47:22,722 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 24ms
2025-03-26 04:47:22,722 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:46085 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:46085 from appattempt_1742964381735_0001_000001: closed
2025-03-26 04:47:22,722 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.13:46085 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.13:46085 from appattempt_1742964381735_0001_000001: stopped, remaining connections 4
2025-03-26 04:47:22,735 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:40385 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:40385 from appattempt_1742964381735_0001_000001: starting, having connections 4
2025-03-26 04:47:22,735 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:36071 from appattempt_1742964381735_0001_000001 sending #6 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-26 04:47:22,741 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:36071 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:36071 from appattempt_1742964381735_0001_000001: starting, having connections 4
2025-03-26 04:47:22,874 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:40385 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:40385 from appattempt_1742964381735_0001_000001 got value #8
2025-03-26 04:47:22,875 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:40385 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:40385 from appattempt_1742964381735_0001_000001: closed
2025-03-26 04:47:22,875 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.11:40385 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.11:40385 from appattempt_1742964381735_0001_000001: stopped, remaining connections 3
2025-03-26 04:47:22,875 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 177ms
2025-03-26 04:47:22,878 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:36071 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:36071 from appattempt_1742964381735_0001_000001 got value #6
2025-03-26 04:47:22,878 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:36071 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:36071 from appattempt_1742964381735_0001_000001: closed
2025-03-26 04:47:22,878 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.12:36071 from appattempt_1742964381735_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.12:36071 from appattempt_1742964381735_0001_000001: stopped, remaining connections 2
2025-03-26 04:47:22,878 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 182ms
2025-03-26 04:47:23,647 INFO [main] org.apache.spark.executor.CoarseGrainedExecutorBackend: Started daemon with process name: 1583@slave2
2025-03-26 04:47:23,654 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for TERM
2025-03-26 04:47:23,654 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for HUP
2025-03-26 04:47:23,655 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for INT
2025-03-26 04:47:23,915 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-26 04:47:23,920 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-26 04:47:23,920 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-26 04:47:23,920 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-26 04:47:23,920 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-26 04:47:23,920 DEBUG [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-26 04:47:23,939 DEBUG [main] org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-26 04:47:23,939 DEBUG [main] org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-26 04:47:23,943 DEBUG [main] org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-26 04:47:23,943 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-26 04:47:23,944 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-26 04:47:23,944 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-26 04:47:23,944 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-26 04:47:23,944 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-26 04:47:23,944 DEBUG [main] org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-26 04:47:23,990 DEBUG [main] org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-26 04:47:23,991 DEBUG [main] org.apache.spark.deploy.SparkHadoopUtil: creating UGI for user: root
2025-03-26 04:47:23,994 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-26 04:47:23,994 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-26 04:47:23,996 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-26 04:47:23,997 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-26 04:47:23,997 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-26 04:47:23,997 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Reading credentials from location /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000004/container_tokens
2025-03-26 04:47:24,002 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Loaded 1 tokens from /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000004/container_tokens
2025-03-26 04:47:24,002 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-26 04:47:24,002 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.spark.deploy.SparkHadoopUtil$$anon$1@59d2400d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:61)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:427)
	at org.apache.spark.executor.YarnCoarseGrainedExecutorBackend$.main(YarnCoarseGrainedExecutorBackend.scala:83)
	at org.apache.spark.executor.YarnCoarseGrainedExecutorBackend.main(YarnCoarseGrainedExecutorBackend.scala)
2025-03-26 04:47:24,010 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:47:24,011 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:47:24,011 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:47:24,011 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:47:24,012 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:47:24,094 DEBUG [main] io.netty.util.internal.logging.InternalLoggerFactory: Using SLF4J as the default logging framework
2025-03-26 04:47:24,098 DEBUG [main] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2025-03-26 04:47:24,099 DEBUG [main] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2025-03-26 04:47:24,107 DEBUG [main] io.netty.channel.MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 4
2025-03-26 04:47:24,129 DEBUG [main] io.netty.util.internal.PlatformDependent0: -Dio.netty.noUnsafe: false
2025-03-26 04:47:24,129 DEBUG [main] io.netty.util.internal.PlatformDependent0: Java version: 8
2025-03-26 04:47:24,129 DEBUG [main] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
2025-03-26 04:47:24,130 DEBUG [main] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
2025-03-26 04:47:24,130 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.Buffer.address: available
2025-03-26 04:47:24,130 DEBUG [main] io.netty.util.internal.PlatformDependent0: direct buffer constructor: available
2025-03-26 04:47:24,131 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.Bits.unaligned: available, true
2025-03-26 04:47:24,131 DEBUG [main] io.netty.util.internal.PlatformDependent0: jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2025-03-26 04:47:24,131 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
2025-03-26 04:47:24,131 DEBUG [main] io.netty.util.internal.PlatformDependent: sun.misc.Unsafe: available
2025-03-26 04:47:24,131 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.tmpdir: /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000004/tmp (java.io.tmpdir)
2025-03-26 04:47:24,131 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
2025-03-26 04:47:24,132 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.maxDirectMemory: 1908932608 bytes
2025-03-26 04:47:24,132 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.uninitializedArrayAllocationThreshold: -1
2025-03-26 04:47:24,132 DEBUG [main] io.netty.util.internal.CleanerJava6: java.nio.ByteBuffer.cleaner(): available
2025-03-26 04:47:24,132 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.noPreferDirect: false
2025-03-26 04:47:24,133 DEBUG [main] io.netty.channel.nio.NioEventLoop: -Dio.netty.noKeySetOptimization: false
2025-03-26 04:47:24,133 DEBUG [main] io.netty.channel.nio.NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
2025-03-26 04:47:24,137 DEBUG [main] io.netty.util.internal.PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
2025-03-26 04:47:24,145 DEBUG [main] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
2025-03-26 04:47:24,145 DEBUG [main] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.targetRecords: 4
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 4
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 4
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.useCacheForAllThreads: true
2025-03-26 04:47:24,147 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2025-03-26 04:47:24,186 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Creating new connection to slave2/172.20.1.13:45495
2025-03-26 04:47:24,199 DEBUG [netty-rpc-connection-0] io.netty.channel.DefaultChannelId: -Dio.netty.processId: 1583 (auto-detected)
2025-03-26 04:47:24,200 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: -Djava.net.preferIPv4Stack: false
2025-03-26 04:47:24,200 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: -Djava.net.preferIPv6Addresses: false
2025-03-26 04:47:24,202 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtilInitializations: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2025-03-26 04:47:24,203 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: /proc/sys/net/core/somaxconn: 4096
2025-03-26 04:47:24,203 DEBUG [netty-rpc-connection-0] io.netty.channel.DefaultChannelId: -Dio.netty.machineId: 02:42:ac:ff:fe:14:01:0d (auto-detected)
2025-03-26 04:47:24,221 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.allocator.type: pooled
2025-03-26 04:47:24,221 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 0
2025-03-26 04:47:24,221 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
2025-03-26 04:47:24,242 DEBUG [rpc-client-1-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkAccessible: true
2025-03-26 04:47:24,242 DEBUG [rpc-client-1-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkBounds: true
2025-03-26 04:47:24,242 DEBUG [rpc-client-1-1] io.netty.util.ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@423237b6
2025-03-26 04:47:24,252 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50] REGISTERED
2025-03-26 04:47:24,252 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50] CONNECT: slave2/172.20.1.13:45495
2025-03-26 04:47:24,254 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Connection to slave2/172.20.1.13:45495 successful, running bootstraps...
2025-03-26 04:47:24,254 INFO [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Successfully created connection to slave2/172.20.1.13:45495 after 57 ms (0 ms spent in bootstraps)
2025-03-26 04:47:24,257 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.maxCapacityPerThread: 4096
2025-03-26 04:47:24,257 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.ratio: 8
2025-03-26 04:47:24,257 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.chunkSize: 32
2025-03-26 04:47:24,257 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.blocking: false
2025-03-26 04:47:24,258 DEBUG [rpc-server-4-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.13:44856.
2025-03-26 04:47:24,264 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] ACTIVE
2025-03-26 04:47:24,272 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 168]
2025-03-26 04:47:24,272 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,273 DEBUG [rpc-server-4-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkAccessible: true
2025-03-26 04:47:24,274 DEBUG [rpc-server-4-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkBounds: true
2025-03-26 04:47:24,274 DEBUG [rpc-server-4-1] io.netty.util.ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@47940b78
2025-03-26 04:47:24,287 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] REGISTERED
2025-03-26 04:47:24,287 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] ACTIVE
2025-03-26 04:47:24,290 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.maxCapacityPerThread: 4096
2025-03-26 04:47:24,290 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.ratio: 8
2025-03-26 04:47:24,290 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.chunkSize: 32
2025-03-26 04:47:24,290 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.blocking: false
2025-03-26 04:47:24,294 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] READ 189B
2025-03-26 04:47:24,302 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] READ COMPLETE
2025-03-26 04:47:24,306 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:24,306 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] FLUSH
2025-03-26 04:47:24,307 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] READ 68B
2025-03-26 04:47:24,313 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,317 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 169]
2025-03-26 04:47:24,317 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,317 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] READ 190B
2025-03-26 04:47:24,318 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] READ COMPLETE
2025-03-26 04:47:24,339 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 4383]
2025-03-26 04:47:24,340 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] FLUSH
2025-03-26 04:47:24,340 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] READ 2048B
2025-03-26 04:47:24,341 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] READ 2356B
2025-03-26 04:47:24,367 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,369 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 - R:slave2/172.20.1.13:45495] CLOSE
2025-03-26 04:47:24,370 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 - R:/172.20.1.13:44856] READ COMPLETE
2025-03-26 04:47:24,370 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 ! R:/172.20.1.13:44856] INACTIVE
2025-03-26 04:47:24,371 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x8f9d8b87, L:/172.20.1.13:45495 ! R:/172.20.1.13:44856] UNREGISTERED
2025-03-26 04:47:24,372 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 ! R:slave2/172.20.1.13:45495] INACTIVE
2025-03-26 04:47:24,373 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x4a572f50, L:/172.20.1.13:44856 ! R:slave2/172.20.1.13:45495] UNREGISTERED
2025-03-26 04:47:24,389 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:47:24,389 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:47:24,389 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:47:24,389 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:47:24,389 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:47:24,412 DEBUG [main] org.apache.spark.SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
2025-03-26 04:47:24,426 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Creating new connection to slave2/172.20.1.13:45495
2025-03-26 04:47:24,428 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c] REGISTERED
2025-03-26 04:47:24,428 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c] CONNECT: slave2/172.20.1.13:45495
2025-03-26 04:47:24,428 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Connection to slave2/172.20.1.13:45495 successful, running bootstraps...
2025-03-26 04:47:24,428 INFO [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Successfully created connection to slave2/172.20.1.13:45495 after 1 ms (0 ms spent in bootstraps)
2025-03-26 04:47:24,428 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] ACTIVE
2025-03-26 04:47:24,428 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 162]
2025-03-26 04:47:24,429 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,429 DEBUG [rpc-server-4-2] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.13:44866.
2025-03-26 04:47:24,430 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] REGISTERED
2025-03-26 04:47:24,430 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] ACTIVE
2025-03-26 04:47:24,430 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 183B
2025-03-26 04:47:24,431 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ COMPLETE
2025-03-26 04:47:24,431 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:24,431 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] FLUSH
2025-03-26 04:47:24,432 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 68B
2025-03-26 04:47:24,432 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,463 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 164]
2025-03-26 04:47:24,463 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,464 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 185B
2025-03-26 04:47:24,465 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ COMPLETE
2025-03-26 04:47:24,465 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:24,465 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] FLUSH
2025-03-26 04:47:24,465 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 21B
2025-03-26 04:47:24,465 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,466 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 47B
2025-03-26 04:47:24,466 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,468 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 173]
2025-03-26 04:47:24,468 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,469 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 194B
2025-03-26 04:47:24,469 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ COMPLETE
2025-03-26 04:47:24,469 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:24,470 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] FLUSH
2025-03-26 04:47:24,470 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 68B
2025-03-26 04:47:24,470 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,484 INFO [main] org.apache.spark.storage.DiskBlockManager: Created local directory at /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/blockmgr-176cb961-11a7-4b82-98fd-f06461f33ae3
2025-03-26 04:47:24,486 DEBUG [main] org.apache.spark.storage.DiskBlockManager: Adding shutdown hook
2025-03-26 04:47:24,487 DEBUG [main] org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-26 04:47:24,512 INFO [main] org.apache.spark.storage.memory.MemoryStore: MemoryStore started with capacity 912.3 MiB
2025-03-26 04:47:24,702 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 169]
2025-03-26 04:47:24,702 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,703 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 190B
2025-03-26 04:47:24,703 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ COMPLETE
2025-03-26 04:47:24,704 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:24,704 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] FLUSH
2025-03-26 04:47:24,704 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 68B
2025-03-26 04:47:24,705 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,719 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@slave2:45495
2025-03-26 04:47:24,747 DEBUG [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Resource profile id is: 0
2025-03-26 04:47:24,751 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:47:24,752 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: No custom resources configured for spark.executor.
2025-03-26 04:47:24,752 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:47:24,752 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 168]
2025-03-26 04:47:24,753 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,753 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 189B
2025-03-26 04:47:24,753 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ COMPLETE
2025-03-26 04:47:24,754 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:24,754 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] FLUSH
2025-03-26 04:47:24,754 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 68B
2025-03-26 04:47:24,782 DEBUG [rpc-client-3-1] org.apache.spark.util.YarnContainerInfoHelper: Base URL for logs: http://slave2:8042/node/containerlogs/container_1742964381735_0001_01_000004/root
2025-03-26 04:47:24,806 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 1916]
2025-03-26 04:47:24,806 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,806 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 512B
2025-03-26 04:47:24,807 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,808 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 1425B
2025-03-26 04:47:24,832 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.1.13:44866) with ID 3,  ResourceProfileId 0
2025-03-26 04:47:24,835 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ COMPLETE
2025-03-26 04:47:24,835 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:24,835 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] FLUSH
2025-03-26 04:47:24,836 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 68B
2025-03-26 04:47:24,837 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,838 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Successfully registered with driver
2025-03-26 04:47:24,843 INFO [dispatcher-Executor] org.apache.spark.executor.Executor: Starting executor ID 3 on host slave2
2025-03-26 04:47:24,877 DEBUG [dispatcher-Executor] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 34481
2025-03-26 04:47:24,878 INFO [dispatcher-Executor] org.apache.spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34481.
2025-03-26 04:47:24,878 INFO [dispatcher-Executor] org.apache.spark.network.netty.NettyBlockTransferService: Server created on slave2:34481
2025-03-26 04:47:24,880 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-26 04:47:24,886 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(3, slave2, 34481, None)
2025-03-26 04:47:24,890 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 1456]
2025-03-26 04:47:24,890 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,890 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 1477B
2025-03-26 04:47:24,893 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ COMPLETE
2025-03-26 04:47:24,893 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave2
2025-03-26 04:47:24,894 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave2:34481 with 912.3 MiB RAM, BlockManagerId(3, slave2, 34481, None)
2025-03-26 04:47:24,904 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 79]
2025-03-26 04:47:24,904 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] FLUSH
2025-03-26 04:47:24,905 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 100B
2025-03-26 04:47:24,906 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,906 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(3, slave2, 34481, None)
2025-03-26 04:47:24,907 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(3, slave2, 34481, None)
2025-03-26 04:47:24,914 INFO [dispatcher-Executor] org.apache.spark.executor.Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000004/__app__.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000004/spark-examples_2.12-3.3.2.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000004/__app__.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000004/spark-examples_2.12-3.3.2.jar'
2025-03-26 04:47:24,920 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 163]
2025-03-26 04:47:24,920 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,920 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 184B
2025-03-26 04:47:24,921 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ COMPLETE
2025-03-26 04:47:24,921 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:24,922 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] FLUSH
2025-03-26 04:47:24,923 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 68B
2025-03-26 04:47:24,923 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:24,946 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 177]
2025-03-26 04:47:24,946 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:24,946 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 190B
2025-03-26 04:47:24,948 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ COMPLETE
2025-03-26 04:47:25,575 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000107826/3000.
2025-03-26 04:47:25,575 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:47:25,575 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 3, executorsStarting: 0
2025-03-26 04:47:25,576 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #9 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:47:25,578 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #9
2025-03-26 04:47:25,578 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-26 04:47:26,066 DEBUG [rpc-server-4-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.12:50674.
2025-03-26 04:47:26,067 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] REGISTERED
2025-03-26 04:47:26,067 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] ACTIVE
2025-03-26 04:47:26,075 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] READ 189B
2025-03-26 04:47:26,075 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] READ COMPLETE
2025-03-26 04:47:26,075 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,075 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] FLUSH
2025-03-26 04:47:26,077 DEBUG [rpc-server-4-2] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.11:38022.
2025-03-26 04:47:26,077 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] REGISTERED
2025-03-26 04:47:26,077 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] ACTIVE
2025-03-26 04:47:26,083 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] READ 190B
2025-03-26 04:47:26,083 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] READ COMPLETE
2025-03-26 04:47:26,084 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 4383]
2025-03-26 04:47:26,084 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] FLUSH
2025-03-26 04:47:26,088 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] READ 189B
2025-03-26 04:47:26,088 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] READ COMPLETE
2025-03-26 04:47:26,088 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,088 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] FLUSH
2025-03-26 04:47:26,096 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] READ 190B
2025-03-26 04:47:26,096 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] READ COMPLETE
2025-03-26 04:47:26,097 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 4383]
2025-03-26 04:47:26,097 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] FLUSH
2025-03-26 04:47:26,110 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 - R:/172.20.1.12:50674] READ COMPLETE
2025-03-26 04:47:26,110 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 ! R:/172.20.1.12:50674] INACTIVE
2025-03-26 04:47:26,110 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xfbf41ca5, L:/172.20.1.13:45495 ! R:/172.20.1.12:50674] UNREGISTERED
2025-03-26 04:47:26,125 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 - R:/172.20.1.11:38022] READ COMPLETE
2025-03-26 04:47:26,125 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 ! R:/172.20.1.11:38022] INACTIVE
2025-03-26 04:47:26,125 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x1f6f52ed, L:/172.20.1.13:45495 ! R:/172.20.1.11:38022] UNREGISTERED
2025-03-26 04:47:26,162 DEBUG [rpc-server-4-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.12:50676.
2025-03-26 04:47:26,163 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] REGISTERED
2025-03-26 04:47:26,163 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] ACTIVE
2025-03-26 04:47:26,163 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 183B
2025-03-26 04:47:26,163 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:26,164 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,164 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] FLUSH
2025-03-26 04:47:26,170 DEBUG [rpc-server-4-2] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.11:38036.
2025-03-26 04:47:26,171 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] REGISTERED
2025-03-26 04:47:26,171 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] ACTIVE
2025-03-26 04:47:26,171 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 183B
2025-03-26 04:47:26,171 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:26,172 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,172 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:26,190 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 185B
2025-03-26 04:47:26,191 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:26,191 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,191 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] FLUSH
2025-03-26 04:47:26,194 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 194B
2025-03-26 04:47:26,195 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:26,195 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,195 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] FLUSH
2025-03-26 04:47:26,202 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 185B
2025-03-26 04:47:26,202 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:26,203 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,203 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:26,207 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 194B
2025-03-26 04:47:26,207 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:26,207 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,207 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:26,426 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 190B
2025-03-26 04:47:26,426 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:26,427 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,427 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] FLUSH
2025-03-26 04:47:26,438 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 190B
2025-03-26 04:47:26,439 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:26,439 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,439 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:26,500 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 189B
2025-03-26 04:47:26,501 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:26,501 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,501 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] FLUSH
2025-03-26 04:47:26,517 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 189B
2025-03-26 04:47:26,518 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:26,518 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,519 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:26,584 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 512B
2025-03-26 04:47:26,585 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 1425B
2025-03-26 04:47:26,586 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.1.12:50676) with ID 2,  ResourceProfileId 0
2025-03-26 04:47:26,586 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:26,586 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,586 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] FLUSH
2025-03-26 04:47:26,604 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 512B
2025-03-26 04:47:26,605 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 1425B
2025-03-26 04:47:26,606 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:26,606 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.1.11:38036) with ID 1,  ResourceProfileId 0
2025-03-26 04:47:26,606 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,606 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:26,650 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 1477B
2025-03-26 04:47:26,651 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:26,651 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave1
2025-03-26 04:47:26,652 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave1:37975 with 912.3 MiB RAM, BlockManagerId(2, slave1, 37975, None)
2025-03-26 04:47:26,652 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 79]
2025-03-26 04:47:26,652 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] FLUSH
2025-03-26 04:47:26,666 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 1477B
2025-03-26 04:47:26,667 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave0
2025-03-26 04:47:26,667 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:26,668 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave0:39879 with 912.3 MiB RAM, BlockManagerId(1, slave0, 39879, None)
2025-03-26 04:47:26,668 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 79]
2025-03-26 04:47:26,668 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:26,668 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 184B
2025-03-26 04:47:26,669 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:26,669 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,670 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] FLUSH
2025-03-26 04:47:26,676 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2025-03-26 04:47:26,676 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterScheduler: YarnClusterScheduler.postStartHook done
2025-03-26 04:47:26,683 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 184B
2025-03-26 04:47:26,684 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:26,684 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:26,684 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:26,685 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 190B
2025-03-26 04:47:26,685 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:26,694 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 190B
2025-03-26 04:47:26,694 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:27,427 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 04:47:27,427 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 04:47:27,427 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:47:27,427 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:47:27,428 INFO [Driver] org.apache.spark.sql.internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-26 04:47:27,429 DEBUG [Driver] org.apache.spark.sql.internal.SharedState: Applying other initial session options to HadoopConf: spark.app.name -> DeveloperApiExample
2025-03-26 04:47:27,429 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000001/spark-warehouse
2025-03-26 04:47:27,429 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000001/spark-warehouse: duration 0:00.000s
2025-03-26 04:47:27,429 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Starting: Creating FS file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000001/spark-warehouse
2025-03-26 04:47:27,429 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 04:47:27,429 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 04:47:27,429 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:47:27,429 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:47:27,430 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Creating FS file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000001/spark-warehouse: duration 0:00.001s
2025-03-26 04:47:27,430 INFO [Driver] org.apache.spark.sql.internal.SharedState: Warehouse path is 'file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/container_1742964381735_0001_01_000001/spark-warehouse'.
2025-03-26 04:47:27,437 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:27,438 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol http
2025-03-26 04:47:27,438 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Unknown protocol http, delegating to default implementation
2025-03-26 04:47:27,438 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:27,439 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:27,439 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:27,440 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol jar
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting jar
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.jar.impl
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Unknown protocol jar, delegating to default implementation
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol file
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Found implementation of file: class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:47:27,441 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Using handler for protocol file
2025-03-26 04:47:27,873 DEBUG [Driver] org.apache.spark.sql.catalyst.parser.CatalystSqlParser: Parsing command: spark_grouping_id
2025-03-26 04:47:28,331 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegression: Input schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}}]}
2025-03-26 04:47:28,334 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegression: Expected output schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}},{"name":"prediction","type":"double","nullable":false,"metadata":{}},{"name":"rawPrediction","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":false,"metadata":{}}]}
2025-03-26 04:47:28,356 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#0
2025-03-26 04:47:28,374 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#7
2025-03-26 04:47:28,374 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'features to features#1
2025-03-26 04:47:28,578 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000059873/3000.
2025-03-26 04:47:28,578 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:47:28,579 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 3, executorsStarting: 0
2025-03-26 04:47:28,579 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #10 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:47:28,580 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #10
2025-03-26 04:47:28,580 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-26 04:47:28,792 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for input[0, double, false],input[1, vector, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */     double value_0 = i.getDouble(0);
/* 036 */     mutableStateArray_0[0].write(0, value_0);
/* 037 */
/* 038 */     boolean isNull_1 = i.isNullAt(1);
/* 039 */     InternalRow value_1 = isNull_1 ?
/* 040 */     null : (i.getStruct(1, 4));
/* 041 */     if (isNull_1) {
/* 042 */       mutableStateArray_0[0].setNullAt(1);
/* 043 */     } else {
/* 044 */       final InternalRow tmpInput_0 = value_1;
/* 045 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 046 */         mutableStateArray_0[0].write(1, (UnsafeRow) tmpInput_0);
/* 047 */       } else {
/* 048 */         // Remember the current cursor so that we can calculate how many bytes are
/* 049 */         // written later.
/* 050 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 051 */
/* 052 */         mutableStateArray_0[1].resetRowWriter();
/* 053 */
/* 054 */
/* 055 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 056 */
/* 057 */
/* 058 */         if ((tmpInput_0.isNullAt(1))) {
/* 059 */           mutableStateArray_0[1].setNullAt(1);
/* 060 */         } else {
/* 061 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 062 */         }
/* 063 */
/* 064 */
/* 065 */         if ((tmpInput_0.isNullAt(2))) {
/* 066 */           mutableStateArray_0[1].setNullAt(2);
/* 067 */         } else {
/* 068 */           // Remember the current cursor so that we can calculate how many bytes are
/* 069 */           // written later.
/* 070 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 071 */
/* 072 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 073 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 074 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 075 */           } else {
/* 076 */             final int numElements_0 = tmpInput_1.numElements();
/* 077 */             mutableStateArray_1[0].initialize(numElements_0);
/* 078 */
/* 079 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 080 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 081 */             }
/* 082 */           }
/* 083 */
/* 084 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 085 */         }
/* 086 */
/* 087 */
/* 088 */         if ((tmpInput_0.isNullAt(3))) {
/* 089 */           mutableStateArray_0[1].setNullAt(3);
/* 090 */         } else {
/* 091 */           // Remember the current cursor so that we can calculate how many bytes are
/* 092 */           // written later.
/* 093 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 094 */
/* 095 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 096 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 097 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 098 */           } else {
/* 099 */             final int numElements_1 = tmpInput_2.numElements();
/* 100 */             mutableStateArray_1[1].initialize(numElements_1);
/* 101 */
/* 102 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 103 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 104 */             }
/* 105 */           }
/* 106 */
/* 107 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 108 */         }
/* 109 */
/* 110 */
/* 111 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(1, previousCursor_0);
/* 112 */       }
/* 113 */     }
/* 114 */     return (mutableStateArray_0[0].getRow());
/* 115 */   }
/* 116 */
/* 117 */
/* 118 */ }

2025-03-26 04:47:28,803 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */     double value_0 = i.getDouble(0);
/* 036 */     mutableStateArray_0[0].write(0, value_0);
/* 037 */
/* 038 */     boolean isNull_1 = i.isNullAt(1);
/* 039 */     InternalRow value_1 = isNull_1 ?
/* 040 */     null : (i.getStruct(1, 4));
/* 041 */     if (isNull_1) {
/* 042 */       mutableStateArray_0[0].setNullAt(1);
/* 043 */     } else {
/* 044 */       final InternalRow tmpInput_0 = value_1;
/* 045 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 046 */         mutableStateArray_0[0].write(1, (UnsafeRow) tmpInput_0);
/* 047 */       } else {
/* 048 */         // Remember the current cursor so that we can calculate how many bytes are
/* 049 */         // written later.
/* 050 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 051 */
/* 052 */         mutableStateArray_0[1].resetRowWriter();
/* 053 */
/* 054 */
/* 055 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 056 */
/* 057 */
/* 058 */         if ((tmpInput_0.isNullAt(1))) {
/* 059 */           mutableStateArray_0[1].setNullAt(1);
/* 060 */         } else {
/* 061 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 062 */         }
/* 063 */
/* 064 */
/* 065 */         if ((tmpInput_0.isNullAt(2))) {
/* 066 */           mutableStateArray_0[1].setNullAt(2);
/* 067 */         } else {
/* 068 */           // Remember the current cursor so that we can calculate how many bytes are
/* 069 */           // written later.
/* 070 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 071 */
/* 072 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 073 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 074 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 075 */           } else {
/* 076 */             final int numElements_0 = tmpInput_1.numElements();
/* 077 */             mutableStateArray_1[0].initialize(numElements_0);
/* 078 */
/* 079 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 080 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 081 */             }
/* 082 */           }
/* 083 */
/* 084 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 085 */         }
/* 086 */
/* 087 */
/* 088 */         if ((tmpInput_0.isNullAt(3))) {
/* 089 */           mutableStateArray_0[1].setNullAt(3);
/* 090 */         } else {
/* 091 */           // Remember the current cursor so that we can calculate how many bytes are
/* 092 */           // written later.
/* 093 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 094 */
/* 095 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 096 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 097 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 098 */           } else {
/* 099 */             final int numElements_1 = tmpInput_2.numElements();
/* 100 */             mutableStateArray_1[1].initialize(numElements_1);
/* 101 */
/* 102 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 103 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 104 */             }
/* 105 */           }
/* 106 */
/* 107 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 108 */         }
/* 109 */
/* 110 */
/* 111 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(1, previousCursor_0);
/* 112 */       }
/* 113 */     }
/* 114 */     return (mutableStateArray_0[0].getRow());
/* 115 */   }
/* 116 */
/* 117 */
/* 118 */ }

2025-03-26 04:47:28,910 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 118.008659 ms
2025-03-26 04:47:28,924 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$doExecute$1
2025-03-26 04:47:28,933 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$doExecute$1) is now cleaned +++
2025-03-26 04:47:28,942 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$rdd$1
2025-03-26 04:47:28,949 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2025-03-26 04:47:28,965 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$extractLabeledPoints$1
2025-03-26 04:47:28,966 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$extractLabeledPoints$1) is now cleaned +++
2025-03-26 04:47:28,972 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$take$2
2025-03-26 04:47:28,975 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$take$2) is now cleaned +++
2025-03-26 04:47:29,034 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5
2025-03-26 04:47:29,037 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2025-03-26 04:47:29,041 INFO [Driver] org.apache.spark.SparkContext: Starting job: take at DeveloperApiExample.scala:127
2025-03-26 04:47:29,043 DEBUG [Driver] org.apache.spark.scheduler.DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 5 took 0.000642 seconds
2025-03-26 04:47:29,045 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Merging stage rdd profiles: Set()
2025-03-26 04:47:29,052 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Got job 0 (take at DeveloperApiExample.scala:127) with 1 output partitions
2025-03-26 04:47:29,053 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 0 (take at DeveloperApiExample.scala:127)
2025-03-26 04:47:29,053 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()
2025-03-26 04:47:29,054 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Missing parents: List()
2025-03-26 04:47:29,080 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: submitStage(ResultStage 0 (name=take at DeveloperApiExample.scala:127;jobs=0))
2025-03-26 04:47:29,083 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: missing: List()
2025-03-26 04:47:29,086 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at Predictor.scala:185), which has no missing parents
2025-03-26 04:47:29,087 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: submitMissingTasks(ResultStage 0)
2025-03-26 04:47:29,132 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.0 KiB, free 2004.6 MiB)
2025-03-26 04:47:29,133 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Put block broadcast_0 locally took 15 ms
2025-03-26 04:47:29,134 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Putting block broadcast_0 without replication took 16 ms
2025-03-26 04:47:29,154 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 2004.6 MiB)
2025-03-26 04:47:29,155 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(driver, slave2, 40899, None)
2025-03-26 04:47:29,156 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on slave2:40899 (size: 9.4 KiB, free: 2004.6 MiB)
2025-03-26 04:47:29,158 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
2025-03-26 04:47:29,159 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Told master about block broadcast_0_piece0
2025-03-26 04:47:29,159 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Put block broadcast_0_piece0 locally took 6 ms
2025-03-26 04:47:29,159 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Putting block broadcast_0_piece0 without replication took 6 ms
2025-03-26 04:47:29,160 INFO [dag-scheduler-event-loop] org.apache.spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
2025-03-26 04:47:29,169 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at Predictor.scala:185) (first 15 tasks are for partitions Vector(0))
2025-03-26 04:47:29,170 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Adding task set 0.0 with 1 tasks resource profile 0
2025-03-26 04:47:29,210 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Epoch for TaskSet 0.0: 0
2025-03-26 04:47:29,213 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Adding pending tasks took 1 ms
2025-03-26 04:47:29,214 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2025-03-26 04:47:29,216 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-26 04:47:29,229 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (slave0, executor 1, partition 0, PROCESS_LOCAL, 4702 bytes) taskResourceAssignments Map()
2025-03-26 04:47:29,232 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
2025-03-26 04:47:29,237 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Launching task 0 on executor id: 1 hostname: slave0.
2025-03-26 04:47:29,241 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 5149]
2025-03-26 04:47:29,241 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:29,262 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 1642B
2025-03-26 04:47:29,267 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:29,360 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 338B
2025-03-26 04:47:29,369 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:29,369 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 760]
2025-03-26 04:47:29,369 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:29,382 DEBUG [shuffle-server-7-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.11:49382.
2025-03-26 04:47:29,383 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] REGISTERED
2025-03-26 04:47:29,383 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] ACTIVE
2025-03-26 04:47:29,385 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] READ 92B
2025-03-26 04:47:29,395 DEBUG [shuffle-server-7-1] org.apache.spark.storage.BlockManager: Getting local block broadcast_0_piece0 as bytes
2025-03-26 04:47:29,396 DEBUG [shuffle-server-7-1] org.apache.spark.storage.BlockManager: Level for block broadcast_0_piece0 is StorageLevel(disk, memory, 1 replicas)
2025-03-26 04:47:29,398 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 13]
2025-03-26 04:47:29,398 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] FLUSH
2025-03-26 04:47:29,398 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] READ COMPLETE
2025-03-26 04:47:29,402 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] READ 21B
2025-03-26 04:47:29,404 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 9655]
2025-03-26 04:47:29,404 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] FLUSH
2025-03-26 04:47:29,405 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] READ COMPLETE
2025-03-26 04:47:29,416 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 194B
2025-03-26 04:47:29,417 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:29,417 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(1, slave0, 39879, None)
2025-03-26 04:47:29,417 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on slave0:39879 (size: 9.4 KiB, free: 912.3 MiB)
2025-03-26 04:47:29,418 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:29,418 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:31,231 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 1024B
2025-03-26 04:47:31,231 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 2045B
2025-03-26 04:47:31,232 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:31,247 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2028 ms on slave0 (executor 1) (1/1)
2025-03-26 04:47:31,252 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: ResultStage 0 (take at DeveloperApiExample.scala:127) finished in 2.156 s
2025-03-26 04:47:31,254 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: After removal of stage 0, remaining stages = 0
2025-03-26 04:47:31,254 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-26 04:47:31,254 INFO [task-result-getter-0] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-26 04:47:31,255 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Killing all running tasks in stage 0: Stage finished
2025-03-26 04:47:31,255 ERROR [dag-scheduler-event-loop] org.apache.spark.scheduler.AsyncEventQueue: Dropping event from queue shared. This likely means one of the listeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
2025-03-26 04:47:31,256 WARN [dag-scheduler-event-loop] org.apache.spark.scheduler.AsyncEventQueue: Dropped 1 events from shared since the application started.
2025-03-26 04:47:31,256 INFO [Driver] org.apache.spark.scheduler.DAGScheduler: Job 0 finished: take at DeveloperApiExample.scala:127, took 2.215117 s
2025-03-26 04:47:31,285 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegressionModel: Input schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}}]}
2025-03-26 04:47:31,295 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegressionModel: Expected output schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}},{"name":"prediction","type":"double","nullable":false,"metadata":{"ml_attr":{"type":"nominal","num_vals":2}}},{"name":"rawPrediction","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":false,"metadata":{"ml_attr":{"num_attrs":2}}}]}
2025-03-26 04:47:31,328 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'features to features#14
2025-03-26 04:47:31,343 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'rawPrediction to rawPrediction#19
2025-03-26 04:47:31,368 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'features to features#14
2025-03-26 04:47:31,368 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#13
2025-03-26 04:47:31,368 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'prediction to prediction#26
2025-03-26 04:47:31,422 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for newInstance(class org.apache.spark.ml.linalg.VectorUDT).serialize:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private boolean resultIsNull_0;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private org.apache.spark.ml.linalg.Vector[] mutableStateArray_0 = new org.apache.spark.ml.linalg.Vector[1];
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */
/* 016 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 017 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_1[0], 4);
/* 018 */     mutableStateArray_2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 4);
/* 019 */     mutableStateArray_2[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 8);
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public void initialize(int partitionIndex) {
/* 024 */
/* 025 */   }
/* 026 */
/* 027 */   // Scala.Function1 need this
/* 028 */   public java.lang.Object apply(java.lang.Object row) {
/* 029 */     return apply((InternalRow) row);
/* 030 */   }
/* 031 */
/* 032 */   public UnsafeRow apply(InternalRow i) {
/* 033 */     mutableStateArray_1[0].reset();
/* 034 */
/* 035 */
/* 036 */     mutableStateArray_1[0].zeroOutNullBytes();
/* 037 */
/* 038 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 039 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 040 */     boolean isNull_0 = true;
/* 041 */     InternalRow value_0 = null;
/* 042 */     resultIsNull_0 = false;
/* 043 */     if (!resultIsNull_0) {
/* 044 */       boolean isNull_2 = i.isNullAt(0);
/* 045 */       org.apache.spark.ml.linalg.Vector value_2 = isNull_2 ?
/* 046 */       null : ((org.apache.spark.ml.linalg.Vector)i.get(0, null));
/* 047 */       resultIsNull_0 = isNull_2;
/* 048 */       mutableStateArray_0[0] = value_2;
/* 049 */     }
/* 050 */
/* 051 */     isNull_0 = resultIsNull_0;
/* 052 */     if (!isNull_0) {
/* 053 */
/* 054 */       Object funcResult_0 = null;
/* 055 */       funcResult_0 = value_1.serialize(mutableStateArray_0[0]);
/* 056 */
/* 057 */       if (funcResult_0 != null) {
/* 058 */         value_0 = (InternalRow) funcResult_0;
/* 059 */       } else {
/* 060 */         isNull_0 = true;
/* 061 */       }
/* 062 */
/* 063 */
/* 064 */     }
/* 065 */     if (isNull_0) {
/* 066 */       mutableStateArray_1[0].setNullAt(0);
/* 067 */     } else {
/* 068 */       final InternalRow tmpInput_0 = value_0;
/* 069 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 070 */         mutableStateArray_1[0].write(0, (UnsafeRow) tmpInput_0);
/* 071 */       } else {
/* 072 */         // Remember the current cursor so that we can calculate how many bytes are
/* 073 */         // written later.
/* 074 */         final int previousCursor_0 = mutableStateArray_1[0].cursor();
/* 075 */
/* 076 */         mutableStateArray_1[1].resetRowWriter();
/* 077 */
/* 078 */
/* 079 */         mutableStateArray_1[1].write(0, (tmpInput_0.getByte(0)));
/* 080 */
/* 081 */
/* 082 */         if ((tmpInput_0.isNullAt(1))) {
/* 083 */           mutableStateArray_1[1].setNullAt(1);
/* 084 */         } else {
/* 085 */           mutableStateArray_1[1].write(1, (tmpInput_0.getInt(1)));
/* 086 */         }
/* 087 */
/* 088 */
/* 089 */         if ((tmpInput_0.isNullAt(2))) {
/* 090 */           mutableStateArray_1[1].setNullAt(2);
/* 091 */         } else {
/* 092 */           // Remember the current cursor so that we can calculate how many bytes are
/* 093 */           // written later.
/* 094 */           final int previousCursor_1 = mutableStateArray_1[1].cursor();
/* 095 */
/* 096 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 097 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 098 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_1);
/* 099 */           } else {
/* 100 */             final int numElements_0 = tmpInput_1.numElements();
/* 101 */             mutableStateArray_2[0].initialize(numElements_0);
/* 102 */
/* 103 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 104 */               mutableStateArray_2[0].write(index_0, tmpInput_1.getInt(index_0));
/* 105 */             }
/* 106 */           }
/* 107 */
/* 108 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 109 */         }
/* 110 */
/* 111 */
/* 112 */         if ((tmpInput_0.isNullAt(3))) {
/* 113 */           mutableStateArray_1[1].setNullAt(3);
/* 114 */         } else {
/* 115 */           // Remember the current cursor so that we can calculate how many bytes are
/* 116 */           // written later.
/* 117 */           final int previousCursor_2 = mutableStateArray_1[1].cursor();
/* 118 */
/* 119 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 120 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 121 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_2);
/* 122 */           } else {
/* 123 */             final int numElements_1 = tmpInput_2.numElements();
/* 124 */             mutableStateArray_2[1].initialize(numElements_1);
/* 125 */
/* 126 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 127 */               mutableStateArray_2[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 128 */             }
/* 129 */           }
/* 130 */
/* 131 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 132 */         }
/* 133 */
/* 134 */
/* 135 */         mutableStateArray_1[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 136 */       }
/* 137 */     }
/* 138 */     return (mutableStateArray_1[0].getRow());
/* 139 */   }
/* 140 */
/* 141 */
/* 142 */ }

2025-03-26 04:47:31,427 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private boolean resultIsNull_0;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private org.apache.spark.ml.linalg.Vector[] mutableStateArray_0 = new org.apache.spark.ml.linalg.Vector[1];
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */
/* 016 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 017 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_1[0], 4);
/* 018 */     mutableStateArray_2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 4);
/* 019 */     mutableStateArray_2[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 8);
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public void initialize(int partitionIndex) {
/* 024 */
/* 025 */   }
/* 026 */
/* 027 */   // Scala.Function1 need this
/* 028 */   public java.lang.Object apply(java.lang.Object row) {
/* 029 */     return apply((InternalRow) row);
/* 030 */   }
/* 031 */
/* 032 */   public UnsafeRow apply(InternalRow i) {
/* 033 */     mutableStateArray_1[0].reset();
/* 034 */
/* 035 */
/* 036 */     mutableStateArray_1[0].zeroOutNullBytes();
/* 037 */
/* 038 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 039 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 040 */     boolean isNull_0 = true;
/* 041 */     InternalRow value_0 = null;
/* 042 */     resultIsNull_0 = false;
/* 043 */     if (!resultIsNull_0) {
/* 044 */       boolean isNull_2 = i.isNullAt(0);
/* 045 */       org.apache.spark.ml.linalg.Vector value_2 = isNull_2 ?
/* 046 */       null : ((org.apache.spark.ml.linalg.Vector)i.get(0, null));
/* 047 */       resultIsNull_0 = isNull_2;
/* 048 */       mutableStateArray_0[0] = value_2;
/* 049 */     }
/* 050 */
/* 051 */     isNull_0 = resultIsNull_0;
/* 052 */     if (!isNull_0) {
/* 053 */
/* 054 */       Object funcResult_0 = null;
/* 055 */       funcResult_0 = value_1.serialize(mutableStateArray_0[0]);
/* 056 */
/* 057 */       if (funcResult_0 != null) {
/* 058 */         value_0 = (InternalRow) funcResult_0;
/* 059 */       } else {
/* 060 */         isNull_0 = true;
/* 061 */       }
/* 062 */
/* 063 */
/* 064 */     }
/* 065 */     if (isNull_0) {
/* 066 */       mutableStateArray_1[0].setNullAt(0);
/* 067 */     } else {
/* 068 */       final InternalRow tmpInput_0 = value_0;
/* 069 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 070 */         mutableStateArray_1[0].write(0, (UnsafeRow) tmpInput_0);
/* 071 */       } else {
/* 072 */         // Remember the current cursor so that we can calculate how many bytes are
/* 073 */         // written later.
/* 074 */         final int previousCursor_0 = mutableStateArray_1[0].cursor();
/* 075 */
/* 076 */         mutableStateArray_1[1].resetRowWriter();
/* 077 */
/* 078 */
/* 079 */         mutableStateArray_1[1].write(0, (tmpInput_0.getByte(0)));
/* 080 */
/* 081 */
/* 082 */         if ((tmpInput_0.isNullAt(1))) {
/* 083 */           mutableStateArray_1[1].setNullAt(1);
/* 084 */         } else {
/* 085 */           mutableStateArray_1[1].write(1, (tmpInput_0.getInt(1)));
/* 086 */         }
/* 087 */
/* 088 */
/* 089 */         if ((tmpInput_0.isNullAt(2))) {
/* 090 */           mutableStateArray_1[1].setNullAt(2);
/* 091 */         } else {
/* 092 */           // Remember the current cursor so that we can calculate how many bytes are
/* 093 */           // written later.
/* 094 */           final int previousCursor_1 = mutableStateArray_1[1].cursor();
/* 095 */
/* 096 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 097 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 098 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_1);
/* 099 */           } else {
/* 100 */             final int numElements_0 = tmpInput_1.numElements();
/* 101 */             mutableStateArray_2[0].initialize(numElements_0);
/* 102 */
/* 103 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 104 */               mutableStateArray_2[0].write(index_0, tmpInput_1.getInt(index_0));
/* 105 */             }
/* 106 */           }
/* 107 */
/* 108 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 109 */         }
/* 110 */
/* 111 */
/* 112 */         if ((tmpInput_0.isNullAt(3))) {
/* 113 */           mutableStateArray_1[1].setNullAt(3);
/* 114 */         } else {
/* 115 */           // Remember the current cursor so that we can calculate how many bytes are
/* 116 */           // written later.
/* 117 */           final int previousCursor_2 = mutableStateArray_1[1].cursor();
/* 118 */
/* 119 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 120 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 121 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_2);
/* 122 */           } else {
/* 123 */             final int numElements_1 = tmpInput_2.numElements();
/* 124 */             mutableStateArray_2[1].initialize(numElements_1);
/* 125 */
/* 126 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 127 */               mutableStateArray_2[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 128 */             }
/* 129 */           }
/* 130 */
/* 131 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 132 */         }
/* 133 */
/* 134 */
/* 135 */         mutableStateArray_1[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 136 */       }
/* 137 */     }
/* 138 */     return (mutableStateArray_1[0].getRow());
/* 139 */   }
/* 140 */
/* 141 */
/* 142 */ }

2025-03-26 04:47:31,461 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 38.123184 ms
2025-03-26 04:47:31,474 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection: code for newInstance(class org.apache.spark.ml.linalg.VectorUDT).deserialize:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 026 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 027 */     boolean isNull_0 = true;
/* 028 */     org.apache.spark.ml.linalg.Vector value_0 = null;
/* 029 */     resultIsNull_0 = false;
/* 030 */     if (!resultIsNull_0) {
/* 031 */       boolean isNull_2 = i.isNullAt(0);
/* 032 */       InternalRow value_2 = isNull_2 ?
/* 033 */       null : (i.getStruct(0, 4));
/* 034 */       resultIsNull_0 = isNull_2;
/* 035 */       mutableStateArray_0[0] = value_2;
/* 036 */     }
/* 037 */
/* 038 */     isNull_0 = resultIsNull_0;
/* 039 */     if (!isNull_0) {
/* 040 */
/* 041 */       Object funcResult_0 = null;
/* 042 */       funcResult_0 = value_1.deserialize(mutableStateArray_0[0]);
/* 043 */
/* 044 */       if (funcResult_0 != null) {
/* 045 */         value_0 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 046 */       } else {
/* 047 */         isNull_0 = true;
/* 048 */       }
/* 049 */
/* 050 */
/* 051 */     }
/* 052 */     if (isNull_0) {
/* 053 */       mutableRow.setNullAt(0);
/* 054 */     } else {
/* 055 */
/* 056 */       mutableRow.update(0, value_0);
/* 057 */     }
/* 058 */
/* 059 */     return mutableRow;
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }

2025-03-26 04:47:31,475 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 026 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 027 */     boolean isNull_0 = true;
/* 028 */     org.apache.spark.ml.linalg.Vector value_0 = null;
/* 029 */     resultIsNull_0 = false;
/* 030 */     if (!resultIsNull_0) {
/* 031 */       boolean isNull_2 = i.isNullAt(0);
/* 032 */       InternalRow value_2 = isNull_2 ?
/* 033 */       null : (i.getStruct(0, 4));
/* 034 */       resultIsNull_0 = isNull_2;
/* 035 */       mutableStateArray_0[0] = value_2;
/* 036 */     }
/* 037 */
/* 038 */     isNull_0 = resultIsNull_0;
/* 039 */     if (!isNull_0) {
/* 040 */
/* 041 */       Object funcResult_0 = null;
/* 042 */       funcResult_0 = value_1.deserialize(mutableStateArray_0[0]);
/* 043 */
/* 044 */       if (funcResult_0 != null) {
/* 045 */         value_0 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 046 */       } else {
/* 047 */         isNull_0 = true;
/* 048 */       }
/* 049 */
/* 050 */
/* 051 */     }
/* 052 */     if (isNull_0) {
/* 053 */       mutableRow.setNullAt(0);
/* 054 */     } else {
/* 055 */
/* 056 */       mutableRow.update(0, value_0);
/* 057 */     }
/* 058 */
/* 059 */     return mutableRow;
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }

2025-03-26 04:47:31,494 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 19.660881 ms
2025-03-26 04:47:31,500 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for input[0, double, false]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     double value_0 = i.getDouble(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

2025-03-26 04:47:31,500 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     double value_0 = i.getDouble(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

2025-03-26 04:47:31,510 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 9.996358 ms
2025-03-26 04:47:31,547 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for input[0, vector, true],input[1, double, false],input[2, double, false]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */     writeFields_0_0(i);
/* 035 */     writeFields_0_1(i);
/* 036 */     return (mutableStateArray_0[0].getRow());
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */   private void writeFields_0_1(InternalRow i) {
/* 041 */
/* 042 */     double value_1 = i.getDouble(1);
/* 043 */     mutableStateArray_0[0].write(1, value_1);
/* 044 */
/* 045 */     double value_2 = i.getDouble(2);
/* 046 */     mutableStateArray_0[0].write(2, value_2);
/* 047 */
/* 048 */   }
/* 049 */
/* 050 */
/* 051 */   private void writeFields_0_0(InternalRow i) {
/* 052 */
/* 053 */     boolean isNull_0 = i.isNullAt(0);
/* 054 */     InternalRow value_0 = isNull_0 ?
/* 055 */     null : (i.getStruct(0, 4));
/* 056 */     if (isNull_0) {
/* 057 */       mutableStateArray_0[0].setNullAt(0);
/* 058 */     } else {
/* 059 */       final InternalRow tmpInput_0 = value_0;
/* 060 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 061 */         mutableStateArray_0[0].write(0, (UnsafeRow) tmpInput_0);
/* 062 */       } else {
/* 063 */         // Remember the current cursor so that we can calculate how many bytes are
/* 064 */         // written later.
/* 065 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 066 */
/* 067 */         mutableStateArray_0[1].resetRowWriter();
/* 068 */
/* 069 */
/* 070 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 071 */
/* 072 */
/* 073 */         if ((tmpInput_0.isNullAt(1))) {
/* 074 */           mutableStateArray_0[1].setNullAt(1);
/* 075 */         } else {
/* 076 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 077 */         }
/* 078 */
/* 079 */
/* 080 */         if ((tmpInput_0.isNullAt(2))) {
/* 081 */           mutableStateArray_0[1].setNullAt(2);
/* 082 */         } else {
/* 083 */           // Remember the current cursor so that we can calculate how many bytes are
/* 084 */           // written later.
/* 085 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 086 */
/* 087 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 088 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 089 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 090 */           } else {
/* 091 */             final int numElements_0 = tmpInput_1.numElements();
/* 092 */             mutableStateArray_1[0].initialize(numElements_0);
/* 093 */
/* 094 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 095 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 096 */             }
/* 097 */           }
/* 098 */
/* 099 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 100 */         }
/* 101 */
/* 102 */
/* 103 */         if ((tmpInput_0.isNullAt(3))) {
/* 104 */           mutableStateArray_0[1].setNullAt(3);
/* 105 */         } else {
/* 106 */           // Remember the current cursor so that we can calculate how many bytes are
/* 107 */           // written later.
/* 108 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 109 */
/* 110 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 111 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 112 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 113 */           } else {
/* 114 */             final int numElements_1 = tmpInput_2.numElements();
/* 115 */             mutableStateArray_1[1].initialize(numElements_1);
/* 116 */
/* 117 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 118 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 119 */             }
/* 120 */           }
/* 121 */
/* 122 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 123 */         }
/* 124 */
/* 125 */
/* 126 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 127 */       }
/* 128 */     }
/* 129 */
/* 130 */   }
/* 131 */
/* 132 */ }

2025-03-26 04:47:31,548 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */     writeFields_0_0(i);
/* 035 */     writeFields_0_1(i);
/* 036 */     return (mutableStateArray_0[0].getRow());
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */   private void writeFields_0_1(InternalRow i) {
/* 041 */
/* 042 */     double value_1 = i.getDouble(1);
/* 043 */     mutableStateArray_0[0].write(1, value_1);
/* 044 */
/* 045 */     double value_2 = i.getDouble(2);
/* 046 */     mutableStateArray_0[0].write(2, value_2);
/* 047 */
/* 048 */   }
/* 049 */
/* 050 */
/* 051 */   private void writeFields_0_0(InternalRow i) {
/* 052 */
/* 053 */     boolean isNull_0 = i.isNullAt(0);
/* 054 */     InternalRow value_0 = isNull_0 ?
/* 055 */     null : (i.getStruct(0, 4));
/* 056 */     if (isNull_0) {
/* 057 */       mutableStateArray_0[0].setNullAt(0);
/* 058 */     } else {
/* 059 */       final InternalRow tmpInput_0 = value_0;
/* 060 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 061 */         mutableStateArray_0[0].write(0, (UnsafeRow) tmpInput_0);
/* 062 */       } else {
/* 063 */         // Remember the current cursor so that we can calculate how many bytes are
/* 064 */         // written later.
/* 065 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 066 */
/* 067 */         mutableStateArray_0[1].resetRowWriter();
/* 068 */
/* 069 */
/* 070 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 071 */
/* 072 */
/* 073 */         if ((tmpInput_0.isNullAt(1))) {
/* 074 */           mutableStateArray_0[1].setNullAt(1);
/* 075 */         } else {
/* 076 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 077 */         }
/* 078 */
/* 079 */
/* 080 */         if ((tmpInput_0.isNullAt(2))) {
/* 081 */           mutableStateArray_0[1].setNullAt(2);
/* 082 */         } else {
/* 083 */           // Remember the current cursor so that we can calculate how many bytes are
/* 084 */           // written later.
/* 085 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 086 */
/* 087 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 088 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 089 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 090 */           } else {
/* 091 */             final int numElements_0 = tmpInput_1.numElements();
/* 092 */             mutableStateArray_1[0].initialize(numElements_0);
/* 093 */
/* 094 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 095 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 096 */             }
/* 097 */           }
/* 098 */
/* 099 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 100 */         }
/* 101 */
/* 102 */
/* 103 */         if ((tmpInput_0.isNullAt(3))) {
/* 104 */           mutableStateArray_0[1].setNullAt(3);
/* 105 */         } else {
/* 106 */           // Remember the current cursor so that we can calculate how many bytes are
/* 107 */           // written later.
/* 108 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 109 */
/* 110 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 111 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 112 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 113 */           } else {
/* 114 */             final int numElements_1 = tmpInput_2.numElements();
/* 115 */             mutableStateArray_1[1].initialize(numElements_1);
/* 116 */
/* 117 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 118 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 119 */             }
/* 120 */           }
/* 121 */
/* 122 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 123 */         }
/* 124 */
/* 125 */
/* 126 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 127 */       }
/* 128 */     }
/* 129 */
/* 130 */   }
/* 131 */
/* 132 */ }

2025-03-26 04:47:31,576 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 28.835603 ms
2025-03-26 04:47:31,581 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000063988/3000.
2025-03-26 04:47:31,581 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:47:31,581 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 3, executorsStarting: 0
2025-03-26 04:47:31,581 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #11 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:47:31,583 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #11
2025-03-26 04:47:31,583 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-26 04:47:31,585 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection: code for createexternalrow(newInstance(class org.apache.spark.ml.linalg.VectorUDT).deserialize, input[1, double, false], input[2, double, false], StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true), StructField(label,DoubleType,false), StructField(prediction,DoubleType,false)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     org.apache.spark.sql.Row value_6 = CreateExternalRow_0(i);
/* 026 */     if (false) {
/* 027 */       mutableRow.setNullAt(0);
/* 028 */     } else {
/* 029 */
/* 030 */       mutableRow.update(0, value_6);
/* 031 */     }
/* 032 */
/* 033 */     return mutableRow;
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */   private org.apache.spark.sql.Row CreateExternalRow_0(InternalRow i) {
/* 038 */     Object[] values_0 = new Object[3];
/* 039 */
/* 040 */     final org.apache.spark.ml.linalg.VectorUDT value_2 = false ?
/* 041 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 042 */     boolean isNull_1 = true;
/* 043 */     org.apache.spark.ml.linalg.Vector value_1 = null;
/* 044 */     resultIsNull_0 = false;
/* 045 */     if (!resultIsNull_0) {
/* 046 */       boolean isNull_3 = i.isNullAt(0);
/* 047 */       InternalRow value_3 = isNull_3 ?
/* 048 */       null : (i.getStruct(0, 4));
/* 049 */       resultIsNull_0 = isNull_3;
/* 050 */       mutableStateArray_0[0] = value_3;
/* 051 */     }
/* 052 */
/* 053 */     isNull_1 = resultIsNull_0;
/* 054 */     if (!isNull_1) {
/* 055 */
/* 056 */       Object funcResult_0 = null;
/* 057 */       funcResult_0 = value_2.deserialize(mutableStateArray_0[0]);
/* 058 */
/* 059 */       if (funcResult_0 != null) {
/* 060 */         value_1 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 061 */       } else {
/* 062 */         isNull_1 = true;
/* 063 */       }
/* 064 */
/* 065 */
/* 066 */     }
/* 067 */     if (isNull_1) {
/* 068 */       values_0[0] = null;
/* 069 */     } else {
/* 070 */       values_0[0] = value_1;
/* 071 */     }
/* 072 */
/* 073 */     double value_4 = i.getDouble(1);
/* 074 */     if (false) {
/* 075 */       values_0[1] = null;
/* 076 */     } else {
/* 077 */       values_0[1] = value_4;
/* 078 */     }
/* 079 */
/* 080 */     double value_5 = i.getDouble(2);
/* 081 */     if (false) {
/* 082 */       values_0[2] = null;
/* 083 */     } else {
/* 084 */       values_0[2] = value_5;
/* 085 */     }
/* 086 */
/* 087 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 088 */
/* 089 */     return value_0;
/* 090 */   }
/* 091 */
/* 092 */ }

2025-03-26 04:47:31,586 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     org.apache.spark.sql.Row value_6 = CreateExternalRow_0(i);
/* 026 */     if (false) {
/* 027 */       mutableRow.setNullAt(0);
/* 028 */     } else {
/* 029 */
/* 030 */       mutableRow.update(0, value_6);
/* 031 */     }
/* 032 */
/* 033 */     return mutableRow;
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */   private org.apache.spark.sql.Row CreateExternalRow_0(InternalRow i) {
/* 038 */     Object[] values_0 = new Object[3];
/* 039 */
/* 040 */     final org.apache.spark.ml.linalg.VectorUDT value_2 = false ?
/* 041 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 042 */     boolean isNull_1 = true;
/* 043 */     org.apache.spark.ml.linalg.Vector value_1 = null;
/* 044 */     resultIsNull_0 = false;
/* 045 */     if (!resultIsNull_0) {
/* 046 */       boolean isNull_3 = i.isNullAt(0);
/* 047 */       InternalRow value_3 = isNull_3 ?
/* 048 */       null : (i.getStruct(0, 4));
/* 049 */       resultIsNull_0 = isNull_3;
/* 050 */       mutableStateArray_0[0] = value_3;
/* 051 */     }
/* 052 */
/* 053 */     isNull_1 = resultIsNull_0;
/* 054 */     if (!isNull_1) {
/* 055 */
/* 056 */       Object funcResult_0 = null;
/* 057 */       funcResult_0 = value_2.deserialize(mutableStateArray_0[0]);
/* 058 */
/* 059 */       if (funcResult_0 != null) {
/* 060 */         value_1 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 061 */       } else {
/* 062 */         isNull_1 = true;
/* 063 */       }
/* 064 */
/* 065 */
/* 066 */     }
/* 067 */     if (isNull_1) {
/* 068 */       values_0[0] = null;
/* 069 */     } else {
/* 070 */       values_0[0] = value_1;
/* 071 */     }
/* 072 */
/* 073 */     double value_4 = i.getDouble(1);
/* 074 */     if (false) {
/* 075 */       values_0[1] = null;
/* 076 */     } else {
/* 077 */       values_0[1] = value_4;
/* 078 */     }
/* 079 */
/* 080 */     double value_5 = i.getDouble(2);
/* 081 */     if (false) {
/* 082 */       values_0[2] = null;
/* 083 */     } else {
/* 084 */       values_0[2] = value_5;
/* 085 */     }
/* 086 */
/* 087 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 088 */
/* 089 */     return value_0;
/* 090 */   }
/* 091 */
/* 092 */ }

2025-03-26 04:47:31,600 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 15.2541 ms
2025-03-26 04:47:31,624 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(4)
2025-03-26 04:47:31,625 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 4
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 4
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(2)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 2
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 2
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(9)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 9
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 9
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(5)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 5
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 5
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(6)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 6
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 6
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(7)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 7
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 7
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(24)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 24
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 24
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(1)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 1
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 1
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(12)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 12
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 12
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(23)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 23
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 23
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(13)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 13
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 13
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(18)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 18
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 18
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(17)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 17
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 17
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(21)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 21
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 21
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(14)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 14
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 14
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(3)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 3
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 3
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(22)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 22
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 22
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(16)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 16
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 16
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(26)
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 26
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 26
2025-03-26 04:47:31,626 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanBroadcast(0)
2025-03-26 04:47:31,627 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning broadcast 0
2025-03-26 04:47:31,627 DEBUG [Spark Context Cleaner] org.apache.spark.broadcast.TorrentBroadcast: Unpersisting TorrentBroadcast 0
2025-03-26 04:47:31,641 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 161]
2025-03-26 04:47:31,641 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] FLUSH
2025-03-26 04:47:31,641 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 182B
2025-03-26 04:47:31,644 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:31,649 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 161]
2025-03-26 04:47:31,649 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:31,651 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 161]
2025-03-26 04:47:31,651 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] FLUSH
2025-03-26 04:47:31,654 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManagerStorageEndpoint: removing broadcast 0
2025-03-26 04:47:31,654 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManager: Removing broadcast 0
2025-03-26 04:47:31,656 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManager: Removing block broadcast_0_piece0
2025-03-26 04:47:31,658 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManagerStorageEndpoint: removing broadcast 0
2025-03-26 04:47:31,659 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManager: Removing broadcast 0
2025-03-26 04:47:31,660 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0_piece0 of size 9655 dropped from memory (free 2101954953)
2025-03-26 04:47:31,660 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 194B
2025-03-26 04:47:31,661 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:31,661 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(driver, slave2, 40899, None)
2025-03-26 04:47:31,664 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ 102B
2025-03-26 04:47:31,665 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:31,666 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on slave2:40899 in memory (size: 9.4 KiB, free: 2004.6 MiB)
2025-03-26 04:47:31,666 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
2025-03-26 04:47:31,666 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManager: Told master about block broadcast_0_piece0
2025-03-26 04:47:31,667 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManager: Removing block broadcast_0
2025-03-26 04:47:31,667 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0 of size 20496 dropped from memory (free 2101975449)
2025-03-26 04:47:31,667 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(1, slave0, 39879, None)
2025-03-26 04:47:31,667 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on slave0:39879 in memory (size: 9.4 KiB, free: 912.3 MiB)
2025-03-26 04:47:31,668 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:47:31,668 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:31,669 DEBUG [block-manager-storage-async-thread-pool-2] org.apache.spark.storage.BlockManagerStorageEndpoint: Done removing broadcast 0, response is 0
2025-03-26 04:47:31,669 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 81]
2025-03-26 04:47:31,669 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] FLUSH
2025-03-26 04:47:31,670 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ 102B
2025-03-26 04:47:31,671 DEBUG [block-manager-storage-async-thread-pool-2] org.apache.spark.storage.BlockManagerStorageEndpoint: Sent response: 0 to slave2:45495
2025-03-26 04:47:31,671 DEBUG [block-manager-storage-async-thread-pool-2] org.apache.spark.storage.BlockManagerStorageEndpoint: Done removing broadcast 0, response is 0
2025-03-26 04:47:31,672 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] READ COMPLETE
2025-03-26 04:47:31,672 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ 102B
2025-03-26 04:47:31,673 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:31,674 DEBUG [block-manager-storage-async-thread-pool-2] org.apache.spark.storage.BlockManagerStorageEndpoint: Sent response: 0 to slave2:45495
2025-03-26 04:47:31,675 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned broadcast 0
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(19)
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 19
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 19
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(20)
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 20
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 20
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(15)
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 15
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 15
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(25)
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 25
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 25
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(0)
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 0
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 0
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(8)
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 8
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 8
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(11)
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 11
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 11
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(10)
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 10
2025-03-26 04:47:31,676 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 10
2025-03-26 04:47:31,679 INFO [Driver] org.apache.spark.ui.SparkUI: Stopped Spark web UI at http://slave2:41959
2025-03-26 04:47:31,683 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterSchedulerBackend: Shutting down all executors
2025-03-26 04:47:31,683 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
2025-03-26 04:47:31,684 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 122]
2025-03-26 04:47:31,684 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] FLUSH
2025-03-26 04:47:31,684 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 122]
2025-03-26 04:47:31,684 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] FLUSH
2025-03-26 04:47:31,685 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 122]
2025-03-26 04:47:31,685 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 - R:/172.20.1.13:44866] FLUSH
2025-03-26 04:47:31,685 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ 135B
2025-03-26 04:47:31,688 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:31,690 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Driver commanded a shutdown
2025-03-26 04:47:31,694 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 - R:/172.20.1.11:49382] READ COMPLETE
2025-03-26 04:47:31,694 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 ! R:/172.20.1.11:49382] INACTIVE
2025-03-26 04:47:31,694 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xec238c84, L:/172.20.1.13:40899 ! R:/172.20.1.11:49382] UNREGISTERED
2025-03-26 04:47:31,702 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 - R:/172.20.1.12:50676] READ COMPLETE
2025-03-26 04:47:31,702 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 ! R:/172.20.1.12:50676] INACTIVE
2025-03-26 04:47:31,703 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x6e236585, L:/172.20.1.13:45495 ! R:/172.20.1.12:50676] UNREGISTERED
2025-03-26 04:47:31,703 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 - R:/172.20.1.11:38036] READ COMPLETE
2025-03-26 04:47:31,703 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 ! R:/172.20.1.11:38036] INACTIVE
2025-03-26 04:47:31,703 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xc9793703, L:/172.20.1.13:45495 ! R:/172.20.1.11:38036] UNREGISTERED
2025-03-26 04:47:31,711 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-03-26 04:47:31,719 INFO [Driver] org.apache.spark.storage.memory.MemoryStore: MemoryStore cleared
2025-03-26 04:47:31,719 INFO [Driver] org.apache.spark.storage.BlockManager: BlockManager stopped
2025-03-26 04:47:31,723 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: BlockManagerMaster stopped
2025-03-26 04:47:31,726 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-03-26 04:47:31,727 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 ! R:/172.20.1.13:44866] INACTIVE
2025-03-26 04:47:31,727 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x74e7228d, L:/172.20.1.13:45495 ! R:/172.20.1.13:44866] UNREGISTERED
2025-03-26 04:47:31,727 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 - R:slave2/172.20.1.13:45495] READ COMPLETE
2025-03-26 04:47:31,727 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 ! R:slave2/172.20.1.13:45495] INACTIVE
2025-03-26 04:47:31,727 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xc58af21c, L:/172.20.1.13:44866 ! R:slave2/172.20.1.13:45495] UNREGISTERED
2025-03-26 04:47:31,730 WARN [rpc-client-3-1] io.netty.channel.nio.NioEventLoop: Selector.select() returned prematurely 512 times in a row; rebuilding Selector io.netty.channel.nio.SelectedSelectionKeySetSelector@237dfcb2.
2025-03-26 04:47:31,730 INFO [rpc-client-3-1] io.netty.channel.nio.NioEventLoop: Migrated 0 channel(s) to the new Selector.
2025-03-26 04:47:31,732 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Driver from slave2:45495 disconnected during shutdown
2025-03-26 04:47:31,732 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Driver from slave2:45495 disconnected during shutdown
2025-03-26 04:47:31,737 INFO [CoarseGrainedExecutorBackend-stop-executor] org.apache.spark.storage.memory.MemoryStore: MemoryStore cleared
2025-03-26 04:47:31,737 INFO [CoarseGrainedExecutorBackend-stop-executor] org.apache.spark.storage.BlockManager: BlockManager stopped
2025-03-26 04:47:31,739 INFO [Driver] org.apache.spark.SparkContext: Successfully stopped SparkContext
2025-03-26 04:47:31,740 INFO [Driver] org.apache.spark.deploy.yarn.ApplicationMaster: Final app status: SUCCEEDED, exitCode: 0
2025-03-26 04:47:31,744 DEBUG [Driver] org.apache.spark.deploy.yarn.ApplicationMaster: shutting down reporter thread
2025-03-26 04:47:31,745 DEBUG [Driver] org.apache.spark.deploy.yarn.ApplicationMaster: Done running user class
2025-03-26 04:47:31,759 INFO [shutdown-hook-0] org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-26 04:47:31,759 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.006 seconds; Timeouts: 0
2025-03-26 04:47:31,763 INFO [shutdown-hook-0] org.apache.spark.deploy.yarn.ApplicationMaster: Unregistering ApplicationMaster with SUCCEEDED
2025-03-26 04:47:31,766 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #12 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.finishApplicationMaster
2025-03-26 04:47:31,770 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
2025-03-26 04:47:31,771 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #12
2025-03-26 04:47:31,774 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: finishApplicationMaster took 9ms
2025-03-26 04:47:31,775 INFO [shutdown-hook-0] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Waiting for application to be successfully unregistered.
2025-03-26 04:47:31,779 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root: closed
2025-03-26 04:47:31,779 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root: stopped, remaining connections 1
2025-03-26 04:47:31,876 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root sending #13 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.finishApplicationMaster
2025-03-26 04:47:31,878 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:8030 from root got value #13
2025-03-26 04:47:31,878 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: finishApplicationMaster took 2ms
2025-03-26 04:47:31,878 DEBUG [shutdown-hook-0] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl entered state STOPPED
2025-03-26 04:47:31,878 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: stopping client from cache: Client-bb9716f5c6784f7384d840c421a623f3
2025-03-26 04:47:31,879 INFO [shutdown-hook-0] org.apache.spark.deploy.yarn.ApplicationMaster: Deleting staging directory hdfs://master:9000/user/root/.sparkStaging/application_1742964381735_0001
2025-03-26 04:47:31,882 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:47:31,882 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.10:9000
2025-03-26 04:47:31,882 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.10:9000
2025-03-26 04:47:31,883 DEBUG [shutdown-hook-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@1deaccd3]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy36.delete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:655)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy37.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1662)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:992)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:989)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:999)
	at org.apache.spark.deploy.yarn.ApplicationMaster.cleanupStagingDir(ApplicationMaster.scala:686)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$run$2(ApplicationMaster.scala:265)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:47:31,883 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:47:31,884 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSelector)
2025-03-26 04:47:31,884 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: tokens aren't supported for this protocol or user doesn't have one
2025-03-26 04:47:31,884 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Use SIMPLE authentication for protocol ClientNamenodeProtocolPB
2025-03-26 04:47:31,884 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

2025-03-26 04:47:31,885 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root: starting, having connections 2
2025-03-26 04:47:31,885 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root sending #14 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete
2025-03-26 04:47:31,993 DEBUG [IPC Client (1244880808) connection to master/172.20.1.10:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.10:9000 from root got value #14
2025-03-26 04:47:31,993 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: delete took 111ms
2025-03-26 04:47:31,999 INFO [shutdown-hook-0] org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-26 04:47:31,999 INFO [shutdown-hook-0] org.apache.spark.util.ShutdownHookManager: Deleting directory /data/tmp/nm-local-dir/usercache/root/appcache/application_1742964381735_0001/spark-8ff3b285-f55c-4cf8-814e-9f02035ed71d
2025-03-26 04:47:32,000 DEBUG [shutdown-hook-0] org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (root (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 3b248a2b
2025-03-26 04:47:32,000 DEBUG [shutdown-hook-0] org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 782e7056
2025-03-26 04:47:32,000 DEBUG [shutdown-hook-0] org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:1518)); Key: (root (auth:SIMPLE))@hdfs://master:9000; URI: hdfs://master:9000; Object Identity Hash: 1c925a75
2025-03-26 04:47:32,001 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: stopping client from cache: Client-bb9716f5c6784f7384d840c421a623f3
2025-03-26 04:47:32,001 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.241 seconds; Timeouts: 0
2025-03-26 04:47:32,011 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
