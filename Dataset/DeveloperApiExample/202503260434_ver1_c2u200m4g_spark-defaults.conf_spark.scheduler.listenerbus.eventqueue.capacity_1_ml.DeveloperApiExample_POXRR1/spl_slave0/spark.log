program=ml.DeveloperApiExample
SPARKLORD_MODE=CONFIG_INJECTION
cpu_cores=2
cpu_util=200
memory=4g
config_file_name=spark-defaults.conf
config_key=spark.scheduler.listenerbus.eventqueue.capacity
config_value=1

2025-03-26 04:36:16,159 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for TERM
2025-03-26 04:36:16,162 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for HUP
2025-03-26 04:36:16,162 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for INT
2025-03-26 04:36:16,386 DEBUG [main] org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-26 04:36:16,489 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:36:16,489 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:36:16,489 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:36:16,490 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:36:16,490 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:36:16,542 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-26 04:36:16,546 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-26 04:36:16,546 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-26 04:36:16,546 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-26 04:36:16,547 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-26 04:36:16,547 DEBUG [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-26 04:36:16,561 DEBUG [main] org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-26 04:36:16,564 DEBUG [main] org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-26 04:36:16,565 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-26 04:36:16,565 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-26 04:36:16,565 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-26 04:36:16,565 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-26 04:36:16,565 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-26 04:36:16,566 DEBUG [main] org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-26 04:36:16,602 DEBUG [main] org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-26 04:36:16,668 DEBUG [main] org.apache.spark.deploy.SparkHadoopUtil: creating UGI for user: root
2025-03-26 04:36:16,670 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-26 04:36:16,670 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-26 04:36:16,672 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-26 04:36:16,672 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-26 04:36:16,672 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-26 04:36:16,673 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Reading credentials from location /data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000001/container_tokens
2025-03-26 04:36:16,676 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Loaded 1 tokens from /data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000001/container_tokens
2025-03-26 04:36:16,676 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-26 04:36:16,676 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3@1522d8a0]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:36:16,681 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1742963702952_0001_000001
2025-03-26 04:36:16,683 DEBUG [main] org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-26 04:36:16,701 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Starting the user application in a separate Thread
2025-03-26 04:36:16,703 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Waiting for spark context initialization...
2025-03-26 04:36:16,748 INFO [Driver] org.apache.spark.SparkContext: Running Spark version 3.3.2
2025-03-26 04:36:16,764 INFO [Driver] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:36:16,764 INFO [Driver] org.apache.spark.resource.ResourceUtils: No custom resources configured for spark.driver.
2025-03-26 04:36:16,765 INFO [Driver] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:36:16,765 INFO [Driver] org.apache.spark.SparkContext: Submitted application: DeveloperApiExample
2025-03-26 04:36:16,778 INFO [Driver] org.apache.spark.resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-26 04:36:16,782 INFO [Driver] org.apache.spark.resource.ResourceProfile: Limiting resource is cpus at 2 tasks per executor
2025-03-26 04:36:16,783 INFO [Driver] org.apache.spark.resource.ResourceProfileManager: Added ResourceProfile id: 0
2025-03-26 04:36:16,811 INFO [Driver] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:36:16,811 INFO [Driver] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:36:16,811 INFO [Driver] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:36:16,811 INFO [Driver] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:36:16,811 INFO [Driver] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:36:16,851 DEBUG [Driver] io.netty.util.internal.logging.InternalLoggerFactory: Using SLF4J as the default logging framework
2025-03-26 04:36:16,856 DEBUG [Driver] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2025-03-26 04:36:16,856 DEBUG [Driver] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2025-03-26 04:36:16,863 DEBUG [Driver] io.netty.channel.MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 4
2025-03-26 04:36:16,879 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: -Dio.netty.noUnsafe: false
2025-03-26 04:36:16,879 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: Java version: 8
2025-03-26 04:36:16,880 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
2025-03-26 04:36:16,880 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
2025-03-26 04:36:16,880 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.Buffer.address: available
2025-03-26 04:36:16,880 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: direct buffer constructor: available
2025-03-26 04:36:16,880 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.Bits.unaligned: available, true
2025-03-26 04:36:16,880 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2025-03-26 04:36:16,880 DEBUG [Driver] io.netty.util.internal.PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
2025-03-26 04:36:16,880 DEBUG [Driver] io.netty.util.internal.PlatformDependent: sun.misc.Unsafe: available
2025-03-26 04:36:16,881 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.tmpdir: /data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000001/tmp (java.io.tmpdir)
2025-03-26 04:36:16,881 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
2025-03-26 04:36:16,881 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.maxDirectMemory: 3817865216 bytes
2025-03-26 04:36:16,881 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.uninitializedArrayAllocationThreshold: -1
2025-03-26 04:36:16,881 DEBUG [Driver] io.netty.util.internal.CleanerJava6: java.nio.ByteBuffer.cleaner(): available
2025-03-26 04:36:16,881 DEBUG [Driver] io.netty.util.internal.PlatformDependent: -Dio.netty.noPreferDirect: false
2025-03-26 04:36:16,882 DEBUG [Driver] io.netty.channel.nio.NioEventLoop: -Dio.netty.noKeySetOptimization: false
2025-03-26 04:36:16,882 DEBUG [Driver] io.netty.channel.nio.NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
2025-03-26 04:36:16,884 DEBUG [Driver] io.netty.util.internal.PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
2025-03-26 04:36:16,891 DEBUG [Driver] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
2025-03-26 04:36:16,891 DEBUG [Driver] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.targetRecords: 4
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 4
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 4
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2025-03-26 04:36:16,892 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.useCacheForAllThreads: true
2025-03-26 04:36:16,893 DEBUG [Driver] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2025-03-26 04:36:16,906 DEBUG [Driver] io.netty.channel.DefaultChannelId: -Dio.netty.processId: 1473 (auto-detected)
2025-03-26 04:36:16,907 DEBUG [Driver] io.netty.util.NetUtil: -Djava.net.preferIPv4Stack: false
2025-03-26 04:36:16,907 DEBUG [Driver] io.netty.util.NetUtil: -Djava.net.preferIPv6Addresses: false
2025-03-26 04:36:16,908 DEBUG [Driver] io.netty.util.NetUtilInitializations: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2025-03-26 04:36:16,909 DEBUG [Driver] io.netty.util.NetUtil: /proc/sys/net/core/somaxconn: 4096
2025-03-26 04:36:16,909 DEBUG [Driver] io.netty.channel.DefaultChannelId: -Dio.netty.machineId: 02:42:ac:ff:fe:14:01:0f (auto-detected)
2025-03-26 04:36:16,918 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.allocator.type: pooled
2025-03-26 04:36:16,918 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 0
2025-03-26 04:36:16,918 DEBUG [Driver] io.netty.buffer.ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
2025-03-26 04:36:16,924 DEBUG [Driver] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 44291
2025-03-26 04:36:16,934 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'sparkDriver' on port 44291.
2025-03-26 04:36:16,935 DEBUG [Driver] org.apache.spark.SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
2025-03-26 04:36:16,953 INFO [Driver] org.apache.spark.SparkEnv: Registering MapOutputTracker
2025-03-26 04:36:16,954 DEBUG [Driver] org.apache.spark.MapOutputTrackerMasterEndpoint: init
2025-03-26 04:36:16,973 INFO [Driver] org.apache.spark.SparkEnv: Registering BlockManagerMaster
2025-03-26 04:36:16,986 INFO [Driver] org.apache.spark.storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-26 04:36:16,986 INFO [Driver] org.apache.spark.storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-03-26 04:36:17,021 INFO [Driver] org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2025-03-26 04:36:17,041 INFO [Driver] org.apache.spark.storage.DiskBlockManager: Created local directory at /data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/blockmgr-7f689dc3-83ba-4940-8bf5-4df885978c94
2025-03-26 04:36:17,042 DEBUG [Driver] org.apache.spark.storage.DiskBlockManager: Adding shutdown hook
2025-03-26 04:36:17,050 INFO [Driver] org.apache.spark.storage.memory.MemoryStore: MemoryStore started with capacity 2004.6 MiB
2025-03-26 04:36:17,081 INFO [Driver] org.apache.spark.SparkEnv: Registering OutputCommitCoordinator
2025-03-26 04:36:17,082 DEBUG [Driver] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: init
2025-03-26 04:36:17,087 DEBUG [Driver] org.apache.spark.SecurityManager: Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2025-03-26 04:36:17,226 DEBUG [Driver] org.apache.spark.ui.JettyUtils: Using requestHeaderSize: 8192
2025-03-26 04:36:17,242 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'SparkUI' on port 35031.
2025-03-26 04:36:17,243 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,305 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Created YarnClusterScheduler
2025-03-26 04:36:17,372 DEBUG [Driver] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 35983
2025-03-26 04:36:17,372 INFO [Driver] org.apache.spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35983.
2025-03-26 04:36:17,372 INFO [Driver] org.apache.spark.network.netty.NettyBlockTransferService: Server created on slave0:35983
2025-03-26 04:36:17,373 INFO [Driver] org.apache.spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-26 04:36:17,378 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, slave0, 35983, None)
2025-03-26 04:36:17,380 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave0
2025-03-26 04:36:17,381 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave0:35983 with 2004.6 MiB RAM, BlockManagerId(driver, slave0, 35983, None)
2025-03-26 04:36:17,383 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, slave0, 35983, None)
2025-03-26 04:36:17,384 INFO [Driver] org.apache.spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, slave0, 35983, None)
2025-03-26 04:36:17,488 ERROR [Driver] org.apache.spark.scheduler.AsyncEventQueue: Dropping event from queue appStatus. This likely means one of the listeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
2025-03-26 04:36:17,490 WARN [Driver] org.apache.spark.scheduler.AsyncEventQueue: Dropped 1 events from appStatus since the application started.
2025-03-26 04:36:17,493 ERROR [Driver] org.apache.spark.scheduler.AsyncEventQueue: Dropping event from queue executorManagement. This likely means one of the listeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
2025-03-26 04:36:17,493 WARN [Driver] org.apache.spark.scheduler.AsyncEventQueue: Dropped 1 events from executorManagement since the application started.
2025-03-26 04:36:17,539 DEBUG [Driver] org.apache.spark.util.YarnContainerInfoHelper: Base URL for logs: http://slave0:8042/node/containerlogs/container_1742963702952_0001_01_000001/root
2025-03-26 04:36:17,559 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,560 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,561 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,562 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,563 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,563 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,564 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,564 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,565 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/pool: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,565 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/pool/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,566 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,566 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,567 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/rdd: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,568 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /storage/rdd/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,569 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /environment: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,569 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /environment/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,570 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,571 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,573 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/threadDump: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,574 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /executors/threadDump/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,574 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /static: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,582 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,583 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /api: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,586 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /jobs/job/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,587 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /stages/stage/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,592 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:17,593 DEBUG [Driver] org.apache.spark.SparkContext: Adding shutdown hook
2025-03-26 04:36:17,599 DEBUG [main] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl entered state INITED
2025-03-26 04:36:17,605 INFO [main] org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master/172.20.1.14:8030
2025-03-26 04:36:17,605 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.RMProxy$1@12dae582]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.RMProxy.getProxy(RMProxy.java:145)
	at org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider.init(DefaultNoHARMFailoverProxyProvider.java:65)
	at org.apache.hadoop.yarn.client.RMProxy.createNonHaRMFailoverProxyProvider(RMProxy.java:172)
	at org.apache.hadoop.yarn.client.RMProxy.newProxyInstance(RMProxy.java:132)
	at org.apache.hadoop.yarn.client.RMProxy.createRMProxy(RMProxy.java:103)
	at org.apache.hadoop.yarn.client.ClientRMProxy.createRMProxy(ClientRMProxy.java:73)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.serviceStart(AMRMClientImpl.java:193)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.spark.deploy.yarn.YarnRMClient.register(YarnRMClient.scala:63)
	at org.apache.spark.deploy.yarn.ApplicationMaster.registerAM(ApplicationMaster.scala:440)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:518)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:36:17,605 DEBUG [main] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:36:17,606 DEBUG [main] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ApplicationMasterProtocol
2025-03-26 04:36:17,613 DEBUG [main] org.apache.hadoop.ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine2$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker@2611b9a3
2025-03-26 04:36:17,616 DEBUG [main] org.apache.hadoop.ipc.Client: getting client out of cache: Client-6ad7922b9131464092a48fde0f34df41
2025-03-26 04:36:17,627 DEBUG [main] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl is started
2025-03-26 04:36:17,627 INFO [main] org.apache.spark.deploy.yarn.YarnRMClient: Registering the ApplicationMaster
2025-03-26 04:36:17,653 DEBUG [main] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:36:17,653 DEBUG [main] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.14:8030
2025-03-26 04:36:17,653 DEBUG [main] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.14:8030
2025-03-26 04:36:17,655 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@3ebff828]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy31.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.registerApplicationMaster(ApplicationMasterProtocolPBClientImpl.java:108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy32.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:247)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:234)
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.registerApplicationMaster(AMRMClientImpl.java:214)
	at org.apache.spark.deploy.yarn.YarnRMClient.register(YarnRMClient.scala:72)
	at org.apache.spark.deploy.yarn.ApplicationMaster.registerAM(ApplicationMaster.scala:440)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:518)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:36:17,702 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:36:17,707 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB info:org.apache.hadoop.yarn.security.SchedulerSecurityInfo$1@2a76b80a
2025-03-26 04:36:17,708 DEBUG [main] org.apache.hadoop.yarn.security.AMRMTokenSelector: Looking for a token with service 172.20.1.14:8030
2025-03-26 04:36:17,708 DEBUG [main] org.apache.hadoop.yarn.security.AMRMTokenSelector: Token kind is YARN_AM_RM_TOKEN and the token's service name is 172.20.1.14:8030
2025-03-26 04:36:17,710 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:36:17,710 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ApplicationMasterProtocolPB
2025-03-26 04:36:17,711 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEKj57YXdMhABEOvw2tcB
2025-03-26 04:36:17,711 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:36:17,711 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:36:17,713 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEKj57YXdMhABEOvw2tcB\",realm=\"default\",nonce=\"hL3Qj74/X83f5dORxtCi2V4rXrOV5mYouT+hV5R1\",nc=00000001,cnonce=\"Yy9c4/jKp79DQIn8U5Ptq0ZKjA2Ua5UNozLuwg/T\",digest-uri=\"/default\",maxbuf=65536,response=41b9c8af00dc360b9512a7ccc63d914d,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:36:17,715 DEBUG [main] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:36:17,718 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root: starting, having connections 1
2025-03-26 04:36:17,720 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #0 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.registerApplicationMaster
2025-03-26 04:36:17,735 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #0
2025-03-26 04:36:17,735 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: registerApplicationMaster took 104ms
2025-03-26 04:36:17,744 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Preparing Local resources
2025-03-26 04:36:17,777 DEBUG [main] org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for hdfs://master:9000/user/root/.sparkStaging/application_1742963702952_0001/__spark_conf__.zip
2025-03-26 04:36:17,777 DEBUG [main] org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for hdfs://master:9000/user/root/.sparkStaging/application_1742963702952_0001/__spark_conf__.zip: duration 0:00.000s
2025-03-26 04:36:17,778 DEBUG [main] org.apache.hadoop.fs.FileSystem: Starting: Creating FS hdfs://master:9000/user/root/.sparkStaging/application_1742963702952_0001/__spark_conf__.zip
2025-03-26 04:36:17,778 DEBUG [main] org.apache.hadoop.fs.FileSystem: Loading filesystems
2025-03-26 04:36:17,782 DEBUG [main] org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.fs.LocalFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__8116758860361911774.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:36:17,784 DEBUG [main] org.apache.hadoop.fs.FileSystem: viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__8116758860361911774.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:36:17,785 DEBUG [main] org.apache.hadoop.fs.FileSystem: har:// = class org.apache.hadoop.fs.HarFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__8116758860361911774.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:36:17,786 DEBUG [main] org.apache.hadoop.fs.FileSystem: http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__8116758860361911774.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:36:17,786 DEBUG [main] org.apache.hadoop.fs.FileSystem: https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__8116758860361911774.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:36:17,789 DEBUG [main] org.apache.hadoop.fs.FileSystem: hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__8116758860361911774.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:36:17,792 DEBUG [main] org.apache.hadoop.fs.FileSystem: webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__8116758860361911774.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:36:17,792 DEBUG [main] org.apache.hadoop.fs.FileSystem: swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__8116758860361911774.zip/hadoop-client-api-3.3.2.jar
2025-03-26 04:36:17,792 DEBUG [main] org.apache.hadoop.fs.FileSystem: nullscan:// = class org.apache.hadoop.hive.ql.io.NullScanFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__8116758860361911774.zip/hive-exec-2.3.9-core.jar
2025-03-26 04:36:17,793 DEBUG [main] org.apache.hadoop.fs.FileSystem: file:// = class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem from /data/tmp/nm-local-dir/usercache/root/filecache/10/__spark_libs__8116758860361911774.zip/hive-exec-2.3.9-core.jar
2025-03-26 04:36:17,793 DEBUG [main] org.apache.hadoop.fs.FileSystem: Looking for FS supporting hdfs
2025-03-26 04:36:17,793 DEBUG [main] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.hdfs.impl
2025-03-26 04:36:17,803 DEBUG [main] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:36:17,803 DEBUG [main] org.apache.hadoop.fs.FileSystem: FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2025-03-26 04:36:17,812 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.use.legacy.blockreader.local = false
2025-03-26 04:36:17,812 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.read.shortcircuit = false
2025-03-26 04:36:17,812 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.client.domain.socket.data.traffic = false
2025-03-26 04:36:17,812 DEBUG [main] org.apache.hadoop.hdfs.client.impl.DfsClientConf: dfs.domain.socket.path = 
2025-03-26 04:36:17,815 DEBUG [main] org.apache.hadoop.hdfs.DFSClient: Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2025-03-26 04:36:17,817 DEBUG [main] org.apache.hadoop.io.retry.RetryUtils: multipleLinearRandomRetry = null
2025-03-26 04:36:17,819 DEBUG [main] org.apache.hadoop.ipc.Client: getting client out of cache: Client-6ad7922b9131464092a48fde0f34df41
2025-03-26 04:36:17,958 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
2025-03-26 04:36:17,961 DEBUG [main] org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2025-03-26 04:36:17,963 DEBUG [main] org.apache.hadoop.fs.FileSystem: Creating FS hdfs://master:9000/user/root/.sparkStaging/application_1742963702952_0001/__spark_conf__.zip: duration 0:00.185s
2025-03-26 04:36:17,966 DEBUG [main] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:36:17,966 DEBUG [main] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.14:9000
2025-03-26 04:36:17,966 DEBUG [main] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.14:9000
2025-03-26 04:36:17,966 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@322803db]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy36.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:965)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy37.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1739)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1753)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1750)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1765)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$prepareLocalResources$4(ApplicationMaster.scala:200)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$prepareLocalResources$4$adapted(ApplicationMaster.scala:197)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.deploy.yarn.ApplicationMaster.prepareLocalResources(ApplicationMaster.scala:197)
	at org.apache.spark.deploy.yarn.ApplicationMaster.createAllocator(ApplicationMaster.scala:463)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:523)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:275)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:926)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:925)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:925)
	at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)
2025-03-26 04:36:17,966 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:36:17,967 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSelector)
2025-03-26 04:36:17,967 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: tokens aren't supported for this protocol or user doesn't have one
2025-03-26 04:36:17,967 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Use SIMPLE authentication for protocol ClientNamenodeProtocolPB
2025-03-26 04:36:17,967 DEBUG [main] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

2025-03-26 04:36:17,967 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root sending #1 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2025-03-26 04:36:17,967 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root: starting, having connections 2
2025-03-26 04:36:17,968 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root got value #1
2025-03-26 04:36:17,968 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: getFileInfo took 2ms
2025-03-26 04:36:17,989 DEBUG [main] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:36:18,010 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: 
===============================================================================
Default YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_YARN_STAGING_DIR -> hdfs://master:9000/user/root/.sparkStaging/application_1742963702952_0001
    SPARK_USER -> root

  command:
    {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx2048m \ 
      '-XX:+IgnoreUnrecognizedVMOptions' \ 
      '--add-opens=java.base/java.lang=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.lang.invoke=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.lang.reflect=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.io=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.net=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.nio=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util.concurrent=ALL-UNNAMED' \ 
      '--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.nio.ch=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.nio.cs=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.security.action=ALL-UNNAMED' \ 
      '--add-opens=java.base/sun.util.calendar=ALL-UNNAMED' \ 
      '--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED' \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.ui.port=0' \ 
      '-Dspark.driver.port=44291' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.YarnCoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@slave0:44291 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      2 \ 
      --app-id \ 
      application_1742963702952_0001 \ 
      --resourceProfileId \ 
      0 \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    __app__.jar -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742963702952_0001/scopt_2.12-3.7.1.jar" } size: 78803 timestamp: 1742963772971 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742963702952_0001/__spark_libs__8116758860361911774.zip" } size: 301733843 timestamp: 1742963772921 type: ARCHIVE visibility: PRIVATE
    __spark_conf__ -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742963702952_0001/__spark_conf__.zip" } size: 947004 timestamp: 1742963773093 type: ARCHIVE visibility: PRIVATE
    spark-examples_2.12-3.3.2.jar -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/root/.sparkStaging/application_1742963702952_0001/spark-examples_2.12-3.3.2.jar" } size: 1567446 timestamp: 1742963772996 type: FILE visibility: PRIVATE

===============================================================================
2025-03-26 04:36:18,025 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Resource profile 0 doesn't exist, adding it
2025-03-26 04:36:18,044 INFO [main] org.apache.hadoop.conf.Configuration: resource-types.xml not found
2025-03-26 04:36:18,044 INFO [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
2025-03-26 04:36:18,046 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
2025-03-26 04:36:18,047 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE
2025-03-26 04:36:18,047 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-mb'
2025-03-26 04:36:18,047 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.memory-mb.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-mb'
2025-03-26 04:36:18,047 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.minimum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.minimum-allocation-vcores'
2025-03-26 04:36:18,047 DEBUG [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Mandatory Resource 'yarn.resource-types.vcores.maximum-allocation' is not configured in resource-types config file. Setting allocation specified using 'yarn.scheduler.maximum-allocation-vcores'
2025-03-26 04:36:18,048 DEBUG [main] org.apache.spark.deploy.yarn.ResourceRequestHelper: Custom resources requested: Map()
2025-03-26 04:36:18,048 DEBUG [main] org.apache.spark.deploy.yarn.YarnAllocator: Created resource capability: <memory:2432, vCores:2>
2025-03-26 04:36:18,049 INFO [dispatcher-event-loop-0] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@slave0:44291)
2025-03-26 04:36:18,051 DEBUG [main] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 0, executorsStarting: 0
2025-03-26 04:36:18,054 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Will request 3 executor container(s) for  ResourceProfile Id: 0, each with 2 core(s) and 2432 MB memory. with custom resources: <memory:2432, vCores:2>
2025-03-26 04:36:18,062 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added priority=0
2025-03-26 04:36:18,062 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added resourceName=*
2025-03-26 04:36:18,062 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Added Execution Type=GUARANTEED
2025-03-26 04:36:18,062 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:36:18,062 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 1, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:36:18,062 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=1 #asks=1
2025-03-26 04:36:18,063 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:36:18,063 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 2, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:36:18,063 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=2 #asks=1
2025-03-26 04:36:18,063 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:36:18,063 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Adding request to ask {AllocationRequestId: 0, Priority: 0, Capability: <memory:2432, vCores:2>, # Containers: 3, Location: *, Relax Locality: true, Execution Type Request: {Execution Type: GUARANTEED, Enforce Execution Type: false}, Node Label Expression: null}
2025-03-26 04:36:18,063 DEBUG [main] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: addResourceRequest: applicationId= priority=0 resourceName=* numContainers=3 #asks=1
2025-03-26 04:36:18,063 INFO [main] org.apache.spark.deploy.yarn.YarnAllocator: Submitted 3 unlocalized container requests.
2025-03-26 04:36:18,074 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #2 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:36:18,081 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #2
2025-03-26 04:36:18,081 DEBUG [main] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 7ms
2025-03-26 04:36:18,090 INFO [main] org.apache.spark.deploy.yarn.ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
2025-03-26 04:36:18,090 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:36:18,091 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-26 04:36:18,091 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #3 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:36:18,092 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #3
2025-03-26 04:36:18,092 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 1ms
2025-03-26 04:36:18,295 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 200146533/200.
2025-03-26 04:36:18,296 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:36:18,296 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-26 04:36:18,296 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #4 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:36:18,298 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #4
2025-03-26 04:36:18,298 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-26 04:36:18,699 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 3. Slept for 400156500/400.
2025-03-26 04:36:18,699 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:36:18,700 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 3, running: 0, executorsStarting: 0
2025-03-26 04:36:18,701 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #5 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:36:18,708 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #5
2025-03-26 04:36:18,709 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 8ms
2025-03-26 04:36:18,716 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave0:37297
2025-03-26 04:36:18,722 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 1. Current executor count: 0. Launching executor count: 0. Cluster resources: <memory:16384, vCores:22>.
2025-03-26 04:36:18,723 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave0, resource: <memory:2432, vCores:2>
2025-03-26 04:36:18,727 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:36:18,727 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:36:18,727 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-26 04:36:18,727 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=3
2025-03-26 04:36:18,727 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=2 #asks=1
2025-03-26 04:36:18,728 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742963702952_0001_01_000002 on host slave0 for executor with ID 1 for ResourceProfile Id 0
2025-03-26 04:36:18,731 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
2025-03-26 04:36:18,733 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:36:18,734 DEBUG [ContainerLauncher-0] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-26 04:36:18,735 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-26 04:36:18,736 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-26 04:36:18,736 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:36:18,737 DEBUG [ContainerLauncher-0] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-26 04:36:18,747 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave0:37297
2025-03-26 04:36:18,757 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.15:37297, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742963702952 } attemptId: 1 } nodeId { host: "slave0" port: 37297 } appSubmitter: "root" keyId: 389911254)
2025-03-26 04:36:18,758 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742963702952_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@6a7b2b7d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:36:18,758 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-26 04:36:18,762 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: getting client out of cache: Client-6ad7922b9131464092a48fde0f34df41
2025-03-26 04:36:18,852 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:36:18,852 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Connecting to slave0/172.20.1.15:37297
2025-03-26 04:36:18,852 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Setup connection to slave0/172.20.1.15:37297
2025-03-26 04:36:18,853 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742963702952_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@38170cfe]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:36:18,854 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:36:18,854 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@10fdf7a9
2025-03-26 04:36:18,855 DEBUG [ContainerLauncher-0] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.15:37297. Current token is Kind: NMToken, Service: 172.20.1.15:37297, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742963702952 } attemptId: 1 } nodeId { host: "slave0" port: 37297 } appSubmitter: "root" keyId: 389911254)
2025-03-26 04:36:18,855 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:36:18,855 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-26 04:36:18,855 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEKj57YXdMhABEgwKBnNsYXZlMBCxowIaBHJvb3Qg1qX2uQE=
2025-03-26 04:36:18,855 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:36:18,855 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:36:18,856 DEBUG [ContainerLauncher-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEKj57YXdMhABEgwKBnNsYXZlMBCxowIaBHJvb3Qg1qX2uQE=\",realm=\"default\",nonce=\"bIZv3PPi+zr1kzPWu6sHoj/jf8Ji77wdwMh6yvdG\",nc=00000001,cnonce=\"kS2HFE3WkP7ycWAr7Bsqib91aP5qHnTbj4WqBbqH\",digest-uri=\"/default\",maxbuf=65536,response=7dc4d203c152eecfc72491d3fc3ecc4b,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:36:18,859 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:36:18,860 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.15:37297 from appattempt_1742963702952_0001_000001 sending #6 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-26 04:36:18,864 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.15:37297 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.15:37297 from appattempt_1742963702952_0001_000001: starting, having connections 3
2025-03-26 04:36:18,864 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.15:37297 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.15:37297 from appattempt_1742963702952_0001_000001 got value #6
2025-03-26 04:36:18,864 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.15:37297 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.15:37297 from appattempt_1742963702952_0001_000001: closed
2025-03-26 04:36:18,864 DEBUG [IPC Client (1244880808) connection to slave0/172.20.1.15:37297 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave0/172.20.1.15:37297 from appattempt_1742963702952_0001_000001: stopped, remaining connections 2
2025-03-26 04:36:18,865 DEBUG [ContainerLauncher-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 13ms
2025-03-26 04:36:19,531 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 2. Slept for 800062917/800.
2025-03-26 04:36:19,531 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:36:19,532 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 2, running: 1, executorsStarting: 0
2025-03-26 04:36:19,533 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #7 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:36:19,536 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #7
2025-03-26 04:36:19,536 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 4ms
2025-03-26 04:36:19,536 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave2:42229
2025-03-26 04:36:19,536 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Received new token for : slave1:35409
2025-03-26 04:36:19,536 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 2. Current executor count: 1. Launching executor count: 0. Cluster resources: <memory:10240, vCores:20>.
2025-03-26 04:36:19,536 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-26 04:36:19,536 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-26 04:36:19,539 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:36:19,539 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:36:19,539 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:36:19,540 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-26 04:36:19,540 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=2
2025-03-26 04:36:19,540 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=1 #asks=1
2025-03-26 04:36:19,540 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:36:19,540 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Removing container request via AM client: Capability[<memory:2432, vCores:2>]Priority[0]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null]
2025-03-26 04:36:19,540 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.RemoteRequestsTable: BEFORE decResourceRequest: applicationId= priority=0 resourceName=* numContainers=1
2025-03-26 04:36:19,540 DEBUG [Reporter] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: AFTER decResourceRequest: allocationRequestId=0 priority=0 resourceName=* numContainers=0 #asks=1
2025-03-26 04:36:19,540 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742963702952_0001_01_000003 on host slave2 for executor with ID 2 for ResourceProfile Id 0
2025-03-26 04:36:19,540 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Launching container container_1742963702952_0001_01_000004 on host slave1 for executor with ID 3 for ResourceProfile Id 0
2025-03-26 04:36:19,541 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:36:19,541 DEBUG [ContainerLauncher-1] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-26 04:36:19,541 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-26 04:36:19,542 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-26 04:36:19,542 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:36:19,542 DEBUG [ContainerLauncher-1] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-26 04:36:19,579 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave2:42229
2025-03-26 04:36:19,579 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 2 containers from YARN, launching executors on 2 of them.
2025-03-26 04:36:19,579 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.17:42229, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742963702952 } attemptId: 1 } nodeId { host: "slave2" port: 42229 } appSubmitter: "root" keyId: 389911254)
2025-03-26 04:36:19,580 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742963702952_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@41d5546f]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:36:19,580 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-26 04:36:19,580 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: getting client out of cache: Client-6ad7922b9131464092a48fde0f34df41
2025-03-26 04:36:19,581 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:36:19,581 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Connecting to slave2/172.20.1.17:42229
2025-03-26 04:36:19,581 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Setup connection to slave2/172.20.1.17:42229
2025-03-26 04:36:19,581 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742963702952_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@64f82d7e]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:36:19,581 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:36:19,582 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:36:19,582 DEBUG [ContainerLauncher-2] org.apache.spark.deploy.yarn.ExecutorRunnable: Starting Executor Container
2025-03-26 04:36:19,582 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.NMClientImpl entered state INITED
2025-03-26 04:36:19,582 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
2025-03-26 04:36:19,582 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2025-03-26 04:36:19,582 DEBUG [ContainerLauncher-2] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.client.api.impl.NMClientImpl is started
2025-03-26 04:36:19,584 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : slave1:35409
2025-03-26 04:36:19,585 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SecurityUtil: Acquired token Kind: NMToken, Service: 172.20.1.16:35409, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742963702952 } attemptId: 1 } nodeId { host: "slave1" port: 35409 } appSubmitter: "root" keyId: 389911254)
2025-03-26 04:36:19,585 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742963702952_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.yarn.client.ServerProxy$1@1c085a4d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1852)
	at org.apache.hadoop.yarn.client.ServerProxy.createRetriableProxy(ServerProxy.java:99)
	at org.apache.hadoop.yarn.client.NMProxy.createNMProxy(NMProxy.java:51)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:270)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:244)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:133)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:202)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:36:19,586 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ContainerManagementProtocol
2025-03-26 04:36:19,586 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: getting client out of cache: Client-6ad7922b9131464092a48fde0f34df41
2025-03-26 04:36:19,586 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:36:19,586 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Connecting to slave1/172.20.1.16:35409
2025-03-26 04:36:19,586 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Setup connection to slave1/172.20.1.16:35409
2025-03-26 04:36:19,586 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: appattempt_1742963702952_0001_000001 (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@392538e7]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy38.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy39.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:213)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:124)
	at org.apache.spark.deploy.yarn.ExecutorRunnable.run(ExecutorRunnable.scala:65)
	at org.apache.spark.deploy.yarn.YarnAllocator.$anonfun$runAllocatedContainers$7(YarnAllocator.scala:731)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:36:19,587 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:36:19,589 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@4500f33c
2025-03-26 04:36:19,589 DEBUG [ContainerLauncher-1] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.17:42229. Current token is Kind: NMToken, Service: 172.20.1.17:42229, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742963702952 } attemptId: 1 } nodeId { host: "slave2" port: 42229 } appSubmitter: "root" keyId: 389911254)
2025-03-26 04:36:19,589 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:36:19,589 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-26 04:36:19,589 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEKj57YXdMhABEgwKBnNsYXZlMhD1yQIaBHJvb3Qg1qX2uQE=
2025-03-26 04:36:19,589 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:36:19,589 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:36:19,589 DEBUG [ContainerLauncher-1] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEKj57YXdMhABEgwKBnNsYXZlMhD1yQIaBHJvb3Qg1qX2uQE=\",realm=\"default\",nonce=\"1jYAP3lLE+JTFMWf7o1k3bKEAuSba6e0LYcXJ0Mr\",nc=00000001,cnonce=\"UpClVDPuzo3EtuYyh0WDE7FVBLYZEQ7tGPjStIez\",digest-uri=\"/default\",maxbuf=65536,response=5df55c4d027c142dcb1b380d46ae4d81,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:36:19,594 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.yarn.api.ContainerManagementProtocolPB info:org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo$1@2d99922f
2025-03-26 04:36:19,595 DEBUG [ContainerLauncher-2] org.apache.hadoop.yarn.security.NMTokenSelector: Looking for service: 172.20.1.16:35409. Current token is Kind: NMToken, Service: 172.20.1.16:35409, Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1742963702952 } attemptId: 1 } nodeId { host: "slave1" port: 35409 } appSubmitter: "root" keyId: 389911254)
2025-03-26 04:36:19,595 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Creating SASL DIGEST-MD5(TOKEN)  client to authenticate to service at default
2025-03-26 04:36:19,595 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Use TOKEN authentication for protocol ContainerManagementProtocolPB
2025-03-26 04:36:19,595 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting username: Cg0KCQgBEKj57YXdMhABEgwKBnNsYXZlMRDRlAIaBHJvb3Qg1qX2uQE=
2025-03-26 04:36:19,595 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting userPassword
2025-03-26 04:36:19,595 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: SASL client callback: setting realm: default
2025-03-26 04:36:19,595 DEBUG [ContainerLauncher-2] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
token: "charset=utf-8,username=\"Cg0KCQgBEKj57YXdMhABEgwKBnNsYXZlMRDRlAIaBHJvb3Qg1qX2uQE=\",realm=\"default\",nonce=\"urjAvGKJSWWGq5HXTDIMvowBlUd0T1L50iHl1EWs\",nc=00000001,cnonce=\"xTKKN/FNXAZrXotT45+UT8kvD8jXxu4RqTAEO3lV\",digest-uri=\"/default\",maxbuf=65536,response=4bea99800ebe9046c32647d26bedfca4,qop=auth"
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
}

2025-03-26 04:36:19,602 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:36:19,608 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.Client: Negotiated QOP is :auth
2025-03-26 04:36:19,615 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.17:42229 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.17:42229 from appattempt_1742963702952_0001_000001: starting, having connections 4
2025-03-26 04:36:19,623 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.16:35409 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.16:35409 from appattempt_1742963702952_0001_000001: starting, having connections 4
2025-03-26 04:36:19,626 DEBUG [IPC Parameter Sending Thread #0] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.17:42229 from appattempt_1742963702952_0001_000001 sending #8 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-26 04:36:19,626 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.16:35409 from appattempt_1742963702952_0001_000001 sending #9 org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.startContainers
2025-03-26 04:36:19,649 INFO [main] org.apache.spark.executor.CoarseGrainedExecutorBackend: Started daemon with process name: 1547@slave0
2025-03-26 04:36:19,662 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for TERM
2025-03-26 04:36:19,662 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for HUP
2025-03-26 04:36:19,662 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for INT
2025-03-26 04:36:19,824 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.16:35409 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.16:35409 from appattempt_1742963702952_0001_000001 got value #9
2025-03-26 04:36:19,824 DEBUG [ContainerLauncher-2] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 238ms
2025-03-26 04:36:19,824 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.16:35409 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.16:35409 from appattempt_1742963702952_0001_000001: closed
2025-03-26 04:36:19,824 DEBUG [IPC Client (1244880808) connection to slave1/172.20.1.16:35409 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave1/172.20.1.16:35409 from appattempt_1742963702952_0001_000001: stopped, remaining connections 3
2025-03-26 04:36:19,857 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.17:42229 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.17:42229 from appattempt_1742963702952_0001_000001 got value #8
2025-03-26 04:36:19,858 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.17:42229 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.17:42229 from appattempt_1742963702952_0001_000001: closed
2025-03-26 04:36:19,858 DEBUG [IPC Client (1244880808) connection to slave2/172.20.1.17:42229 from appattempt_1742963702952_0001_000001] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to slave2/172.20.1.17:42229 from appattempt_1742963702952_0001_000001: stopped, remaining connections 2
2025-03-26 04:36:19,858 DEBUG [ContainerLauncher-1] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: startContainers took 278ms
2025-03-26 04:36:19,972 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-26 04:36:19,977 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-26 04:36:19,978 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-26 04:36:19,978 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-26 04:36:19,978 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-26 04:36:19,979 DEBUG [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-26 04:36:20,010 DEBUG [main] org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-26 04:36:20,011 DEBUG [main] org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-26 04:36:20,015 DEBUG [main] org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-26 04:36:20,016 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-26 04:36:20,016 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-26 04:36:20,016 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-26 04:36:20,016 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-26 04:36:20,016 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-26 04:36:20,017 DEBUG [main] org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-26 04:36:20,072 DEBUG [main] org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-26 04:36:20,074 DEBUG [main] org.apache.spark.deploy.SparkHadoopUtil: creating UGI for user: root
2025-03-26 04:36:20,077 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-26 04:36:20,077 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-26 04:36:20,079 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-26 04:36:20,080 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-26 04:36:20,080 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-26 04:36:20,080 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Reading credentials from location /data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000002/container_tokens
2025-03-26 04:36:20,086 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Loaded 1 tokens from /data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000002/container_tokens
2025-03-26 04:36:20,086 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-26 04:36:20,086 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.spark.deploy.SparkHadoopUtil$$anon$1@59d2400d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:61)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:427)
	at org.apache.spark.executor.YarnCoarseGrainedExecutorBackend$.main(YarnCoarseGrainedExecutorBackend.scala:83)
	at org.apache.spark.executor.YarnCoarseGrainedExecutorBackend.main(YarnCoarseGrainedExecutorBackend.scala)
2025-03-26 04:36:20,100 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:36:20,101 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:36:20,101 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:36:20,102 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:36:20,103 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:36:20,185 DEBUG [main] io.netty.util.internal.logging.InternalLoggerFactory: Using SLF4J as the default logging framework
2025-03-26 04:36:20,189 DEBUG [main] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2025-03-26 04:36:20,189 DEBUG [main] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2025-03-26 04:36:20,197 DEBUG [main] io.netty.channel.MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 4
2025-03-26 04:36:20,216 DEBUG [main] io.netty.util.internal.PlatformDependent0: -Dio.netty.noUnsafe: false
2025-03-26 04:36:20,216 DEBUG [main] io.netty.util.internal.PlatformDependent0: Java version: 8
2025-03-26 04:36:20,217 DEBUG [main] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
2025-03-26 04:36:20,217 DEBUG [main] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
2025-03-26 04:36:20,217 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.Buffer.address: available
2025-03-26 04:36:20,217 DEBUG [main] io.netty.util.internal.PlatformDependent0: direct buffer constructor: available
2025-03-26 04:36:20,218 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.Bits.unaligned: available, true
2025-03-26 04:36:20,218 DEBUG [main] io.netty.util.internal.PlatformDependent0: jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2025-03-26 04:36:20,218 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
2025-03-26 04:36:20,218 DEBUG [main] io.netty.util.internal.PlatformDependent: sun.misc.Unsafe: available
2025-03-26 04:36:20,218 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.tmpdir: /data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000002/tmp (java.io.tmpdir)
2025-03-26 04:36:20,218 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
2025-03-26 04:36:20,218 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.maxDirectMemory: 1908932608 bytes
2025-03-26 04:36:20,218 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.uninitializedArrayAllocationThreshold: -1
2025-03-26 04:36:20,219 DEBUG [main] io.netty.util.internal.CleanerJava6: java.nio.ByteBuffer.cleaner(): available
2025-03-26 04:36:20,219 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.noPreferDirect: false
2025-03-26 04:36:20,220 DEBUG [main] io.netty.channel.nio.NioEventLoop: -Dio.netty.noKeySetOptimization: false
2025-03-26 04:36:20,220 DEBUG [main] io.netty.channel.nio.NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
2025-03-26 04:36:20,224 DEBUG [main] io.netty.util.internal.PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
2025-03-26 04:36:20,234 DEBUG [main] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
2025-03-26 04:36:20,235 DEBUG [main] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.targetRecords: 4
2025-03-26 04:36:20,236 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 4
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 4
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.useCacheForAllThreads: true
2025-03-26 04:36:20,237 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2025-03-26 04:36:20,272 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Creating new connection to slave0/172.20.1.15:44291
2025-03-26 04:36:20,283 DEBUG [netty-rpc-connection-0] io.netty.channel.DefaultChannelId: -Dio.netty.processId: 1547 (auto-detected)
2025-03-26 04:36:20,285 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: -Djava.net.preferIPv4Stack: false
2025-03-26 04:36:20,285 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: -Djava.net.preferIPv6Addresses: false
2025-03-26 04:36:20,289 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtilInitializations: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2025-03-26 04:36:20,290 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: /proc/sys/net/core/somaxconn: 4096
2025-03-26 04:36:20,291 DEBUG [netty-rpc-connection-0] io.netty.channel.DefaultChannelId: -Dio.netty.machineId: 02:42:ac:ff:fe:14:01:0f (auto-detected)
2025-03-26 04:36:20,320 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.allocator.type: pooled
2025-03-26 04:36:20,320 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 0
2025-03-26 04:36:20,320 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
2025-03-26 04:36:20,344 DEBUG [rpc-client-1-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkAccessible: true
2025-03-26 04:36:20,344 DEBUG [rpc-client-1-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkBounds: true
2025-03-26 04:36:20,344 DEBUG [rpc-client-1-1] io.netty.util.ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@319dc7b7
2025-03-26 04:36:20,353 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa] REGISTERED
2025-03-26 04:36:20,354 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa] CONNECT: slave0/172.20.1.15:44291
2025-03-26 04:36:20,356 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Connection to slave0/172.20.1.15:44291 successful, running bootstraps...
2025-03-26 04:36:20,356 INFO [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Successfully created connection to slave0/172.20.1.15:44291 after 75 ms (0 ms spent in bootstraps)
2025-03-26 04:36:20,360 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.maxCapacityPerThread: 4096
2025-03-26 04:36:20,360 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.ratio: 8
2025-03-26 04:36:20,361 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.chunkSize: 32
2025-03-26 04:36:20,361 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.blocking: false
2025-03-26 04:36:20,362 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] ACTIVE
2025-03-26 04:36:20,365 DEBUG [rpc-server-4-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.15:49164.
2025-03-26 04:36:20,370 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 168]
2025-03-26 04:36:20,371 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:20,378 DEBUG [rpc-server-4-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkAccessible: true
2025-03-26 04:36:20,378 DEBUG [rpc-server-4-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkBounds: true
2025-03-26 04:36:20,378 DEBUG [rpc-server-4-1] io.netty.util.ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@7aa88a3f
2025-03-26 04:36:20,387 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] REGISTERED
2025-03-26 04:36:20,387 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] ACTIVE
2025-03-26 04:36:20,390 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.maxCapacityPerThread: 4096
2025-03-26 04:36:20,390 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.ratio: 8
2025-03-26 04:36:20,390 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.chunkSize: 32
2025-03-26 04:36:20,390 DEBUG [rpc-server-4-1] io.netty.util.Recycler: -Dio.netty.recycler.blocking: false
2025-03-26 04:36:20,394 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] READ 189B
2025-03-26 04:36:20,403 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] READ COMPLETE
2025-03-26 04:36:20,406 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:20,407 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] FLUSH
2025-03-26 04:36:20,408 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] READ 21B
2025-03-26 04:36:20,411 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:20,411 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] READ 47B
2025-03-26 04:36:20,427 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:20,429 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 169]
2025-03-26 04:36:20,429 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:20,430 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] READ 190B
2025-03-26 04:36:20,432 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] READ COMPLETE
2025-03-26 04:36:20,453 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 4376]
2025-03-26 04:36:20,454 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] FLUSH
2025-03-26 04:36:20,454 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] READ 1024B
2025-03-26 04:36:20,454 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] READ 3373B
2025-03-26 04:36:20,473 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:20,474 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 - R:slave0/172.20.1.15:44291] CLOSE
2025-03-26 04:36:20,474 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 - R:/172.20.1.15:49164] READ COMPLETE
2025-03-26 04:36:20,475 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 ! R:slave0/172.20.1.15:44291] INACTIVE
2025-03-26 04:36:20,475 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 ! R:/172.20.1.15:49164] INACTIVE
2025-03-26 04:36:20,475 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0x259c6cfa, L:/172.20.1.15:49164 ! R:slave0/172.20.1.15:44291] UNREGISTERED
2025-03-26 04:36:20,476 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xaebc009a, L:/172.20.1.15:44291 ! R:/172.20.1.15:49164] UNREGISTERED
2025-03-26 04:36:20,486 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-26 04:36:20,486 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-26 04:36:20,486 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-26 04:36:20,486 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-26 04:36:20,486 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-26 04:36:20,505 DEBUG [main] org.apache.spark.SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
2025-03-26 04:36:20,523 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Creating new connection to slave0/172.20.1.15:44291
2025-03-26 04:36:20,525 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4] REGISTERED
2025-03-26 04:36:20,525 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4] CONNECT: slave0/172.20.1.15:44291
2025-03-26 04:36:20,525 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Connection to slave0/172.20.1.15:44291 successful, running bootstraps...
2025-03-26 04:36:20,525 INFO [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Successfully created connection to slave0/172.20.1.15:44291 after 1 ms (0 ms spent in bootstraps)
2025-03-26 04:36:20,525 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] ACTIVE
2025-03-26 04:36:20,525 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 162]
2025-03-26 04:36:20,525 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:20,526 DEBUG [rpc-server-4-2] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.15:49166.
2025-03-26 04:36:20,526 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] REGISTERED
2025-03-26 04:36:20,526 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] ACTIVE
2025-03-26 04:36:20,527 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 183B
2025-03-26 04:36:20,527 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:20,528 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:20,528 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] FLUSH
2025-03-26 04:36:20,528 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 21B
2025-03-26 04:36:20,528 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:20,528 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 47B
2025-03-26 04:36:20,529 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:20,554 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 164]
2025-03-26 04:36:20,554 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:20,554 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 185B
2025-03-26 04:36:20,555 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:20,555 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:20,555 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] FLUSH
2025-03-26 04:36:20,556 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 68B
2025-03-26 04:36:20,556 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:20,558 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 173]
2025-03-26 04:36:20,558 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:20,558 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 194B
2025-03-26 04:36:20,558 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:20,559 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:20,559 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] FLUSH
2025-03-26 04:36:20,559 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 68B
2025-03-26 04:36:20,559 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:20,574 INFO [main] org.apache.spark.storage.DiskBlockManager: Created local directory at /data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/blockmgr-e9304ada-1afb-409f-9340-2613eab836e3
2025-03-26 04:36:20,576 DEBUG [main] org.apache.spark.storage.DiskBlockManager: Adding shutdown hook
2025-03-26 04:36:20,578 DEBUG [main] org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-26 04:36:20,598 INFO [main] org.apache.spark.storage.memory.MemoryStore: MemoryStore started with capacity 912.3 MiB
2025-03-26 04:36:20,785 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 169]
2025-03-26 04:36:20,785 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:20,786 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 190B
2025-03-26 04:36:20,786 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:20,786 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:20,787 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] FLUSH
2025-03-26 04:36:20,787 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 68B
2025-03-26 04:36:20,787 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:20,809 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@slave0:44291
2025-03-26 04:36:20,844 DEBUG [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Resource profile id is: 0
2025-03-26 04:36:20,851 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:36:20,851 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: No custom resources configured for spark.executor.
2025-03-26 04:36:20,851 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-26 04:36:20,852 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 168]
2025-03-26 04:36:20,852 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:20,853 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 189B
2025-03-26 04:36:20,853 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:20,854 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:20,854 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] FLUSH
2025-03-26 04:36:20,854 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 68B
2025-03-26 04:36:20,854 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:20,893 DEBUG [dispatcher-Executor] org.apache.spark.util.YarnContainerInfoHelper: Base URL for logs: http://slave0:8042/node/containerlogs/container_1742963702952_0001_01_000002/root
2025-03-26 04:36:20,925 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 1916]
2025-03-26 04:36:20,925 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:20,925 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 512B
2025-03-26 04:36:20,928 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 1425B
2025-03-26 04:36:20,937 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:20,947 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.1.15:49166) with ID 1,  ResourceProfileId 0
2025-03-26 04:36:20,954 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:20,972 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] FLUSH
2025-03-26 04:36:20,973 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 68B
2025-03-26 04:36:20,975 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:20,976 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Successfully registered with driver
2025-03-26 04:36:20,981 INFO [dispatcher-Executor] org.apache.spark.executor.Executor: Starting executor ID 1 on host slave0
2025-03-26 04:36:21,016 DEBUG [dispatcher-Executor] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 41967
2025-03-26 04:36:21,017 INFO [dispatcher-Executor] org.apache.spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41967.
2025-03-26 04:36:21,017 INFO [dispatcher-Executor] org.apache.spark.network.netty.NettyBlockTransferService: Server created on slave0:41967
2025-03-26 04:36:21,018 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-26 04:36:21,024 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, slave0, 41967, None)
2025-03-26 04:36:21,029 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 1456]
2025-03-26 04:36:21,029 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:21,029 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 1477B
2025-03-26 04:36:21,032 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:21,033 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave0
2025-03-26 04:36:21,034 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave0:41967 with 912.3 MiB RAM, BlockManagerId(1, slave0, 41967, None)
2025-03-26 04:36:21,040 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 79]
2025-03-26 04:36:21,040 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] FLUSH
2025-03-26 04:36:21,041 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 100B
2025-03-26 04:36:21,042 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:21,047 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, slave0, 41967, None)
2025-03-26 04:36:21,049 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(1, slave0, 41967, None)
2025-03-26 04:36:21,056 INFO [dispatcher-Executor] org.apache.spark.executor.Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000002/__app__.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000002/spark-examples_2.12-3.3.2.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000002/__app__.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000002/spark-examples_2.12-3.3.2.jar'
2025-03-26 04:36:21,062 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 163]
2025-03-26 04:36:21,062 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:21,063 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 184B
2025-03-26 04:36:21,063 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:21,064 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:21,065 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] FLUSH
2025-03-26 04:36:21,065 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 68B
2025-03-26 04:36:21,065 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:21,079 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 177]
2025-03-26 04:36:21,079 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:21,080 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 190B
2025-03-26 04:36:21,082 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:22,579 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000105249/3000.
2025-03-26 04:36:22,579 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:36:22,579 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 3, executorsStarting: 0
2025-03-26 04:36:22,580 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #10 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:36:22,583 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #10
2025-03-26 04:36:22,583 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 3ms
2025-03-26 04:36:22,584 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Allocated containers: 2. Current executor count: 3. Launching executor count: 0. Cluster resources: <memory:4096, vCores:18>.
2025-03-26 04:36:22,584 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave2, resource: <memory:2432, vCores:2>
2025-03-26 04:36:22,584 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: slave1, resource: <memory:2432, vCores:2>
2025-03-26 04:36:22,584 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:36:22,584 DEBUG [spark-rack-resolver] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: /default-rack, resource: <memory:2432, vCores:2>
2025-03-26 04:36:22,584 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:36:22,584 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Calling amClient.getMatchingRequests with parameters: priority: 0, location: *, resource: <memory:2432, vCores:2>
2025-03-26 04:36:22,585 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Releasing 2 unneeded containers that were allocated to us
2025-03-26 04:36:22,585 INFO [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Received 2 containers from YARN, launching executors on 0 of them.
2025-03-26 04:36:24,401 DEBUG [rpc-server-4-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.16:49848.
2025-03-26 04:36:24,401 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] REGISTERED
2025-03-26 04:36:24,401 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] ACTIVE
2025-03-26 04:36:24,416 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] READ 189B
2025-03-26 04:36:24,417 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] READ COMPLETE
2025-03-26 04:36:24,417 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,417 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] FLUSH
2025-03-26 04:36:24,419 DEBUG [rpc-server-4-2] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.17:47138.
2025-03-26 04:36:24,419 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] REGISTERED
2025-03-26 04:36:24,419 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] ACTIVE
2025-03-26 04:36:24,430 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] READ 190B
2025-03-26 04:36:24,430 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] READ COMPLETE
2025-03-26 04:36:24,431 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 4376]
2025-03-26 04:36:24,431 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] FLUSH
2025-03-26 04:36:24,435 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] READ 189B
2025-03-26 04:36:24,436 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] READ COMPLETE
2025-03-26 04:36:24,436 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,436 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] FLUSH
2025-03-26 04:36:24,449 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] READ 190B
2025-03-26 04:36:24,449 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] READ COMPLETE
2025-03-26 04:36:24,450 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 4376]
2025-03-26 04:36:24,450 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] FLUSH
2025-03-26 04:36:24,464 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 - R:/172.20.1.16:49848] READ COMPLETE
2025-03-26 04:36:24,464 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 ! R:/172.20.1.16:49848] INACTIVE
2025-03-26 04:36:24,464 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0x945b4e0b, L:/172.20.1.15:44291 ! R:/172.20.1.16:49848] UNREGISTERED
2025-03-26 04:36:24,483 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 - R:/172.20.1.17:47138] READ COMPLETE
2025-03-26 04:36:24,483 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 ! R:/172.20.1.17:47138] INACTIVE
2025-03-26 04:36:24,483 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xd5b05cdd, L:/172.20.1.15:44291 ! R:/172.20.1.17:47138] UNREGISTERED
2025-03-26 04:36:24,527 DEBUG [rpc-server-4-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.16:49850.
2025-03-26 04:36:24,527 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] REGISTERED
2025-03-26 04:36:24,527 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] ACTIVE
2025-03-26 04:36:24,527 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 183B
2025-03-26 04:36:24,528 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:24,528 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,528 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:24,550 DEBUG [rpc-server-4-2] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.17:47154.
2025-03-26 04:36:24,550 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] REGISTERED
2025-03-26 04:36:24,550 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] ACTIVE
2025-03-26 04:36:24,550 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 183B
2025-03-26 04:36:24,551 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:24,551 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,551 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] FLUSH
2025-03-26 04:36:24,571 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 185B
2025-03-26 04:36:24,571 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:24,571 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,572 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:24,575 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 194B
2025-03-26 04:36:24,576 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:24,576 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,576 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:24,594 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 185B
2025-03-26 04:36:24,595 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:24,595 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,595 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] FLUSH
2025-03-26 04:36:24,600 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 194B
2025-03-26 04:36:24,600 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:24,600 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,601 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] FLUSH
2025-03-26 04:36:24,867 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 190B
2025-03-26 04:36:24,867 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:24,867 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,868 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:24,880 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 190B
2025-03-26 04:36:24,880 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:24,881 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,881 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] FLUSH
2025-03-26 04:36:24,938 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 189B
2025-03-26 04:36:24,939 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:24,939 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,939 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:24,951 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 189B
2025-03-26 04:36:24,951 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:24,951 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:24,952 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] FLUSH
2025-03-26 04:36:25,015 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 512B
2025-03-26 04:36:25,017 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 1425B
2025-03-26 04:36:25,018 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.1.17:47154) with ID 2,  ResourceProfileId 0
2025-03-26 04:36:25,019 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:25,019 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:25,019 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 512B
2025-03-26 04:36:25,019 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 1425B
2025-03-26 04:36:25,019 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] FLUSH
2025-03-26 04:36:25,020 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.1.16:49850) with ID 3,  ResourceProfileId 0
2025-03-26 04:36:25,020 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:25,020 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:25,020 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:25,043 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2025-03-26 04:36:25,043 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterScheduler: YarnClusterScheduler.postStartHook done
2025-03-26 04:36:25,089 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 1477B
2025-03-26 04:36:25,090 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:25,090 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave1
2025-03-26 04:36:25,091 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave1:41659 with 912.3 MiB RAM, BlockManagerId(3, slave1, 41659, None)
2025-03-26 04:36:25,091 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 79]
2025-03-26 04:36:25,091 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:25,093 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 1477B
2025-03-26 04:36:25,094 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:25,094 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.DefaultTopologyMapper: Got a request for slave2
2025-03-26 04:36:25,094 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Registering block manager slave2:45307 with 912.3 MiB RAM, BlockManagerId(2, slave2, 45307, None)
2025-03-26 04:36:25,095 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 79]
2025-03-26 04:36:25,095 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] FLUSH
2025-03-26 04:36:25,109 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 184B
2025-03-26 04:36:25,110 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:25,110 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:25,110 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:25,118 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 184B
2025-03-26 04:36:25,119 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:25,119 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:25,120 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] FLUSH
2025-03-26 04:36:25,144 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 190B
2025-03-26 04:36:25,144 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:25,145 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 190B
2025-03-26 04:36:25,146 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:25,585 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000062821/3000.
2025-03-26 04:36:25,585 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:36:25,585 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 3, executorsStarting: 0
2025-03-26 04:36:25,586 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #11 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:36:25,594 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #11
2025-03-26 04:36:25,594 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 8ms
2025-03-26 04:36:25,597 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Completed 2 containers
2025-03-26 04:36:25,598 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Finished processing 2 completed containers. Current running executor count: 3.
2025-03-26 04:36:25,842 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 04:36:25,842 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 04:36:25,842 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:36:25,842 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:36:25,843 INFO [Driver] org.apache.spark.sql.internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-26 04:36:25,844 DEBUG [Driver] org.apache.spark.sql.internal.SharedState: Applying other initial session options to HadoopConf: spark.app.name -> DeveloperApiExample
2025-03-26 04:36:25,844 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Starting: Acquiring creator semaphore for file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000001/spark-warehouse
2025-03-26 04:36:25,844 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Acquiring creator semaphore for file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000001/spark-warehouse: duration 0:00.000s
2025-03-26 04:36:25,845 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Starting: Creating FS file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000001/spark-warehouse
2025-03-26 04:36:25,845 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 04:36:25,845 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 04:36:25,845 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:36:25,845 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:36:25,845 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Creating FS file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000001/spark-warehouse: duration 0:00.000s
2025-03-26 04:36:25,845 INFO [Driver] org.apache.spark.sql.internal.SharedState: Warehouse path is 'file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/container_1742963702952_0001_01_000001/spark-warehouse'.
2025-03-26 04:36:25,852 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:25,853 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol http
2025-03-26 04:36:25,853 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Unknown protocol http, delegating to default implementation
2025-03-26 04:36:25,853 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:25,854 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:25,855 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:25,856 INFO [Driver] org.apache.spark.ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol jar
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting jar
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.jar.impl
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Unknown protocol jar, delegating to default implementation
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Creating handler for protocol file
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking for FS supporting file
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: looking for configuration option fs.file.impl
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: Looking in service filesystems for implementation class
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FileSystem: FS for file is class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Found implementation of file: class org.apache.hadoop.hive.ql.io.ProxyLocalFileSystem
2025-03-26 04:36:25,857 DEBUG [Driver] org.apache.hadoop.fs.FsUrlStreamHandlerFactory: Using handler for protocol file
2025-03-26 04:36:26,306 DEBUG [Driver] org.apache.spark.sql.catalyst.parser.CatalystSqlParser: Parsing command: spark_grouping_id
2025-03-26 04:36:26,760 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegression: Input schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}}]}
2025-03-26 04:36:26,763 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegression: Expected output schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}},{"name":"prediction","type":"double","nullable":false,"metadata":{}},{"name":"rawPrediction","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":false,"metadata":{}}]}
2025-03-26 04:36:26,784 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#0
2025-03-26 04:36:26,800 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#7
2025-03-26 04:36:26,800 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'features to features#1
2025-03-26 04:36:27,226 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for input[0, double, false],input[1, vector, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */     double value_0 = i.getDouble(0);
/* 036 */     mutableStateArray_0[0].write(0, value_0);
/* 037 */
/* 038 */     boolean isNull_1 = i.isNullAt(1);
/* 039 */     InternalRow value_1 = isNull_1 ?
/* 040 */     null : (i.getStruct(1, 4));
/* 041 */     if (isNull_1) {
/* 042 */       mutableStateArray_0[0].setNullAt(1);
/* 043 */     } else {
/* 044 */       final InternalRow tmpInput_0 = value_1;
/* 045 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 046 */         mutableStateArray_0[0].write(1, (UnsafeRow) tmpInput_0);
/* 047 */       } else {
/* 048 */         // Remember the current cursor so that we can calculate how many bytes are
/* 049 */         // written later.
/* 050 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 051 */
/* 052 */         mutableStateArray_0[1].resetRowWriter();
/* 053 */
/* 054 */
/* 055 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 056 */
/* 057 */
/* 058 */         if ((tmpInput_0.isNullAt(1))) {
/* 059 */           mutableStateArray_0[1].setNullAt(1);
/* 060 */         } else {
/* 061 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 062 */         }
/* 063 */
/* 064 */
/* 065 */         if ((tmpInput_0.isNullAt(2))) {
/* 066 */           mutableStateArray_0[1].setNullAt(2);
/* 067 */         } else {
/* 068 */           // Remember the current cursor so that we can calculate how many bytes are
/* 069 */           // written later.
/* 070 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 071 */
/* 072 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 073 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 074 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 075 */           } else {
/* 076 */             final int numElements_0 = tmpInput_1.numElements();
/* 077 */             mutableStateArray_1[0].initialize(numElements_0);
/* 078 */
/* 079 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 080 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 081 */             }
/* 082 */           }
/* 083 */
/* 084 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 085 */         }
/* 086 */
/* 087 */
/* 088 */         if ((tmpInput_0.isNullAt(3))) {
/* 089 */           mutableStateArray_0[1].setNullAt(3);
/* 090 */         } else {
/* 091 */           // Remember the current cursor so that we can calculate how many bytes are
/* 092 */           // written later.
/* 093 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 094 */
/* 095 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 096 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 097 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 098 */           } else {
/* 099 */             final int numElements_1 = tmpInput_2.numElements();
/* 100 */             mutableStateArray_1[1].initialize(numElements_1);
/* 101 */
/* 102 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 103 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 104 */             }
/* 105 */           }
/* 106 */
/* 107 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 108 */         }
/* 109 */
/* 110 */
/* 111 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(1, previousCursor_0);
/* 112 */       }
/* 113 */     }
/* 114 */     return (mutableStateArray_0[0].getRow());
/* 115 */   }
/* 116 */
/* 117 */
/* 118 */ }

2025-03-26 04:36:27,239 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */     double value_0 = i.getDouble(0);
/* 036 */     mutableStateArray_0[0].write(0, value_0);
/* 037 */
/* 038 */     boolean isNull_1 = i.isNullAt(1);
/* 039 */     InternalRow value_1 = isNull_1 ?
/* 040 */     null : (i.getStruct(1, 4));
/* 041 */     if (isNull_1) {
/* 042 */       mutableStateArray_0[0].setNullAt(1);
/* 043 */     } else {
/* 044 */       final InternalRow tmpInput_0 = value_1;
/* 045 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 046 */         mutableStateArray_0[0].write(1, (UnsafeRow) tmpInput_0);
/* 047 */       } else {
/* 048 */         // Remember the current cursor so that we can calculate how many bytes are
/* 049 */         // written later.
/* 050 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 051 */
/* 052 */         mutableStateArray_0[1].resetRowWriter();
/* 053 */
/* 054 */
/* 055 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 056 */
/* 057 */
/* 058 */         if ((tmpInput_0.isNullAt(1))) {
/* 059 */           mutableStateArray_0[1].setNullAt(1);
/* 060 */         } else {
/* 061 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 062 */         }
/* 063 */
/* 064 */
/* 065 */         if ((tmpInput_0.isNullAt(2))) {
/* 066 */           mutableStateArray_0[1].setNullAt(2);
/* 067 */         } else {
/* 068 */           // Remember the current cursor so that we can calculate how many bytes are
/* 069 */           // written later.
/* 070 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 071 */
/* 072 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 073 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 074 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 075 */           } else {
/* 076 */             final int numElements_0 = tmpInput_1.numElements();
/* 077 */             mutableStateArray_1[0].initialize(numElements_0);
/* 078 */
/* 079 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 080 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 081 */             }
/* 082 */           }
/* 083 */
/* 084 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 085 */         }
/* 086 */
/* 087 */
/* 088 */         if ((tmpInput_0.isNullAt(3))) {
/* 089 */           mutableStateArray_0[1].setNullAt(3);
/* 090 */         } else {
/* 091 */           // Remember the current cursor so that we can calculate how many bytes are
/* 092 */           // written later.
/* 093 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 094 */
/* 095 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 096 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 097 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 098 */           } else {
/* 099 */             final int numElements_1 = tmpInput_2.numElements();
/* 100 */             mutableStateArray_1[1].initialize(numElements_1);
/* 101 */
/* 102 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 103 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 104 */             }
/* 105 */           }
/* 106 */
/* 107 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 108 */         }
/* 109 */
/* 110 */
/* 111 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(1, previousCursor_0);
/* 112 */       }
/* 113 */     }
/* 114 */     return (mutableStateArray_0[0].getRow());
/* 115 */   }
/* 116 */
/* 117 */
/* 118 */ }

2025-03-26 04:36:27,397 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 169.637944 ms
2025-03-26 04:36:27,412 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$doExecute$1
2025-03-26 04:36:27,424 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$doExecute$1) is now cleaned +++
2025-03-26 04:36:27,436 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$rdd$1
2025-03-26 04:36:27,444 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2025-03-26 04:36:27,463 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$extractLabeledPoints$1
2025-03-26 04:36:27,464 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$extractLabeledPoints$1) is now cleaned +++
2025-03-26 04:36:27,474 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$take$2
2025-03-26 04:36:27,478 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$take$2) is now cleaned +++
2025-03-26 04:36:27,532 DEBUG [Driver] org.apache.spark.util.ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5
2025-03-26 04:36:27,535 DEBUG [Driver] org.apache.spark.util.ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2025-03-26 04:36:27,537 INFO [Driver] org.apache.spark.SparkContext: Starting job: take at DeveloperApiExample.scala:127
2025-03-26 04:36:27,539 DEBUG [Driver] org.apache.spark.scheduler.DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 5 took 0.000617 seconds
2025-03-26 04:36:27,541 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Merging stage rdd profiles: Set()
2025-03-26 04:36:27,549 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Got job 0 (take at DeveloperApiExample.scala:127) with 1 output partitions
2025-03-26 04:36:27,549 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 0 (take at DeveloperApiExample.scala:127)
2025-03-26 04:36:27,550 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()
2025-03-26 04:36:27,550 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Missing parents: List()
2025-03-26 04:36:27,569 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: submitStage(ResultStage 0 (name=take at DeveloperApiExample.scala:127;jobs=0))
2025-03-26 04:36:27,570 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: missing: List()
2025-03-26 04:36:27,571 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at Predictor.scala:185), which has no missing parents
2025-03-26 04:36:27,571 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: submitMissingTasks(ResultStage 0)
2025-03-26 04:36:27,643 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 20.0 KiB, free 2004.6 MiB)
2025-03-26 04:36:27,643 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Put block broadcast_0 locally took 17 ms
2025-03-26 04:36:27,644 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Putting block broadcast_0 without replication took 18 ms
2025-03-26 04:36:27,664 INFO [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 2004.6 MiB)
2025-03-26 04:36:27,665 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(driver, slave0, 35983, None)
2025-03-26 04:36:27,666 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on slave0:35983 (size: 9.4 KiB, free: 2004.6 MiB)
2025-03-26 04:36:27,669 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
2025-03-26 04:36:27,670 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Told master about block broadcast_0_piece0
2025-03-26 04:36:27,670 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Put block broadcast_0_piece0 locally took 8 ms
2025-03-26 04:36:27,670 DEBUG [dag-scheduler-event-loop] org.apache.spark.storage.BlockManager: Putting block broadcast_0_piece0 without replication took 8 ms
2025-03-26 04:36:27,670 INFO [dag-scheduler-event-loop] org.apache.spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
2025-03-26 04:36:27,681 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at Predictor.scala:185) (first 15 tasks are for partitions Vector(0))
2025-03-26 04:36:27,682 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Adding task set 0.0 with 1 tasks resource profile 0
2025-03-26 04:36:27,695 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Epoch for TaskSet 0.0: 0
2025-03-26 04:36:27,697 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Adding pending tasks took 1 ms
2025-03-26 04:36:27,699 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2025-03-26 04:36:27,702 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnClusterScheduler: parentName: , name: TaskSet_0.0, runningTasks: 0
2025-03-26 04:36:27,717 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (slave1, executor 3, partition 0, PROCESS_LOCAL, 4702 bytes) taskResourceAssignments Map()
2025-03-26 04:36:27,727 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
2025-03-26 04:36:27,731 DEBUG [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Launching task 0 on executor id: 3 hostname: slave1.
2025-03-26 04:36:27,736 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 5149]
2025-03-26 04:36:27,736 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:27,770 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 1642B
2025-03-26 04:36:27,775 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:27,892 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 338B
2025-03-26 04:36:27,897 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:27,897 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 760]
2025-03-26 04:36:27,898 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:27,916 DEBUG [shuffle-server-7-1] org.apache.spark.network.server.TransportServer: New connection accepted for remote address /172.20.1.16:60234.
2025-03-26 04:36:27,917 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] REGISTERED
2025-03-26 04:36:27,917 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] ACTIVE
2025-03-26 04:36:27,920 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] READ 92B
2025-03-26 04:36:27,927 DEBUG [shuffle-server-7-1] org.apache.spark.storage.BlockManager: Getting local block broadcast_0_piece0 as bytes
2025-03-26 04:36:27,928 DEBUG [shuffle-server-7-1] org.apache.spark.storage.BlockManager: Level for block broadcast_0_piece0 is StorageLevel(disk, memory, 1 replicas)
2025-03-26 04:36:27,930 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 13]
2025-03-26 04:36:27,930 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] FLUSH
2025-03-26 04:36:27,930 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] READ COMPLETE
2025-03-26 04:36:27,935 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] READ 21B
2025-03-26 04:36:27,937 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 9640]
2025-03-26 04:36:27,937 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] FLUSH
2025-03-26 04:36:27,937 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] READ COMPLETE
2025-03-26 04:36:27,953 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 194B
2025-03-26 04:36:27,955 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:27,955 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(3, slave1, 41659, None)
2025-03-26 04:36:27,955 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on slave1:41659 (size: 9.4 KiB, free: 912.3 MiB)
2025-03-26 04:36:27,956 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:27,956 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:27,967 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root: closed
2025-03-26 04:36:27,967 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root: stopped, remaining connections 1
2025-03-26 04:36:28,599 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Number of pending allocations is 0. Slept for 3000060152/3000.
2025-03-26 04:36:28,599 DEBUG [Reporter] org.apache.spark.deploy.yarn.ApplicationMaster: Sending progress
2025-03-26 04:36:28,599 DEBUG [Reporter] org.apache.spark.deploy.yarn.YarnAllocator: Updating resource requests for ResourceProfile id: 0, target: 3, pending: 0, running: 3, executorsStarting: 0
2025-03-26 04:36:28,599 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #12 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate
2025-03-26 04:36:28,601 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #12
2025-03-26 04:36:28,601 DEBUG [Reporter] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: allocate took 2ms
2025-03-26 04:36:30,091 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 1024B
2025-03-26 04:36:30,091 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 2045B
2025-03-26 04:36:30,092 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:30,099 INFO [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2394 ms on slave1 (executor 3) (1/1)
2025-03-26 04:36:30,102 INFO [task-result-getter-0] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-26 04:36:30,106 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: ResultStage 0 (take at DeveloperApiExample.scala:127) finished in 2.504 s
2025-03-26 04:36:30,106 ERROR [dag-scheduler-event-loop] org.apache.spark.scheduler.AsyncEventQueue: Dropping event from queue shared. This likely means one of the listeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
2025-03-26 04:36:30,106 WARN [dag-scheduler-event-loop] org.apache.spark.scheduler.AsyncEventQueue: Dropped 1 events from shared since the application started.
2025-03-26 04:36:30,108 DEBUG [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: After removal of stage 0, remaining stages = 0
2025-03-26 04:36:30,108 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-26 04:36:30,108 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.cluster.YarnClusterScheduler: Killing all running tasks in stage 0: Stage finished
2025-03-26 04:36:30,116 INFO [Driver] org.apache.spark.scheduler.DAGScheduler: Job 0 finished: take at DeveloperApiExample.scala:127, took 2.578875 s
2025-03-26 04:36:30,139 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegressionModel: Input schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}}]}
2025-03-26 04:36:30,147 DEBUG [Driver] org.apache.spark.examples.ml.MyLogisticRegressionModel: Expected output schema: {"type":"struct","fields":[{"name":"label","type":"double","nullable":false,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}},{"name":"prediction","type":"double","nullable":false,"metadata":{"ml_attr":{"type":"nominal","num_vals":2}}},{"name":"rawPrediction","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":false,"metadata":{"ml_attr":{"num_attrs":2}}}]}
2025-03-26 04:36:30,176 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'features to features#14
2025-03-26 04:36:30,192 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'rawPrediction to rawPrediction#19
2025-03-26 04:36:30,213 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'features to features#14
2025-03-26 04:36:30,214 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'label to label#13
2025-03-26 04:36:30,214 DEBUG [Driver] org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1: Resolving 'prediction to prediction#26
2025-03-26 04:36:30,246 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for newInstance(class org.apache.spark.ml.linalg.VectorUDT).serialize:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private boolean resultIsNull_0;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private org.apache.spark.ml.linalg.Vector[] mutableStateArray_0 = new org.apache.spark.ml.linalg.Vector[1];
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */
/* 016 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 017 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_1[0], 4);
/* 018 */     mutableStateArray_2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 4);
/* 019 */     mutableStateArray_2[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 8);
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public void initialize(int partitionIndex) {
/* 024 */
/* 025 */   }
/* 026 */
/* 027 */   // Scala.Function1 need this
/* 028 */   public java.lang.Object apply(java.lang.Object row) {
/* 029 */     return apply((InternalRow) row);
/* 030 */   }
/* 031 */
/* 032 */   public UnsafeRow apply(InternalRow i) {
/* 033 */     mutableStateArray_1[0].reset();
/* 034 */
/* 035 */
/* 036 */     mutableStateArray_1[0].zeroOutNullBytes();
/* 037 */
/* 038 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 039 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 040 */     boolean isNull_0 = true;
/* 041 */     InternalRow value_0 = null;
/* 042 */     resultIsNull_0 = false;
/* 043 */     if (!resultIsNull_0) {
/* 044 */       boolean isNull_2 = i.isNullAt(0);
/* 045 */       org.apache.spark.ml.linalg.Vector value_2 = isNull_2 ?
/* 046 */       null : ((org.apache.spark.ml.linalg.Vector)i.get(0, null));
/* 047 */       resultIsNull_0 = isNull_2;
/* 048 */       mutableStateArray_0[0] = value_2;
/* 049 */     }
/* 050 */
/* 051 */     isNull_0 = resultIsNull_0;
/* 052 */     if (!isNull_0) {
/* 053 */
/* 054 */       Object funcResult_0 = null;
/* 055 */       funcResult_0 = value_1.serialize(mutableStateArray_0[0]);
/* 056 */
/* 057 */       if (funcResult_0 != null) {
/* 058 */         value_0 = (InternalRow) funcResult_0;
/* 059 */       } else {
/* 060 */         isNull_0 = true;
/* 061 */       }
/* 062 */
/* 063 */
/* 064 */     }
/* 065 */     if (isNull_0) {
/* 066 */       mutableStateArray_1[0].setNullAt(0);
/* 067 */     } else {
/* 068 */       final InternalRow tmpInput_0 = value_0;
/* 069 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 070 */         mutableStateArray_1[0].write(0, (UnsafeRow) tmpInput_0);
/* 071 */       } else {
/* 072 */         // Remember the current cursor so that we can calculate how many bytes are
/* 073 */         // written later.
/* 074 */         final int previousCursor_0 = mutableStateArray_1[0].cursor();
/* 075 */
/* 076 */         mutableStateArray_1[1].resetRowWriter();
/* 077 */
/* 078 */
/* 079 */         mutableStateArray_1[1].write(0, (tmpInput_0.getByte(0)));
/* 080 */
/* 081 */
/* 082 */         if ((tmpInput_0.isNullAt(1))) {
/* 083 */           mutableStateArray_1[1].setNullAt(1);
/* 084 */         } else {
/* 085 */           mutableStateArray_1[1].write(1, (tmpInput_0.getInt(1)));
/* 086 */         }
/* 087 */
/* 088 */
/* 089 */         if ((tmpInput_0.isNullAt(2))) {
/* 090 */           mutableStateArray_1[1].setNullAt(2);
/* 091 */         } else {
/* 092 */           // Remember the current cursor so that we can calculate how many bytes are
/* 093 */           // written later.
/* 094 */           final int previousCursor_1 = mutableStateArray_1[1].cursor();
/* 095 */
/* 096 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 097 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 098 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_1);
/* 099 */           } else {
/* 100 */             final int numElements_0 = tmpInput_1.numElements();
/* 101 */             mutableStateArray_2[0].initialize(numElements_0);
/* 102 */
/* 103 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 104 */               mutableStateArray_2[0].write(index_0, tmpInput_1.getInt(index_0));
/* 105 */             }
/* 106 */           }
/* 107 */
/* 108 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 109 */         }
/* 110 */
/* 111 */
/* 112 */         if ((tmpInput_0.isNullAt(3))) {
/* 113 */           mutableStateArray_1[1].setNullAt(3);
/* 114 */         } else {
/* 115 */           // Remember the current cursor so that we can calculate how many bytes are
/* 116 */           // written later.
/* 117 */           final int previousCursor_2 = mutableStateArray_1[1].cursor();
/* 118 */
/* 119 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 120 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 121 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_2);
/* 122 */           } else {
/* 123 */             final int numElements_1 = tmpInput_2.numElements();
/* 124 */             mutableStateArray_2[1].initialize(numElements_1);
/* 125 */
/* 126 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 127 */               mutableStateArray_2[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 128 */             }
/* 129 */           }
/* 130 */
/* 131 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 132 */         }
/* 133 */
/* 134 */
/* 135 */         mutableStateArray_1[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 136 */       }
/* 137 */     }
/* 138 */     return (mutableStateArray_1[0].getRow());
/* 139 */   }
/* 140 */
/* 141 */
/* 142 */ }

2025-03-26 04:36:30,249 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private boolean resultIsNull_0;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private org.apache.spark.ml.linalg.Vector[] mutableStateArray_0 = new org.apache.spark.ml.linalg.Vector[1];
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */
/* 016 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 017 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_1[0], 4);
/* 018 */     mutableStateArray_2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 4);
/* 019 */     mutableStateArray_2[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_1[1], 8);
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public void initialize(int partitionIndex) {
/* 024 */
/* 025 */   }
/* 026 */
/* 027 */   // Scala.Function1 need this
/* 028 */   public java.lang.Object apply(java.lang.Object row) {
/* 029 */     return apply((InternalRow) row);
/* 030 */   }
/* 031 */
/* 032 */   public UnsafeRow apply(InternalRow i) {
/* 033 */     mutableStateArray_1[0].reset();
/* 034 */
/* 035 */
/* 036 */     mutableStateArray_1[0].zeroOutNullBytes();
/* 037 */
/* 038 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 039 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 040 */     boolean isNull_0 = true;
/* 041 */     InternalRow value_0 = null;
/* 042 */     resultIsNull_0 = false;
/* 043 */     if (!resultIsNull_0) {
/* 044 */       boolean isNull_2 = i.isNullAt(0);
/* 045 */       org.apache.spark.ml.linalg.Vector value_2 = isNull_2 ?
/* 046 */       null : ((org.apache.spark.ml.linalg.Vector)i.get(0, null));
/* 047 */       resultIsNull_0 = isNull_2;
/* 048 */       mutableStateArray_0[0] = value_2;
/* 049 */     }
/* 050 */
/* 051 */     isNull_0 = resultIsNull_0;
/* 052 */     if (!isNull_0) {
/* 053 */
/* 054 */       Object funcResult_0 = null;
/* 055 */       funcResult_0 = value_1.serialize(mutableStateArray_0[0]);
/* 056 */
/* 057 */       if (funcResult_0 != null) {
/* 058 */         value_0 = (InternalRow) funcResult_0;
/* 059 */       } else {
/* 060 */         isNull_0 = true;
/* 061 */       }
/* 062 */
/* 063 */
/* 064 */     }
/* 065 */     if (isNull_0) {
/* 066 */       mutableStateArray_1[0].setNullAt(0);
/* 067 */     } else {
/* 068 */       final InternalRow tmpInput_0 = value_0;
/* 069 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 070 */         mutableStateArray_1[0].write(0, (UnsafeRow) tmpInput_0);
/* 071 */       } else {
/* 072 */         // Remember the current cursor so that we can calculate how many bytes are
/* 073 */         // written later.
/* 074 */         final int previousCursor_0 = mutableStateArray_1[0].cursor();
/* 075 */
/* 076 */         mutableStateArray_1[1].resetRowWriter();
/* 077 */
/* 078 */
/* 079 */         mutableStateArray_1[1].write(0, (tmpInput_0.getByte(0)));
/* 080 */
/* 081 */
/* 082 */         if ((tmpInput_0.isNullAt(1))) {
/* 083 */           mutableStateArray_1[1].setNullAt(1);
/* 084 */         } else {
/* 085 */           mutableStateArray_1[1].write(1, (tmpInput_0.getInt(1)));
/* 086 */         }
/* 087 */
/* 088 */
/* 089 */         if ((tmpInput_0.isNullAt(2))) {
/* 090 */           mutableStateArray_1[1].setNullAt(2);
/* 091 */         } else {
/* 092 */           // Remember the current cursor so that we can calculate how many bytes are
/* 093 */           // written later.
/* 094 */           final int previousCursor_1 = mutableStateArray_1[1].cursor();
/* 095 */
/* 096 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 097 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 098 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_1);
/* 099 */           } else {
/* 100 */             final int numElements_0 = tmpInput_1.numElements();
/* 101 */             mutableStateArray_2[0].initialize(numElements_0);
/* 102 */
/* 103 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 104 */               mutableStateArray_2[0].write(index_0, tmpInput_1.getInt(index_0));
/* 105 */             }
/* 106 */           }
/* 107 */
/* 108 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 109 */         }
/* 110 */
/* 111 */
/* 112 */         if ((tmpInput_0.isNullAt(3))) {
/* 113 */           mutableStateArray_1[1].setNullAt(3);
/* 114 */         } else {
/* 115 */           // Remember the current cursor so that we can calculate how many bytes are
/* 116 */           // written later.
/* 117 */           final int previousCursor_2 = mutableStateArray_1[1].cursor();
/* 118 */
/* 119 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 120 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 121 */             mutableStateArray_1[1].write((UnsafeArrayData) tmpInput_2);
/* 122 */           } else {
/* 123 */             final int numElements_1 = tmpInput_2.numElements();
/* 124 */             mutableStateArray_2[1].initialize(numElements_1);
/* 125 */
/* 126 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 127 */               mutableStateArray_2[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 128 */             }
/* 129 */           }
/* 130 */
/* 131 */           mutableStateArray_1[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 132 */         }
/* 133 */
/* 134 */
/* 135 */         mutableStateArray_1[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 136 */       }
/* 137 */     }
/* 138 */     return (mutableStateArray_1[0].getRow());
/* 139 */   }
/* 140 */
/* 141 */
/* 142 */ }

2025-03-26 04:36:30,262 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 16.051713 ms
2025-03-26 04:36:30,271 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection: code for newInstance(class org.apache.spark.ml.linalg.VectorUDT).deserialize:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 026 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 027 */     boolean isNull_0 = true;
/* 028 */     org.apache.spark.ml.linalg.Vector value_0 = null;
/* 029 */     resultIsNull_0 = false;
/* 030 */     if (!resultIsNull_0) {
/* 031 */       boolean isNull_2 = i.isNullAt(0);
/* 032 */       InternalRow value_2 = isNull_2 ?
/* 033 */       null : (i.getStruct(0, 4));
/* 034 */       resultIsNull_0 = isNull_2;
/* 035 */       mutableStateArray_0[0] = value_2;
/* 036 */     }
/* 037 */
/* 038 */     isNull_0 = resultIsNull_0;
/* 039 */     if (!isNull_0) {
/* 040 */
/* 041 */       Object funcResult_0 = null;
/* 042 */       funcResult_0 = value_1.deserialize(mutableStateArray_0[0]);
/* 043 */
/* 044 */       if (funcResult_0 != null) {
/* 045 */         value_0 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 046 */       } else {
/* 047 */         isNull_0 = true;
/* 048 */       }
/* 049 */
/* 050 */
/* 051 */     }
/* 052 */     if (isNull_0) {
/* 053 */       mutableRow.setNullAt(0);
/* 054 */     } else {
/* 055 */
/* 056 */       mutableRow.update(0, value_0);
/* 057 */     }
/* 058 */
/* 059 */     return mutableRow;
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }

2025-03-26 04:36:30,272 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     final org.apache.spark.ml.linalg.VectorUDT value_1 = false ?
/* 026 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 027 */     boolean isNull_0 = true;
/* 028 */     org.apache.spark.ml.linalg.Vector value_0 = null;
/* 029 */     resultIsNull_0 = false;
/* 030 */     if (!resultIsNull_0) {
/* 031 */       boolean isNull_2 = i.isNullAt(0);
/* 032 */       InternalRow value_2 = isNull_2 ?
/* 033 */       null : (i.getStruct(0, 4));
/* 034 */       resultIsNull_0 = isNull_2;
/* 035 */       mutableStateArray_0[0] = value_2;
/* 036 */     }
/* 037 */
/* 038 */     isNull_0 = resultIsNull_0;
/* 039 */     if (!isNull_0) {
/* 040 */
/* 041 */       Object funcResult_0 = null;
/* 042 */       funcResult_0 = value_1.deserialize(mutableStateArray_0[0]);
/* 043 */
/* 044 */       if (funcResult_0 != null) {
/* 045 */         value_0 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 046 */       } else {
/* 047 */         isNull_0 = true;
/* 048 */       }
/* 049 */
/* 050 */
/* 051 */     }
/* 052 */     if (isNull_0) {
/* 053 */       mutableRow.setNullAt(0);
/* 054 */     } else {
/* 055 */
/* 056 */       mutableRow.update(0, value_0);
/* 057 */     }
/* 058 */
/* 059 */     return mutableRow;
/* 060 */   }
/* 061 */
/* 062 */
/* 063 */ }

2025-03-26 04:36:30,278 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.92937 ms
2025-03-26 04:36:30,283 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for input[0, double, false]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     double value_0 = i.getDouble(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

2025-03-26 04:36:30,283 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */
/* 030 */
/* 031 */     double value_0 = i.getDouble(0);
/* 032 */     mutableStateArray_0[0].write(0, value_0);
/* 033 */     return (mutableStateArray_0[0].getRow());
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */ }

2025-03-26 04:36:30,288 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.097218 ms
2025-03-26 04:36:30,317 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection: code for input[0, vector, true],input[1, double, false],input[2, double, false]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */     writeFields_0_0(i);
/* 035 */     writeFields_0_1(i);
/* 036 */     return (mutableStateArray_0[0].getRow());
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */   private void writeFields_0_1(InternalRow i) {
/* 041 */
/* 042 */     double value_1 = i.getDouble(1);
/* 043 */     mutableStateArray_0[0].write(1, value_1);
/* 044 */
/* 045 */     double value_2 = i.getDouble(2);
/* 046 */     mutableStateArray_0[0].write(2, value_2);
/* 047 */
/* 048 */   }
/* 049 */
/* 050 */
/* 051 */   private void writeFields_0_0(InternalRow i) {
/* 052 */
/* 053 */     boolean isNull_0 = i.isNullAt(0);
/* 054 */     InternalRow value_0 = isNull_0 ?
/* 055 */     null : (i.getStruct(0, 4));
/* 056 */     if (isNull_0) {
/* 057 */       mutableStateArray_0[0].setNullAt(0);
/* 058 */     } else {
/* 059 */       final InternalRow tmpInput_0 = value_0;
/* 060 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 061 */         mutableStateArray_0[0].write(0, (UnsafeRow) tmpInput_0);
/* 062 */       } else {
/* 063 */         // Remember the current cursor so that we can calculate how many bytes are
/* 064 */         // written later.
/* 065 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 066 */
/* 067 */         mutableStateArray_0[1].resetRowWriter();
/* 068 */
/* 069 */
/* 070 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 071 */
/* 072 */
/* 073 */         if ((tmpInput_0.isNullAt(1))) {
/* 074 */           mutableStateArray_0[1].setNullAt(1);
/* 075 */         } else {
/* 076 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 077 */         }
/* 078 */
/* 079 */
/* 080 */         if ((tmpInput_0.isNullAt(2))) {
/* 081 */           mutableStateArray_0[1].setNullAt(2);
/* 082 */         } else {
/* 083 */           // Remember the current cursor so that we can calculate how many bytes are
/* 084 */           // written later.
/* 085 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 086 */
/* 087 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 088 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 089 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 090 */           } else {
/* 091 */             final int numElements_0 = tmpInput_1.numElements();
/* 092 */             mutableStateArray_1[0].initialize(numElements_0);
/* 093 */
/* 094 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 095 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 096 */             }
/* 097 */           }
/* 098 */
/* 099 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 100 */         }
/* 101 */
/* 102 */
/* 103 */         if ((tmpInput_0.isNullAt(3))) {
/* 104 */           mutableStateArray_0[1].setNullAt(3);
/* 105 */         } else {
/* 106 */           // Remember the current cursor so that we can calculate how many bytes are
/* 107 */           // written later.
/* 108 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 109 */
/* 110 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 111 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 112 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 113 */           } else {
/* 114 */             final int numElements_1 = tmpInput_2.numElements();
/* 115 */             mutableStateArray_1[1].initialize(numElements_1);
/* 116 */
/* 117 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 118 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 119 */             }
/* 120 */           }
/* 121 */
/* 122 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 123 */         }
/* 124 */
/* 125 */
/* 126 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 127 */       }
/* 128 */     }
/* 129 */
/* 130 */   }
/* 131 */
/* 132 */ }

2025-03-26 04:36:30,319 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[] mutableStateArray_1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter[2];
/* 010 */
/* 011 */   public SpecificUnsafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 014 */     mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray_0[0], 4);
/* 015 */     mutableStateArray_1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 4);
/* 016 */     mutableStateArray_1[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter(mutableStateArray_0[1], 8);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray_0[0].reset();
/* 031 */
/* 032 */
/* 033 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */     writeFields_0_0(i);
/* 035 */     writeFields_0_1(i);
/* 036 */     return (mutableStateArray_0[0].getRow());
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */   private void writeFields_0_1(InternalRow i) {
/* 041 */
/* 042 */     double value_1 = i.getDouble(1);
/* 043 */     mutableStateArray_0[0].write(1, value_1);
/* 044 */
/* 045 */     double value_2 = i.getDouble(2);
/* 046 */     mutableStateArray_0[0].write(2, value_2);
/* 047 */
/* 048 */   }
/* 049 */
/* 050 */
/* 051 */   private void writeFields_0_0(InternalRow i) {
/* 052 */
/* 053 */     boolean isNull_0 = i.isNullAt(0);
/* 054 */     InternalRow value_0 = isNull_0 ?
/* 055 */     null : (i.getStruct(0, 4));
/* 056 */     if (isNull_0) {
/* 057 */       mutableStateArray_0[0].setNullAt(0);
/* 058 */     } else {
/* 059 */       final InternalRow tmpInput_0 = value_0;
/* 060 */       if (tmpInput_0 instanceof UnsafeRow) {
/* 061 */         mutableStateArray_0[0].write(0, (UnsafeRow) tmpInput_0);
/* 062 */       } else {
/* 063 */         // Remember the current cursor so that we can calculate how many bytes are
/* 064 */         // written later.
/* 065 */         final int previousCursor_0 = mutableStateArray_0[0].cursor();
/* 066 */
/* 067 */         mutableStateArray_0[1].resetRowWriter();
/* 068 */
/* 069 */
/* 070 */         mutableStateArray_0[1].write(0, (tmpInput_0.getByte(0)));
/* 071 */
/* 072 */
/* 073 */         if ((tmpInput_0.isNullAt(1))) {
/* 074 */           mutableStateArray_0[1].setNullAt(1);
/* 075 */         } else {
/* 076 */           mutableStateArray_0[1].write(1, (tmpInput_0.getInt(1)));
/* 077 */         }
/* 078 */
/* 079 */
/* 080 */         if ((tmpInput_0.isNullAt(2))) {
/* 081 */           mutableStateArray_0[1].setNullAt(2);
/* 082 */         } else {
/* 083 */           // Remember the current cursor so that we can calculate how many bytes are
/* 084 */           // written later.
/* 085 */           final int previousCursor_1 = mutableStateArray_0[1].cursor();
/* 086 */
/* 087 */           final ArrayData tmpInput_1 = (tmpInput_0.getArray(2));
/* 088 */           if (tmpInput_1 instanceof UnsafeArrayData) {
/* 089 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_1);
/* 090 */           } else {
/* 091 */             final int numElements_0 = tmpInput_1.numElements();
/* 092 */             mutableStateArray_1[0].initialize(numElements_0);
/* 093 */
/* 094 */             for (int index_0 = 0; index_0 < numElements_0; index_0++) {
/* 095 */               mutableStateArray_1[0].write(index_0, tmpInput_1.getInt(index_0));
/* 096 */             }
/* 097 */           }
/* 098 */
/* 099 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(2, previousCursor_1);
/* 100 */         }
/* 101 */
/* 102 */
/* 103 */         if ((tmpInput_0.isNullAt(3))) {
/* 104 */           mutableStateArray_0[1].setNullAt(3);
/* 105 */         } else {
/* 106 */           // Remember the current cursor so that we can calculate how many bytes are
/* 107 */           // written later.
/* 108 */           final int previousCursor_2 = mutableStateArray_0[1].cursor();
/* 109 */
/* 110 */           final ArrayData tmpInput_2 = (tmpInput_0.getArray(3));
/* 111 */           if (tmpInput_2 instanceof UnsafeArrayData) {
/* 112 */             mutableStateArray_0[1].write((UnsafeArrayData) tmpInput_2);
/* 113 */           } else {
/* 114 */             final int numElements_1 = tmpInput_2.numElements();
/* 115 */             mutableStateArray_1[1].initialize(numElements_1);
/* 116 */
/* 117 */             for (int index_1 = 0; index_1 < numElements_1; index_1++) {
/* 118 */               mutableStateArray_1[1].write(index_1, tmpInput_2.getDouble(index_1));
/* 119 */             }
/* 120 */           }
/* 121 */
/* 122 */           mutableStateArray_0[1].setOffsetAndSizeFromPreviousCursor(3, previousCursor_2);
/* 123 */         }
/* 124 */
/* 125 */
/* 126 */         mutableStateArray_0[0].setOffsetAndSizeFromPreviousCursor(0, previousCursor_0);
/* 127 */       }
/* 128 */     }
/* 129 */
/* 130 */   }
/* 131 */
/* 132 */ }

2025-03-26 04:36:30,337 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 19.392198 ms
2025-03-26 04:36:30,345 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection: code for createexternalrow(newInstance(class org.apache.spark.ml.linalg.VectorUDT).deserialize, input[1, double, false], input[2, double, false], StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true), StructField(label,DoubleType,false), StructField(prediction,DoubleType,false)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     org.apache.spark.sql.Row value_6 = CreateExternalRow_0(i);
/* 026 */     if (false) {
/* 027 */       mutableRow.setNullAt(0);
/* 028 */     } else {
/* 029 */
/* 030 */       mutableRow.update(0, value_6);
/* 031 */     }
/* 032 */
/* 033 */     return mutableRow;
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */   private org.apache.spark.sql.Row CreateExternalRow_0(InternalRow i) {
/* 038 */     Object[] values_0 = new Object[3];
/* 039 */
/* 040 */     final org.apache.spark.ml.linalg.VectorUDT value_2 = false ?
/* 041 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 042 */     boolean isNull_1 = true;
/* 043 */     org.apache.spark.ml.linalg.Vector value_1 = null;
/* 044 */     resultIsNull_0 = false;
/* 045 */     if (!resultIsNull_0) {
/* 046 */       boolean isNull_3 = i.isNullAt(0);
/* 047 */       InternalRow value_3 = isNull_3 ?
/* 048 */       null : (i.getStruct(0, 4));
/* 049 */       resultIsNull_0 = isNull_3;
/* 050 */       mutableStateArray_0[0] = value_3;
/* 051 */     }
/* 052 */
/* 053 */     isNull_1 = resultIsNull_0;
/* 054 */     if (!isNull_1) {
/* 055 */
/* 056 */       Object funcResult_0 = null;
/* 057 */       funcResult_0 = value_2.deserialize(mutableStateArray_0[0]);
/* 058 */
/* 059 */       if (funcResult_0 != null) {
/* 060 */         value_1 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 061 */       } else {
/* 062 */         isNull_1 = true;
/* 063 */       }
/* 064 */
/* 065 */
/* 066 */     }
/* 067 */     if (isNull_1) {
/* 068 */       values_0[0] = null;
/* 069 */     } else {
/* 070 */       values_0[0] = value_1;
/* 071 */     }
/* 072 */
/* 073 */     double value_4 = i.getDouble(1);
/* 074 */     if (false) {
/* 075 */       values_0[1] = null;
/* 076 */     } else {
/* 077 */       values_0[1] = value_4;
/* 078 */     }
/* 079 */
/* 080 */     double value_5 = i.getDouble(2);
/* 081 */     if (false) {
/* 082 */       values_0[2] = null;
/* 083 */     } else {
/* 084 */       values_0[2] = value_5;
/* 085 */     }
/* 086 */
/* 087 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 088 */
/* 089 */     return value_0;
/* 090 */   }
/* 091 */
/* 092 */ }

2025-03-26 04:36:30,346 DEBUG [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private boolean resultIsNull_0;
/* 010 */   private InternalRow[] mutableStateArray_0 = new InternalRow[1];
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     org.apache.spark.sql.Row value_6 = CreateExternalRow_0(i);
/* 026 */     if (false) {
/* 027 */       mutableRow.setNullAt(0);
/* 028 */     } else {
/* 029 */
/* 030 */       mutableRow.update(0, value_6);
/* 031 */     }
/* 032 */
/* 033 */     return mutableRow;
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */   private org.apache.spark.sql.Row CreateExternalRow_0(InternalRow i) {
/* 038 */     Object[] values_0 = new Object[3];
/* 039 */
/* 040 */     final org.apache.spark.ml.linalg.VectorUDT value_2 = false ?
/* 041 */     null : new org.apache.spark.ml.linalg.VectorUDT();
/* 042 */     boolean isNull_1 = true;
/* 043 */     org.apache.spark.ml.linalg.Vector value_1 = null;
/* 044 */     resultIsNull_0 = false;
/* 045 */     if (!resultIsNull_0) {
/* 046 */       boolean isNull_3 = i.isNullAt(0);
/* 047 */       InternalRow value_3 = isNull_3 ?
/* 048 */       null : (i.getStruct(0, 4));
/* 049 */       resultIsNull_0 = isNull_3;
/* 050 */       mutableStateArray_0[0] = value_3;
/* 051 */     }
/* 052 */
/* 053 */     isNull_1 = resultIsNull_0;
/* 054 */     if (!isNull_1) {
/* 055 */
/* 056 */       Object funcResult_0 = null;
/* 057 */       funcResult_0 = value_2.deserialize(mutableStateArray_0[0]);
/* 058 */
/* 059 */       if (funcResult_0 != null) {
/* 060 */         value_1 = (org.apache.spark.ml.linalg.Vector) funcResult_0;
/* 061 */       } else {
/* 062 */         isNull_1 = true;
/* 063 */       }
/* 064 */
/* 065 */
/* 066 */     }
/* 067 */     if (isNull_1) {
/* 068 */       values_0[0] = null;
/* 069 */     } else {
/* 070 */       values_0[0] = value_1;
/* 071 */     }
/* 072 */
/* 073 */     double value_4 = i.getDouble(1);
/* 074 */     if (false) {
/* 075 */       values_0[1] = null;
/* 076 */     } else {
/* 077 */       values_0[1] = value_4;
/* 078 */     }
/* 079 */
/* 080 */     double value_5 = i.getDouble(2);
/* 081 */     if (false) {
/* 082 */       values_0[2] = null;
/* 083 */     } else {
/* 084 */       values_0[2] = value_5;
/* 085 */     }
/* 086 */
/* 087 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 088 */
/* 089 */     return value_0;
/* 090 */   }
/* 091 */
/* 092 */ }

2025-03-26 04:36:30,353 INFO [Driver] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.025653 ms
2025-03-26 04:36:30,375 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanAccum(0)
2025-03-26 04:36:30,376 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning accumulator 0
2025-03-26 04:36:30,377 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned accumulator 0
2025-03-26 04:36:30,377 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Got cleaning task CleanBroadcast(0)
2025-03-26 04:36:30,377 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaning broadcast 0
2025-03-26 04:36:30,377 DEBUG [Spark Context Cleaner] org.apache.spark.broadcast.TorrentBroadcast: Unpersisting TorrentBroadcast 0
2025-03-26 04:36:30,399 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 161]
2025-03-26 04:36:30,400 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] FLUSH
2025-03-26 04:36:30,400 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 182B
2025-03-26 04:36:30,404 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:30,411 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 161]
2025-03-26 04:36:30,412 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:30,412 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 161]
2025-03-26 04:36:30,412 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] FLUSH
2025-03-26 04:36:30,422 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManagerStorageEndpoint: removing broadcast 0
2025-03-26 04:36:30,422 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManager: Removing broadcast 0
2025-03-26 04:36:30,424 INFO [Driver] org.apache.spark.ui.SparkUI: Stopped Spark web UI at http://slave0:35031
2025-03-26 04:36:30,425 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManagerStorageEndpoint: removing broadcast 0
2025-03-26 04:36:30,425 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManager: Removing broadcast 0
2025-03-26 04:36:30,427 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 194B
2025-03-26 04:36:30,427 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:30,427 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(3, slave1, 41659, None)
2025-03-26 04:36:30,428 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on slave1:41659 in memory (size: 9.4 KiB, free: 912.3 MiB)
2025-03-26 04:36:30,429 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 47]
2025-03-26 04:36:30,429 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:30,430 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManager: Removing block broadcast_0_piece0
2025-03-26 04:36:30,431 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0_piece0 of size 9640 dropped from memory (free 2101954961)
2025-03-26 04:36:30,431 DEBUG [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(driver, slave0, 35983, None)
2025-03-26 04:36:30,432 INFO [dispatcher-BlockManagerMaster] org.apache.spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on slave0:35983 in memory (size: 9.4 KiB, free: 2004.6 MiB)
2025-03-26 04:36:30,432 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ 102B
2025-03-26 04:36:30,433 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ 102B
2025-03-26 04:36:30,434 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
2025-03-26 04:36:30,434 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManager: Told master about block broadcast_0_piece0
2025-03-26 04:36:30,434 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.BlockManager: Removing block broadcast_0
2025-03-26 04:36:30,435 DEBUG [block-manager-storage-async-thread-pool-0] org.apache.spark.storage.memory.MemoryStore: Block broadcast_0 of size 20488 dropped from memory (free 2101975449)
2025-03-26 04:36:30,435 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:30,438 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:30,439 DEBUG [block-manager-storage-async-thread-pool-2] org.apache.spark.storage.BlockManagerStorageEndpoint: Done removing broadcast 0, response is 0
2025-03-26 04:36:30,440 DEBUG [block-manager-storage-async-thread-pool-2] org.apache.spark.storage.BlockManagerStorageEndpoint: Sent response: 0 to slave0:44291
2025-03-26 04:36:30,441 DEBUG [block-manager-storage-async-thread-pool-2] org.apache.spark.storage.BlockManagerStorageEndpoint: Done removing broadcast 0, response is 0
2025-03-26 04:36:30,441 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 81]
2025-03-26 04:36:30,441 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] FLUSH
2025-03-26 04:36:30,441 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ 102B
2025-03-26 04:36:30,443 DEBUG [block-manager-storage-async-thread-pool-2] org.apache.spark.storage.BlockManagerStorageEndpoint: Sent response: 0 to slave0:44291
2025-03-26 04:36:30,443 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:30,444 DEBUG [Spark Context Cleaner] org.apache.spark.ContextCleaner: Cleaned broadcast 0
2025-03-26 04:36:30,448 INFO [Driver] org.apache.spark.scheduler.cluster.YarnClusterSchedulerBackend: Shutting down all executors
2025-03-26 04:36:30,448 INFO [dispatcher-CoarseGrainedScheduler] org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
2025-03-26 04:36:30,450 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 122]
2025-03-26 04:36:30,450 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] FLUSH
2025-03-26 04:36:30,450 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 122]
2025-03-26 04:36:30,450 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] FLUSH
2025-03-26 04:36:30,450 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 122]
2025-03-26 04:36:30,450 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] FLUSH
2025-03-26 04:36:30,450 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ 135B
2025-03-26 04:36:30,454 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] READ COMPLETE
2025-03-26 04:36:30,456 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Driver commanded a shutdown
2025-03-26 04:36:30,464 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 - R:/172.20.1.16:60234] READ COMPLETE
2025-03-26 04:36:30,464 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 ! R:/172.20.1.16:60234] INACTIVE
2025-03-26 04:36:30,464 DEBUG [shuffle-server-7-1] org.apache.spark.network.util.NettyLogger: [id: 0xa2d2128c, L:/172.20.1.15:35983 ! R:/172.20.1.16:60234] UNREGISTERED
2025-03-26 04:36:30,467 INFO [dispatcher-event-loop-0] org.apache.spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-03-26 04:36:30,481 INFO [CoarseGrainedExecutorBackend-stop-executor] org.apache.spark.storage.memory.MemoryStore: MemoryStore cleared
2025-03-26 04:36:30,481 INFO [CoarseGrainedExecutorBackend-stop-executor] org.apache.spark.storage.BlockManager: BlockManager stopped
2025-03-26 04:36:30,483 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 - R:/172.20.1.17:47154] READ COMPLETE
2025-03-26 04:36:30,483 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 ! R:/172.20.1.17:47154] INACTIVE
2025-03-26 04:36:30,483 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0x3a7f6ca3, L:/172.20.1.15:44291 ! R:/172.20.1.17:47154] UNREGISTERED
2025-03-26 04:36:30,485 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 - R:slave0/172.20.1.15:44291] CLOSE
2025-03-26 04:36:30,485 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 ! R:slave0/172.20.1.15:44291] INACTIVE
2025-03-26 04:36:30,485 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0x245b3bf4, L:/172.20.1.15:49166 ! R:slave0/172.20.1.15:44291] UNREGISTERED
2025-03-26 04:36:30,485 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 - R:/172.20.1.15:49166] READ COMPLETE
2025-03-26 04:36:30,486 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 ! R:/172.20.1.15:49166] INACTIVE
2025-03-26 04:36:30,486 DEBUG [rpc-server-4-2] org.apache.spark.network.util.NettyLogger: [id: 0xb4f27504, L:/172.20.1.15:44291 ! R:/172.20.1.15:49166] UNREGISTERED
2025-03-26 04:36:30,486 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 - R:/172.20.1.16:49850] READ COMPLETE
2025-03-26 04:36:30,486 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 ! R:/172.20.1.16:49850] INACTIVE
2025-03-26 04:36:30,486 DEBUG [rpc-server-4-1] org.apache.spark.network.util.NettyLogger: [id: 0xa92bebd6, L:/172.20.1.15:44291 ! R:/172.20.1.16:49850] UNREGISTERED
2025-03-26 04:36:30,500 INFO [Driver] org.apache.spark.storage.memory.MemoryStore: MemoryStore cleared
2025-03-26 04:36:30,501 INFO [Driver] org.apache.spark.storage.BlockManager: BlockManager stopped
2025-03-26 04:36:30,505 INFO [Driver] org.apache.spark.storage.BlockManagerMaster: BlockManagerMaster stopped
2025-03-26 04:36:30,506 INFO [shutdown-hook-0] org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-26 04:36:30,507 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.008 seconds; Timeouts: 0
2025-03-26 04:36:30,508 INFO [dispatcher-event-loop-1] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-03-26 04:36:30,524 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
2025-03-26 04:36:30,537 INFO [Driver] org.apache.spark.SparkContext: Successfully stopped SparkContext
2025-03-26 04:36:30,538 INFO [Driver] org.apache.spark.deploy.yarn.ApplicationMaster: Final app status: SUCCEEDED, exitCode: 0
2025-03-26 04:36:30,542 DEBUG [Driver] org.apache.spark.deploy.yarn.ApplicationMaster: shutting down reporter thread
2025-03-26 04:36:30,543 DEBUG [Driver] org.apache.spark.deploy.yarn.ApplicationMaster: Done running user class
2025-03-26 04:36:30,571 INFO [shutdown-hook-0] org.apache.spark.deploy.yarn.ApplicationMaster: Unregistering ApplicationMaster with SUCCEEDED
2025-03-26 04:36:30,575 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #13 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.finishApplicationMaster
2025-03-26 04:36:30,579 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #13
2025-03-26 04:36:30,582 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: finishApplicationMaster took 9ms
2025-03-26 04:36:30,583 INFO [shutdown-hook-0] org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl: Waiting for application to be successfully unregistered.
2025-03-26 04:36:30,684 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root sending #14 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.finishApplicationMaster
2025-03-26 04:36:30,687 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:8030 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:8030 from root got value #14
2025-03-26 04:36:30,689 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: finishApplicationMaster took 5ms
2025-03-26 04:36:30,689 DEBUG [shutdown-hook-0] org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl entered state STOPPED
2025-03-26 04:36:30,689 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: stopping client from cache: Client-6ad7922b9131464092a48fde0f34df41
2025-03-26 04:36:30,689 INFO [shutdown-hook-0] org.apache.spark.deploy.yarn.ApplicationMaster: Deleting staging directory hdfs://master:9000/user/root/.sparkStaging/application_1742963702952_0001
2025-03-26 04:36:30,691 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: The ping interval is 60000 ms.
2025-03-26 04:36:30,691 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: Connecting to master/172.20.1.14:9000
2025-03-26 04:36:30,691 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: Setup connection to master/172.20.1.14:9000
2025-03-26 04:36:30,691 DEBUG [shutdown-hook-0] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.hadoop.ipc.Client$Connection$2@75bb2ddb]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy36.delete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:655)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy37.delete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1662)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:992)
	at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:989)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:999)
	at org.apache.spark.deploy.yarn.ApplicationMaster.cleanupStagingDir(ApplicationMaster.scala:686)
	at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$run$2(ApplicationMaster.scala:265)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2025-03-26 04:36:30,691 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: NEGOTIATE

2025-03-26 04:36:30,692 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSelector)
2025-03-26 04:36:30,692 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: tokens aren't supported for this protocol or user doesn't have one
2025-03-26 04:36:30,692 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Use SIMPLE authentication for protocol ClientNamenodeProtocolPB
2025-03-26 04:36:30,692 DEBUG [shutdown-hook-0] org.apache.hadoop.security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

2025-03-26 04:36:30,692 DEBUG [IPC Parameter Sending Thread #1] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root sending #15 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete
2025-03-26 04:36:30,692 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root: starting, having connections 2
2025-03-26 04:36:30,813 DEBUG [IPC Client (1244880808) connection to master/172.20.1.14:9000 from root] org.apache.hadoop.ipc.Client: IPC Client (1244880808) connection to master/172.20.1.14:9000 from root got value #15
2025-03-26 04:36:30,814 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.ProtobufRpcEngine2: Call: delete took 123ms
2025-03-26 04:36:30,818 INFO [shutdown-hook-0] org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-26 04:36:30,819 INFO [shutdown-hook-0] org.apache.spark.util.ShutdownHookManager: Deleting directory /data/tmp/nm-local-dir/usercache/root/appcache/application_1742963702952_0001/spark-4d42701a-8031-4a9c-aac5-e923896e1158
2025-03-26 04:36:30,821 DEBUG [shutdown-hook-0] org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (root (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 55e9a3e
2025-03-26 04:36:30,821 DEBUG [shutdown-hook-0] org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 48ab2ea9
2025-03-26 04:36:30,821 DEBUG [shutdown-hook-0] org.apache.hadoop.fs.FileSystem: FileSystem.close() by method: org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:1518)); Key: (root (auth:SIMPLE))@hdfs://master:9000; URI: hdfs://master:9000; Object Identity Hash: ae796bc
2025-03-26 04:36:30,822 DEBUG [shutdown-hook-0] org.apache.hadoop.ipc.Client: stopping client from cache: Client-6ad7922b9131464092a48fde0f34df41
2025-03-26 04:36:30,822 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.264 seconds; Timeouts: 0
2025-03-26 04:36:30,831 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
