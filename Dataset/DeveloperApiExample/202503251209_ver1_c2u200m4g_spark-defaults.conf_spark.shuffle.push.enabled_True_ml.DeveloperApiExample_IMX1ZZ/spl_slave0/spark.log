program=ml.DeveloperApiExample
SPARKLORD_MODE=CONFIG_INJECTION
cpu_cores=2
cpu_util=200
memory=4g
config_file_name=spark-defaults.conf
config_key=spark.shuffle.push.enabled
config_value=True

2025-03-25 12:11:51,524 INFO [main] org.apache.spark.executor.CoarseGrainedExecutorBackend: Started daemon with process name: 1503@slave0
2025-03-25 12:11:51,531 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for TERM
2025-03-25 12:11:51,531 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for HUP
2025-03-25 12:11:51,531 INFO [main] org.apache.spark.util.SignalUtils: Registering signal handler for INT
2025-03-25 12:11:51,874 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[GetGroups])
2025-03-25 12:11:51,880 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)])
2025-03-25 12:11:51,880 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)])
2025-03-25 12:11:51,880 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since last successful login])
2025-03-25 12:11:51,880 DEBUG [main] org.apache.hadoop.metrics2.lib.MutableMetricsFactory: field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, valueName=Time, about=, interval=10, type=DEFAULT, value=[Renewal failures since startup])
2025-03-25 12:11:51,881 DEBUG [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
2025-03-25 12:11:51,905 DEBUG [main] org.apache.hadoop.util.Shell: setsid exited with exit code 0
2025-03-25 12:11:51,905 DEBUG [main] org.apache.hadoop.security.SecurityUtil: Setting hadoop.security.token.service.use_ip to true
2025-03-25 12:11:51,909 DEBUG [main] org.apache.hadoop.security.Groups:  Creating new Groups object
2025-03-25 12:11:51,910 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
2025-03-25 12:11:51,911 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2025-03-25 12:11:51,911 DEBUG [main] org.apache.hadoop.util.NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2025-03-25 12:11:51,911 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-03-25 12:11:51,911 DEBUG [main] org.apache.hadoop.util.PerformanceAdvisory: Falling back to shell based
2025-03-25 12:11:51,912 DEBUG [main] org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2025-03-25 12:11:51,962 DEBUG [main] org.apache.hadoop.security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2025-03-25 12:11:51,964 DEBUG [main] org.apache.spark.deploy.SparkHadoopUtil: creating UGI for user: root
2025-03-25 12:11:51,967 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Hadoop login
2025-03-25 12:11:51,967 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: hadoop login commit
2025-03-25 12:11:51,969 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using local user: UnixPrincipal: root
2025-03-25 12:11:51,970 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Using user: "UnixPrincipal: root" with name: root
2025-03-25 12:11:51,970 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: User entry: "root"
2025-03-25 12:11:51,970 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Reading credentials from location /data/tmp/nm-local-dir/usercache/root/appcache/application_1742904630293_0001/container_1742904630293_0001_01_000002/container_tokens
2025-03-25 12:11:51,975 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: Loaded 1 tokens from /data/tmp/nm-local-dir/usercache/root/appcache/application_1742904630293_0001/container_1742904630293_0001_01_000002/container_tokens
2025-03-25 12:11:51,975 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: UGI loginUser: root (auth:SIMPLE)
2025-03-25 12:11:51,976 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction [as: root (auth:SIMPLE)][action: org.apache.spark.deploy.SparkHadoopUtil$$anon$1@59d2400d]
java.lang.Exception
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:61)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:427)
	at org.apache.spark.executor.YarnCoarseGrainedExecutorBackend$.main(YarnCoarseGrainedExecutorBackend.scala:83)
	at org.apache.spark.executor.YarnCoarseGrainedExecutorBackend.main(YarnCoarseGrainedExecutorBackend.scala)
2025-03-25 12:11:51,985 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-25 12:11:51,985 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-25 12:11:51,986 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-25 12:11:51,986 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-25 12:11:51,986 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-25 12:11:52,065 DEBUG [main] io.netty.util.internal.logging.InternalLoggerFactory: Using SLF4J as the default logging framework
2025-03-25 12:11:52,068 DEBUG [main] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2025-03-25 12:11:52,068 DEBUG [main] io.netty.util.internal.InternalThreadLocalMap: -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2025-03-25 12:11:52,077 DEBUG [main] io.netty.channel.MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 4
2025-03-25 12:11:52,095 DEBUG [main] io.netty.util.internal.PlatformDependent0: -Dio.netty.noUnsafe: false
2025-03-25 12:11:52,095 DEBUG [main] io.netty.util.internal.PlatformDependent0: Java version: 8
2025-03-25 12:11:52,096 DEBUG [main] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
2025-03-25 12:11:52,096 DEBUG [main] io.netty.util.internal.PlatformDependent0: sun.misc.Unsafe.copyMemory: available
2025-03-25 12:11:52,096 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.Buffer.address: available
2025-03-25 12:11:52,096 DEBUG [main] io.netty.util.internal.PlatformDependent0: direct buffer constructor: available
2025-03-25 12:11:52,097 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.Bits.unaligned: available, true
2025-03-25 12:11:52,097 DEBUG [main] io.netty.util.internal.PlatformDependent0: jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2025-03-25 12:11:52,097 DEBUG [main] io.netty.util.internal.PlatformDependent0: java.nio.DirectByteBuffer.<init>(long, int): available
2025-03-25 12:11:52,097 DEBUG [main] io.netty.util.internal.PlatformDependent: sun.misc.Unsafe: available
2025-03-25 12:11:52,097 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.tmpdir: /data/tmp/nm-local-dir/usercache/root/appcache/application_1742904630293_0001/container_1742904630293_0001_01_000002/tmp (java.io.tmpdir)
2025-03-25 12:11:52,097 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
2025-03-25 12:11:52,097 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.maxDirectMemory: 1908932608 bytes
2025-03-25 12:11:52,097 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.uninitializedArrayAllocationThreshold: -1
2025-03-25 12:11:52,098 DEBUG [main] io.netty.util.internal.CleanerJava6: java.nio.ByteBuffer.cleaner(): available
2025-03-25 12:11:52,098 DEBUG [main] io.netty.util.internal.PlatformDependent: -Dio.netty.noPreferDirect: false
2025-03-25 12:11:52,099 DEBUG [main] io.netty.channel.nio.NioEventLoop: -Dio.netty.noKeySetOptimization: false
2025-03-25 12:11:52,099 DEBUG [main] io.netty.channel.nio.NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
2025-03-25 12:11:52,103 DEBUG [main] io.netty.util.internal.PlatformDependent: org.jctools-core.MpscChunkedArrayQueue: available
2025-03-25 12:11:52,113 DEBUG [main] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.level: simple
2025-03-25 12:11:52,113 DEBUG [main] io.netty.util.ResourceLeakDetector: -Dio.netty.leakDetection.targetRecords: 4
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 4
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 4
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.useCacheForAllThreads: true
2025-03-25 12:11:52,115 DEBUG [main] io.netty.buffer.PooledByteBufAllocator: -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2025-03-25 12:11:52,153 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Creating new connection to slave2/172.20.1.13:40591
2025-03-25 12:11:52,164 DEBUG [netty-rpc-connection-0] io.netty.channel.DefaultChannelId: -Dio.netty.processId: 1503 (auto-detected)
2025-03-25 12:11:52,177 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: -Djava.net.preferIPv4Stack: false
2025-03-25 12:11:52,177 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: -Djava.net.preferIPv6Addresses: false
2025-03-25 12:11:52,184 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtilInitializations: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2025-03-25 12:11:52,185 DEBUG [netty-rpc-connection-0] io.netty.util.NetUtil: /proc/sys/net/core/somaxconn: 4096
2025-03-25 12:11:52,185 DEBUG [netty-rpc-connection-0] io.netty.channel.DefaultChannelId: -Dio.netty.machineId: 02:42:ac:ff:fe:14:01:0b (auto-detected)
2025-03-25 12:11:52,197 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.allocator.type: pooled
2025-03-25 12:11:52,198 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 0
2025-03-25 12:11:52,198 DEBUG [netty-rpc-connection-0] io.netty.buffer.ByteBufUtil: -Dio.netty.maxThreadLocalCharBufferSize: 16384
2025-03-25 12:11:52,220 DEBUG [rpc-client-1-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkAccessible: true
2025-03-25 12:11:52,220 DEBUG [rpc-client-1-1] io.netty.buffer.AbstractByteBuf: -Dio.netty.buffer.checkBounds: true
2025-03-25 12:11:52,221 DEBUG [rpc-client-1-1] io.netty.util.ResourceLeakDetectorFactory: Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@31491a42
2025-03-25 12:11:52,232 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9] REGISTERED
2025-03-25 12:11:52,233 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9] CONNECT: slave2/172.20.1.13:40591
2025-03-25 12:11:52,234 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] ACTIVE
2025-03-25 12:11:52,234 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Connection to slave2/172.20.1.13:40591 successful, running bootstraps...
2025-03-25 12:11:52,234 INFO [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Successfully created connection to slave2/172.20.1.13:40591 after 73 ms (0 ms spent in bootstraps)
2025-03-25 12:11:52,237 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.maxCapacityPerThread: 4096
2025-03-25 12:11:52,237 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.ratio: 8
2025-03-25 12:11:52,237 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.chunkSize: 32
2025-03-25 12:11:52,237 DEBUG [netty-rpc-connection-0] io.netty.util.Recycler: -Dio.netty.recycler.blocking: false
2025-03-25 12:11:52,243 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 168]
2025-03-25 12:11:52,243 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:52,245 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] READ 68B
2025-03-25 12:11:52,252 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:52,253 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 169]
2025-03-25 12:11:52,253 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:52,255 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] READ 2048B
2025-03-25 12:11:52,257 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] READ 2331B
2025-03-25 12:11:52,278 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:52,283 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 - R:slave2/172.20.1.13:40591] CLOSE
2025-03-25 12:11:52,283 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 ! R:slave2/172.20.1.13:40591] INACTIVE
2025-03-25 12:11:52,284 DEBUG [rpc-client-1-1] org.apache.spark.network.util.NettyLogger: [id: 0xb41c70c9, L:/172.20.1.11:46548 ! R:slave2/172.20.1.13:40591] UNREGISTERED
2025-03-25 12:11:52,296 INFO [main] org.apache.spark.SecurityManager: Changing view acls to: root
2025-03-25 12:11:52,296 INFO [main] org.apache.spark.SecurityManager: Changing modify acls to: root
2025-03-25 12:11:52,296 INFO [main] org.apache.spark.SecurityManager: Changing view acls groups to: 
2025-03-25 12:11:52,297 INFO [main] org.apache.spark.SecurityManager: Changing modify acls groups to: 
2025-03-25 12:11:52,297 INFO [main] org.apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2025-03-25 12:11:52,327 DEBUG [main] org.apache.spark.SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer
2025-03-25 12:11:52,350 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Creating new connection to slave2/172.20.1.13:40591
2025-03-25 12:11:52,352 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca] REGISTERED
2025-03-25 12:11:52,352 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca] CONNECT: slave2/172.20.1.13:40591
2025-03-25 12:11:52,353 DEBUG [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Connection to slave2/172.20.1.13:40591 successful, running bootstraps...
2025-03-25 12:11:52,353 INFO [netty-rpc-connection-0] org.apache.spark.network.client.TransportClientFactory: Successfully created connection to slave2/172.20.1.13:40591 after 2 ms (0 ms spent in bootstraps)
2025-03-25 12:11:52,353 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] ACTIVE
2025-03-25 12:11:52,354 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 162]
2025-03-25 12:11:52,354 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:52,355 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ 68B
2025-03-25 12:11:52,357 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:52,382 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 164]
2025-03-25 12:11:52,382 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:52,384 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ 68B
2025-03-25 12:11:52,384 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:52,386 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 173]
2025-03-25 12:11:52,386 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:52,387 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ 68B
2025-03-25 12:11:52,387 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:52,402 INFO [main] org.apache.spark.storage.DiskBlockManager: Created local directory at /data/tmp/nm-local-dir/usercache/root/appcache/application_1742904630293_0001/blockmgr-ce251d6a-d4fd-41b8-8a01-dc0418f0053e
2025-03-25 12:11:52,405 WARN [main] org.apache.spark.util.Utils: Push-based shuffle can only be enabled when the application is submitted to run in YARN mode, with external shuffle service enabled, IO encryption disabled, and relocation of serialized objects supported.
2025-03-25 12:11:52,405 DEBUG [main] org.apache.spark.storage.DiskBlockManager: Adding shutdown hook
2025-03-25 12:11:52,407 DEBUG [main] org.apache.spark.util.ShutdownHookManager: Adding shutdown hook
2025-03-25 12:11:52,431 INFO [main] org.apache.spark.storage.memory.MemoryStore: MemoryStore started with capacity 912.3 MiB
2025-03-25 12:11:52,616 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 169]
2025-03-25 12:11:52,616 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:52,619 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ 68B
2025-03-25 12:11:52,619 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:52,638 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@slave2:40591
2025-03-25 12:11:52,666 DEBUG [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Resource profile id is: 0
2025-03-25 12:11:52,672 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-25 12:11:52,672 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: No custom resources configured for spark.executor.
2025-03-25 12:11:52,672 INFO [dispatcher-Executor] org.apache.spark.resource.ResourceUtils: ==============================================================
2025-03-25 12:11:52,673 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 168]
2025-03-25 12:11:52,673 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:52,675 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ 68B
2025-03-25 12:11:52,704 DEBUG [rpc-client-3-1] org.apache.spark.util.YarnContainerInfoHelper: Base URL for logs: http://slave0:8042/node/containerlogs/container_1742904630293_0001_01_000002/root
2025-03-25 12:11:52,728 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 1916]
2025-03-25 12:11:52,729 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:52,729 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:52,731 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ 68B
2025-03-25 12:11:52,733 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:52,734 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Successfully registered with driver
2025-03-25 12:11:52,739 INFO [dispatcher-Executor] org.apache.spark.executor.Executor: Starting executor ID 1 on host slave0
2025-03-25 12:11:52,770 DEBUG [dispatcher-Executor] org.apache.spark.network.server.TransportServer: Shuffle server started on port: 39127
2025-03-25 12:11:52,771 INFO [dispatcher-Executor] org.apache.spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39127.
2025-03-25 12:11:52,771 INFO [dispatcher-Executor] org.apache.spark.network.netty.NettyBlockTransferService: Server created on slave0:39127
2025-03-25 12:11:52,772 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-25 12:11:52,779 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, slave0, 39127, None)
2025-03-25 12:11:52,785 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 1456]
2025-03-25 12:11:52,786 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:52,788 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ 100B
2025-03-25 12:11:52,789 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:52,790 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, slave0, 39127, None)
2025-03-25 12:11:52,793 INFO [dispatcher-Executor] org.apache.spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(1, slave0, 39127, None)
2025-03-25 12:11:52,802 INFO [dispatcher-Executor] org.apache.spark.executor.Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742904630293_0001/container_1742904630293_0001_01_000002/__app__.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742904630293_0001/container_1742904630293_0001_01_000002/spark-examples_2.12-3.3.2.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742904630293_0001/container_1742904630293_0001_01_000002/__app__.jar,file:/data/tmp/nm-local-dir/usercache/root/appcache/application_1742904630293_0001/container_1742904630293_0001_01_000002/spark-examples_2.12-3.3.2.jar'
2025-03-25 12:11:52,808 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 21, bodyLength: 163]
2025-03-25 12:11:52,808 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:52,810 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ 68B
2025-03-25 12:11:52,810 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:52,833 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] WRITE: MessageWithHeader [headerLength: 13, bodyLength: 177]
2025-03-25 12:11:52,833 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] FLUSH
2025-03-25 12:11:58,361 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ 135B
2025-03-25 12:11:58,364 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] READ COMPLETE
2025-03-25 12:11:58,365 INFO [dispatcher-Executor] org.apache.spark.executor.YarnCoarseGrainedExecutorBackend: Driver commanded a shutdown
2025-03-25 12:11:58,369 WARN [CoarseGrainedExecutorBackend-stop-executor] org.apache.spark.util.Utils: Push-based shuffle can only be enabled when the application is submitted to run in YARN mode, with external shuffle service enabled, IO encryption disabled, and relocation of serialized objects supported.
2025-03-25 12:11:58,378 INFO [CoarseGrainedExecutorBackend-stop-executor] org.apache.spark.storage.memory.MemoryStore: MemoryStore cleared
2025-03-25 12:11:58,379 INFO [CoarseGrainedExecutorBackend-stop-executor] org.apache.spark.storage.BlockManager: BlockManager stopped
2025-03-25 12:11:58,380 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 - R:slave2/172.20.1.13:40591] CLOSE
2025-03-25 12:11:58,380 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 ! R:slave2/172.20.1.13:40591] INACTIVE
2025-03-25 12:11:58,380 DEBUG [rpc-client-3-1] org.apache.spark.network.util.NettyLogger: [id: 0xbc56f5ca, L:/172.20.1.11:46554 ! R:slave2/172.20.1.13:40591] UNREGISTERED
2025-03-25 12:11:58,393 INFO [shutdown-hook-0] org.apache.spark.util.ShutdownHookManager: Shutdown hook called
2025-03-25 12:11:58,394 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: Completed shutdown in 0.001 seconds; Timeouts: 0
2025-03-25 12:11:58,402 DEBUG [Thread-2] org.apache.hadoop.util.ShutdownHookManager: ShutdownHookManager completed shutdown.
